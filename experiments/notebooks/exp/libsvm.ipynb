{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/oldrain123/IMBALANCED_CLASSIFICATION/MOMs\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from experiment import run_exp\n",
    "from imblearn.datasets import fetch_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = \"cuda\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath, target_variable = '+1'):\n",
    "    \"\"\"\n",
    "    Load and preprocess the australian_scale.txt dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - filepath: str, path to the australian_scale.txt file.\n",
    "\n",
    "    Returns:\n",
    "    - X: np.ndarray, feature matrix.\n",
    "    - Y: np.ndarray, binary labels.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            label = 1 if parts[0] == target_variable else 0\n",
    "            features = [float(pair.split(':')[1]) for pair in parts[1:] if ':' in pair]\n",
    "            labels.append(label)\n",
    "            data.append(features)\n",
    "\n",
    "    max_features = max(len(row) for row in data)\n",
    "    data = [row + [0] * (max_features - len(row)) for row in data]\n",
    "\n",
    "    return np.array(data, dtype=np.float64), np.array(labels, dtype=np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/data4/oldrain123/oldrain123/dataset/LIBSVM'\n",
    "save_path = \"/data4/oldrain123/oldrain123/results/ablation_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from experiment import run_exp\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"Original\", \"SMOTE\", \"ADASYN\", \"bSMOTE\", \"ROS\", \"MWMOTE\", \"CTGAN\", \"Ours\"]\n",
    "base_models = {\n",
    "    \"SVM\": SVC(kernel='rbf', probability=True, random_state=1203),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(max_depth=6, random_state=1203),\n",
    "    \"kNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, early_stopping=True, random_state=1203),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=500, random_state=1203)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# australian\n",
    "data_name = 'australian'\n",
    "target_variable = '+1'\n",
    "australian_path = f'{data_path}/{data_name}_scale.txt'\n",
    "australian, label = load_data(australian_path, target_variable=target_variable)\n",
    "australian = pd.DataFrame(np.column_stack([australian, label]))\n",
    "\n",
    "n_epochs = 2000\n",
    "hidden_dims = [16, 32, 64, 128]\n",
    "latent_dim = 256\n",
    "lr = 0.005\n",
    "beta = 0.01\n",
    "\n",
    "# Run experiment\n",
    "final_results = run_exp(\n",
    "    data=australian, \n",
    "    cat_idx=[0, 6, 7, 12, 13], \n",
    "    methods=methods, \n",
    "    base_model=base_models, \n",
    "    device=device,\n",
    "    n_epochs=n_epochs, \n",
    "    hidden_dims=hidden_dims, \n",
    "    latent_dim=latent_dim, \n",
    "    lr=lr, \n",
    "    beta=beta,\n",
    "    data_name=data_name, \n",
    "    maj_target_name=0,\n",
    "    seed=1203, \n",
    "    visualize=True, \n",
    "    save_path=save_path\n",
    ")\n",
    "# Expecting keys like \"Original - DecisionTree\", \"SMOTE - kNN\", etc.\n",
    "res_data = {\n",
    "    \"Classifier\": [],\n",
    "    \"Method\": [],\n",
    "    \"Metric\": [],\n",
    "    \"Value\": [],\n",
    "}\n",
    "\n",
    "for key, metrics in final_results.items():\n",
    "    # Split the key into oversampling method and classifier if possible\n",
    "    if \" - \" in key:\n",
    "        method_name, clf_name = key.split(\" - \", 1)\n",
    "    else:\n",
    "        method_name, clf_name = key, \"Default\"\n",
    "    for metric, values in metrics.items():\n",
    "        avg_val = np.mean(values) if values else \"N/A\"\n",
    "        res_data[\"Classifier\"].append(clf_name)\n",
    "        res_data[\"Method\"].append(method_name)\n",
    "        res_data[\"Metric\"].append(metric)\n",
    "        res_data[\"Value\"].append(avg_val)\n",
    "\n",
    "res_df = pd.DataFrame(res_data)\n",
    "\n",
    "# Save the final results with classifier information\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "save_file = os.path.join(save_path, f\"{data_name}_results.csv\")\n",
    "res_df.to_csv(save_file, index=False)\n",
    "print(f\"\\n[Saved] Final results are saved to {save_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# breast-cancer\n",
    "data_name = 'breast-cancer'\n",
    "target_variable = '4'\n",
    "breast_path = f'{data_path}/{data_name}_scale.txt'\n",
    "breast_cancer, label = load_data(breast_path, target_variable=target_variable)\n",
    "bc = pd.DataFrame(np.column_stack([breast_cancer, label]))\n",
    "\n",
    "n_epochs = 2000\n",
    "hidden_dims = [16, 32, 64, 128]\n",
    "latent_dim = 256\n",
    "lr = 0.005\n",
    "beta = 0.001\n",
    "\n",
    "# Run experiment\n",
    "final_results = run_exp(\n",
    "    data=bc, \n",
    "    cat_idx=[], \n",
    "    methods=methods, \n",
    "    base_model=base_models, \n",
    "    device=device,\n",
    "    n_epochs=n_epochs, \n",
    "    hidden_dims=hidden_dims, \n",
    "    latent_dim=latent_dim, \n",
    "    lr=lr, \n",
    "    beta=beta,\n",
    "    data_name=data_name, \n",
    "    maj_target_name=0,\n",
    "    seed=1203, \n",
    "    visualize=True, \n",
    "    save_path=save_path\n",
    ")\n",
    "# Expecting keys like \"Original - DecisionTree\", \"SMOTE - kNN\", etc.\n",
    "res_data = {\n",
    "    \"Classifier\": [],\n",
    "    \"Method\": [],\n",
    "    \"Metric\": [],\n",
    "    \"Value\": [],\n",
    "}\n",
    "\n",
    "for key, metrics in final_results.items():\n",
    "    # Split the key into oversampling method and classifier if possible\n",
    "    if \" - \" in key:\n",
    "        method_name, clf_name = key.split(\" - \", 1)\n",
    "    else:\n",
    "        method_name, clf_name = key, \"Default\"\n",
    "    for metric, values in metrics.items():\n",
    "        avg_val = np.mean(values) if values else \"N/A\"\n",
    "        res_data[\"Classifier\"].append(clf_name)\n",
    "        res_data[\"Method\"].append(method_name)\n",
    "        res_data[\"Metric\"].append(metric)\n",
    "        res_data[\"Value\"].append(avg_val)\n",
    "\n",
    "res_df = pd.DataFrame(res_data)\n",
    "\n",
    "# Save the final results with classifier information\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "save_file = os.path.join(save_path, f\"{data_name}_results.csv\")\n",
    "res_df.to_csv(save_file, index=False)\n",
    "print(f\"\\n[Saved] Final results are saved to {save_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes\n",
    "data_name = 'diabetes'\n",
    "target_variable = '-1'\n",
    "diabetes_path = f'{data_path}/{data_name}_scale.txt'\n",
    "diabetes, label = load_data(diabetes_path)\n",
    "diabetes = pd.DataFrame(np.column_stack([diabetes, label]))\n",
    "\n",
    "n_epochs = 2000\n",
    "hidden_dims = [16, 32, 64, 128]\n",
    "latent_dim = 256\n",
    "lr = 0.005\n",
    "beta = 0.001\n",
    "\n",
    "# Run experiment\n",
    "final_results = run_exp(\n",
    "    data=diabetes, \n",
    "    cat_idx=[], \n",
    "    methods=methods, \n",
    "    base_model=base_models, \n",
    "    device=device,\n",
    "    n_epochs=n_epochs, \n",
    "    hidden_dims=hidden_dims, \n",
    "    latent_dim=latent_dim, \n",
    "    lr=lr, \n",
    "    beta=beta,\n",
    "    data_name=data_name, \n",
    "    maj_target_name=1,\n",
    "    seed=1203, \n",
    "    visualize=True, \n",
    "    save_path=save_path\n",
    ")\n",
    "# Expecting keys like \"Original - DecisionTree\", \"SMOTE - kNN\", etc.\n",
    "res_data = {\n",
    "    \"Classifier\": [],\n",
    "    \"Method\": [],\n",
    "    \"Metric\": [],\n",
    "    \"Value\": [],\n",
    "}\n",
    "\n",
    "for key, metrics in final_results.items():\n",
    "    # Split the key into oversampling method and classifier if possible\n",
    "    if \" - \" in key:\n",
    "        method_name, clf_name = key.split(\" - \", 1)\n",
    "    else:\n",
    "        method_name, clf_name = key, \"Default\"\n",
    "    for metric, values in metrics.items():\n",
    "        avg_val = np.mean(values) if values else \"N/A\"\n",
    "        res_data[\"Classifier\"].append(clf_name)\n",
    "        res_data[\"Method\"].append(method_name)\n",
    "        res_data[\"Metric\"].append(metric)\n",
    "        res_data[\"Value\"].append(avg_val)\n",
    "\n",
    "res_df = pd.DataFrame(res_data)\n",
    "\n",
    "# Save the final results with classifier information\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "save_file = os.path.join(save_path, f\"{data_name}_results.csv\")\n",
    "res_df.to_csv(save_file, index=False)\n",
    "print(f\"\\n[Saved] Final results are saved to {save_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# german\n",
    "data_name = 'german'\n",
    "target_variable = '+1'\n",
    "german_path = f'{data_path}/{data_name}_scale.txt'\n",
    "german, label = load_data(german_path)\n",
    "german = pd.DataFrame(np.column_stack([german, label]))\n",
    "\n",
    "n_epochs = 2000\n",
    "hidden_dims = [32, 64, 128, 256]\n",
    "latent_dim = 512\n",
    "lr = 0.005\n",
    "beta = 0.001\n",
    "\n",
    "# Run experiment\n",
    "final_results = run_exp(\n",
    "    data=german, \n",
    "    cat_idx=[], \n",
    "    methods=methods, \n",
    "    base_model=base_models, \n",
    "    device=device,\n",
    "    n_epochs=n_epochs, \n",
    "    hidden_dims=hidden_dims, \n",
    "    latent_dim=latent_dim, \n",
    "    lr=lr, \n",
    "    beta=beta,\n",
    "    data_name=data_name, \n",
    "    maj_target_name=0,\n",
    "    seed=1203, \n",
    "    visualize=True, \n",
    "    save_path=save_path\n",
    ")\n",
    "# Expecting keys like \"Original - DecisionTree\", \"SMOTE - kNN\", etc.\n",
    "res_data = {\n",
    "    \"Classifier\": [],\n",
    "    \"Method\": [],\n",
    "    \"Metric\": [],\n",
    "    \"Value\": [],\n",
    "}\n",
    "\n",
    "for key, metrics in final_results.items():\n",
    "    # Split the key into oversampling method and classifier if possible\n",
    "    if \" - \" in key:\n",
    "        method_name, clf_name = key.split(\" - \", 1)\n",
    "    else:\n",
    "        method_name, clf_name = key, \"Default\"\n",
    "    for metric, values in metrics.items():\n",
    "        avg_val = np.mean(values) if values else \"N/A\"\n",
    "        res_data[\"Classifier\"].append(clf_name)\n",
    "        res_data[\"Method\"].append(method_name)\n",
    "        res_data[\"Metric\"].append(metric)\n",
    "        res_data[\"Value\"].append(avg_val)\n",
    "\n",
    "res_df = pd.DataFrame(res_data)\n",
    "\n",
    "# Save the final results with classifier information\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "save_file = os.path.join(save_path, f\"{data_name}_results.csv\")\n",
    "res_df.to_csv(save_file, index=False)\n",
    "print(f\"\\n[Saved] Final results are saved to {save_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imb_clf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
