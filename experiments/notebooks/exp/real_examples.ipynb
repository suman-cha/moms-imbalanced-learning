{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/oldrain123/IMBALANCED_CLASSIFICATION/MOMs\")\n",
    "sys.path.append(\"/home/oldrain123/IMBALANCED_CLASSIFICATION/boost\")\n",
    "sys.path.append('/home/oldrain123/IMBALANCED_CLASSIFICATION/')\n",
    "sys.path.append('/home/oldrain123/IMBALANCED_CLASSIFICATION/SMOTE_variants/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef, f1_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, RandomOverSampler\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from collections import Counter\n",
    "from moms_generate import apply_transformation\n",
    "from moms_losses import MMD_est_torch\n",
    "from boost import AdaBoostClassifier, SMOTEBoost, RUSBoost, OUBoost\n",
    "from moms_utils import set_seed\n",
    "from sklearn.svm import SVC\n",
    "from SMOTE_variants.sm_variants.oversampling.mwmote import MWMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:1\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data, device, h_dim, num_layers, beta, lr, n_runs=10, n_splits=10, save_path = '/results', data_name = 'wine'):\n",
    "    \"\"\"\n",
    "    Run experiments on the provided dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pandas DataFrame with the last column as labels.\n",
    "    - n_runs: Number of repeated experiments.\n",
    "    - n_splits: Number of splits for Stratified K-Fold.\n",
    "\n",
    "    Returns:\n",
    "    - final_results: Dictionary containing averaged metrics for all methods.\n",
    "    \"\"\"\n",
    "    X = data.iloc[:, :-1].values\n",
    "    Y = np.where(data.iloc[:, -1].values == 'negative', 0, 1)  # Convert labels\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"Class distribution: {Counter(Y)}\")\n",
    "\n",
    "    # Parameters\n",
    "    n_epochs, h = 2000, 1.0\n",
    "\n",
    "    # Initialize final results storage\n",
    "    final_results = {\n",
    "        method: {\"AUC\": [], \"G-Mean\": [], \"MCC\": [], \"F1-score\": []}\n",
    "        for method in [\"AdaBoost\", \"SMOTEBoost\", \"RUSBoost\", \"OUBoost\", \"SVM\", \"SMOTE\", \"ADASYN\", \"bSMOTE\", \"ROS\", \"MWMOTE\", \"Trans(Direct)\"]\n",
    "    }\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        kf = StratifiedKFold(n_splits=n_splits, random_state=1203 + run, shuffle=True)\n",
    "        print(f\"\\nStarting experiment {run + 1}/{n_runs}\")\n",
    "        results = {\n",
    "            method: {\"AUC\": [], \"G-Mean\": [], \"MCC\": [], \"F1-score\": []}\n",
    "            for method in [\"AdaBoost\", \"SMOTEBoost\", \"RUSBoost\", \"OUBoost\", \"SVM\", \"SMOTE\", \"ADASYN\", \"bSMOTE\", \"ROS\", \"MWMOTE\", \"Trans(Direct)\"]\n",
    "        }\n",
    "\n",
    "        for fold, (train_index, test_index) in enumerate(kf.split(X, Y)):\n",
    "            # if fold < 3:\n",
    "            #     continue\n",
    "            print(f\"  Fold {fold + 1}/{n_splits} - Experiment {run + 1}/{n_runs}\")\n",
    "            seed = 1203 + fold + 10 * run\n",
    "            set_seed(seed)\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "            \n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            X_train = np.ascontiguousarray(X_train, dtype=np.float64)\n",
    "            X_test = np.ascontiguousarray(X_test, dtype=np.float64)\n",
    "\n",
    "            X_maj = X_train[Y_train == 0]\n",
    "            X_min = X_train[Y_train == 1]\n",
    "\n",
    "            input_dim = X_train.shape[1]\n",
    "\n",
    "            # Apply transformations\n",
    "            X_maj_direct, X_min_direct, X_trans_direct = apply_transformation(\n",
    "                X_maj,\n",
    "                X_min,\n",
    "                in_dim=input_dim,\n",
    "                h_dim=h_dim,\n",
    "                num_layers=num_layers,\n",
    "                loss_fn=MMD_est_torch,\n",
    "                device=device,\n",
    "                method='direct',\n",
    "                # selection=\"overlap\",\n",
    "                n_epochs=n_epochs,\n",
    "                h=h,\n",
    "                beta=beta,\n",
    "                lr=lr,\n",
    "                seed=seed,\n",
    "                batch_size=128,\n",
    "                k=3,\n",
    "                undersample=False\n",
    "            )\n",
    "\n",
    "            datasets = {\n",
    "                \"SVM\": (X_train, Y_train),\n",
    "                \"Boost\": (X_train, Y_train),\n",
    "                \"SMOTE\": SMOTE(random_state=seed).fit_resample(X_train, Y_train),\n",
    "                \"ADASYN\": ADASYN(random_state=seed).fit_resample(X_train, Y_train),\n",
    "                \"bSMOTE\": BorderlineSMOTE(random_state=seed).fit_resample(X_train, Y_train),\n",
    "                \"ROS\": RandomOverSampler(random_state=seed).fit_resample(X_train, Y_train),\n",
    "                \"MWMOTE\": MWMOTE(random_state=seed).sample(X_train, Y_train),\n",
    "                \"Trans(Direct)\": (\n",
    "                    np.vstack((X_maj_direct, X_min_direct, X_trans_direct)),\n",
    "                    np.hstack((np.zeros(len(X_maj_direct)), np.ones(len(X_min_direct) + len(X_trans_direct)))),\n",
    "                ),\n",
    "            }\n",
    "\n",
    "            for method, (X_resampled, Y_resampled) in datasets.items():\n",
    "                if method == \"Boost\":\n",
    "                    # AdaBoost\n",
    "                    model_ada = AdaBoostClassifier(\n",
    "                        DecisionTreeClassifier(max_depth=5),\n",
    "                        n_estimators=100,\n",
    "                        algorithm=\"SAMME\",\n",
    "                        learning_rate=0.1,\n",
    "                        random_state=seed,\n",
    "                    )\n",
    "                    model_ada.fit(X_resampled, Y_resampled)\n",
    "                    predictions_ada = model_ada.predict(X_test)\n",
    "                    proba_ada = model_ada.predict_proba(X_test)[:, 1]\n",
    "                    results[\"AdaBoost\"][\"AUC\"].append(roc_auc_score(Y_test, proba_ada))\n",
    "                    results[\"AdaBoost\"][\"G-Mean\"].append(\n",
    "                        np.mean(geometric_mean_score(Y_test, predictions_ada, average=None))\n",
    "                    )\n",
    "                    results[\"AdaBoost\"][\"MCC\"].append(matthews_corrcoef(Y_test, predictions_ada))\n",
    "                    results['AdaBoost']['F1-score'].append(f1_score(Y_test, predictions_ada))\n",
    "\n",
    "                    # SMOTEBoost\n",
    "                    classification_smote = SMOTEBoost(\n",
    "                        learning_rate=0.1, n_samples=5, n_estimators=100, random_state=seed\n",
    "                    )\n",
    "                    classification_smote.fit(X_resampled, Y_resampled)\n",
    "                    y_pred_smote = classification_smote.predict(X_test)\n",
    "                    proba_smote = classification_smote.predict_proba(X_test)[:, 1]\n",
    "                    results[\"SMOTEBoost\"][\"AUC\"].append(roc_auc_score(Y_test, proba_smote))\n",
    "                    results[\"SMOTEBoost\"][\"G-Mean\"].append(\n",
    "                        np.mean(geometric_mean_score(Y_test, y_pred_smote, average=None))\n",
    "                    )\n",
    "                    results[\"SMOTEBoost\"][\"MCC\"].append(matthews_corrcoef(Y_test, y_pred_smote))\n",
    "                    results['SMOTEBoost']['F1-score'].append(f1_score(Y_test, y_pred_smote))\n",
    "\n",
    "                    # RUSBoost\n",
    "                    classification_rusboost = RUSBoost(\n",
    "                        learning_rate=0.1, n_samples=5, n_estimators=100, random_state=seed\n",
    "                    )\n",
    "                    classification_rusboost.fit(X_resampled, Y_resampled)\n",
    "                    y_pred_rus = classification_rusboost.predict(X_test)\n",
    "                    proba_rus = classification_rusboost.predict_proba(X_test)[:, 1]\n",
    "                    results[\"RUSBoost\"][\"AUC\"].append(roc_auc_score(Y_test, proba_rus))\n",
    "                    results[\"RUSBoost\"][\"G-Mean\"].append(\n",
    "                        np.mean(geometric_mean_score(Y_test, y_pred_rus, average=None))\n",
    "                    )\n",
    "                    results[\"RUSBoost\"][\"MCC\"].append(matthews_corrcoef(Y_test, y_pred_rus))\n",
    "                    results['RUSBoost']['F1-score'].append(f1_score(Y_test, y_pred_rus))\n",
    "\n",
    "                    # OUBoost\n",
    "                    classification_ouboost = OUBoost(\n",
    "                        learning_rate=0.1, n_samples=5, n_estimators=100, random_state=seed\n",
    "                    )\n",
    "                    classification_ouboost.fit(X_resampled, Y_resampled)\n",
    "                    y_pred_ouboost = classification_ouboost.predict(X_test)\n",
    "                    proba_ouboost = classification_ouboost.predict_proba(X_test)[:, 1]\n",
    "                    results[\"OUBoost\"][\"AUC\"].append(roc_auc_score(Y_test, proba_ouboost))\n",
    "                    results[\"OUBoost\"][\"G-Mean\"].append(\n",
    "                        np.mean(geometric_mean_score(Y_test, y_pred_ouboost, average=None))\n",
    "                    )\n",
    "                    results[\"OUBoost\"][\"MCC\"].append(matthews_corrcoef(Y_test, y_pred_ouboost))\n",
    "                    results['OUBoost']['F1-score'].append(f1_score(Y_test, y_pred_ouboost))\n",
    "                else:\n",
    "                    svm = SVC(kernel='rbf', probability=True, random_state=seed)\n",
    "                    svm.fit(X_resampled, Y_resampled)\n",
    "\n",
    "                    # Predict on the test data\n",
    "                    y_pred = svm.predict(X_test)\n",
    "                    y_pred_prob = svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "                    # xgb = XGBClassifier(n_estimators=100, max_depth=5, random_state=1203)\n",
    "                    # xgb.fit(X_resampled, Y_resampled)\n",
    "                    # y_pred = xgb.predict(X_test)\n",
    "                    # y_pred_prob = xgb.predict_proba(X_test)[:, 1]\n",
    "                    # Calculate performance metrics\n",
    "                    results[method][\"AUC\"].append(roc_auc_score(Y_test, y_pred_prob))\n",
    "                    results[method][\"G-Mean\"].append(\n",
    "                        np.mean(geometric_mean_score(Y_test, y_pred, average=None))\n",
    "                    )\n",
    "                    results[method][\"MCC\"].append(matthews_corrcoef(Y_test, y_pred))\n",
    "                    results[method][\"F1-score\"].append(f1_score(Y_test, y_pred))\n",
    "\n",
    "            # Print fold-wise results for monitoring\n",
    "            print(f\"    Intermediate Fold Results for Fold {fold + 1}:\")\n",
    "            for method, metrics in results.items():\n",
    "                print(f\"      {method}: AUC = {np.mean(metrics['AUC']):.4f}, \"\n",
    "                      f\"G-Mean = {np.mean(metrics['G-Mean']):.4f}, \"\n",
    "                      f\"MCC = {np.mean(metrics['MCC']):.4f}, \"\n",
    "                      f\"F1-score = {np.mean(metrics['F1-score']):.4f}\")\n",
    "\n",
    "        # Aggregate results across folds for this experiment\n",
    "        for method, metrics in results.items():\n",
    "            for metric, values in metrics.items():\n",
    "                final_results[method][metric].append(np.round(np.mean(values), 4))\n",
    "\n",
    "    # Print final averaged results\n",
    "    print(\"\\nFinal Averaged Results Across Experiments:\")\n",
    "    for method, metrics in final_results.items():\n",
    "        print(f\"  {method}:\")\n",
    "        for metric, values in metrics.items():\n",
    "            print(f\"    {metric}: {np.mean(values):.4f}\")\n",
    "\n",
    "    # Convert final_results to a pandas DataFrame\n",
    "    result_data = {\n",
    "        \"Method\": [],\n",
    "        \"Metric\": [],\n",
    "        \"Value\": [],\n",
    "    }\n",
    "\n",
    "    for method, metrics in final_results.items():\n",
    "        for metric, values in metrics.items():\n",
    "            avg_value = np.mean(values) if values else \"N/A\"\n",
    "            result_data[\"Method\"].append(method)\n",
    "            result_data[\"Metric\"].append(metric)\n",
    "            result_data[\"Value\"].append(avg_value)\n",
    "\n",
    "    results_df = pd.DataFrame(result_data)\n",
    "\n",
    "    # Save results as CSV\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    save_file = os.path.join(save_path, f\"{data_name}_final_results.csv\")\n",
    "    results_df.to_csv(save_file, index=False)\n",
    "    print(f\"\\nFinal results saved to {save_file}\")\n",
    "    \n",
    "    return final_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save path \n",
    "data_path = \"/data4/oldrain123/oldrain123/dataset/\"\n",
    "save_path = \"/data4/oldrain123/oldrain123/results/real_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (767, 8)\n",
      "Class distribution: Counter({np.int64(0): 500, np.int64(1): 267})\n",
      "\n",
      "Starting experiment 1/10\n",
      "  Fold 1/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.46145, Reg Loss: 0.17139\n",
      "Epoch 200/2000, Avg Loss: 0.41218, Reg Loss: 0.16937\n",
      "Epoch 300/2000, Avg Loss: 0.39246, Reg Loss: 0.17105\n",
      "Epoch 400/2000, Avg Loss: 0.37651, Reg Loss: 0.17399\n",
      "Epoch 500/2000, Avg Loss: 0.36113, Reg Loss: 0.17034\n",
      "Epoch 600/2000, Avg Loss: 0.43490, Reg Loss: 0.18842\n",
      "Epoch 700/2000, Avg Loss: 0.33712, Reg Loss: 0.17302\n",
      "Epoch 800/2000, Avg Loss: 0.32110, Reg Loss: 0.16783\n",
      "Epoch 900/2000, Avg Loss: 0.31151, Reg Loss: 0.16752\n",
      "Epoch 1000/2000, Avg Loss: 0.30176, Reg Loss: 0.16772\n",
      "Epoch 1100/2000, Avg Loss: 0.28856, Reg Loss: 0.16521\n",
      "Epoch 1200/2000, Avg Loss: 0.28817, Reg Loss: 0.16394\n",
      "Epoch 1300/2000, Avg Loss: 0.28428, Reg Loss: 0.16517\n",
      "Epoch 1400/2000, Avg Loss: 0.26735, Reg Loss: 0.16300\n",
      "Epoch 1500/2000, Avg Loss: 0.26442, Reg Loss: 0.16165\n",
      "Epoch 1600/2000, Avg Loss: 0.26801, Reg Loss: 0.16093\n",
      "Epoch 1700/2000, Avg Loss: 0.25813, Reg Loss: 0.15791\n",
      "Epoch 1800/2000, Avg Loss: 0.25731, Reg Loss: 0.15771\n",
      "Epoch 1900/2000, Avg Loss: 0.28217, Reg Loss: 0.16068\n",
      "Epoch 2000/2000, Avg Loss: 0.25268, Reg Loss: 0.15790\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.7533, G-Mean = 0.6360, MCC = 0.3042, F1-score = 0.5385\n",
      "      SMOTEBoost: AUC = 0.8630, G-Mean = 0.7688, MCC = 0.5437, F1-score = 0.7037\n",
      "      RUSBoost: AUC = 0.6800, G-Mean = 0.4422, MCC = 0.1347, F1-score = 0.5333\n",
      "      OUBoost: AUC = 0.8552, G-Mean = 0.7483, MCC = 0.5112, F1-score = 0.6792\n",
      "      SVM: AUC = 0.8622, G-Mean = 0.7221, MCC = 0.4992, F1-score = 0.6531\n",
      "      SMOTE: AUC = 0.8185, G-Mean = 0.7587, MCC = 0.4975, F1-score = 0.6885\n",
      "      ADASYN: AUC = 0.8393, G-Mean = 0.7765, MCC = 0.5317, F1-score = 0.7097\n",
      "      bSMOTE: AUC = 0.8259, G-Mean = 0.7552, MCC = 0.4917, F1-score = 0.6875\n",
      "      ROS: AUC = 0.8548, G-Mean = 0.7503, MCC = 0.4848, F1-score = 0.6780\n",
      "      MWMOTE: AUC = 0.8422, G-Mean = 0.7611, MCC = 0.5076, F1-score = 0.6970\n",
      "      Trans(Direct): AUC = 0.8630, G-Mean = 0.7659, MCC = 0.5115, F1-score = 0.6984\n",
      "  Fold 2/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.50379, Reg Loss: 0.15528\n",
      "Epoch 200/2000, Avg Loss: 0.43697, Reg Loss: 0.15565\n",
      "Epoch 300/2000, Avg Loss: 0.37467, Reg Loss: 0.15186\n",
      "Epoch 400/2000, Avg Loss: 0.33862, Reg Loss: 0.14868\n",
      "Epoch 500/2000, Avg Loss: 0.32072, Reg Loss: 0.14871\n",
      "Epoch 600/2000, Avg Loss: 0.31433, Reg Loss: 0.15025\n",
      "Epoch 700/2000, Avg Loss: 0.30656, Reg Loss: 0.14770\n",
      "Epoch 800/2000, Avg Loss: 0.29390, Reg Loss: 0.14895\n",
      "Epoch 900/2000, Avg Loss: 0.30489, Reg Loss: 0.15351\n",
      "Epoch 1000/2000, Avg Loss: 0.29338, Reg Loss: 0.14982\n",
      "Epoch 1100/2000, Avg Loss: 0.28638, Reg Loss: 0.14813\n",
      "Epoch 1200/2000, Avg Loss: 0.27825, Reg Loss: 0.14726\n",
      "Epoch 1300/2000, Avg Loss: 0.27323, Reg Loss: 0.14647\n",
      "Epoch 1400/2000, Avg Loss: 0.27109, Reg Loss: 0.14544\n",
      "Epoch 1500/2000, Avg Loss: 0.26322, Reg Loss: 0.14521\n",
      "Epoch 1600/2000, Avg Loss: 0.26169, Reg Loss: 0.14413\n",
      "Epoch 1700/2000, Avg Loss: 0.25660, Reg Loss: 0.14247\n",
      "Epoch 1800/2000, Avg Loss: 0.25596, Reg Loss: 0.14180\n",
      "Epoch 1900/2000, Avg Loss: 0.25376, Reg Loss: 0.14200\n",
      "Epoch 2000/2000, Avg Loss: 0.26205, Reg Loss: 0.14216\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.7926, G-Mean = 0.7024, MCC = 0.4240, F1-score = 0.6211\n",
      "      SMOTEBoost: AUC = 0.8417, G-Mean = 0.7541, MCC = 0.5152, F1-score = 0.6852\n",
      "      RUSBoost: AUC = 0.6998, G-Mean = 0.4950, MCC = 0.2481, F1-score = 0.5700\n",
      "      OUBoost: AUC = 0.8422, G-Mean = 0.7378, MCC = 0.4949, F1-score = 0.6665\n",
      "      SVM: AUC = 0.8600, G-Mean = 0.7440, MCC = 0.5312, F1-score = 0.6795\n",
      "      SMOTE: AUC = 0.8311, G-Mean = 0.7688, MCC = 0.5188, F1-score = 0.7002\n",
      "      ADASYN: AUC = 0.8367, G-Mean = 0.7906, MCC = 0.5590, F1-score = 0.7258\n",
      "      bSMOTE: AUC = 0.8263, G-Mean = 0.7939, MCC = 0.5663, F1-score = 0.7308\n",
      "      ROS: AUC = 0.8533, G-Mean = 0.7686, MCC = 0.5186, F1-score = 0.6996\n",
      "      MWMOTE: AUC = 0.8363, G-Mean = 0.8022, MCC = 0.5848, F1-score = 0.7419\n",
      "      Trans(Direct): AUC = 0.8581, G-Mean = 0.7905, MCC = 0.5593, F1-score = 0.7263\n",
      "  Fold 3/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.50500, Reg Loss: 0.15867\n",
      "Epoch 200/2000, Avg Loss: 0.47364, Reg Loss: 0.16260\n",
      "Epoch 300/2000, Avg Loss: 0.45555, Reg Loss: 0.16412\n",
      "Epoch 400/2000, Avg Loss: 0.43486, Reg Loss: 0.16196\n",
      "Epoch 500/2000, Avg Loss: 0.40366, Reg Loss: 0.16256\n",
      "Epoch 600/2000, Avg Loss: 0.35444, Reg Loss: 0.15670\n",
      "Epoch 700/2000, Avg Loss: 0.34147, Reg Loss: 0.15964\n",
      "Epoch 800/2000, Avg Loss: 0.32556, Reg Loss: 0.15796\n",
      "Epoch 900/2000, Avg Loss: 0.34012, Reg Loss: 0.15808\n",
      "Epoch 1000/2000, Avg Loss: 0.31569, Reg Loss: 0.15600\n",
      "Epoch 1100/2000, Avg Loss: 0.31462, Reg Loss: 0.15739\n",
      "Epoch 1200/2000, Avg Loss: 0.30350, Reg Loss: 0.15699\n",
      "Epoch 1300/2000, Avg Loss: 0.29389, Reg Loss: 0.15641\n",
      "Epoch 1400/2000, Avg Loss: 0.29158, Reg Loss: 0.15456\n",
      "Epoch 1500/2000, Avg Loss: 0.29310, Reg Loss: 0.15425\n",
      "Epoch 1600/2000, Avg Loss: 0.29200, Reg Loss: 0.15336\n",
      "Epoch 1700/2000, Avg Loss: 0.29603, Reg Loss: 0.15564\n",
      "Epoch 1800/2000, Avg Loss: 0.29086, Reg Loss: 0.15475\n",
      "Epoch 1900/2000, Avg Loss: 0.28911, Reg Loss: 0.15420\n",
      "Epoch 2000/2000, Avg Loss: 0.34863, Reg Loss: 0.16733\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.8249, G-Mean = 0.7265, MCC = 0.4796, F1-score = 0.6541\n",
      "      SMOTEBoost: AUC = 0.8446, G-Mean = 0.7462, MCC = 0.5194, F1-score = 0.6790\n",
      "      RUSBoost: AUC = 0.7441, G-Mean = 0.5683, MCC = 0.3101, F1-score = 0.5991\n",
      "      OUBoost: AUC = 0.8528, G-Mean = 0.7302, MCC = 0.5054, F1-score = 0.6618\n",
      "      SVM: AUC = 0.8615, G-Mean = 0.7525, MCC = 0.5607, F1-score = 0.6941\n",
      "      SMOTE: AUC = 0.8412, G-Mean = 0.7816, MCC = 0.5443, F1-score = 0.7154\n",
      "      ADASYN: AUC = 0.8440, G-Mean = 0.7894, MCC = 0.5568, F1-score = 0.7243\n",
      "      bSMOTE: AUC = 0.8353, G-Mean = 0.7975, MCC = 0.5730, F1-score = 0.7345\n",
      "      ROS: AUC = 0.8531, G-Mean = 0.7625, MCC = 0.5111, F1-score = 0.6926\n",
      "      MWMOTE: AUC = 0.8398, G-Mean = 0.7914, MCC = 0.5662, F1-score = 0.7285\n",
      "      Trans(Direct): AUC = 0.8583, G-Mean = 0.7867, MCC = 0.5529, F1-score = 0.7215\n",
      "  Fold 4/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.42752, Reg Loss: 0.15939\n",
      "Epoch 200/2000, Avg Loss: 0.40221, Reg Loss: 0.15719\n",
      "Epoch 300/2000, Avg Loss: 0.39648, Reg Loss: 0.16109\n",
      "Epoch 400/2000, Avg Loss: 0.39920, Reg Loss: 0.16032\n",
      "Epoch 500/2000, Avg Loss: 0.40721, Reg Loss: 0.16907\n",
      "Epoch 600/2000, Avg Loss: 0.33430, Reg Loss: 0.17191\n",
      "Epoch 700/2000, Avg Loss: 0.29619, Reg Loss: 0.16204\n",
      "Epoch 800/2000, Avg Loss: 0.29178, Reg Loss: 0.15854\n",
      "Epoch 900/2000, Avg Loss: 0.25986, Reg Loss: 0.15526\n",
      "Epoch 1000/2000, Avg Loss: 0.24831, Reg Loss: 0.15591\n",
      "Epoch 1100/2000, Avg Loss: 0.24359, Reg Loss: 0.15624\n",
      "Epoch 1200/2000, Avg Loss: 0.24611, Reg Loss: 0.15576\n",
      "Epoch 1300/2000, Avg Loss: 0.23694, Reg Loss: 0.15409\n",
      "Epoch 1400/2000, Avg Loss: 0.24020, Reg Loss: 0.15428\n",
      "Epoch 1500/2000, Avg Loss: 0.26591, Reg Loss: 0.15678\n",
      "Epoch 1600/2000, Avg Loss: 0.24219, Reg Loss: 0.15332\n",
      "Epoch 1700/2000, Avg Loss: 0.23365, Reg Loss: 0.15014\n",
      "Epoch 1800/2000, Avg Loss: 0.23142, Reg Loss: 0.14803\n",
      "Epoch 1900/2000, Avg Loss: 0.22870, Reg Loss: 0.14680\n",
      "Epoch 2000/2000, Avg Loss: 0.22651, Reg Loss: 0.14494\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.8028, G-Mean = 0.6911, MCC = 0.4281, F1-score = 0.6101\n",
      "      SMOTEBoost: AUC = 0.8040, G-Mean = 0.7110, MCC = 0.4417, F1-score = 0.6364\n",
      "      RUSBoost: AUC = 0.7178, G-Mean = 0.5623, MCC = 0.2547, F1-score = 0.5670\n",
      "      OUBoost: AUC = 0.8135, G-Mean = 0.7004, MCC = 0.4382, F1-score = 0.6236\n",
      "      SVM: AUC = 0.8391, G-Mean = 0.6951, MCC = 0.4638, F1-score = 0.6206\n",
      "      SMOTE: AUC = 0.8289, G-Mean = 0.7529, MCC = 0.4988, F1-score = 0.6808\n",
      "      ADASYN: AUC = 0.8276, G-Mean = 0.7566, MCC = 0.5022, F1-score = 0.6847\n",
      "      bSMOTE: AUC = 0.8227, G-Mean = 0.7606, MCC = 0.5086, F1-score = 0.6898\n",
      "      ROS: AUC = 0.8365, G-Mean = 0.7406, MCC = 0.4800, F1-score = 0.6665\n",
      "      MWMOTE: AUC = 0.8222, G-Mean = 0.7602, MCC = 0.5153, F1-score = 0.6906\n",
      "      Trans(Direct): AUC = 0.8367, G-Mean = 0.7652, MCC = 0.5163, F1-score = 0.6956\n",
      "  Fold 5/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.51946, Reg Loss: 0.16132\n",
      "Epoch 200/2000, Avg Loss: 0.47325, Reg Loss: 0.15614\n",
      "Epoch 300/2000, Avg Loss: 0.40565, Reg Loss: 0.15767\n",
      "Epoch 400/2000, Avg Loss: 0.37190, Reg Loss: 0.15630\n",
      "Epoch 500/2000, Avg Loss: 0.36388, Reg Loss: 0.15686\n",
      "Epoch 600/2000, Avg Loss: 0.31956, Reg Loss: 0.15509\n",
      "Epoch 700/2000, Avg Loss: 0.30943, Reg Loss: 0.15298\n",
      "Epoch 800/2000, Avg Loss: 0.30418, Reg Loss: 0.15081\n",
      "Epoch 900/2000, Avg Loss: 0.30253, Reg Loss: 0.15000\n",
      "Epoch 1000/2000, Avg Loss: 0.29804, Reg Loss: 0.14771\n",
      "Epoch 1100/2000, Avg Loss: 0.30329, Reg Loss: 0.14831\n",
      "Epoch 1200/2000, Avg Loss: 0.30223, Reg Loss: 0.14792\n",
      "Epoch 1300/2000, Avg Loss: 0.29559, Reg Loss: 0.14653\n",
      "Epoch 1400/2000, Avg Loss: 0.30680, Reg Loss: 0.14665\n",
      "Epoch 1500/2000, Avg Loss: 0.29528, Reg Loss: 0.14779\n",
      "Epoch 1600/2000, Avg Loss: 0.30818, Reg Loss: 0.14778\n",
      "Epoch 1700/2000, Avg Loss: 0.28792, Reg Loss: 0.14497\n",
      "Epoch 1800/2000, Avg Loss: 0.28574, Reg Loss: 0.14433\n",
      "Epoch 1900/2000, Avg Loss: 0.28244, Reg Loss: 0.14316\n",
      "Epoch 2000/2000, Avg Loss: 0.28715, Reg Loss: 0.14594\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.8110, G-Mean = 0.6816, MCC = 0.4168, F1-score = 0.5987\n",
      "      SMOTEBoost: AUC = 0.7980, G-Mean = 0.7108, MCC = 0.4393, F1-score = 0.6350\n",
      "      RUSBoost: AUC = 0.7113, G-Mean = 0.5403, MCC = 0.2254, F1-score = 0.5581\n",
      "      OUBoost: AUC = 0.8093, G-Mean = 0.6985, MCC = 0.4383, F1-score = 0.6213\n",
      "      SVM: AUC = 0.8366, G-Mean = 0.6728, MCC = 0.4429, F1-score = 0.5940\n",
      "      SMOTE: AUC = 0.8304, G-Mean = 0.7524, MCC = 0.4983, F1-score = 0.6803\n",
      "      ADASYN: AUC = 0.8274, G-Mean = 0.7573, MCC = 0.5031, F1-score = 0.6857\n",
      "      bSMOTE: AUC = 0.8251, G-Mean = 0.7662, MCC = 0.5194, F1-score = 0.6967\n",
      "      ROS: AUC = 0.8401, G-Mean = 0.7484, MCC = 0.4945, F1-score = 0.6761\n",
      "      MWMOTE: AUC = 0.8267, G-Mean = 0.7601, MCC = 0.5161, F1-score = 0.6907\n",
      "      Trans(Direct): AUC = 0.8347, G-Mean = 0.7603, MCC = 0.5077, F1-score = 0.6898\n",
      "  Fold 6/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.53569, Reg Loss: 0.15896\n",
      "Epoch 200/2000, Avg Loss: 0.45701, Reg Loss: 0.15605\n",
      "Epoch 300/2000, Avg Loss: 0.39263, Reg Loss: 0.15489\n",
      "Epoch 400/2000, Avg Loss: 0.39025, Reg Loss: 0.15924\n",
      "Epoch 500/2000, Avg Loss: 0.38778, Reg Loss: 0.15594\n",
      "Epoch 600/2000, Avg Loss: 0.34295, Reg Loss: 0.15481\n",
      "Epoch 700/2000, Avg Loss: 0.31878, Reg Loss: 0.15440\n",
      "Epoch 800/2000, Avg Loss: 0.30721, Reg Loss: 0.15199\n",
      "Epoch 900/2000, Avg Loss: 0.29903, Reg Loss: 0.15257\n",
      "Epoch 1000/2000, Avg Loss: 0.29343, Reg Loss: 0.15031\n",
      "Epoch 1100/2000, Avg Loss: 0.27826, Reg Loss: 0.15069\n",
      "Epoch 1200/2000, Avg Loss: 0.27716, Reg Loss: 0.15007\n",
      "Epoch 1300/2000, Avg Loss: 0.26906, Reg Loss: 0.15031\n",
      "Epoch 1400/2000, Avg Loss: 0.25899, Reg Loss: 0.14903\n",
      "Epoch 1500/2000, Avg Loss: 0.26370, Reg Loss: 0.14995\n",
      "Epoch 1600/2000, Avg Loss: 0.26276, Reg Loss: 0.14797\n",
      "Epoch 1700/2000, Avg Loss: 0.24482, Reg Loss: 0.14601\n",
      "Epoch 1800/2000, Avg Loss: 0.23523, Reg Loss: 0.14484\n",
      "Epoch 1900/2000, Avg Loss: 0.22697, Reg Loss: 0.14210\n",
      "Epoch 2000/2000, Avg Loss: 0.22260, Reg Loss: 0.14252\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.8173, G-Mean = 0.6930, MCC = 0.4300, F1-score = 0.6120\n",
      "      SMOTEBoost: AUC = 0.8088, G-Mean = 0.7269, MCC = 0.4653, F1-score = 0.6535\n",
      "      RUSBoost: AUC = 0.7335, G-Mean = 0.5474, MCC = 0.2530, F1-score = 0.5685\n",
      "      OUBoost: AUC = 0.8196, G-Mean = 0.7167, MCC = 0.4645, F1-score = 0.6421\n",
      "      SVM: AUC = 0.8427, G-Mean = 0.6952, MCC = 0.4734, F1-score = 0.6208\n",
      "      SMOTE: AUC = 0.8333, G-Mean = 0.7470, MCC = 0.4856, F1-score = 0.6745\n",
      "      ADASYN: AUC = 0.8283, G-Mean = 0.7495, MCC = 0.4886, F1-score = 0.6793\n",
      "      bSMOTE: AUC = 0.8251, G-Mean = 0.7596, MCC = 0.5082, F1-score = 0.6917\n",
      "      ROS: AUC = 0.8431, G-Mean = 0.7437, MCC = 0.4825, F1-score = 0.6709\n",
      "      MWMOTE: AUC = 0.8293, G-Mean = 0.7571, MCC = 0.5116, F1-score = 0.6899\n",
      "      Trans(Direct): AUC = 0.8401, G-Mean = 0.7595, MCC = 0.5050, F1-score = 0.6895\n",
      "  Fold 7/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.52172, Reg Loss: 0.16882\n",
      "Epoch 200/2000, Avg Loss: 0.43405, Reg Loss: 0.17822\n",
      "Epoch 300/2000, Avg Loss: 0.38622, Reg Loss: 0.17363\n",
      "Epoch 400/2000, Avg Loss: 0.34510, Reg Loss: 0.17102\n",
      "Epoch 500/2000, Avg Loss: 0.33028, Reg Loss: 0.16981\n",
      "Epoch 600/2000, Avg Loss: 0.32241, Reg Loss: 0.16518\n",
      "Epoch 700/2000, Avg Loss: 0.31532, Reg Loss: 0.16840\n",
      "Epoch 800/2000, Avg Loss: 0.26854, Reg Loss: 0.16650\n",
      "Epoch 900/2000, Avg Loss: 0.27481, Reg Loss: 0.16435\n",
      "Epoch 1000/2000, Avg Loss: 0.26101, Reg Loss: 0.15701\n",
      "Epoch 1100/2000, Avg Loss: 0.25397, Reg Loss: 0.15619\n",
      "Epoch 1200/2000, Avg Loss: 0.25064, Reg Loss: 0.15394\n",
      "Epoch 1300/2000, Avg Loss: 0.25811, Reg Loss: 0.15492\n",
      "Epoch 1400/2000, Avg Loss: 0.24795, Reg Loss: 0.15357\n",
      "Epoch 1500/2000, Avg Loss: 0.24612, Reg Loss: 0.15266\n",
      "Epoch 1600/2000, Avg Loss: 0.24611, Reg Loss: 0.15195\n",
      "Epoch 1700/2000, Avg Loss: 0.24585, Reg Loss: 0.15157\n",
      "Epoch 1800/2000, Avg Loss: 0.27340, Reg Loss: 0.15608\n",
      "Epoch 1900/2000, Avg Loss: 0.24361, Reg Loss: 0.15213\n",
      "Epoch 2000/2000, Avg Loss: 0.24762, Reg Loss: 0.15177\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.8130, G-Mean = 0.6998, MCC = 0.4348, F1-score = 0.6198\n",
      "      SMOTEBoost: AUC = 0.8035, G-Mean = 0.7181, MCC = 0.4508, F1-score = 0.6489\n",
      "      RUSBoost: AUC = 0.7298, G-Mean = 0.5263, MCC = 0.2298, F1-score = 0.5619\n",
      "      OUBoost: AUC = 0.8140, G-Mean = 0.7119, MCC = 0.4498, F1-score = 0.6386\n",
      "      SVM: AUC = 0.8310, G-Mean = 0.6899, MCC = 0.4542, F1-score = 0.6130\n",
      "      SMOTE: AUC = 0.8221, G-Mean = 0.7339, MCC = 0.4601, F1-score = 0.6621\n",
      "      ADASYN: AUC = 0.8172, G-Mean = 0.7390, MCC = 0.4704, F1-score = 0.6708\n",
      "      bSMOTE: AUC = 0.8143, G-Mean = 0.7444, MCC = 0.4851, F1-score = 0.6805\n",
      "      ROS: AUC = 0.8307, G-Mean = 0.7302, MCC = 0.4549, F1-score = 0.6573\n",
      "      MWMOTE: AUC = 0.8153, G-Mean = 0.7393, MCC = 0.4770, F1-score = 0.6729\n",
      "      Trans(Direct): AUC = 0.8279, G-Mean = 0.7457, MCC = 0.4819, F1-score = 0.6783\n",
      "  Fold 8/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.47557, Reg Loss: 0.16551\n",
      "Epoch 200/2000, Avg Loss: 0.45741, Reg Loss: 0.16821\n",
      "Epoch 300/2000, Avg Loss: 0.40892, Reg Loss: 0.16603\n",
      "Epoch 400/2000, Avg Loss: 0.37690, Reg Loss: 0.16251\n",
      "Epoch 500/2000, Avg Loss: 0.34537, Reg Loss: 0.16197\n",
      "Epoch 600/2000, Avg Loss: 0.33214, Reg Loss: 0.16184\n",
      "Epoch 700/2000, Avg Loss: 0.32722, Reg Loss: 0.16045\n",
      "Epoch 800/2000, Avg Loss: 0.31543, Reg Loss: 0.15900\n",
      "Epoch 900/2000, Avg Loss: 0.32866, Reg Loss: 0.15871\n",
      "Epoch 1000/2000, Avg Loss: 0.30933, Reg Loss: 0.15840\n",
      "Epoch 1100/2000, Avg Loss: 0.29987, Reg Loss: 0.15878\n",
      "Epoch 1200/2000, Avg Loss: 0.29025, Reg Loss: 0.15794\n",
      "Epoch 1300/2000, Avg Loss: 0.28357, Reg Loss: 0.15693\n",
      "Epoch 1400/2000, Avg Loss: 0.34675, Reg Loss: 0.15731\n",
      "Epoch 1500/2000, Avg Loss: 0.28736, Reg Loss: 0.15846\n",
      "Epoch 1600/2000, Avg Loss: 0.28271, Reg Loss: 0.15724\n",
      "Epoch 1700/2000, Avg Loss: 0.29029, Reg Loss: 0.15775\n",
      "Epoch 1800/2000, Avg Loss: 0.28290, Reg Loss: 0.15644\n",
      "Epoch 1900/2000, Avg Loss: 0.27740, Reg Loss: 0.15614\n",
      "Epoch 2000/2000, Avg Loss: 0.27950, Reg Loss: 0.15682\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.8083, G-Mean = 0.7014, MCC = 0.4411, F1-score = 0.6221\n",
      "      SMOTEBoost: AUC = 0.8036, G-Mean = 0.7237, MCC = 0.4610, F1-score = 0.6544\n",
      "      RUSBoost: AUC = 0.7241, G-Mean = 0.5281, MCC = 0.2173, F1-score = 0.5550\n",
      "      OUBoost: AUC = 0.8108, G-Mean = 0.7117, MCC = 0.4485, F1-score = 0.6372\n",
      "      SVM: AUC = 0.8241, G-Mean = 0.6857, MCC = 0.4459, F1-score = 0.6070\n",
      "      SMOTE: AUC = 0.8174, G-Mean = 0.7314, MCC = 0.4559, F1-score = 0.6581\n",
      "      ADASYN: AUC = 0.8112, G-Mean = 0.7347, MCC = 0.4621, F1-score = 0.6642\n",
      "      bSMOTE: AUC = 0.8083, G-Mean = 0.7368, MCC = 0.4706, F1-score = 0.6695\n",
      "      ROS: AUC = 0.8250, G-Mean = 0.7259, MCC = 0.4459, F1-score = 0.6511\n",
      "      MWMOTE: AUC = 0.8094, G-Mean = 0.7269, MCC = 0.4547, F1-score = 0.6561\n",
      "      Trans(Direct): AUC = 0.8231, G-Mean = 0.7418, MCC = 0.4750, F1-score = 0.6722\n",
      "  Fold 9/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.52533, Reg Loss: 0.15414\n",
      "Epoch 200/2000, Avg Loss: 0.49205, Reg Loss: 0.15405\n",
      "Epoch 300/2000, Avg Loss: 0.44857, Reg Loss: 0.15404\n",
      "Epoch 400/2000, Avg Loss: 0.43921, Reg Loss: 0.15714\n",
      "Epoch 500/2000, Avg Loss: 0.41867, Reg Loss: 0.15575\n",
      "Epoch 600/2000, Avg Loss: 0.38172, Reg Loss: 0.15822\n",
      "Epoch 700/2000, Avg Loss: 0.39565, Reg Loss: 0.15611\n",
      "Epoch 800/2000, Avg Loss: 0.33149, Reg Loss: 0.15861\n",
      "Epoch 900/2000, Avg Loss: 0.30730, Reg Loss: 0.15712\n",
      "Epoch 1000/2000, Avg Loss: 0.30113, Reg Loss: 0.15600\n",
      "Epoch 1100/2000, Avg Loss: 0.34088, Reg Loss: 0.15648\n",
      "Epoch 1200/2000, Avg Loss: 0.30144, Reg Loss: 0.15541\n",
      "Epoch 1300/2000, Avg Loss: 0.28733, Reg Loss: 0.15346\n",
      "Epoch 1400/2000, Avg Loss: 0.28222, Reg Loss: 0.15271\n",
      "Epoch 1500/2000, Avg Loss: 0.28442, Reg Loss: 0.15203\n",
      "Epoch 1600/2000, Avg Loss: 0.29345, Reg Loss: 0.15130\n",
      "Epoch 1700/2000, Avg Loss: 0.26860, Reg Loss: 0.14929\n",
      "Epoch 1800/2000, Avg Loss: 0.26731, Reg Loss: 0.14976\n",
      "Epoch 1900/2000, Avg Loss: 0.26315, Reg Loss: 0.14923\n",
      "Epoch 2000/2000, Avg Loss: 0.24836, Reg Loss: 0.14672\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.8141, G-Mean = 0.7033, MCC = 0.4437, F1-score = 0.6241\n",
      "      SMOTEBoost: AUC = 0.8102, G-Mean = 0.7303, MCC = 0.4701, F1-score = 0.6607\n",
      "      RUSBoost: AUC = 0.7315, G-Mean = 0.5384, MCC = 0.2358, F1-score = 0.5619\n",
      "      OUBoost: AUC = 0.8172, G-Mean = 0.7197, MCC = 0.4615, F1-score = 0.6460\n",
      "      SVM: AUC = 0.8245, G-Mean = 0.6811, MCC = 0.4421, F1-score = 0.6016\n",
      "      SMOTE: AUC = 0.8190, G-Mean = 0.7340, MCC = 0.4594, F1-score = 0.6603\n",
      "      ADASYN: AUC = 0.8136, G-Mean = 0.7378, MCC = 0.4666, F1-score = 0.6669\n",
      "      bSMOTE: AUC = 0.8115, G-Mean = 0.7397, MCC = 0.4741, F1-score = 0.6716\n",
      "      ROS: AUC = 0.8261, G-Mean = 0.7281, MCC = 0.4490, F1-score = 0.6528\n",
      "      MWMOTE: AUC = 0.8105, G-Mean = 0.7256, MCC = 0.4506, F1-score = 0.6534\n",
      "      Trans(Direct): AUC = 0.8225, G-Mean = 0.7388, MCC = 0.4679, F1-score = 0.6679\n",
      "  Fold 10/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.50225, Reg Loss: 0.14828\n",
      "Epoch 200/2000, Avg Loss: 0.45407, Reg Loss: 0.15367\n",
      "Epoch 300/2000, Avg Loss: 0.41051, Reg Loss: 0.15284\n",
      "Epoch 400/2000, Avg Loss: 0.40022, Reg Loss: 0.15247\n",
      "Epoch 500/2000, Avg Loss: 0.39570, Reg Loss: 0.15581\n",
      "Epoch 600/2000, Avg Loss: 0.35532, Reg Loss: 0.15245\n",
      "Epoch 700/2000, Avg Loss: 0.33629, Reg Loss: 0.15217\n",
      "Epoch 800/2000, Avg Loss: 0.30942, Reg Loss: 0.15119\n",
      "Epoch 900/2000, Avg Loss: 0.34460, Reg Loss: 0.15147\n",
      "Epoch 1000/2000, Avg Loss: 0.30984, Reg Loss: 0.15202\n",
      "Epoch 1100/2000, Avg Loss: 0.29566, Reg Loss: 0.14844\n",
      "Epoch 1200/2000, Avg Loss: 0.30421, Reg Loss: 0.15126\n",
      "Epoch 1300/2000, Avg Loss: 0.28867, Reg Loss: 0.14834\n",
      "Epoch 1400/2000, Avg Loss: 0.30279, Reg Loss: 0.15206\n",
      "Epoch 1500/2000, Avg Loss: 0.29897, Reg Loss: 0.14999\n",
      "Epoch 1600/2000, Avg Loss: 0.27813, Reg Loss: 0.14627\n",
      "Epoch 1700/2000, Avg Loss: 0.27605, Reg Loss: 0.14634\n",
      "Epoch 1800/2000, Avg Loss: 0.28152, Reg Loss: 0.14629\n",
      "Epoch 1900/2000, Avg Loss: 0.27325, Reg Loss: 0.14720\n",
      "Epoch 2000/2000, Avg Loss: 0.26653, Reg Loss: 0.14682\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.8205, G-Mean = 0.7141, MCC = 0.4637, F1-score = 0.6377\n",
      "      SMOTEBoost: AUC = 0.8157, G-Mean = 0.7375, MCC = 0.4810, F1-score = 0.6680\n",
      "      RUSBoost: AUC = 0.7347, G-Mean = 0.5450, MCC = 0.2490, F1-score = 0.5667\n",
      "      OUBoost: AUC = 0.8265, G-Mean = 0.7301, MCC = 0.4786, F1-score = 0.6578\n",
      "      SVM: AUC = 0.8298, G-Mean = 0.6919, MCC = 0.4590, F1-score = 0.6149\n",
      "      SMOTE: AUC = 0.8272, G-Mean = 0.7420, MCC = 0.4744, F1-score = 0.6693\n",
      "      ADASYN: AUC = 0.8215, G-Mean = 0.7432, MCC = 0.4757, F1-score = 0.6723\n",
      "      bSMOTE: AUC = 0.8192, G-Mean = 0.7409, MCC = 0.4749, F1-score = 0.6722\n",
      "      ROS: AUC = 0.8334, G-Mean = 0.7354, MCC = 0.4619, F1-score = 0.6608\n",
      "      MWMOTE: AUC = 0.8197, G-Mean = 0.7340, MCC = 0.4649, F1-score = 0.6623\n",
      "      Trans(Direct): AUC = 0.8287, G-Mean = 0.7433, MCC = 0.4755, F1-score = 0.6723\n",
      "\n",
      "Starting experiment 2/10\n",
      "  Fold 1/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.47143, Reg Loss: 0.16006\n",
      "Epoch 200/2000, Avg Loss: 0.42582, Reg Loss: 0.16063\n",
      "Epoch 300/2000, Avg Loss: 0.40874, Reg Loss: 0.15946\n",
      "Epoch 400/2000, Avg Loss: 0.38183, Reg Loss: 0.15918\n",
      "Epoch 500/2000, Avg Loss: 0.35599, Reg Loss: 0.15836\n",
      "Epoch 600/2000, Avg Loss: 0.32682, Reg Loss: 0.15950\n",
      "Epoch 700/2000, Avg Loss: 0.31758, Reg Loss: 0.15850\n",
      "Epoch 800/2000, Avg Loss: 0.30223, Reg Loss: 0.15684\n",
      "Epoch 900/2000, Avg Loss: 0.28778, Reg Loss: 0.15549\n",
      "Epoch 1000/2000, Avg Loss: 0.27841, Reg Loss: 0.15563\n",
      "Epoch 1100/2000, Avg Loss: 0.27896, Reg Loss: 0.15611\n",
      "Epoch 1200/2000, Avg Loss: 0.27772, Reg Loss: 0.15508\n",
      "Epoch 1300/2000, Avg Loss: 0.26135, Reg Loss: 0.15418\n",
      "Epoch 1400/2000, Avg Loss: 0.25703, Reg Loss: 0.15262\n",
      "Epoch 1500/2000, Avg Loss: 0.25365, Reg Loss: 0.15133\n",
      "Epoch 1600/2000, Avg Loss: 0.25051, Reg Loss: 0.15007\n",
      "Epoch 1700/2000, Avg Loss: 0.24899, Reg Loss: 0.14959\n",
      "Epoch 1800/2000, Avg Loss: 0.25808, Reg Loss: 0.15011\n",
      "Epoch 1900/2000, Avg Loss: 0.24853, Reg Loss: 0.14887\n",
      "Epoch 2000/2000, Avg Loss: 0.24570, Reg Loss: 0.14842\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.7948, G-Mean = 0.6667, MCC = 0.3623, F1-score = 0.5769\n",
      "      SMOTEBoost: AUC = 0.8407, G-Mean = 0.7503, MCC = 0.4960, F1-score = 0.6786\n",
      "      RUSBoost: AUC = 0.8178, G-Mean = 0.5292, MCC = 0.3464, F1-score = 0.6000\n",
      "      OUBoost: AUC = 0.8222, G-Mean = 0.6992, MCC = 0.4667, F1-score = 0.6250\n",
      "      SVM: AUC = 0.8081, G-Mean = 0.6188, MCC = 0.4298, F1-score = 0.5366\n",
      "      SMOTE: AUC = 0.7852, G-Mean = 0.6918, MCC = 0.3837, F1-score = 0.6071\n",
      "      ADASYN: AUC = 0.7548, G-Mean = 0.7055, MCC = 0.3987, F1-score = 0.6364\n",
      "      bSMOTE: AUC = 0.7607, G-Mean = 0.6733, MCC = 0.3331, F1-score = 0.5902\n",
      "      ROS: AUC = 0.7689, G-Mean = 0.6441, MCC = 0.2847, F1-score = 0.5517\n",
      "      MWMOTE: AUC = 0.7622, G-Mean = 0.7118, MCC = 0.4086, F1-score = 0.6333\n",
      "      Trans(Direct): AUC = 0.8119, G-Mean = 0.7201, MCC = 0.4224, F1-score = 0.6452\n",
      "  Fold 2/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.46409, Reg Loss: 0.15432\n",
      "Epoch 200/2000, Avg Loss: 0.41922, Reg Loss: 0.15831\n",
      "Epoch 300/2000, Avg Loss: 0.41023, Reg Loss: 0.15681\n",
      "Epoch 400/2000, Avg Loss: 0.38728, Reg Loss: 0.15721\n",
      "Epoch 500/2000, Avg Loss: 0.37596, Reg Loss: 0.15752\n",
      "Epoch 600/2000, Avg Loss: 0.35759, Reg Loss: 0.15758\n",
      "Epoch 700/2000, Avg Loss: 0.36068, Reg Loss: 0.15700\n",
      "Epoch 800/2000, Avg Loss: 0.37833, Reg Loss: 0.15663\n",
      "Epoch 900/2000, Avg Loss: 0.33533, Reg Loss: 0.15668\n",
      "Epoch 1000/2000, Avg Loss: 0.33275, Reg Loss: 0.15312\n",
      "Epoch 1100/2000, Avg Loss: 0.32082, Reg Loss: 0.15382\n",
      "Epoch 1200/2000, Avg Loss: 0.31958, Reg Loss: 0.15272\n",
      "Epoch 1300/2000, Avg Loss: 0.31640, Reg Loss: 0.15303\n",
      "Epoch 1400/2000, Avg Loss: 0.31696, Reg Loss: 0.15150\n",
      "Epoch 1500/2000, Avg Loss: 0.32339, Reg Loss: 0.15179\n",
      "Epoch 1600/2000, Avg Loss: 0.31569, Reg Loss: 0.15226\n",
      "Epoch 1700/2000, Avg Loss: 0.36398, Reg Loss: 0.15143\n",
      "Epoch 1800/2000, Avg Loss: 0.30940, Reg Loss: 0.15143\n",
      "Epoch 1900/2000, Avg Loss: 0.32258, Reg Loss: 0.15091\n",
      "Epoch 2000/2000, Avg Loss: 0.32635, Reg Loss: 0.14971\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.8019, G-Mean = 0.6708, MCC = 0.3746, F1-score = 0.5826\n",
      "      SMOTEBoost: AUC = 0.8365, G-Mean = 0.7167, MCC = 0.4542, F1-score = 0.6393\n",
      "      RUSBoost: AUC = 0.7885, G-Mean = 0.5909, MCC = 0.3698, F1-score = 0.6165\n",
      "      OUBoost: AUC = 0.8230, G-Mean = 0.6835, MCC = 0.4361, F1-score = 0.6042\n",
      "      SVM: AUC = 0.8137, G-Mean = 0.6054, MCC = 0.3656, F1-score = 0.5127\n",
      "      SMOTE: AUC = 0.7926, G-Mean = 0.6874, MCC = 0.3981, F1-score = 0.6036\n",
      "      ADASYN: AUC = 0.7789, G-Mean = 0.7269, MCC = 0.4550, F1-score = 0.6578\n",
      "      bSMOTE: AUC = 0.7767, G-Mean = 0.7211, MCC = 0.4384, F1-score = 0.6469\n",
      "      ROS: AUC = 0.7874, G-Mean = 0.6900, MCC = 0.3946, F1-score = 0.6092\n",
      "      MWMOTE: AUC = 0.7783, G-Mean = 0.7044, MCC = 0.4145, F1-score = 0.6244\n",
      "      Trans(Direct): AUC = 0.8150, G-Mean = 0.7193, MCC = 0.4380, F1-score = 0.6433\n",
      "  Fold 3/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.49501, Reg Loss: 0.15515\n",
      "Epoch 200/2000, Avg Loss: 0.43510, Reg Loss: 0.15617\n",
      "Epoch 300/2000, Avg Loss: 0.39237, Reg Loss: 0.15331\n",
      "Epoch 400/2000, Avg Loss: 0.38475, Reg Loss: 0.15118\n",
      "Epoch 500/2000, Avg Loss: 0.38995, Reg Loss: 0.15007\n",
      "Epoch 600/2000, Avg Loss: 0.35731, Reg Loss: 0.14861\n",
      "Epoch 700/2000, Avg Loss: 0.35044, Reg Loss: 0.14820\n",
      "Epoch 800/2000, Avg Loss: 0.35569, Reg Loss: 0.15118\n",
      "Epoch 900/2000, Avg Loss: 0.34471, Reg Loss: 0.15068\n",
      "Epoch 1000/2000, Avg Loss: 0.35376, Reg Loss: 0.14989\n",
      "Epoch 1100/2000, Avg Loss: 0.30394, Reg Loss: 0.14661\n",
      "Epoch 1200/2000, Avg Loss: 0.29718, Reg Loss: 0.14498\n",
      "Epoch 1300/2000, Avg Loss: 0.28916, Reg Loss: 0.14326\n",
      "Epoch 1400/2000, Avg Loss: 0.35732, Reg Loss: 0.14876\n",
      "Epoch 1500/2000, Avg Loss: 0.28733, Reg Loss: 0.14353\n",
      "Epoch 1600/2000, Avg Loss: 0.28548, Reg Loss: 0.14228\n",
      "Epoch 1700/2000, Avg Loss: 0.27122, Reg Loss: 0.14158\n",
      "Epoch 1800/2000, Avg Loss: 0.33276, Reg Loss: 0.15195\n",
      "Epoch 1900/2000, Avg Loss: 0.26719, Reg Loss: 0.14519\n",
      "Epoch 2000/2000, Avg Loss: 0.26401, Reg Loss: 0.14321\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.8096, G-Mean = 0.6906, MCC = 0.4257, F1-score = 0.6106\n",
      "      SMOTEBoost: AUC = 0.8475, G-Mean = 0.7243, MCC = 0.4650, F1-score = 0.6484\n",
      "      RUSBoost: AUC = 0.7802, G-Mean = 0.6059, MCC = 0.3814, F1-score = 0.6224\n",
      "      OUBoost: AUC = 0.8380, G-Mean = 0.7110, MCC = 0.4785, F1-score = 0.6381\n",
      "      SVM: AUC = 0.8222, G-Mean = 0.6262, MCC = 0.3790, F1-score = 0.5363\n",
      "      SMOTE: AUC = 0.8178, G-Mean = 0.7077, MCC = 0.4358, F1-score = 0.6288\n",
      "      ADASYN: AUC = 0.8005, G-Mean = 0.7252, MCC = 0.4465, F1-score = 0.6532\n",
      "      bSMOTE: AUC = 0.7990, G-Mean = 0.7308, MCC = 0.4576, F1-score = 0.6575\n",
      "      ROS: AUC = 0.8052, G-Mean = 0.7198, MCC = 0.4471, F1-score = 0.6442\n",
      "      MWMOTE: AUC = 0.8085, G-Mean = 0.7191, MCC = 0.4467, F1-score = 0.6427\n",
      "      Trans(Direct): AUC = 0.8325, G-Mean = 0.7230, MCC = 0.4463, F1-score = 0.6471\n",
      "  Fold 4/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.44971, Reg Loss: 0.16903\n",
      "Epoch 200/2000, Avg Loss: 0.38828, Reg Loss: 0.17371\n",
      "Epoch 300/2000, Avg Loss: 0.34842, Reg Loss: 0.17165\n",
      "Epoch 400/2000, Avg Loss: 0.36256, Reg Loss: 0.17538\n",
      "Epoch 500/2000, Avg Loss: 0.30704, Reg Loss: 0.16892\n",
      "Epoch 600/2000, Avg Loss: 0.29137, Reg Loss: 0.16530\n",
      "Epoch 700/2000, Avg Loss: 0.27923, Reg Loss: 0.16359\n",
      "Epoch 800/2000, Avg Loss: 0.26881, Reg Loss: 0.15952\n",
      "Epoch 900/2000, Avg Loss: 0.26684, Reg Loss: 0.16008\n",
      "Epoch 1000/2000, Avg Loss: 0.25448, Reg Loss: 0.15697\n",
      "Epoch 1100/2000, Avg Loss: 0.25060, Reg Loss: 0.15686\n",
      "Epoch 1200/2000, Avg Loss: 0.24605, Reg Loss: 0.15486\n",
      "Epoch 1300/2000, Avg Loss: 0.25590, Reg Loss: 0.15466\n",
      "Epoch 1400/2000, Avg Loss: 0.24099, Reg Loss: 0.15263\n",
      "Epoch 1500/2000, Avg Loss: 0.24648, Reg Loss: 0.15377\n",
      "Epoch 1600/2000, Avg Loss: 0.23923, Reg Loss: 0.15204\n",
      "Epoch 1700/2000, Avg Loss: 0.24761, Reg Loss: 0.15292\n",
      "Epoch 1800/2000, Avg Loss: 0.23871, Reg Loss: 0.15217\n",
      "Epoch 1900/2000, Avg Loss: 0.32624, Reg Loss: 0.16312\n",
      "Epoch 2000/2000, Avg Loss: 0.31883, Reg Loss: 0.16360\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.8219, G-Mean = 0.7062, MCC = 0.4591, F1-score = 0.6314\n",
      "      SMOTEBoost: AUC = 0.8403, G-Mean = 0.7236, MCC = 0.4562, F1-score = 0.6473\n",
      "      RUSBoost: AUC = 0.7848, G-Mean = 0.6103, MCC = 0.3762, F1-score = 0.6211\n",
      "      OUBoost: AUC = 0.8344, G-Mean = 0.7135, MCC = 0.4688, F1-score = 0.6393\n",
      "      SVM: AUC = 0.8369, G-Mean = 0.6542, MCC = 0.4237, F1-score = 0.5724\n",
      "      SMOTE: AUC = 0.8267, G-Mean = 0.7230, MCC = 0.4628, F1-score = 0.6475\n",
      "      ADASYN: AUC = 0.8165, G-Mean = 0.7411, MCC = 0.4754, F1-score = 0.6710\n",
      "      bSMOTE: AUC = 0.8115, G-Mean = 0.7381, MCC = 0.4699, F1-score = 0.6655\n",
      "      ROS: AUC = 0.8200, G-Mean = 0.7250, MCC = 0.4537, F1-score = 0.6498\n",
      "      MWMOTE: AUC = 0.8168, G-Mean = 0.7340, MCC = 0.4701, F1-score = 0.6600\n",
      "      Trans(Direct): AUC = 0.8438, G-Mean = 0.7419, MCC = 0.4810, F1-score = 0.6695\n",
      "  Fold 5/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.48741, Reg Loss: 0.15913\n",
      "Epoch 200/2000, Avg Loss: 0.43244, Reg Loss: 0.16188\n",
      "Epoch 300/2000, Avg Loss: 0.38651, Reg Loss: 0.16004\n",
      "Epoch 400/2000, Avg Loss: 0.37038, Reg Loss: 0.16222\n",
      "Epoch 500/2000, Avg Loss: 0.39493, Reg Loss: 0.16401\n",
      "Epoch 600/2000, Avg Loss: 0.34928, Reg Loss: 0.16478\n",
      "Epoch 700/2000, Avg Loss: 0.32995, Reg Loss: 0.16428\n",
      "Epoch 800/2000, Avg Loss: 0.37752, Reg Loss: 0.16162\n",
      "Epoch 900/2000, Avg Loss: 0.30911, Reg Loss: 0.15724\n",
      "Epoch 1000/2000, Avg Loss: 0.29763, Reg Loss: 0.15669\n",
      "Epoch 1100/2000, Avg Loss: 0.29566, Reg Loss: 0.15568\n",
      "Epoch 1200/2000, Avg Loss: 0.27612, Reg Loss: 0.15255\n",
      "Epoch 1300/2000, Avg Loss: 0.28349, Reg Loss: 0.15517\n",
      "Epoch 1400/2000, Avg Loss: 0.26966, Reg Loss: 0.15105\n",
      "Epoch 1500/2000, Avg Loss: 0.25572, Reg Loss: 0.15010\n",
      "Epoch 1600/2000, Avg Loss: 0.24721, Reg Loss: 0.14879\n",
      "Epoch 1700/2000, Avg Loss: 0.24669, Reg Loss: 0.14744\n",
      "Epoch 1800/2000, Avg Loss: 0.24105, Reg Loss: 0.14631\n",
      "Epoch 1900/2000, Avg Loss: 0.24399, Reg Loss: 0.14754\n",
      "Epoch 2000/2000, Avg Loss: 0.24894, Reg Loss: 0.14728\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.8020, G-Mean = 0.6996, MCC = 0.4339, F1-score = 0.6232\n",
      "      SMOTEBoost: AUC = 0.8087, G-Mean = 0.7038, MCC = 0.4127, F1-score = 0.6258\n",
      "      RUSBoost: AUC = 0.7588, G-Mean = 0.5998, MCC = 0.3329, F1-score = 0.6021\n",
      "      OUBoost: AUC = 0.8133, G-Mean = 0.7036, MCC = 0.4389, F1-score = 0.6267\n",
      "      SVM: AUC = 0.8184, G-Mean = 0.6506, MCC = 0.3998, F1-score = 0.5656\n",
      "      SMOTE: AUC = 0.8119, G-Mean = 0.7139, MCC = 0.4391, F1-score = 0.6392\n",
      "      ADASYN: AUC = 0.8001, G-Mean = 0.7272, MCC = 0.4489, F1-score = 0.6585\n",
      "      bSMOTE: AUC = 0.8004, G-Mean = 0.7271, MCC = 0.4482, F1-score = 0.6559\n",
      "      ROS: AUC = 0.8061, G-Mean = 0.7156, MCC = 0.4318, F1-score = 0.6411\n",
      "      MWMOTE: AUC = 0.8011, G-Mean = 0.7206, MCC = 0.4411, F1-score = 0.6474\n",
      "      Trans(Direct): AUC = 0.8222, G-Mean = 0.7333, MCC = 0.4643, F1-score = 0.6631\n",
      "  Fold 6/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.47305, Reg Loss: 0.15968\n",
      "Epoch 200/2000, Avg Loss: 0.43817, Reg Loss: 0.15627\n",
      "Epoch 300/2000, Avg Loss: 0.39415, Reg Loss: 0.15652\n",
      "Epoch 400/2000, Avg Loss: 0.38667, Reg Loss: 0.15700\n",
      "Epoch 500/2000, Avg Loss: 0.36932, Reg Loss: 0.16014\n",
      "Epoch 600/2000, Avg Loss: 0.33439, Reg Loss: 0.15869\n",
      "Epoch 700/2000, Avg Loss: 0.30617, Reg Loss: 0.15761\n",
      "Epoch 800/2000, Avg Loss: 0.30623, Reg Loss: 0.15689\n",
      "Epoch 900/2000, Avg Loss: 0.29604, Reg Loss: 0.15708\n",
      "Epoch 1000/2000, Avg Loss: 0.29148, Reg Loss: 0.15589\n",
      "Epoch 1100/2000, Avg Loss: 0.28865, Reg Loss: 0.15749\n",
      "Epoch 1200/2000, Avg Loss: 0.28136, Reg Loss: 0.15515\n",
      "Epoch 1300/2000, Avg Loss: 0.28577, Reg Loss: 0.15739\n",
      "Epoch 1400/2000, Avg Loss: 0.26169, Reg Loss: 0.15509\n",
      "Epoch 1500/2000, Avg Loss: 0.25821, Reg Loss: 0.15344\n",
      "Epoch 1600/2000, Avg Loss: 0.25665, Reg Loss: 0.15549\n",
      "Epoch 1700/2000, Avg Loss: 0.24530, Reg Loss: 0.15334\n",
      "Epoch 1800/2000, Avg Loss: 0.25077, Reg Loss: 0.15178\n",
      "Epoch 1900/2000, Avg Loss: 0.25214, Reg Loss: 0.15376\n",
      "Epoch 2000/2000, Avg Loss: 0.23978, Reg Loss: 0.15132\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.8130, G-Mean = 0.7080, MCC = 0.4443, F1-score = 0.6324\n",
      "      SMOTEBoost: AUC = 0.8224, G-Mean = 0.7277, MCC = 0.4588, F1-score = 0.6548\n",
      "      RUSBoost: AUC = 0.7756, G-Mean = 0.6104, MCC = 0.3548, F1-score = 0.6115\n",
      "      OUBoost: AUC = 0.8273, G-Mean = 0.7209, MCC = 0.4701, F1-score = 0.6480\n",
      "      SVM: AUC = 0.8309, G-Mean = 0.6718, MCC = 0.4279, F1-score = 0.5909\n",
      "      SMOTE: AUC = 0.8244, G-Mean = 0.7283, MCC = 0.4627, F1-score = 0.6558\n",
      "      ADASYN: AUC = 0.8123, G-Mean = 0.7421, MCC = 0.4769, F1-score = 0.6750\n",
      "      bSMOTE: AUC = 0.8127, G-Mean = 0.7401, MCC = 0.4731, F1-score = 0.6710\n",
      "      ROS: AUC = 0.8186, G-Mean = 0.7240, MCC = 0.4451, F1-score = 0.6506\n",
      "      MWMOTE: AUC = 0.8120, G-Mean = 0.7365, MCC = 0.4704, F1-score = 0.6657\n",
      "      Trans(Direct): AUC = 0.8335, G-Mean = 0.7388, MCC = 0.4721, F1-score = 0.6690\n",
      "  Fold 7/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.48390, Reg Loss: 0.16296\n",
      "Epoch 200/2000, Avg Loss: 0.41884, Reg Loss: 0.15949\n",
      "Epoch 300/2000, Avg Loss: 0.40566, Reg Loss: 0.16543\n",
      "Epoch 400/2000, Avg Loss: 0.38883, Reg Loss: 0.16301\n",
      "Epoch 500/2000, Avg Loss: 0.37880, Reg Loss: 0.16371\n",
      "Epoch 600/2000, Avg Loss: 0.37323, Reg Loss: 0.16562\n",
      "Epoch 700/2000, Avg Loss: 0.35365, Reg Loss: 0.16964\n",
      "Epoch 800/2000, Avg Loss: 0.34415, Reg Loss: 0.16718\n",
      "Epoch 900/2000, Avg Loss: 0.32190, Reg Loss: 0.16413\n",
      "Epoch 1000/2000, Avg Loss: 0.34490, Reg Loss: 0.16458\n",
      "Epoch 1100/2000, Avg Loss: 0.30849, Reg Loss: 0.15793\n",
      "Epoch 1200/2000, Avg Loss: 0.30488, Reg Loss: 0.15401\n",
      "Epoch 1300/2000, Avg Loss: 0.29960, Reg Loss: 0.15131\n",
      "Epoch 1400/2000, Avg Loss: 0.29998, Reg Loss: 0.14822\n",
      "Epoch 1500/2000, Avg Loss: 0.30258, Reg Loss: 0.14742\n",
      "Epoch 1600/2000, Avg Loss: 0.30037, Reg Loss: 0.14649\n",
      "Epoch 1700/2000, Avg Loss: 0.29460, Reg Loss: 0.14568\n",
      "Epoch 1800/2000, Avg Loss: 0.29418, Reg Loss: 0.14512\n",
      "Epoch 1900/2000, Avg Loss: 0.30975, Reg Loss: 0.14707\n",
      "Epoch 2000/2000, Avg Loss: 0.28993, Reg Loss: 0.14352\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.8243, G-Mean = 0.7176, MCC = 0.4652, F1-score = 0.6449\n",
      "      SMOTEBoost: AUC = 0.8338, G-Mean = 0.7416, MCC = 0.4830, F1-score = 0.6708\n",
      "      RUSBoost: AUC = 0.7820, G-Mean = 0.5947, MCC = 0.3436, F1-score = 0.6067\n",
      "      OUBoost: AUC = 0.8380, G-Mean = 0.7306, MCC = 0.4833, F1-score = 0.6589\n",
      "      SVM: AUC = 0.8381, G-Mean = 0.6877, MCC = 0.4553, F1-score = 0.6114\n",
      "      SMOTE: AUC = 0.8314, G-Mean = 0.7381, MCC = 0.4786, F1-score = 0.6668\n",
      "      ADASYN: AUC = 0.8193, G-Mean = 0.7540, MCC = 0.4985, F1-score = 0.6881\n",
      "      bSMOTE: AUC = 0.8204, G-Mean = 0.7538, MCC = 0.4985, F1-score = 0.6865\n",
      "      ROS: AUC = 0.8288, G-Mean = 0.7385, MCC = 0.4713, F1-score = 0.6672\n",
      "      MWMOTE: AUC = 0.8216, G-Mean = 0.7507, MCC = 0.4961, F1-score = 0.6820\n",
      "      Trans(Direct): AUC = 0.8395, G-Mean = 0.7482, MCC = 0.4885, F1-score = 0.6794\n",
      "  Fold 8/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.50443, Reg Loss: 0.16070\n",
      "Epoch 200/2000, Avg Loss: 0.47003, Reg Loss: 0.15541\n",
      "Epoch 300/2000, Avg Loss: 0.40934, Reg Loss: 0.15958\n",
      "Epoch 400/2000, Avg Loss: 0.36774, Reg Loss: 0.15787\n",
      "Epoch 500/2000, Avg Loss: 0.34772, Reg Loss: 0.16032\n",
      "Epoch 600/2000, Avg Loss: 0.38574, Reg Loss: 0.15938\n",
      "Epoch 700/2000, Avg Loss: 0.32704, Reg Loss: 0.15708\n",
      "Epoch 800/2000, Avg Loss: 0.30824, Reg Loss: 0.15580\n",
      "Epoch 900/2000, Avg Loss: 0.30213, Reg Loss: 0.15408\n",
      "Epoch 1000/2000, Avg Loss: 0.27930, Reg Loss: 0.15159\n",
      "Epoch 1100/2000, Avg Loss: 0.28381, Reg Loss: 0.15196\n",
      "Epoch 1200/2000, Avg Loss: 0.29148, Reg Loss: 0.15299\n",
      "Epoch 1300/2000, Avg Loss: 0.27024, Reg Loss: 0.15015\n",
      "Epoch 1400/2000, Avg Loss: 0.26299, Reg Loss: 0.14826\n",
      "Epoch 1500/2000, Avg Loss: 0.26039, Reg Loss: 0.14791\n",
      "Epoch 1600/2000, Avg Loss: 0.26033, Reg Loss: 0.14733\n",
      "Epoch 1700/2000, Avg Loss: 0.25093, Reg Loss: 0.14449\n",
      "Epoch 1800/2000, Avg Loss: 0.25041, Reg Loss: 0.14485\n",
      "Epoch 1900/2000, Avg Loss: 0.25498, Reg Loss: 0.14453\n",
      "Epoch 2000/2000, Avg Loss: 0.24596, Reg Loss: 0.14289\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.8224, G-Mean = 0.7108, MCC = 0.4591, F1-score = 0.6365\n",
      "      SMOTEBoost: AUC = 0.8363, G-Mean = 0.7388, MCC = 0.4807, F1-score = 0.6670\n",
      "      RUSBoost: AUC = 0.7796, G-Mean = 0.6018, MCC = 0.3490, F1-score = 0.6088\n",
      "      OUBoost: AUC = 0.8391, G-Mean = 0.7203, MCC = 0.4680, F1-score = 0.6457\n",
      "      SVM: AUC = 0.8376, G-Mean = 0.6874, MCC = 0.4624, F1-score = 0.6124\n",
      "      SMOTE: AUC = 0.8327, G-Mean = 0.7412, MCC = 0.4853, F1-score = 0.6700\n",
      "      ADASYN: AUC = 0.8221, G-Mean = 0.7578, MCC = 0.5053, F1-score = 0.6914\n",
      "      bSMOTE: AUC = 0.8229, G-Mean = 0.7551, MCC = 0.4997, F1-score = 0.6869\n",
      "      ROS: AUC = 0.8290, G-Mean = 0.7377, MCC = 0.4716, F1-score = 0.6655\n",
      "      MWMOTE: AUC = 0.8249, G-Mean = 0.7537, MCC = 0.5004, F1-score = 0.6845\n",
      "      Trans(Direct): AUC = 0.8410, G-Mean = 0.7484, MCC = 0.4930, F1-score = 0.6795\n",
      "  Fold 9/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.49811, Reg Loss: 0.15759\n",
      "Epoch 200/2000, Avg Loss: 0.45820, Reg Loss: 0.16034\n",
      "Epoch 300/2000, Avg Loss: 0.43648, Reg Loss: 0.15897\n",
      "Epoch 400/2000, Avg Loss: 0.41470, Reg Loss: 0.16100\n",
      "Epoch 500/2000, Avg Loss: 0.38887, Reg Loss: 0.16137\n",
      "Epoch 600/2000, Avg Loss: 0.37747, Reg Loss: 0.15817\n",
      "Epoch 700/2000, Avg Loss: 0.36397, Reg Loss: 0.16065\n",
      "Epoch 800/2000, Avg Loss: 0.36314, Reg Loss: 0.15950\n",
      "Epoch 900/2000, Avg Loss: 0.33769, Reg Loss: 0.15734\n",
      "Epoch 1000/2000, Avg Loss: 0.31915, Reg Loss: 0.15630\n",
      "Epoch 1100/2000, Avg Loss: 0.31457, Reg Loss: 0.15730\n",
      "Epoch 1200/2000, Avg Loss: 0.30324, Reg Loss: 0.15575\n",
      "Epoch 1300/2000, Avg Loss: 0.30201, Reg Loss: 0.15323\n",
      "Epoch 1400/2000, Avg Loss: 0.29563, Reg Loss: 0.15281\n",
      "Epoch 1500/2000, Avg Loss: 0.29582, Reg Loss: 0.15218\n",
      "Epoch 1600/2000, Avg Loss: 0.28389, Reg Loss: 0.15017\n",
      "Epoch 1700/2000, Avg Loss: 0.29548, Reg Loss: 0.15148\n",
      "Epoch 1800/2000, Avg Loss: 0.27612, Reg Loss: 0.14990\n",
      "Epoch 1900/2000, Avg Loss: 0.28450, Reg Loss: 0.15015\n",
      "Epoch 2000/2000, Avg Loss: 0.30323, Reg Loss: 0.15240\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.8198, G-Mean = 0.7029, MCC = 0.4412, F1-score = 0.6256\n",
      "      SMOTEBoost: AUC = 0.8359, G-Mean = 0.7446, MCC = 0.4893, F1-score = 0.6730\n",
      "      RUSBoost: AUC = 0.7855, G-Mean = 0.6038, MCC = 0.3528, F1-score = 0.6097\n",
      "      OUBoost: AUC = 0.8383, G-Mean = 0.7241, MCC = 0.4710, F1-score = 0.6493\n",
      "      SVM: AUC = 0.8371, G-Mean = 0.6867, MCC = 0.4580, F1-score = 0.6105\n",
      "      SMOTE: AUC = 0.8330, G-Mean = 0.7436, MCC = 0.4872, F1-score = 0.6721\n",
      "      ADASYN: AUC = 0.8229, G-Mean = 0.7591, MCC = 0.5067, F1-score = 0.6922\n",
      "      bSMOTE: AUC = 0.8233, G-Mean = 0.7548, MCC = 0.4978, F1-score = 0.6859\n",
      "      ROS: AUC = 0.8298, G-Mean = 0.7352, MCC = 0.4649, F1-score = 0.6620\n",
      "      MWMOTE: AUC = 0.8236, G-Mean = 0.7517, MCC = 0.4950, F1-score = 0.6812\n",
      "      Trans(Direct): AUC = 0.8406, G-Mean = 0.7511, MCC = 0.4962, F1-score = 0.6818\n",
      "  Fold 10/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.48785, Reg Loss: 0.16881\n",
      "Epoch 200/2000, Avg Loss: 0.43705, Reg Loss: 0.16748\n",
      "Epoch 300/2000, Avg Loss: 0.40696, Reg Loss: 0.15868\n",
      "Epoch 400/2000, Avg Loss: 0.38499, Reg Loss: 0.15618\n",
      "Epoch 500/2000, Avg Loss: 0.36142, Reg Loss: 0.15703\n",
      "Epoch 600/2000, Avg Loss: 0.35517, Reg Loss: 0.15575\n",
      "Epoch 700/2000, Avg Loss: 0.32882, Reg Loss: 0.15346\n",
      "Epoch 800/2000, Avg Loss: 0.37080, Reg Loss: 0.15757\n",
      "Epoch 900/2000, Avg Loss: 0.31703, Reg Loss: 0.15409\n",
      "Epoch 1000/2000, Avg Loss: 0.32076, Reg Loss: 0.15412\n",
      "Epoch 1100/2000, Avg Loss: 0.31496, Reg Loss: 0.15472\n",
      "Epoch 1200/2000, Avg Loss: 0.33035, Reg Loss: 0.15362\n",
      "Epoch 1300/2000, Avg Loss: 0.30011, Reg Loss: 0.15234\n",
      "Epoch 1400/2000, Avg Loss: 0.29459, Reg Loss: 0.15249\n",
      "Epoch 1500/2000, Avg Loss: 0.29200, Reg Loss: 0.15390\n",
      "Epoch 1600/2000, Avg Loss: 0.28532, Reg Loss: 0.15185\n",
      "Epoch 1700/2000, Avg Loss: 0.28163, Reg Loss: 0.15189\n",
      "Epoch 1800/2000, Avg Loss: 0.29117, Reg Loss: 0.15335\n",
      "Epoch 1900/2000, Avg Loss: 0.27859, Reg Loss: 0.15062\n",
      "Epoch 2000/2000, Avg Loss: 0.27868, Reg Loss: 0.15034\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.8116, G-Mean = 0.7010, MCC = 0.4340, F1-score = 0.6223\n",
      "      SMOTEBoost: AUC = 0.8245, G-Mean = 0.7339, MCC = 0.4667, F1-score = 0.6599\n",
      "      RUSBoost: AUC = 0.7846, G-Mean = 0.5943, MCC = 0.3412, F1-score = 0.6046\n",
      "      OUBoost: AUC = 0.8299, G-Mean = 0.7183, MCC = 0.4565, F1-score = 0.6415\n",
      "      SVM: AUC = 0.8297, G-Mean = 0.6851, MCC = 0.4479, F1-score = 0.6072\n",
      "      SMOTE: AUC = 0.8233, G-Mean = 0.7394, MCC = 0.4773, F1-score = 0.6674\n",
      "      ADASYN: AUC = 0.8149, G-Mean = 0.7505, MCC = 0.4912, F1-score = 0.6838\n",
      "      bSMOTE: AUC = 0.8153, G-Mean = 0.7456, MCC = 0.4835, F1-score = 0.6784\n",
      "      ROS: AUC = 0.8211, G-Mean = 0.7313, MCC = 0.4572, F1-score = 0.6585\n",
      "      MWMOTE: AUC = 0.8143, G-Mean = 0.7449, MCC = 0.4825, F1-score = 0.6749\n",
      "      Trans(Direct): AUC = 0.8309, G-Mean = 0.7449, MCC = 0.4857, F1-score = 0.6765\n",
      "\n",
      "Starting experiment 3/10\n",
      "  Fold 1/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.45171, Reg Loss: 0.16456\n",
      "Epoch 200/2000, Avg Loss: 0.40852, Reg Loss: 0.16612\n",
      "Epoch 300/2000, Avg Loss: 0.37609, Reg Loss: 0.16661\n",
      "Epoch 400/2000, Avg Loss: 0.35239, Reg Loss: 0.16930\n",
      "Epoch 500/2000, Avg Loss: 0.33551, Reg Loss: 0.16798\n",
      "Epoch 600/2000, Avg Loss: 0.32739, Reg Loss: 0.16625\n",
      "Epoch 700/2000, Avg Loss: 0.32454, Reg Loss: 0.16534\n",
      "Epoch 800/2000, Avg Loss: 0.37848, Reg Loss: 0.16490\n",
      "Epoch 900/2000, Avg Loss: 0.32035, Reg Loss: 0.16671\n",
      "Epoch 1000/2000, Avg Loss: 0.30611, Reg Loss: 0.16820\n",
      "Epoch 1100/2000, Avg Loss: 0.30097, Reg Loss: 0.16641\n",
      "Epoch 1200/2000, Avg Loss: 0.33038, Reg Loss: 0.16470\n",
      "Epoch 1300/2000, Avg Loss: 0.29331, Reg Loss: 0.16236\n",
      "Epoch 1400/2000, Avg Loss: 0.27953, Reg Loss: 0.16068\n",
      "Epoch 1500/2000, Avg Loss: 0.27975, Reg Loss: 0.16333\n",
      "Epoch 1600/2000, Avg Loss: 0.27185, Reg Loss: 0.16161\n",
      "Epoch 1700/2000, Avg Loss: 0.26580, Reg Loss: 0.16005\n",
      "Epoch 1800/2000, Avg Loss: 0.26938, Reg Loss: 0.16109\n",
      "Epoch 1900/2000, Avg Loss: 0.27197, Reg Loss: 0.16076\n",
      "Epoch 2000/2000, Avg Loss: 0.26793, Reg Loss: 0.16191\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.7978, G-Mean = 0.7359, MCC = 0.5044, F1-score = 0.6667\n",
      "      SMOTEBoost: AUC = 0.8296, G-Mean = 0.7313, MCC = 0.4512, F1-score = 0.6552\n",
      "      RUSBoost: AUC = 0.7889, G-Mean = 0.6236, MCC = 0.3607, F1-score = 0.6173\n",
      "      OUBoost: AUC = 0.8274, G-Mean = 0.7483, MCC = 0.5112, F1-score = 0.6792\n",
      "      SVM: AUC = 0.8044, G-Mean = 0.7303, MCC = 0.5278, F1-score = 0.6667\n",
      "      SMOTE: AUC = 0.7974, G-Mean = 0.7404, MCC = 0.4635, F1-score = 0.6667\n",
      "      ADASYN: AUC = 0.8111, G-Mean = 0.7216, MCC = 0.4296, F1-score = 0.6441\n",
      "      bSMOTE: AUC = 0.7896, G-Mean = 0.7018, MCC = 0.3879, F1-score = 0.6230\n",
      "      ROS: AUC = 0.8074, G-Mean = 0.7601, MCC = 0.5067, F1-score = 0.6897\n",
      "      MWMOTE: AUC = 0.8022, G-Mean = 0.7118, MCC = 0.4175, F1-score = 0.6316\n",
      "      Trans(Direct): AUC = 0.8459, G-Mean = 0.7698, MCC = 0.5291, F1-score = 0.7018\n",
      "  Fold 2/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.48150, Reg Loss: 0.16957\n",
      "Epoch 200/2000, Avg Loss: 0.41123, Reg Loss: 0.16502\n",
      "Epoch 300/2000, Avg Loss: 0.43157, Reg Loss: 0.15940\n",
      "Epoch 400/2000, Avg Loss: 0.38005, Reg Loss: 0.15940\n",
      "Epoch 500/2000, Avg Loss: 0.36064, Reg Loss: 0.15596\n",
      "Epoch 600/2000, Avg Loss: 0.33807, Reg Loss: 0.15467\n",
      "Epoch 700/2000, Avg Loss: 0.31477, Reg Loss: 0.15332\n",
      "Epoch 800/2000, Avg Loss: 0.30568, Reg Loss: 0.15090\n",
      "Epoch 900/2000, Avg Loss: 0.30615, Reg Loss: 0.15038\n",
      "Epoch 1000/2000, Avg Loss: 0.29931, Reg Loss: 0.14978\n",
      "Epoch 1100/2000, Avg Loss: 0.29693, Reg Loss: 0.15128\n",
      "Epoch 1200/2000, Avg Loss: 0.29952, Reg Loss: 0.15007\n",
      "Epoch 1300/2000, Avg Loss: 0.31662, Reg Loss: 0.15174\n",
      "Epoch 1400/2000, Avg Loss: 0.29879, Reg Loss: 0.15433\n",
      "Epoch 1500/2000, Avg Loss: 0.27610, Reg Loss: 0.15335\n",
      "Epoch 1600/2000, Avg Loss: 0.27740, Reg Loss: 0.15382\n",
      "Epoch 1700/2000, Avg Loss: 0.26508, Reg Loss: 0.15341\n",
      "Epoch 1800/2000, Avg Loss: 0.25854, Reg Loss: 0.15270\n",
      "Epoch 1900/2000, Avg Loss: 0.34147, Reg Loss: 0.16112\n",
      "Epoch 2000/2000, Avg Loss: 0.30326, Reg Loss: 0.15881\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.8054, G-Mean = 0.7095, MCC = 0.4584, F1-score = 0.6333\n",
      "      SMOTEBoost: AUC = 0.8228, G-Mean = 0.7457, MCC = 0.4789, F1-score = 0.6724\n",
      "      RUSBoost: AUC = 0.7156, G-Mean = 0.5379, MCC = 0.2343, F1-score = 0.5700\n",
      "      OUBoost: AUC = 0.8293, G-Mean = 0.7591, MCC = 0.5202, F1-score = 0.6905\n",
      "      SVM: AUC = 0.8022, G-Mean = 0.7226, MCC = 0.5271, F1-score = 0.6594\n",
      "      SMOTE: AUC = 0.8165, G-Mean = 0.7295, MCC = 0.4586, F1-score = 0.6541\n",
      "      ADASYN: AUC = 0.8117, G-Mean = 0.7260, MCC = 0.4362, F1-score = 0.6499\n",
      "      bSMOTE: AUC = 0.7881, G-Mean = 0.7199, MCC = 0.4224, F1-score = 0.6448\n",
      "      ROS: AUC = 0.8193, G-Mean = 0.7599, MCC = 0.5131, F1-score = 0.6903\n",
      "      MWMOTE: AUC = 0.8044, G-Mean = 0.7071, MCC = 0.4066, F1-score = 0.6261\n",
      "      Trans(Direct): AUC = 0.8356, G-Mean = 0.7500, MCC = 0.4859, F1-score = 0.6787\n",
      "  Fold 3/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.48854, Reg Loss: 0.16547\n",
      "Epoch 200/2000, Avg Loss: 0.47793, Reg Loss: 0.16461\n",
      "Epoch 300/2000, Avg Loss: 0.42692, Reg Loss: 0.15987\n",
      "Epoch 400/2000, Avg Loss: 0.43041, Reg Loss: 0.16382\n",
      "Epoch 500/2000, Avg Loss: 0.38818, Reg Loss: 0.16041\n",
      "Epoch 600/2000, Avg Loss: 0.37815, Reg Loss: 0.15905\n",
      "Epoch 700/2000, Avg Loss: 0.36075, Reg Loss: 0.15793\n",
      "Epoch 800/2000, Avg Loss: 0.33837, Reg Loss: 0.15507\n",
      "Epoch 900/2000, Avg Loss: 0.32724, Reg Loss: 0.15658\n",
      "Epoch 1000/2000, Avg Loss: 0.30644, Reg Loss: 0.15355\n",
      "Epoch 1100/2000, Avg Loss: 0.29137, Reg Loss: 0.14914\n",
      "Epoch 1200/2000, Avg Loss: 0.27681, Reg Loss: 0.14919\n",
      "Epoch 1300/2000, Avg Loss: 0.26698, Reg Loss: 0.14897\n",
      "Epoch 1400/2000, Avg Loss: 0.25944, Reg Loss: 0.14743\n",
      "Epoch 1500/2000, Avg Loss: 0.26024, Reg Loss: 0.14565\n",
      "Epoch 1600/2000, Avg Loss: 0.25419, Reg Loss: 0.14485\n",
      "Epoch 1700/2000, Avg Loss: 0.25431, Reg Loss: 0.14375\n",
      "Epoch 1800/2000, Avg Loss: 0.24706, Reg Loss: 0.14257\n",
      "Epoch 1900/2000, Avg Loss: 0.24488, Reg Loss: 0.14050\n",
      "Epoch 2000/2000, Avg Loss: 0.24418, Reg Loss: 0.14122\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.8053, G-Mean = 0.7224, MCC = 0.4760, F1-score = 0.6486\n",
      "      SMOTEBoost: AUC = 0.8336, G-Mean = 0.7380, MCC = 0.5055, F1-score = 0.6705\n",
      "      RUSBoost: AUC = 0.7333, G-Mean = 0.5602, MCC = 0.2806, F1-score = 0.5864\n",
      "      OUBoost: AUC = 0.8423, G-Mean = 0.7495, MCC = 0.5445, F1-score = 0.6876\n",
      "      SVM: AUC = 0.8240, G-Mean = 0.7354, MCC = 0.5477, F1-score = 0.6757\n",
      "      SMOTE: AUC = 0.8352, G-Mean = 0.7588, MCC = 0.5116, F1-score = 0.6889\n",
      "      ADASYN: AUC = 0.8275, G-Mean = 0.7463, MCC = 0.4749, F1-score = 0.6737\n",
      "      bSMOTE: AUC = 0.8131, G-Mean = 0.7456, MCC = 0.4728, F1-score = 0.6743\n",
      "      ROS: AUC = 0.8388, G-Mean = 0.7824, MCC = 0.5556, F1-score = 0.7175\n",
      "      MWMOTE: AUC = 0.8244, G-Mean = 0.7337, MCC = 0.4552, F1-score = 0.6579\n",
      "      Trans(Direct): AUC = 0.8479, G-Mean = 0.7630, MCC = 0.5113, F1-score = 0.6939\n",
      "  Fold 4/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.45090, Reg Loss: 0.15158\n",
      "Epoch 200/2000, Avg Loss: 0.42168, Reg Loss: 0.15172\n",
      "Epoch 300/2000, Avg Loss: 0.40463, Reg Loss: 0.14774\n",
      "Epoch 400/2000, Avg Loss: 0.38739, Reg Loss: 0.14769\n",
      "Epoch 500/2000, Avg Loss: 0.36286, Reg Loss: 0.14563\n",
      "Epoch 600/2000, Avg Loss: 0.37914, Reg Loss: 0.14480\n",
      "Epoch 700/2000, Avg Loss: 0.34294, Reg Loss: 0.14387\n",
      "Epoch 800/2000, Avg Loss: 0.32374, Reg Loss: 0.14434\n",
      "Epoch 900/2000, Avg Loss: 0.32469, Reg Loss: 0.14398\n",
      "Epoch 1000/2000, Avg Loss: 0.31901, Reg Loss: 0.14444\n",
      "Epoch 1100/2000, Avg Loss: 0.31823, Reg Loss: 0.14589\n",
      "Epoch 1200/2000, Avg Loss: 0.31780, Reg Loss: 0.14709\n",
      "Epoch 1300/2000, Avg Loss: 0.32378, Reg Loss: 0.14738\n",
      "Epoch 1400/2000, Avg Loss: 0.29939, Reg Loss: 0.14675\n",
      "Epoch 1500/2000, Avg Loss: 0.29358, Reg Loss: 0.14868\n",
      "Epoch 1600/2000, Avg Loss: 0.28522, Reg Loss: 0.14618\n",
      "Epoch 1700/2000, Avg Loss: 0.26297, Reg Loss: 0.14717\n",
      "Epoch 1800/2000, Avg Loss: 0.26131, Reg Loss: 0.14694\n",
      "Epoch 1900/2000, Avg Loss: 0.25510, Reg Loss: 0.14637\n",
      "Epoch 2000/2000, Avg Loss: 0.25046, Reg Loss: 0.14500\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.8214, G-Mean = 0.7343, MCC = 0.4893, F1-score = 0.6619\n",
      "      SMOTEBoost: AUC = 0.8366, G-Mean = 0.7386, MCC = 0.4950, F1-score = 0.6695\n",
      "      RUSBoost: AUC = 0.7441, G-Mean = 0.5659, MCC = 0.3083, F1-score = 0.5949\n",
      "      OUBoost: AUC = 0.8476, G-Mean = 0.7520, MCC = 0.5382, F1-score = 0.6884\n",
      "      SVM: AUC = 0.8404, G-Mean = 0.7461, MCC = 0.5530, F1-score = 0.6860\n",
      "      SMOTE: AUC = 0.8457, G-Mean = 0.7552, MCC = 0.5018, F1-score = 0.6859\n",
      "      ADASYN: AUC = 0.8390, G-Mean = 0.7541, MCC = 0.4920, F1-score = 0.6844\n",
      "      bSMOTE: AUC = 0.8261, G-Mean = 0.7398, MCC = 0.4632, F1-score = 0.6699\n",
      "      ROS: AUC = 0.8502, G-Mean = 0.7770, MCC = 0.5436, F1-score = 0.7124\n",
      "      MWMOTE: AUC = 0.8356, G-Mean = 0.7267, MCC = 0.4411, F1-score = 0.6525\n",
      "      Trans(Direct): AUC = 0.8530, G-Mean = 0.7608, MCC = 0.5102, F1-score = 0.6943\n",
      "  Fold 5/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.44540, Reg Loss: 0.16028\n",
      "Epoch 200/2000, Avg Loss: 0.41240, Reg Loss: 0.16196\n",
      "Epoch 300/2000, Avg Loss: 0.38450, Reg Loss: 0.15720\n",
      "Epoch 400/2000, Avg Loss: 0.35885, Reg Loss: 0.15791\n",
      "Epoch 500/2000, Avg Loss: 0.31196, Reg Loss: 0.15410\n",
      "Epoch 600/2000, Avg Loss: 0.31062, Reg Loss: 0.15213\n",
      "Epoch 700/2000, Avg Loss: 0.30485, Reg Loss: 0.15804\n",
      "Epoch 800/2000, Avg Loss: 0.28985, Reg Loss: 0.15339\n",
      "Epoch 900/2000, Avg Loss: 0.28194, Reg Loss: 0.15365\n",
      "Epoch 1000/2000, Avg Loss: 0.27785, Reg Loss: 0.15179\n",
      "Epoch 1100/2000, Avg Loss: 0.26823, Reg Loss: 0.15200\n",
      "Epoch 1200/2000, Avg Loss: 0.25972, Reg Loss: 0.15061\n",
      "Epoch 1300/2000, Avg Loss: 0.25706, Reg Loss: 0.15046\n",
      "Epoch 1400/2000, Avg Loss: 0.24735, Reg Loss: 0.14882\n",
      "Epoch 1500/2000, Avg Loss: 0.24596, Reg Loss: 0.14720\n",
      "Epoch 1600/2000, Avg Loss: 0.27620, Reg Loss: 0.14968\n",
      "Epoch 1700/2000, Avg Loss: 0.23811, Reg Loss: 0.14550\n",
      "Epoch 1800/2000, Avg Loss: 0.23284, Reg Loss: 0.14533\n",
      "Epoch 1900/2000, Avg Loss: 0.24401, Reg Loss: 0.14635\n",
      "Epoch 2000/2000, Avg Loss: 0.22835, Reg Loss: 0.14697\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.8248, G-Mean = 0.7363, MCC = 0.4977, F1-score = 0.6655\n",
      "      SMOTEBoost: AUC = 0.8359, G-Mean = 0.7410, MCC = 0.4952, F1-score = 0.6713\n",
      "      RUSBoost: AUC = 0.7439, G-Mean = 0.5017, MCC = 0.2762, F1-score = 0.5829\n",
      "      OUBoost: AUC = 0.8437, G-Mean = 0.7513, MCC = 0.5328, F1-score = 0.6866\n",
      "      SVM: AUC = 0.8388, G-Mean = 0.7367, MCC = 0.5357, F1-score = 0.6738\n",
      "      SMOTE: AUC = 0.8379, G-Mean = 0.7465, MCC = 0.4831, F1-score = 0.6754\n",
      "      ADASYN: AUC = 0.8333, G-Mean = 0.7456, MCC = 0.4753, F1-score = 0.6742\n",
      "      bSMOTE: AUC = 0.8181, G-Mean = 0.7385, MCC = 0.4612, F1-score = 0.6693\n",
      "      ROS: AUC = 0.8450, G-Mean = 0.7541, MCC = 0.5004, F1-score = 0.6842\n",
      "      MWMOTE: AUC = 0.8305, G-Mean = 0.7351, MCC = 0.4566, F1-score = 0.6620\n",
      "      Trans(Direct): AUC = 0.8455, G-Mean = 0.7470, MCC = 0.4817, F1-score = 0.6780\n",
      "  Fold 6/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.54781, Reg Loss: 0.15849\n",
      "Epoch 200/2000, Avg Loss: 0.50508, Reg Loss: 0.16258\n",
      "Epoch 300/2000, Avg Loss: 0.44791, Reg Loss: 0.16732\n",
      "Epoch 400/2000, Avg Loss: 0.41053, Reg Loss: 0.16869\n",
      "Epoch 500/2000, Avg Loss: 0.40119, Reg Loss: 0.17296\n",
      "Epoch 600/2000, Avg Loss: 0.36026, Reg Loss: 0.16760\n",
      "Epoch 700/2000, Avg Loss: 0.35331, Reg Loss: 0.16877\n",
      "Epoch 800/2000, Avg Loss: 0.33314, Reg Loss: 0.16810\n",
      "Epoch 900/2000, Avg Loss: 0.32266, Reg Loss: 0.16546\n",
      "Epoch 1000/2000, Avg Loss: 0.31825, Reg Loss: 0.16442\n",
      "Epoch 1100/2000, Avg Loss: 0.30976, Reg Loss: 0.16184\n",
      "Epoch 1200/2000, Avg Loss: 0.30752, Reg Loss: 0.16031\n",
      "Epoch 1300/2000, Avg Loss: 0.31247, Reg Loss: 0.16189\n",
      "Epoch 1400/2000, Avg Loss: 0.30386, Reg Loss: 0.15844\n",
      "Epoch 1500/2000, Avg Loss: 0.30378, Reg Loss: 0.15707\n",
      "Epoch 1600/2000, Avg Loss: 0.29974, Reg Loss: 0.15574\n",
      "Epoch 1700/2000, Avg Loss: 0.37193, Reg Loss: 0.16996\n",
      "Epoch 1800/2000, Avg Loss: 0.31779, Reg Loss: 0.16305\n",
      "Epoch 1900/2000, Avg Loss: 0.29125, Reg Loss: 0.16251\n",
      "Epoch 2000/2000, Avg Loss: 0.28505, Reg Loss: 0.16008\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.8198, G-Mean = 0.7258, MCC = 0.4714, F1-score = 0.6523\n",
      "      SMOTEBoost: AUC = 0.8286, G-Mean = 0.7392, MCC = 0.4865, F1-score = 0.6687\n",
      "      RUSBoost: AUC = 0.7422, G-Mean = 0.5266, MCC = 0.3002, F1-score = 0.5927\n",
      "      OUBoost: AUC = 0.8410, G-Mean = 0.7559, MCC = 0.5340, F1-score = 0.6908\n",
      "      SVM: AUC = 0.8296, G-Mean = 0.7252, MCC = 0.5140, F1-score = 0.6587\n",
      "      SMOTE: AUC = 0.8269, G-Mean = 0.7375, MCC = 0.4650, F1-score = 0.6645\n",
      "      ADASYN: AUC = 0.8261, G-Mean = 0.7414, MCC = 0.4665, F1-score = 0.6693\n",
      "      bSMOTE: AUC = 0.8130, G-Mean = 0.7404, MCC = 0.4658, F1-score = 0.6722\n",
      "      ROS: AUC = 0.8336, G-Mean = 0.7455, MCC = 0.4830, F1-score = 0.6736\n",
      "      MWMOTE: AUC = 0.8227, G-Mean = 0.7338, MCC = 0.4533, F1-score = 0.6610\n",
      "      Trans(Direct): AUC = 0.8381, G-Mean = 0.7536, MCC = 0.4935, F1-score = 0.6852\n",
      "  Fold 7/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.49697, Reg Loss: 0.15264\n",
      "Epoch 200/2000, Avg Loss: 0.43395, Reg Loss: 0.15279\n",
      "Epoch 300/2000, Avg Loss: 0.39367, Reg Loss: 0.15197\n",
      "Epoch 400/2000, Avg Loss: 0.37841, Reg Loss: 0.15584\n",
      "Epoch 500/2000, Avg Loss: 0.35943, Reg Loss: 0.15556\n",
      "Epoch 600/2000, Avg Loss: 0.35647, Reg Loss: 0.15239\n",
      "Epoch 700/2000, Avg Loss: 0.39998, Reg Loss: 0.15929\n",
      "Epoch 800/2000, Avg Loss: 0.31450, Reg Loss: 0.15515\n",
      "Epoch 900/2000, Avg Loss: 0.34100, Reg Loss: 0.15963\n",
      "Epoch 1000/2000, Avg Loss: 0.29315, Reg Loss: 0.14663\n",
      "Epoch 1100/2000, Avg Loss: 0.28384, Reg Loss: 0.14883\n",
      "Epoch 1200/2000, Avg Loss: 0.26936, Reg Loss: 0.14469\n",
      "Epoch 1300/2000, Avg Loss: 0.26937, Reg Loss: 0.14421\n",
      "Epoch 1400/2000, Avg Loss: 0.26282, Reg Loss: 0.14296\n",
      "Epoch 1500/2000, Avg Loss: 0.26592, Reg Loss: 0.14081\n",
      "Epoch 1600/2000, Avg Loss: 0.26907, Reg Loss: 0.14270\n",
      "Epoch 1700/2000, Avg Loss: 0.25989, Reg Loss: 0.14241\n",
      "Epoch 1800/2000, Avg Loss: 0.25187, Reg Loss: 0.14074\n",
      "Epoch 1900/2000, Avg Loss: 0.24960, Reg Loss: 0.13983\n",
      "Epoch 2000/2000, Avg Loss: 0.25598, Reg Loss: 0.14105\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.8133, G-Mean = 0.7130, MCC = 0.4476, F1-score = 0.6360\n",
      "      SMOTEBoost: AUC = 0.8256, G-Mean = 0.7387, MCC = 0.4890, F1-score = 0.6684\n",
      "      RUSBoost: AUC = 0.7329, G-Mean = 0.5187, MCC = 0.2866, F1-score = 0.5874\n",
      "      OUBoost: AUC = 0.8353, G-Mean = 0.7478, MCC = 0.5244, F1-score = 0.6814\n",
      "      SVM: AUC = 0.8306, G-Mean = 0.7237, MCC = 0.5158, F1-score = 0.6578\n",
      "      SMOTE: AUC = 0.8256, G-Mean = 0.7324, MCC = 0.4540, F1-score = 0.6586\n",
      "      ADASYN: AUC = 0.8243, G-Mean = 0.7383, MCC = 0.4602, F1-score = 0.6659\n",
      "      bSMOTE: AUC = 0.8095, G-Mean = 0.7375, MCC = 0.4596, F1-score = 0.6683\n",
      "      ROS: AUC = 0.8321, G-Mean = 0.7420, MCC = 0.4768, F1-score = 0.6692\n",
      "      MWMOTE: AUC = 0.8195, G-Mean = 0.7384, MCC = 0.4616, F1-score = 0.6664\n",
      "      Trans(Direct): AUC = 0.8363, G-Mean = 0.7433, MCC = 0.4727, F1-score = 0.6735\n",
      "  Fold 8/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.50982, Reg Loss: 0.16858\n",
      "Epoch 200/2000, Avg Loss: 0.43632, Reg Loss: 0.16453\n",
      "Epoch 300/2000, Avg Loss: 0.38106, Reg Loss: 0.16065\n",
      "Epoch 400/2000, Avg Loss: 0.35513, Reg Loss: 0.15973\n",
      "Epoch 500/2000, Avg Loss: 0.36455, Reg Loss: 0.16062\n",
      "Epoch 600/2000, Avg Loss: 0.33200, Reg Loss: 0.15697\n",
      "Epoch 700/2000, Avg Loss: 0.32888, Reg Loss: 0.15370\n",
      "Epoch 800/2000, Avg Loss: 0.31834, Reg Loss: 0.15200\n",
      "Epoch 900/2000, Avg Loss: 0.31668, Reg Loss: 0.15230\n",
      "Epoch 1000/2000, Avg Loss: 0.31148, Reg Loss: 0.15172\n",
      "Epoch 1100/2000, Avg Loss: 0.33354, Reg Loss: 0.15307\n",
      "Epoch 1200/2000, Avg Loss: 0.31344, Reg Loss: 0.15377\n",
      "Epoch 1300/2000, Avg Loss: 0.37919, Reg Loss: 0.15465\n",
      "Epoch 1400/2000, Avg Loss: 0.37788, Reg Loss: 0.15739\n",
      "Epoch 1500/2000, Avg Loss: 0.28960, Reg Loss: 0.15243\n",
      "Epoch 1600/2000, Avg Loss: 0.27623, Reg Loss: 0.15148\n",
      "Epoch 1700/2000, Avg Loss: 0.27176, Reg Loss: 0.15497\n",
      "Epoch 1800/2000, Avg Loss: 0.28324, Reg Loss: 0.15566\n",
      "Epoch 1900/2000, Avg Loss: 0.26575, Reg Loss: 0.15160\n",
      "Epoch 2000/2000, Avg Loss: 0.26166, Reg Loss: 0.15235\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.8175, G-Mean = 0.7148, MCC = 0.4530, F1-score = 0.6382\n",
      "      SMOTEBoost: AUC = 0.8260, G-Mean = 0.7323, MCC = 0.4786, F1-score = 0.6599\n",
      "      RUSBoost: AUC = 0.7329, G-Mean = 0.5314, MCC = 0.2987, F1-score = 0.5912\n",
      "      OUBoost: AUC = 0.8338, G-Mean = 0.7403, MCC = 0.5095, F1-score = 0.6712\n",
      "      SVM: AUC = 0.8323, G-Mean = 0.7193, MCC = 0.5077, F1-score = 0.6517\n",
      "      SMOTE: AUC = 0.8260, G-Mean = 0.7326, MCC = 0.4531, F1-score = 0.6582\n",
      "      ADASYN: AUC = 0.8265, G-Mean = 0.7337, MCC = 0.4512, F1-score = 0.6608\n",
      "      bSMOTE: AUC = 0.8129, G-Mean = 0.7366, MCC = 0.4576, F1-score = 0.6668\n",
      "      ROS: AUC = 0.8299, G-Mean = 0.7362, MCC = 0.4641, F1-score = 0.6618\n",
      "      MWMOTE: AUC = 0.8217, G-Mean = 0.7342, MCC = 0.4528, F1-score = 0.6609\n",
      "      Trans(Direct): AUC = 0.8371, G-Mean = 0.7421, MCC = 0.4694, F1-score = 0.6713\n",
      "  Fold 9/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.47424, Reg Loss: 0.15742\n",
      "Epoch 200/2000, Avg Loss: 0.43242, Reg Loss: 0.15633\n",
      "Epoch 300/2000, Avg Loss: 0.41400, Reg Loss: 0.15629\n",
      "Epoch 400/2000, Avg Loss: 0.40725, Reg Loss: 0.15491\n",
      "Epoch 500/2000, Avg Loss: 0.39625, Reg Loss: 0.15572\n",
      "Epoch 600/2000, Avg Loss: 0.35055, Reg Loss: 0.15921\n",
      "Epoch 700/2000, Avg Loss: 0.33898, Reg Loss: 0.15816\n",
      "Epoch 800/2000, Avg Loss: 0.31725, Reg Loss: 0.15673\n",
      "Epoch 900/2000, Avg Loss: 0.30519, Reg Loss: 0.15496\n",
      "Epoch 1000/2000, Avg Loss: 0.32294, Reg Loss: 0.15655\n",
      "Epoch 1100/2000, Avg Loss: 0.29730, Reg Loss: 0.15079\n",
      "Epoch 1200/2000, Avg Loss: 0.30011, Reg Loss: 0.15165\n",
      "Epoch 1300/2000, Avg Loss: 0.29664, Reg Loss: 0.15156\n",
      "Epoch 1400/2000, Avg Loss: 0.29835, Reg Loss: 0.15061\n",
      "Epoch 1500/2000, Avg Loss: 0.28487, Reg Loss: 0.14890\n",
      "Epoch 1600/2000, Avg Loss: 0.27585, Reg Loss: 0.15020\n",
      "Epoch 1700/2000, Avg Loss: 0.27005, Reg Loss: 0.14858\n",
      "Epoch 1800/2000, Avg Loss: 0.26657, Reg Loss: 0.14784\n",
      "Epoch 1900/2000, Avg Loss: 0.26900, Reg Loss: 0.14914\n",
      "Epoch 2000/2000, Avg Loss: 0.26528, Reg Loss: 0.14705\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.8205, G-Mean = 0.7177, MCC = 0.4581, F1-score = 0.6413\n",
      "      SMOTEBoost: AUC = 0.8291, G-Mean = 0.7380, MCC = 0.4858, F1-score = 0.6657\n",
      "      RUSBoost: AUC = 0.7304, G-Mean = 0.5224, MCC = 0.2856, F1-score = 0.5854\n",
      "      OUBoost: AUC = 0.8366, G-Mean = 0.7438, MCC = 0.5149, F1-score = 0.6751\n",
      "      SVM: AUC = 0.8358, G-Mean = 0.7227, MCC = 0.5095, F1-score = 0.6548\n",
      "      SMOTE: AUC = 0.8272, G-Mean = 0.7359, MCC = 0.4585, F1-score = 0.6616\n",
      "      ADASYN: AUC = 0.8265, G-Mean = 0.7384, MCC = 0.4606, F1-score = 0.6660\n",
      "      bSMOTE: AUC = 0.8141, G-Mean = 0.7421, MCC = 0.4684, F1-score = 0.6726\n",
      "      ROS: AUC = 0.8331, G-Mean = 0.7383, MCC = 0.4667, F1-score = 0.6636\n",
      "      MWMOTE: AUC = 0.8252, G-Mean = 0.7401, MCC = 0.4641, F1-score = 0.6674\n",
      "      Trans(Direct): AUC = 0.8385, G-Mean = 0.7464, MCC = 0.4770, F1-score = 0.6756\n",
      "  Fold 10/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.44886, Reg Loss: 0.16882\n",
      "Epoch 200/2000, Avg Loss: 0.41677, Reg Loss: 0.16437\n",
      "Epoch 300/2000, Avg Loss: 0.37915, Reg Loss: 0.15841\n",
      "Epoch 400/2000, Avg Loss: 0.34691, Reg Loss: 0.16038\n",
      "Epoch 500/2000, Avg Loss: 0.33756, Reg Loss: 0.16191\n",
      "Epoch 600/2000, Avg Loss: 0.34068, Reg Loss: 0.15887\n",
      "Epoch 700/2000, Avg Loss: 0.31433, Reg Loss: 0.15806\n",
      "Epoch 800/2000, Avg Loss: 0.29418, Reg Loss: 0.15642\n",
      "Epoch 900/2000, Avg Loss: 0.28707, Reg Loss: 0.15620\n",
      "Epoch 1000/2000, Avg Loss: 0.28416, Reg Loss: 0.15659\n",
      "Epoch 1100/2000, Avg Loss: 0.27802, Reg Loss: 0.15643\n",
      "Epoch 1200/2000, Avg Loss: 0.27343, Reg Loss: 0.15706\n",
      "Epoch 1300/2000, Avg Loss: 0.26694, Reg Loss: 0.15603\n",
      "Epoch 1400/2000, Avg Loss: 0.26462, Reg Loss: 0.15696\n",
      "Epoch 1500/2000, Avg Loss: 0.26286, Reg Loss: 0.15418\n",
      "Epoch 1600/2000, Avg Loss: 0.26232, Reg Loss: 0.15288\n",
      "Epoch 1700/2000, Avg Loss: 0.25601, Reg Loss: 0.15206\n",
      "Epoch 1800/2000, Avg Loss: 0.26219, Reg Loss: 0.15198\n",
      "Epoch 1900/2000, Avg Loss: 0.25334, Reg Loss: 0.15013\n",
      "Epoch 2000/2000, Avg Loss: 0.25859, Reg Loss: 0.15038\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.8225, G-Mean = 0.7155, MCC = 0.4603, F1-score = 0.6394\n",
      "      SMOTEBoost: AUC = 0.8278, G-Mean = 0.7386, MCC = 0.4856, F1-score = 0.6658\n",
      "      RUSBoost: AUC = 0.7345, G-Mean = 0.5202, MCC = 0.2841, F1-score = 0.5837\n",
      "      OUBoost: AUC = 0.8355, G-Mean = 0.7435, MCC = 0.5132, F1-score = 0.6742\n",
      "      SVM: AUC = 0.8286, G-Mean = 0.7086, MCC = 0.4894, F1-score = 0.6370\n",
      "      SMOTE: AUC = 0.8236, G-Mean = 0.7328, MCC = 0.4584, F1-score = 0.6579\n",
      "      ADASYN: AUC = 0.8210, G-Mean = 0.7318, MCC = 0.4541, F1-score = 0.6577\n",
      "      bSMOTE: AUC = 0.8103, G-Mean = 0.7381, MCC = 0.4631, F1-score = 0.6668\n",
      "      ROS: AUC = 0.8273, G-Mean = 0.7301, MCC = 0.4546, F1-score = 0.6533\n",
      "      MWMOTE: AUC = 0.8200, G-Mean = 0.7316, MCC = 0.4565, F1-score = 0.6572\n",
      "      Trans(Direct): AUC = 0.8354, G-Mean = 0.7441, MCC = 0.4743, F1-score = 0.6722\n",
      "\n",
      "Starting experiment 4/10\n",
      "  Fold 1/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.44392, Reg Loss: 0.16727\n",
      "Epoch 200/2000, Avg Loss: 0.44861, Reg Loss: 0.17183\n",
      "Epoch 300/2000, Avg Loss: 0.35353, Reg Loss: 0.16696\n",
      "Epoch 400/2000, Avg Loss: 0.30822, Reg Loss: 0.16372\n",
      "Epoch 500/2000, Avg Loss: 0.30416, Reg Loss: 0.16687\n",
      "Epoch 600/2000, Avg Loss: 0.28143, Reg Loss: 0.16403\n",
      "Epoch 700/2000, Avg Loss: 0.27510, Reg Loss: 0.16363\n",
      "Epoch 800/2000, Avg Loss: 0.27454, Reg Loss: 0.16132\n",
      "Epoch 900/2000, Avg Loss: 0.26444, Reg Loss: 0.16151\n",
      "Epoch 1000/2000, Avg Loss: 0.25693, Reg Loss: 0.16029\n",
      "Epoch 1100/2000, Avg Loss: 0.25209, Reg Loss: 0.15984\n",
      "Epoch 1200/2000, Avg Loss: 0.25486, Reg Loss: 0.15916\n",
      "Epoch 1300/2000, Avg Loss: 0.42626, Reg Loss: 0.16620\n",
      "Epoch 1400/2000, Avg Loss: 0.32383, Reg Loss: 0.16568\n",
      "Epoch 1500/2000, Avg Loss: 0.30449, Reg Loss: 0.16333\n",
      "Epoch 1600/2000, Avg Loss: 0.27256, Reg Loss: 0.16064\n",
      "Epoch 1700/2000, Avg Loss: 0.27374, Reg Loss: 0.15731\n",
      "Epoch 1800/2000, Avg Loss: 0.25737, Reg Loss: 0.15761\n",
      "Epoch 1900/2000, Avg Loss: 0.25230, Reg Loss: 0.15686\n",
      "Epoch 2000/2000, Avg Loss: 0.25039, Reg Loss: 0.15684\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.8581, G-Mean = 0.7572, MCC = 0.5367, F1-score = 0.6923\n",
      "      SMOTEBoost: AUC = 0.8511, G-Mean = 0.7071, MCC = 0.4957, F1-score = 0.6383\n",
      "      RUSBoost: AUC = 0.8089, G-Mean = 0.6782, MCC = 0.3813, F1-score = 0.6301\n",
      "      OUBoost: AUC = 0.8526, G-Mean = 0.6992, MCC = 0.4667, F1-score = 0.6250\n",
      "      SVM: AUC = 0.8600, G-Mean = 0.6912, MCC = 0.4389, F1-score = 0.6122\n",
      "      SMOTE: AUC = 0.8600, G-Mean = 0.7688, MCC = 0.5185, F1-score = 0.7000\n",
      "      ADASYN: AUC = 0.8667, G-Mean = 0.7940, MCC = 0.5660, F1-score = 0.7302\n",
      "      bSMOTE: AUC = 0.8533, G-Mean = 0.7659, MCC = 0.5115, F1-score = 0.6984\n",
      "      ROS: AUC = 0.8711, G-Mean = 0.8074, MCC = 0.5953, F1-score = 0.7458\n",
      "      MWMOTE: AUC = 0.8770, G-Mean = 0.7688, MCC = 0.5185, F1-score = 0.7000\n",
      "      Trans(Direct): AUC = 0.8630, G-Mean = 0.7503, MCC = 0.4848, F1-score = 0.6780\n",
      "  Fold 2/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.48949, Reg Loss: 0.16815\n",
      "Epoch 200/2000, Avg Loss: 0.44982, Reg Loss: 0.16912\n",
      "Epoch 300/2000, Avg Loss: 0.41672, Reg Loss: 0.17277\n",
      "Epoch 400/2000, Avg Loss: 0.42221, Reg Loss: 0.17045\n",
      "Epoch 500/2000, Avg Loss: 0.36884, Reg Loss: 0.16914\n",
      "Epoch 600/2000, Avg Loss: 0.34907, Reg Loss: 0.16658\n",
      "Epoch 700/2000, Avg Loss: 0.35118, Reg Loss: 0.16420\n",
      "Epoch 800/2000, Avg Loss: 0.36889, Reg Loss: 0.16851\n",
      "Epoch 900/2000, Avg Loss: 0.33741, Reg Loss: 0.16248\n",
      "Epoch 1000/2000, Avg Loss: 0.32816, Reg Loss: 0.16103\n",
      "Epoch 1100/2000, Avg Loss: 0.31747, Reg Loss: 0.16351\n",
      "Epoch 1200/2000, Avg Loss: 0.31504, Reg Loss: 0.16192\n",
      "Epoch 1300/2000, Avg Loss: 0.31245, Reg Loss: 0.16084\n",
      "Epoch 1400/2000, Avg Loss: 0.30092, Reg Loss: 0.16033\n",
      "Epoch 1500/2000, Avg Loss: 0.33615, Reg Loss: 0.16527\n",
      "Epoch 1600/2000, Avg Loss: 0.28696, Reg Loss: 0.15930\n",
      "Epoch 1700/2000, Avg Loss: 0.27774, Reg Loss: 0.15735\n",
      "Epoch 1800/2000, Avg Loss: 0.29143, Reg Loss: 0.15712\n",
      "Epoch 1900/2000, Avg Loss: 0.27098, Reg Loss: 0.15719\n",
      "Epoch 2000/2000, Avg Loss: 0.26417, Reg Loss: 0.15665\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.8620, G-Mean = 0.7730, MCC = 0.5494, F1-score = 0.7082\n",
      "      SMOTEBoost: AUC = 0.8485, G-Mean = 0.7341, MCC = 0.5017, F1-score = 0.6676\n",
      "      RUSBoost: AUC = 0.7524, G-Mean = 0.6037, MCC = 0.3638, F1-score = 0.6151\n",
      "      OUBoost: AUC = 0.8559, G-Mean = 0.7248, MCC = 0.4758, F1-score = 0.6515\n",
      "      SVM: AUC = 0.8559, G-Mean = 0.6784, MCC = 0.4504, F1-score = 0.6016\n",
      "      SMOTE: AUC = 0.8489, G-Mean = 0.7586, MCC = 0.4978, F1-score = 0.6887\n",
      "      ADASYN: AUC = 0.8396, G-Mean = 0.7497, MCC = 0.4824, F1-score = 0.6833\n",
      "      bSMOTE: AUC = 0.8267, G-Mean = 0.7463, MCC = 0.4818, F1-score = 0.6825\n",
      "      ROS: AUC = 0.8519, G-Mean = 0.7931, MCC = 0.5677, F1-score = 0.7288\n",
      "      MWMOTE: AUC = 0.8452, G-Mean = 0.7688, MCC = 0.5185, F1-score = 0.7000\n",
      "      Trans(Direct): AUC = 0.8522, G-Mean = 0.7686, MCC = 0.5186, F1-score = 0.6996\n",
      "  Fold 3/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.50542, Reg Loss: 0.16150\n",
      "Epoch 200/2000, Avg Loss: 0.50300, Reg Loss: 0.16593\n",
      "Epoch 300/2000, Avg Loss: 0.42996, Reg Loss: 0.16138\n",
      "Epoch 400/2000, Avg Loss: 0.40147, Reg Loss: 0.15736\n",
      "Epoch 500/2000, Avg Loss: 0.37002, Reg Loss: 0.16759\n",
      "Epoch 600/2000, Avg Loss: 0.35048, Reg Loss: 0.16558\n",
      "Epoch 700/2000, Avg Loss: 0.32911, Reg Loss: 0.16020\n",
      "Epoch 800/2000, Avg Loss: 0.33944, Reg Loss: 0.15812\n",
      "Epoch 900/2000, Avg Loss: 0.30879, Reg Loss: 0.15557\n",
      "Epoch 1000/2000, Avg Loss: 0.31203, Reg Loss: 0.15688\n",
      "Epoch 1100/2000, Avg Loss: 0.29547, Reg Loss: 0.15426\n",
      "Epoch 1200/2000, Avg Loss: 0.29537, Reg Loss: 0.15413\n",
      "Epoch 1300/2000, Avg Loss: 0.29902, Reg Loss: 0.15423\n",
      "Epoch 1400/2000, Avg Loss: 0.28726, Reg Loss: 0.15380\n",
      "Epoch 1500/2000, Avg Loss: 0.28821, Reg Loss: 0.15381\n",
      "Epoch 1600/2000, Avg Loss: 0.28355, Reg Loss: 0.15311\n",
      "Epoch 1700/2000, Avg Loss: 0.28213, Reg Loss: 0.15163\n",
      "Epoch 1800/2000, Avg Loss: 0.28637, Reg Loss: 0.15153\n",
      "Epoch 1900/2000, Avg Loss: 0.28066, Reg Loss: 0.15058\n",
      "Epoch 2000/2000, Avg Loss: 0.28237, Reg Loss: 0.15079\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.8702, G-Mean = 0.7735, MCC = 0.5632, F1-score = 0.7121\n",
      "      SMOTEBoost: AUC = 0.8705, G-Mean = 0.7684, MCC = 0.5560, F1-score = 0.7070\n",
      "      RUSBoost: AUC = 0.7858, G-Mean = 0.6061, MCC = 0.3486, F1-score = 0.6100\n",
      "      OUBoost: AUC = 0.8774, G-Mean = 0.7651, MCC = 0.5542, F1-score = 0.7036\n",
      "      SVM: AUC = 0.8664, G-Mean = 0.7063, MCC = 0.5199, F1-score = 0.6435\n",
      "      SMOTE: AUC = 0.8649, G-Mean = 0.7719, MCC = 0.5268, F1-score = 0.7048\n",
      "      ADASYN: AUC = 0.8556, G-Mean = 0.7680, MCC = 0.5170, F1-score = 0.7028\n",
      "      bSMOTE: AUC = 0.8459, G-Mean = 0.7658, MCC = 0.5167, F1-score = 0.7023\n",
      "      ROS: AUC = 0.8689, G-Mean = 0.8012, MCC = 0.5843, F1-score = 0.7387\n",
      "      MWMOTE: AUC = 0.8514, G-Mean = 0.7722, MCC = 0.5257, F1-score = 0.7040\n",
      "      Trans(Direct): AUC = 0.8640, G-Mean = 0.7753, MCC = 0.5331, F1-score = 0.7078\n",
      "  Fold 4/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.49029, Reg Loss: 0.16671\n",
      "Epoch 200/2000, Avg Loss: 0.45209, Reg Loss: 0.16622\n",
      "Epoch 300/2000, Avg Loss: 0.41801, Reg Loss: 0.16287\n",
      "Epoch 400/2000, Avg Loss: 0.41510, Reg Loss: 0.16802\n",
      "Epoch 500/2000, Avg Loss: 0.37555, Reg Loss: 0.16400\n",
      "Epoch 600/2000, Avg Loss: 0.37253, Reg Loss: 0.16411\n",
      "Epoch 700/2000, Avg Loss: 0.39901, Reg Loss: 0.16358\n",
      "Epoch 800/2000, Avg Loss: 0.35861, Reg Loss: 0.16160\n",
      "Epoch 900/2000, Avg Loss: 0.34200, Reg Loss: 0.16153\n",
      "Epoch 1000/2000, Avg Loss: 0.35253, Reg Loss: 0.16261\n",
      "Epoch 1100/2000, Avg Loss: 0.32044, Reg Loss: 0.16085\n",
      "Epoch 1200/2000, Avg Loss: 0.31170, Reg Loss: 0.15915\n",
      "Epoch 1300/2000, Avg Loss: 0.29497, Reg Loss: 0.15783\n",
      "Epoch 1400/2000, Avg Loss: 0.29599, Reg Loss: 0.15529\n",
      "Epoch 1500/2000, Avg Loss: 0.29309, Reg Loss: 0.15612\n",
      "Epoch 1600/2000, Avg Loss: 0.28628, Reg Loss: 0.15367\n",
      "Epoch 1700/2000, Avg Loss: 0.28342, Reg Loss: 0.15340\n",
      "Epoch 1800/2000, Avg Loss: 0.28111, Reg Loss: 0.15331\n",
      "Epoch 1900/2000, Avg Loss: 0.27781, Reg Loss: 0.15294\n",
      "Epoch 2000/2000, Avg Loss: 0.27188, Reg Loss: 0.15290\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.8608, G-Mean = 0.7627, MCC = 0.5544, F1-score = 0.7008\n",
      "      SMOTEBoost: AUC = 0.8600, G-Mean = 0.7538, MCC = 0.5244, F1-score = 0.6877\n",
      "      RUSBoost: AUC = 0.7947, G-Mean = 0.5976, MCC = 0.3469, F1-score = 0.6087\n",
      "      OUBoost: AUC = 0.8656, G-Mean = 0.7564, MCC = 0.5314, F1-score = 0.6913\n",
      "      SVM: AUC = 0.8552, G-Mean = 0.6861, MCC = 0.4813, F1-score = 0.6159\n",
      "      SMOTE: AUC = 0.8565, G-Mean = 0.7594, MCC = 0.5025, F1-score = 0.6896\n",
      "      ADASYN: AUC = 0.8524, G-Mean = 0.7691, MCC = 0.5195, F1-score = 0.7040\n",
      "      bSMOTE: AUC = 0.8409, G-Mean = 0.7618, MCC = 0.5097, F1-score = 0.6984\n",
      "      ROS: AUC = 0.8620, G-Mean = 0.7765, MCC = 0.5372, F1-score = 0.7092\n",
      "      MWMOTE: AUC = 0.8454, G-Mean = 0.7662, MCC = 0.5135, F1-score = 0.6973\n",
      "      Trans(Direct): AUC = 0.8557, G-Mean = 0.7666, MCC = 0.5157, F1-score = 0.6975\n",
      "  Fold 5/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.51154, Reg Loss: 0.17804\n",
      "Epoch 200/2000, Avg Loss: 0.42092, Reg Loss: 0.17381\n",
      "Epoch 300/2000, Avg Loss: 0.44262, Reg Loss: 0.17094\n",
      "Epoch 400/2000, Avg Loss: 0.39654, Reg Loss: 0.17009\n",
      "Epoch 500/2000, Avg Loss: 0.36961, Reg Loss: 0.17104\n",
      "Epoch 600/2000, Avg Loss: 0.35641, Reg Loss: 0.16492\n",
      "Epoch 700/2000, Avg Loss: 0.32624, Reg Loss: 0.16509\n",
      "Epoch 800/2000, Avg Loss: 0.30295, Reg Loss: 0.16495\n",
      "Epoch 900/2000, Avg Loss: 0.32071, Reg Loss: 0.16839\n",
      "Epoch 1000/2000, Avg Loss: 0.29831, Reg Loss: 0.16571\n",
      "Epoch 1100/2000, Avg Loss: 0.28898, Reg Loss: 0.16710\n",
      "Epoch 1200/2000, Avg Loss: 0.27529, Reg Loss: 0.16510\n",
      "Epoch 1300/2000, Avg Loss: 0.28764, Reg Loss: 0.16512\n",
      "Epoch 1400/2000, Avg Loss: 0.26545, Reg Loss: 0.16374\n",
      "Epoch 1500/2000, Avg Loss: 0.25675, Reg Loss: 0.16174\n",
      "Epoch 1600/2000, Avg Loss: 0.25499, Reg Loss: 0.15965\n",
      "Epoch 1700/2000, Avg Loss: 0.25114, Reg Loss: 0.15865\n",
      "Epoch 1800/2000, Avg Loss: 0.25202, Reg Loss: 0.15844\n",
      "Epoch 1900/2000, Avg Loss: 0.26666, Reg Loss: 0.16284\n",
      "Epoch 2000/2000, Avg Loss: 0.25780, Reg Loss: 0.15821\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.8536, G-Mean = 0.7282, MCC = 0.5226, F1-score = 0.6606\n",
      "      SMOTEBoost: AUC = 0.8569, G-Mean = 0.7502, MCC = 0.5204, F1-score = 0.6835\n",
      "      RUSBoost: AUC = 0.7967, G-Mean = 0.6086, MCC = 0.3562, F1-score = 0.6135\n",
      "      OUBoost: AUC = 0.8637, G-Mean = 0.7479, MCC = 0.5195, F1-score = 0.6810\n",
      "      SVM: AUC = 0.8502, G-Mean = 0.6656, MCC = 0.4569, F1-score = 0.5903\n",
      "      SMOTE: AUC = 0.8461, G-Mean = 0.7435, MCC = 0.4765, F1-score = 0.6702\n",
      "      ADASYN: AUC = 0.8431, G-Mean = 0.7576, MCC = 0.4973, F1-score = 0.6899\n",
      "      bSMOTE: AUC = 0.8287, G-Mean = 0.7498, MCC = 0.4854, F1-score = 0.6833\n",
      "      ROS: AUC = 0.8563, G-Mean = 0.7614, MCC = 0.5110, F1-score = 0.6910\n",
      "      MWMOTE: AUC = 0.8387, G-Mean = 0.7513, MCC = 0.4876, F1-score = 0.6793\n",
      "      Trans(Direct): AUC = 0.8501, G-Mean = 0.7516, MCC = 0.4893, F1-score = 0.6794\n",
      "  Fold 6/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.49178, Reg Loss: 0.16494\n",
      "Epoch 200/2000, Avg Loss: 0.45704, Reg Loss: 0.16352\n",
      "Epoch 300/2000, Avg Loss: 0.40068, Reg Loss: 0.15816\n",
      "Epoch 400/2000, Avg Loss: 0.37059, Reg Loss: 0.16288\n",
      "Epoch 500/2000, Avg Loss: 0.34775, Reg Loss: 0.16471\n",
      "Epoch 600/2000, Avg Loss: 0.32526, Reg Loss: 0.16383\n",
      "Epoch 700/2000, Avg Loss: 0.31153, Reg Loss: 0.16293\n",
      "Epoch 800/2000, Avg Loss: 0.31113, Reg Loss: 0.16166\n",
      "Epoch 900/2000, Avg Loss: 0.29218, Reg Loss: 0.16140\n",
      "Epoch 1000/2000, Avg Loss: 0.29154, Reg Loss: 0.16060\n",
      "Epoch 1100/2000, Avg Loss: 0.28436, Reg Loss: 0.16014\n",
      "Epoch 1200/2000, Avg Loss: 0.27402, Reg Loss: 0.15922\n",
      "Epoch 1300/2000, Avg Loss: 0.29267, Reg Loss: 0.16164\n",
      "Epoch 1400/2000, Avg Loss: 0.26813, Reg Loss: 0.15743\n",
      "Epoch 1500/2000, Avg Loss: 0.26497, Reg Loss: 0.15736\n",
      "Epoch 1600/2000, Avg Loss: 0.26568, Reg Loss: 0.15596\n",
      "Epoch 1700/2000, Avg Loss: 0.26621, Reg Loss: 0.15511\n",
      "Epoch 1800/2000, Avg Loss: 0.26101, Reg Loss: 0.15384\n",
      "Epoch 1900/2000, Avg Loss: 0.27861, Reg Loss: 0.15880\n",
      "Epoch 2000/2000, Avg Loss: 0.25795, Reg Loss: 0.15481\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.8508, G-Mean = 0.7234, MCC = 0.5132, F1-score = 0.6547\n",
      "      SMOTEBoost: AUC = 0.8528, G-Mean = 0.7534, MCC = 0.5218, F1-score = 0.6865\n",
      "      RUSBoost: AUC = 0.8037, G-Mean = 0.6106, MCC = 0.3616, F1-score = 0.6157\n",
      "      OUBoost: AUC = 0.8590, G-Mean = 0.7480, MCC = 0.5181, F1-score = 0.6807\n",
      "      SVM: AUC = 0.8521, G-Mean = 0.6712, MCC = 0.4585, F1-score = 0.5961\n",
      "      SMOTE: AUC = 0.8460, G-Mean = 0.7446, MCC = 0.4779, F1-score = 0.6715\n",
      "      ADASYN: AUC = 0.8447, G-Mean = 0.7612, MCC = 0.5044, F1-score = 0.6936\n",
      "      bSMOTE: AUC = 0.8358, G-Mean = 0.7563, MCC = 0.4982, F1-score = 0.6901\n",
      "      ROS: AUC = 0.8562, G-Mean = 0.7659, MCC = 0.5195, F1-score = 0.6965\n",
      "      MWMOTE: AUC = 0.8425, G-Mean = 0.7480, MCC = 0.4815, F1-score = 0.6753\n",
      "      Trans(Direct): AUC = 0.8517, G-Mean = 0.7545, MCC = 0.4942, F1-score = 0.6829\n",
      "  Fold 7/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.50037, Reg Loss: 0.17253\n",
      "Epoch 200/2000, Avg Loss: 0.43042, Reg Loss: 0.17228\n",
      "Epoch 300/2000, Avg Loss: 0.37697, Reg Loss: 0.16961\n",
      "Epoch 400/2000, Avg Loss: 0.37400, Reg Loss: 0.16828\n",
      "Epoch 500/2000, Avg Loss: 0.34648, Reg Loss: 0.16434\n",
      "Epoch 600/2000, Avg Loss: 0.33788, Reg Loss: 0.16469\n",
      "Epoch 700/2000, Avg Loss: 0.33501, Reg Loss: 0.16396\n",
      "Epoch 800/2000, Avg Loss: 0.31463, Reg Loss: 0.16091\n",
      "Epoch 900/2000, Avg Loss: 0.30396, Reg Loss: 0.15961\n",
      "Epoch 1000/2000, Avg Loss: 0.29560, Reg Loss: 0.15879\n",
      "Epoch 1100/2000, Avg Loss: 0.29574, Reg Loss: 0.15717\n",
      "Epoch 1200/2000, Avg Loss: 0.29893, Reg Loss: 0.15745\n",
      "Epoch 1300/2000, Avg Loss: 0.29506, Reg Loss: 0.15843\n",
      "Epoch 1400/2000, Avg Loss: 0.29093, Reg Loss: 0.15979\n",
      "Epoch 1500/2000, Avg Loss: 0.29468, Reg Loss: 0.16346\n",
      "Epoch 1600/2000, Avg Loss: 0.28573, Reg Loss: 0.16102\n",
      "Epoch 1700/2000, Avg Loss: 0.29202, Reg Loss: 0.16099\n",
      "Epoch 1800/2000, Avg Loss: 0.31082, Reg Loss: 0.16621\n",
      "Epoch 1900/2000, Avg Loss: 0.27450, Reg Loss: 0.15823\n",
      "Epoch 2000/2000, Avg Loss: 0.27900, Reg Loss: 0.15731\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.8424, G-Mean = 0.7314, MCC = 0.5188, F1-score = 0.6632\n",
      "      SMOTEBoost: AUC = 0.8417, G-Mean = 0.7489, MCC = 0.5087, F1-score = 0.6804\n",
      "      RUSBoost: AUC = 0.8076, G-Mean = 0.6002, MCC = 0.3541, F1-score = 0.6122\n",
      "      OUBoost: AUC = 0.8511, G-Mean = 0.7511, MCC = 0.5197, F1-score = 0.6837\n",
      "      SVM: AUC = 0.8416, G-Mean = 0.6780, MCC = 0.4578, F1-score = 0.6026\n",
      "      SMOTE: AUC = 0.8340, G-Mean = 0.7396, MCC = 0.4671, F1-score = 0.6663\n",
      "      ADASYN: AUC = 0.8348, G-Mean = 0.7612, MCC = 0.5049, F1-score = 0.6940\n",
      "      bSMOTE: AUC = 0.8254, G-Mean = 0.7514, MCC = 0.4890, F1-score = 0.6853\n",
      "      ROS: AUC = 0.8451, G-Mean = 0.7619, MCC = 0.5106, F1-score = 0.6923\n",
      "      MWMOTE: AUC = 0.8314, G-Mean = 0.7419, MCC = 0.4697, F1-score = 0.6697\n",
      "      Trans(Direct): AUC = 0.8392, G-Mean = 0.7491, MCC = 0.4833, F1-score = 0.6776\n",
      "  Fold 8/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.49124, Reg Loss: 0.15696\n",
      "Epoch 200/2000, Avg Loss: 0.45805, Reg Loss: 0.15459\n",
      "Epoch 300/2000, Avg Loss: 0.39703, Reg Loss: 0.15607\n",
      "Epoch 400/2000, Avg Loss: 0.36929, Reg Loss: 0.15699\n",
      "Epoch 500/2000, Avg Loss: 0.36286, Reg Loss: 0.15672\n",
      "Epoch 600/2000, Avg Loss: 0.33344, Reg Loss: 0.15362\n",
      "Epoch 700/2000, Avg Loss: 0.30567, Reg Loss: 0.15224\n",
      "Epoch 800/2000, Avg Loss: 0.29700, Reg Loss: 0.15032\n",
      "Epoch 900/2000, Avg Loss: 0.29584, Reg Loss: 0.15025\n",
      "Epoch 1000/2000, Avg Loss: 0.27495, Reg Loss: 0.14825\n",
      "Epoch 1100/2000, Avg Loss: 0.27126, Reg Loss: 0.15017\n",
      "Epoch 1200/2000, Avg Loss: 0.26975, Reg Loss: 0.14838\n",
      "Epoch 1300/2000, Avg Loss: 0.27390, Reg Loss: 0.14877\n",
      "Epoch 1400/2000, Avg Loss: 0.27318, Reg Loss: 0.15224\n",
      "Epoch 1500/2000, Avg Loss: 0.25619, Reg Loss: 0.14818\n",
      "Epoch 1600/2000, Avg Loss: 0.25730, Reg Loss: 0.14820\n",
      "Epoch 1700/2000, Avg Loss: 0.24777, Reg Loss: 0.14488\n",
      "Epoch 1800/2000, Avg Loss: 0.24896, Reg Loss: 0.14609\n",
      "Epoch 1900/2000, Avg Loss: 0.25868, Reg Loss: 0.14517\n",
      "Epoch 2000/2000, Avg Loss: 0.24234, Reg Loss: 0.14278\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.8356, G-Mean = 0.7254, MCC = 0.5001, F1-score = 0.6544\n",
      "      SMOTEBoost: AUC = 0.8379, G-Mean = 0.7423, MCC = 0.4920, F1-score = 0.6717\n",
      "      RUSBoost: AUC = 0.8053, G-Mean = 0.5987, MCC = 0.3539, F1-score = 0.6109\n",
      "      OUBoost: AUC = 0.8450, G-Mean = 0.7430, MCC = 0.4998, F1-score = 0.6728\n",
      "      SVM: AUC = 0.8374, G-Mean = 0.6841, MCC = 0.4620, F1-score = 0.6089\n",
      "      SMOTE: AUC = 0.8293, G-Mean = 0.7342, MCC = 0.4557, F1-score = 0.6592\n",
      "      ADASYN: AUC = 0.8294, G-Mean = 0.7541, MCC = 0.4906, F1-score = 0.6852\n",
      "      bSMOTE: AUC = 0.8193, G-Mean = 0.7416, MCC = 0.4695, F1-score = 0.6739\n",
      "      ROS: AUC = 0.8391, G-Mean = 0.7561, MCC = 0.4981, F1-score = 0.6849\n",
      "      MWMOTE: AUC = 0.8247, G-Mean = 0.7337, MCC = 0.4529, F1-score = 0.6598\n",
      "      Trans(Direct): AUC = 0.8357, G-Mean = 0.7399, MCC = 0.4648, F1-score = 0.6667\n",
      "  Fold 9/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.44423, Reg Loss: 0.16947\n",
      "Epoch 200/2000, Avg Loss: 0.40344, Reg Loss: 0.16793\n",
      "Epoch 300/2000, Avg Loss: 0.38378, Reg Loss: 0.16596\n",
      "Epoch 400/2000, Avg Loss: 0.36539, Reg Loss: 0.16720\n",
      "Epoch 500/2000, Avg Loss: 0.35566, Reg Loss: 0.16460\n",
      "Epoch 600/2000, Avg Loss: 0.31868, Reg Loss: 0.16446\n",
      "Epoch 700/2000, Avg Loss: 0.31517, Reg Loss: 0.16815\n",
      "Epoch 800/2000, Avg Loss: 0.28827, Reg Loss: 0.16508\n",
      "Epoch 900/2000, Avg Loss: 0.27207, Reg Loss: 0.16231\n",
      "Epoch 1000/2000, Avg Loss: 0.26635, Reg Loss: 0.16001\n",
      "Epoch 1100/2000, Avg Loss: 0.26252, Reg Loss: 0.15917\n",
      "Epoch 1200/2000, Avg Loss: 0.25597, Reg Loss: 0.15916\n",
      "Epoch 1300/2000, Avg Loss: 0.25045, Reg Loss: 0.15752\n",
      "Epoch 1400/2000, Avg Loss: 0.27421, Reg Loss: 0.15800\n",
      "Epoch 1500/2000, Avg Loss: 0.24766, Reg Loss: 0.15782\n",
      "Epoch 1600/2000, Avg Loss: 0.24601, Reg Loss: 0.15667\n",
      "Epoch 1700/2000, Avg Loss: 0.25589, Reg Loss: 0.15560\n",
      "Epoch 1800/2000, Avg Loss: 0.23102, Reg Loss: 0.15287\n",
      "Epoch 1900/2000, Avg Loss: 0.22937, Reg Loss: 0.15230\n",
      "Epoch 2000/2000, Avg Loss: 0.22792, Reg Loss: 0.15056\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.8282, G-Mean = 0.7177, MCC = 0.4829, F1-score = 0.6439\n",
      "      SMOTEBoost: AUC = 0.8284, G-Mean = 0.7361, MCC = 0.4775, F1-score = 0.6633\n",
      "      RUSBoost: AUC = 0.7963, G-Mean = 0.5997, MCC = 0.3521, F1-score = 0.6097\n",
      "      OUBoost: AUC = 0.8346, G-Mean = 0.7359, MCC = 0.4866, F1-score = 0.6634\n",
      "      SVM: AUC = 0.8287, G-Mean = 0.6820, MCC = 0.4518, F1-score = 0.6047\n",
      "      SMOTE: AUC = 0.8221, G-Mean = 0.7288, MCC = 0.4451, F1-score = 0.6523\n",
      "      ADASYN: AUC = 0.8215, G-Mean = 0.7455, MCC = 0.4739, F1-score = 0.6742\n",
      "      bSMOTE: AUC = 0.8110, G-Mean = 0.7355, MCC = 0.4568, F1-score = 0.6657\n",
      "      ROS: AUC = 0.8316, G-Mean = 0.7471, MCC = 0.4814, F1-score = 0.6735\n",
      "      MWMOTE: AUC = 0.8176, G-Mean = 0.7273, MCC = 0.4403, F1-score = 0.6516\n",
      "      Trans(Direct): AUC = 0.8300, G-Mean = 0.7329, MCC = 0.4509, F1-score = 0.6577\n",
      "  Fold 10/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.52287, Reg Loss: 0.16755\n",
      "Epoch 200/2000, Avg Loss: 0.45582, Reg Loss: 0.16294\n",
      "Epoch 300/2000, Avg Loss: 0.43303, Reg Loss: 0.16458\n",
      "Epoch 400/2000, Avg Loss: 0.39144, Reg Loss: 0.16374\n",
      "Epoch 500/2000, Avg Loss: 0.39683, Reg Loss: 0.16221\n",
      "Epoch 600/2000, Avg Loss: 0.36528, Reg Loss: 0.15928\n",
      "Epoch 700/2000, Avg Loss: 0.36185, Reg Loss: 0.15996\n",
      "Epoch 800/2000, Avg Loss: 0.35703, Reg Loss: 0.16022\n",
      "Epoch 900/2000, Avg Loss: 0.34211, Reg Loss: 0.15993\n",
      "Epoch 1000/2000, Avg Loss: 0.33919, Reg Loss: 0.16076\n",
      "Epoch 1100/2000, Avg Loss: 0.32341, Reg Loss: 0.16151\n",
      "Epoch 1200/2000, Avg Loss: 0.31594, Reg Loss: 0.16108\n",
      "Epoch 1300/2000, Avg Loss: 0.30922, Reg Loss: 0.16011\n",
      "Epoch 1400/2000, Avg Loss: 0.39476, Reg Loss: 0.16931\n",
      "Epoch 1500/2000, Avg Loss: 0.32528, Reg Loss: 0.15921\n",
      "Epoch 1600/2000, Avg Loss: 0.29738, Reg Loss: 0.15777\n",
      "Epoch 1700/2000, Avg Loss: 0.29381, Reg Loss: 0.15586\n",
      "Epoch 1800/2000, Avg Loss: 0.28628, Reg Loss: 0.15604\n",
      "Epoch 1900/2000, Avg Loss: 0.28285, Reg Loss: 0.15617\n",
      "Epoch 2000/2000, Avg Loss: 0.27495, Reg Loss: 0.15417\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.8301, G-Mean = 0.7213, MCC = 0.4854, F1-score = 0.6474\n",
      "      SMOTEBoost: AUC = 0.8246, G-Mean = 0.7319, MCC = 0.4668, F1-score = 0.6583\n",
      "      RUSBoost: AUC = 0.7841, G-Mean = 0.5597, MCC = 0.3288, F1-score = 0.6008\n",
      "      OUBoost: AUC = 0.8332, G-Mean = 0.7349, MCC = 0.4818, F1-score = 0.6614\n",
      "      SVM: AUC = 0.8285, G-Mean = 0.6834, MCC = 0.4497, F1-score = 0.6055\n",
      "      SMOTE: AUC = 0.8219, G-Mean = 0.7324, MCC = 0.4515, F1-score = 0.6560\n",
      "      ADASYN: AUC = 0.8209, G-Mean = 0.7445, MCC = 0.4717, F1-score = 0.6723\n",
      "      bSMOTE: AUC = 0.8114, G-Mean = 0.7384, MCC = 0.4620, F1-score = 0.6681\n",
      "      ROS: AUC = 0.8305, G-Mean = 0.7449, MCC = 0.4764, F1-score = 0.6705\n",
      "      MWMOTE: AUC = 0.8173, G-Mean = 0.7291, MCC = 0.4437, F1-score = 0.6531\n",
      "      Trans(Direct): AUC = 0.8289, G-Mean = 0.7350, MCC = 0.4546, F1-score = 0.6598\n",
      "\n",
      "Starting experiment 5/10\n",
      "  Fold 1/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.52525, Reg Loss: 0.15684\n",
      "Epoch 200/2000, Avg Loss: 0.43575, Reg Loss: 0.16528\n",
      "Epoch 300/2000, Avg Loss: 0.39148, Reg Loss: 0.16402\n",
      "Epoch 400/2000, Avg Loss: 0.34217, Reg Loss: 0.16156\n",
      "Epoch 500/2000, Avg Loss: 0.34256, Reg Loss: 0.16141\n",
      "Epoch 600/2000, Avg Loss: 0.30543, Reg Loss: 0.16348\n",
      "Epoch 700/2000, Avg Loss: 0.28765, Reg Loss: 0.15998\n",
      "Epoch 800/2000, Avg Loss: 0.28226, Reg Loss: 0.16039\n",
      "Epoch 900/2000, Avg Loss: 0.27665, Reg Loss: 0.16013\n",
      "Epoch 1000/2000, Avg Loss: 0.26795, Reg Loss: 0.15824\n",
      "Epoch 1100/2000, Avg Loss: 0.28713, Reg Loss: 0.15883\n",
      "Epoch 1200/2000, Avg Loss: 0.26428, Reg Loss: 0.15872\n",
      "Epoch 1300/2000, Avg Loss: 0.26379, Reg Loss: 0.15731\n",
      "Epoch 1400/2000, Avg Loss: 0.26007, Reg Loss: 0.15736\n",
      "Epoch 1500/2000, Avg Loss: 0.25798, Reg Loss: 0.15750\n",
      "Epoch 1600/2000, Avg Loss: 0.25412, Reg Loss: 0.15713\n",
      "Epoch 1700/2000, Avg Loss: 0.25151, Reg Loss: 0.15703\n",
      "Epoch 1800/2000, Avg Loss: 0.26001, Reg Loss: 0.15711\n",
      "Epoch 1900/2000, Avg Loss: 0.24560, Reg Loss: 0.15654\n",
      "Epoch 2000/2000, Avg Loss: 0.24632, Reg Loss: 0.15556\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.7919, G-Mean = 0.6394, MCC = 0.4286, F1-score = 0.5581\n",
      "      SMOTEBoost: AUC = 0.8074, G-Mean = 0.6749, MCC = 0.3869, F1-score = 0.5882\n",
      "      RUSBoost: AUC = 0.8267, G-Mean = 0.6526, MCC = 0.3933, F1-score = 0.6329\n",
      "      OUBoost: AUC = 0.8185, G-Mean = 0.6831, MCC = 0.4632, F1-score = 0.6087\n",
      "      SVM: AUC = 0.8022, G-Mean = 0.5477, MCC = 0.2887, F1-score = 0.4390\n",
      "      SMOTE: AUC = 0.8274, G-Mean = 0.7221, MCC = 0.4992, F1-score = 0.6531\n",
      "      ADASYN: AUC = 0.8207, G-Mean = 0.7221, MCC = 0.4992, F1-score = 0.6531\n",
      "      bSMOTE: AUC = 0.8281, G-Mean = 0.7444, MCC = 0.5313, F1-score = 0.6800\n",
      "      ROS: AUC = 0.8193, G-Mean = 0.6912, MCC = 0.4389, F1-score = 0.6122\n",
      "      MWMOTE: AUC = 0.8207, G-Mean = 0.7444, MCC = 0.5313, F1-score = 0.6800\n",
      "      Trans(Direct): AUC = 0.8007, G-Mean = 0.7055, MCC = 0.4457, F1-score = 0.6275\n",
      "  Fold 2/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.45160, Reg Loss: 0.15741\n",
      "Epoch 200/2000, Avg Loss: 0.40567, Reg Loss: 0.15933\n",
      "Epoch 300/2000, Avg Loss: 0.39091, Reg Loss: 0.16177\n",
      "Epoch 400/2000, Avg Loss: 0.34036, Reg Loss: 0.15832\n",
      "Epoch 500/2000, Avg Loss: 0.38038, Reg Loss: 0.16640\n",
      "Epoch 600/2000, Avg Loss: 0.30974, Reg Loss: 0.15369\n",
      "Epoch 700/2000, Avg Loss: 0.29275, Reg Loss: 0.14940\n",
      "Epoch 800/2000, Avg Loss: 0.28353, Reg Loss: 0.14864\n",
      "Epoch 900/2000, Avg Loss: 0.27464, Reg Loss: 0.14711\n",
      "Epoch 1000/2000, Avg Loss: 0.27975, Reg Loss: 0.14840\n",
      "Epoch 1100/2000, Avg Loss: 0.26502, Reg Loss: 0.14707\n",
      "Epoch 1200/2000, Avg Loss: 0.26471, Reg Loss: 0.14745\n",
      "Epoch 1300/2000, Avg Loss: 0.25421, Reg Loss: 0.14589\n",
      "Epoch 1400/2000, Avg Loss: 0.25737, Reg Loss: 0.15267\n",
      "Epoch 1500/2000, Avg Loss: 0.26061, Reg Loss: 0.15205\n",
      "Epoch 1600/2000, Avg Loss: 0.29250, Reg Loss: 0.15729\n",
      "Epoch 1700/2000, Avg Loss: 0.24586, Reg Loss: 0.15305\n",
      "Epoch 1800/2000, Avg Loss: 0.23762, Reg Loss: 0.14909\n",
      "Epoch 1900/2000, Avg Loss: 0.23258, Reg Loss: 0.14628\n",
      "Epoch 2000/2000, Avg Loss: 0.23821, Reg Loss: 0.14867\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.7756, G-Mean = 0.6553, MCC = 0.3892, F1-score = 0.5700\n",
      "      SMOTEBoost: AUC = 0.7898, G-Mean = 0.6923, MCC = 0.3946, F1-score = 0.6116\n",
      "      RUSBoost: AUC = 0.7911, G-Mean = 0.5985, MCC = 0.3353, F1-score = 0.6072\n",
      "      OUBoost: AUC = 0.8026, G-Mean = 0.6975, MCC = 0.4404, F1-score = 0.6201\n",
      "      SVM: AUC = 0.7870, G-Mean = 0.6113, MCC = 0.3378, F1-score = 0.5136\n",
      "      SMOTE: AUC = 0.8039, G-Mean = 0.7193, MCC = 0.4585, F1-score = 0.6496\n",
      "      ADASYN: AUC = 0.7981, G-Mean = 0.6999, MCC = 0.4217, F1-score = 0.6296\n",
      "      bSMOTE: AUC = 0.7970, G-Mean = 0.7249, MCC = 0.4650, F1-score = 0.6582\n",
      "      ROS: AUC = 0.7959, G-Mean = 0.6812, MCC = 0.3836, F1-score = 0.6030\n",
      "      MWMOTE: AUC = 0.7863, G-Mean = 0.7110, MCC = 0.4378, F1-score = 0.6430\n",
      "      Trans(Direct): AUC = 0.8002, G-Mean = 0.7249, MCC = 0.4590, F1-score = 0.6522\n",
      "  Fold 3/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.47045, Reg Loss: 0.16254\n",
      "Epoch 200/2000, Avg Loss: 0.41292, Reg Loss: 0.16366\n",
      "Epoch 300/2000, Avg Loss: 0.37522, Reg Loss: 0.16249\n",
      "Epoch 400/2000, Avg Loss: 0.37272, Reg Loss: 0.16192\n",
      "Epoch 500/2000, Avg Loss: 0.34656, Reg Loss: 0.16374\n",
      "Epoch 600/2000, Avg Loss: 0.32601, Reg Loss: 0.16254\n",
      "Epoch 700/2000, Avg Loss: 0.30690, Reg Loss: 0.16318\n",
      "Epoch 800/2000, Avg Loss: 0.30188, Reg Loss: 0.16246\n",
      "Epoch 900/2000, Avg Loss: 0.30313, Reg Loss: 0.16008\n",
      "Epoch 1000/2000, Avg Loss: 0.29029, Reg Loss: 0.16025\n",
      "Epoch 1100/2000, Avg Loss: 0.28399, Reg Loss: 0.15785\n",
      "Epoch 1200/2000, Avg Loss: 0.27919, Reg Loss: 0.15626\n",
      "Epoch 1300/2000, Avg Loss: 0.28644, Reg Loss: 0.15555\n",
      "Epoch 1400/2000, Avg Loss: 0.28660, Reg Loss: 0.15735\n",
      "Epoch 1500/2000, Avg Loss: 0.28779, Reg Loss: 0.15632\n",
      "Epoch 1600/2000, Avg Loss: 0.27434, Reg Loss: 0.15486\n",
      "Epoch 1700/2000, Avg Loss: 0.27021, Reg Loss: 0.15688\n",
      "Epoch 1800/2000, Avg Loss: 0.26674, Reg Loss: 0.15453\n",
      "Epoch 1900/2000, Avg Loss: 0.26413, Reg Loss: 0.15266\n",
      "Epoch 2000/2000, Avg Loss: 0.26384, Reg Loss: 0.15445\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.7963, G-Mean = 0.6833, MCC = 0.4217, F1-score = 0.6022\n",
      "      SMOTEBoost: AUC = 0.8016, G-Mean = 0.6785, MCC = 0.3717, F1-score = 0.6086\n",
      "      RUSBoost: AUC = 0.7977, G-Mean = 0.5768, MCC = 0.3006, F1-score = 0.5930\n",
      "      OUBoost: AUC = 0.8078, G-Mean = 0.6980, MCC = 0.4261, F1-score = 0.6260\n",
      "      SVM: AUC = 0.8017, G-Mean = 0.6433, MCC = 0.3904, F1-score = 0.5552\n",
      "      SMOTE: AUC = 0.7986, G-Mean = 0.7168, MCC = 0.4419, F1-score = 0.6442\n",
      "      ADASYN: AUC = 0.7998, G-Mean = 0.7089, MCC = 0.4319, F1-score = 0.6419\n",
      "      bSMOTE: AUC = 0.7911, G-Mean = 0.7055, MCC = 0.4185, F1-score = 0.6378\n",
      "      ROS: AUC = 0.7985, G-Mean = 0.6907, MCC = 0.3899, F1-score = 0.6136\n",
      "      MWMOTE: AUC = 0.7896, G-Mean = 0.7235, MCC = 0.4509, F1-score = 0.6545\n",
      "      Trans(Direct): AUC = 0.8080, G-Mean = 0.7407, MCC = 0.4815, F1-score = 0.6707\n",
      "  Fold 4/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.44194, Reg Loss: 0.16360\n",
      "Epoch 200/2000, Avg Loss: 0.42321, Reg Loss: 0.15974\n",
      "Epoch 300/2000, Avg Loss: 0.39666, Reg Loss: 0.15987\n",
      "Epoch 400/2000, Avg Loss: 0.36868, Reg Loss: 0.16300\n",
      "Epoch 500/2000, Avg Loss: 0.35262, Reg Loss: 0.15897\n",
      "Epoch 600/2000, Avg Loss: 0.38217, Reg Loss: 0.15931\n",
      "Epoch 700/2000, Avg Loss: 0.31782, Reg Loss: 0.15964\n",
      "Epoch 800/2000, Avg Loss: 0.31026, Reg Loss: 0.15820\n",
      "Epoch 900/2000, Avg Loss: 0.30104, Reg Loss: 0.15694\n",
      "Epoch 1000/2000, Avg Loss: 0.31270, Reg Loss: 0.16114\n",
      "Epoch 1100/2000, Avg Loss: 0.30173, Reg Loss: 0.15976\n",
      "Epoch 1200/2000, Avg Loss: 0.29167, Reg Loss: 0.15817\n",
      "Epoch 1300/2000, Avg Loss: 0.27475, Reg Loss: 0.15619\n",
      "Epoch 1400/2000, Avg Loss: 0.29362, Reg Loss: 0.16063\n",
      "Epoch 1500/2000, Avg Loss: 0.26911, Reg Loss: 0.15531\n",
      "Epoch 1600/2000, Avg Loss: 0.26940, Reg Loss: 0.15349\n",
      "Epoch 1700/2000, Avg Loss: 0.25824, Reg Loss: 0.15180\n",
      "Epoch 1800/2000, Avg Loss: 0.25939, Reg Loss: 0.15065\n",
      "Epoch 1900/2000, Avg Loss: 0.27751, Reg Loss: 0.15421\n",
      "Epoch 2000/2000, Avg Loss: 0.25444, Reg Loss: 0.15038\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.8086, G-Mean = 0.6853, MCC = 0.4260, F1-score = 0.6047\n",
      "      SMOTEBoost: AUC = 0.8062, G-Mean = 0.6863, MCC = 0.3862, F1-score = 0.6139\n",
      "      RUSBoost: AUC = 0.7888, G-Mean = 0.5600, MCC = 0.3082, F1-score = 0.5931\n",
      "      OUBoost: AUC = 0.8123, G-Mean = 0.6963, MCC = 0.4293, F1-score = 0.6226\n",
      "      SVM: AUC = 0.8176, G-Mean = 0.6452, MCC = 0.3929, F1-score = 0.5577\n",
      "      SMOTE: AUC = 0.8119, G-Mean = 0.7180, MCC = 0.4388, F1-score = 0.6442\n",
      "      ADASYN: AUC = 0.8109, G-Mean = 0.7120, MCC = 0.4313, F1-score = 0.6425\n",
      "      bSMOTE: AUC = 0.8011, G-Mean = 0.7071, MCC = 0.4160, F1-score = 0.6367\n",
      "      ROS: AUC = 0.8126, G-Mean = 0.6976, MCC = 0.4058, F1-score = 0.6206\n",
      "      MWMOTE: AUC = 0.8019, G-Mean = 0.7229, MCC = 0.4481, F1-score = 0.6516\n",
      "      Trans(Direct): AUC = 0.8212, G-Mean = 0.7406, MCC = 0.4770, F1-score = 0.6697\n",
      "  Fold 5/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.48840, Reg Loss: 0.16602\n",
      "Epoch 200/2000, Avg Loss: 0.45491, Reg Loss: 0.16934\n",
      "Epoch 300/2000, Avg Loss: 0.44479, Reg Loss: 0.16414\n",
      "Epoch 400/2000, Avg Loss: 0.36894, Reg Loss: 0.16701\n",
      "Epoch 500/2000, Avg Loss: 0.34230, Reg Loss: 0.16035\n",
      "Epoch 600/2000, Avg Loss: 0.32568, Reg Loss: 0.16182\n",
      "Epoch 700/2000, Avg Loss: 0.34828, Reg Loss: 0.16658\n",
      "Epoch 800/2000, Avg Loss: 0.29954, Reg Loss: 0.16031\n",
      "Epoch 900/2000, Avg Loss: 0.28618, Reg Loss: 0.15603\n",
      "Epoch 1000/2000, Avg Loss: 0.27978, Reg Loss: 0.15540\n",
      "Epoch 1100/2000, Avg Loss: 0.27600, Reg Loss: 0.15580\n",
      "Epoch 1200/2000, Avg Loss: 0.27361, Reg Loss: 0.15429\n",
      "Epoch 1300/2000, Avg Loss: 0.27041, Reg Loss: 0.15400\n",
      "Epoch 1400/2000, Avg Loss: 0.26992, Reg Loss: 0.15370\n",
      "Epoch 1500/2000, Avg Loss: 0.26539, Reg Loss: 0.15063\n",
      "Epoch 1600/2000, Avg Loss: 0.26943, Reg Loss: 0.14969\n",
      "Epoch 1700/2000, Avg Loss: 0.26649, Reg Loss: 0.14811\n",
      "Epoch 1800/2000, Avg Loss: 0.24804, Reg Loss: 0.14613\n",
      "Epoch 1900/2000, Avg Loss: 0.25259, Reg Loss: 0.14599\n",
      "Epoch 2000/2000, Avg Loss: 0.24608, Reg Loss: 0.14652\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.8096, G-Mean = 0.6961, MCC = 0.4381, F1-score = 0.6171\n",
      "      SMOTEBoost: AUC = 0.8079, G-Mean = 0.7008, MCC = 0.4084, F1-score = 0.6288\n",
      "      RUSBoost: AUC = 0.7901, G-Mean = 0.5625, MCC = 0.3149, F1-score = 0.5954\n",
      "      OUBoost: AUC = 0.8136, G-Mean = 0.7091, MCC = 0.4448, F1-score = 0.6360\n",
      "      SVM: AUC = 0.8197, G-Mean = 0.6693, MCC = 0.4269, F1-score = 0.5873\n",
      "      SMOTE: AUC = 0.8110, G-Mean = 0.7276, MCC = 0.4533, F1-score = 0.6550\n",
      "      ADASYN: AUC = 0.8116, G-Mean = 0.7228, MCC = 0.4474, F1-score = 0.6537\n",
      "      bSMOTE: AUC = 0.8025, G-Mean = 0.7145, MCC = 0.4273, F1-score = 0.6447\n",
      "      ROS: AUC = 0.8160, G-Mean = 0.7078, MCC = 0.4201, F1-score = 0.6320\n",
      "      MWMOTE: AUC = 0.8052, G-Mean = 0.7336, MCC = 0.4648, F1-score = 0.6632\n",
      "      Trans(Direct): AUC = 0.8226, G-Mean = 0.7406, MCC = 0.4743, F1-score = 0.6691\n",
      "  Fold 6/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.50414, Reg Loss: 0.17635\n",
      "Epoch 200/2000, Avg Loss: 0.47961, Reg Loss: 0.17294\n",
      "Epoch 300/2000, Avg Loss: 0.44460, Reg Loss: 0.17663\n",
      "Epoch 400/2000, Avg Loss: 0.40866, Reg Loss: 0.17358\n",
      "Epoch 500/2000, Avg Loss: 0.40988, Reg Loss: 0.17039\n",
      "Epoch 600/2000, Avg Loss: 0.40359, Reg Loss: 0.17479\n",
      "Epoch 700/2000, Avg Loss: 0.38432, Reg Loss: 0.17576\n",
      "Epoch 800/2000, Avg Loss: 0.33993, Reg Loss: 0.17243\n",
      "Epoch 900/2000, Avg Loss: 0.33519, Reg Loss: 0.17030\n",
      "Epoch 1000/2000, Avg Loss: 0.32885, Reg Loss: 0.17190\n",
      "Epoch 1100/2000, Avg Loss: 0.32210, Reg Loss: 0.17059\n",
      "Epoch 1200/2000, Avg Loss: 0.31222, Reg Loss: 0.16932\n",
      "Epoch 1300/2000, Avg Loss: 0.42671, Reg Loss: 0.17615\n",
      "Epoch 1400/2000, Avg Loss: 0.32711, Reg Loss: 0.17114\n",
      "Epoch 1500/2000, Avg Loss: 0.32080, Reg Loss: 0.17118\n",
      "Epoch 1600/2000, Avg Loss: 0.30566, Reg Loss: 0.16974\n",
      "Epoch 1700/2000, Avg Loss: 0.29169, Reg Loss: 0.16585\n",
      "Epoch 1800/2000, Avg Loss: 0.29401, Reg Loss: 0.16495\n",
      "Epoch 1900/2000, Avg Loss: 0.29726, Reg Loss: 0.16519\n",
      "Epoch 2000/2000, Avg Loss: 0.28921, Reg Loss: 0.16369\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.8085, G-Mean = 0.6998, MCC = 0.4407, F1-score = 0.6212\n",
      "      SMOTEBoost: AUC = 0.8230, G-Mean = 0.7151, MCC = 0.4324, F1-score = 0.6442\n",
      "      RUSBoost: AUC = 0.7814, G-Mean = 0.5504, MCC = 0.3150, F1-score = 0.5940\n",
      "      OUBoost: AUC = 0.8203, G-Mean = 0.7126, MCC = 0.4478, F1-score = 0.6391\n",
      "      SVM: AUC = 0.8254, G-Mean = 0.6704, MCC = 0.4280, F1-score = 0.5887\n",
      "      SMOTE: AUC = 0.8209, G-Mean = 0.7357, MCC = 0.4664, F1-score = 0.6641\n",
      "      ADASYN: AUC = 0.8254, G-Mean = 0.7357, MCC = 0.4697, F1-score = 0.6678\n",
      "      bSMOTE: AUC = 0.8190, G-Mean = 0.7342, MCC = 0.4648, F1-score = 0.6666\n",
      "      ROS: AUC = 0.8262, G-Mean = 0.7232, MCC = 0.4469, F1-score = 0.6497\n",
      "      MWMOTE: AUC = 0.8198, G-Mean = 0.7501, MCC = 0.4942, F1-score = 0.6817\n",
      "      Trans(Direct): AUC = 0.8299, G-Mean = 0.7466, MCC = 0.4839, F1-score = 0.6758\n",
      "  Fold 7/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.47150, Reg Loss: 0.15900\n",
      "Epoch 200/2000, Avg Loss: 0.41414, Reg Loss: 0.17027\n",
      "Epoch 300/2000, Avg Loss: 0.36302, Reg Loss: 0.16619\n",
      "Epoch 400/2000, Avg Loss: 0.34525, Reg Loss: 0.16329\n",
      "Epoch 500/2000, Avg Loss: 0.34646, Reg Loss: 0.16065\n",
      "Epoch 600/2000, Avg Loss: 0.29195, Reg Loss: 0.16012\n",
      "Epoch 700/2000, Avg Loss: 0.27577, Reg Loss: 0.15900\n",
      "Epoch 800/2000, Avg Loss: 0.27561, Reg Loss: 0.15868\n",
      "Epoch 900/2000, Avg Loss: 0.27263, Reg Loss: 0.15996\n",
      "Epoch 1000/2000, Avg Loss: 0.25710, Reg Loss: 0.15784\n",
      "Epoch 1100/2000, Avg Loss: 0.25220, Reg Loss: 0.15842\n",
      "Epoch 1200/2000, Avg Loss: 0.25146, Reg Loss: 0.15748\n",
      "Epoch 1300/2000, Avg Loss: 0.25049, Reg Loss: 0.15599\n",
      "Epoch 1400/2000, Avg Loss: 0.25315, Reg Loss: 0.15504\n",
      "Epoch 1500/2000, Avg Loss: 0.25694, Reg Loss: 0.15546\n",
      "Epoch 1600/2000, Avg Loss: 0.24514, Reg Loss: 0.15368\n",
      "Epoch 1700/2000, Avg Loss: 0.23956, Reg Loss: 0.15326\n",
      "Epoch 1800/2000, Avg Loss: 0.23722, Reg Loss: 0.15236\n",
      "Epoch 1900/2000, Avg Loss: 0.24014, Reg Loss: 0.15283\n",
      "Epoch 2000/2000, Avg Loss: 0.24514, Reg Loss: 0.15325\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.8156, G-Mean = 0.7055, MCC = 0.4473, F1-score = 0.6277\n",
      "      SMOTEBoost: AUC = 0.8237, G-Mean = 0.7169, MCC = 0.4331, F1-score = 0.6459\n",
      "      RUSBoost: AUC = 0.7756, G-Mean = 0.5377, MCC = 0.2922, F1-score = 0.5862\n",
      "      OUBoost: AUC = 0.8226, G-Mean = 0.7152, MCC = 0.4471, F1-score = 0.6414\n",
      "      SVM: AUC = 0.8317, G-Mean = 0.6809, MCC = 0.4428, F1-score = 0.6018\n",
      "      SMOTE: AUC = 0.8261, G-Mean = 0.7433, MCC = 0.4801, F1-score = 0.6731\n",
      "      ADASYN: AUC = 0.8297, G-Mean = 0.7449, MCC = 0.4856, F1-score = 0.6779\n",
      "      bSMOTE: AUC = 0.8219, G-Mean = 0.7393, MCC = 0.4761, F1-score = 0.6734\n",
      "      ROS: AUC = 0.8323, G-Mean = 0.7267, MCC = 0.4512, F1-score = 0.6537\n",
      "      MWMOTE: AUC = 0.8250, G-Mean = 0.7533, MCC = 0.4988, F1-score = 0.6854\n",
      "      Trans(Direct): AUC = 0.8333, G-Mean = 0.7468, MCC = 0.4829, F1-score = 0.6761\n",
      "  Fold 8/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.46618, Reg Loss: 0.16602\n",
      "Epoch 200/2000, Avg Loss: 0.42324, Reg Loss: 0.16328\n",
      "Epoch 300/2000, Avg Loss: 0.43236, Reg Loss: 0.16227\n",
      "Epoch 400/2000, Avg Loss: 0.37002, Reg Loss: 0.16582\n",
      "Epoch 500/2000, Avg Loss: 0.38225, Reg Loss: 0.16629\n",
      "Epoch 600/2000, Avg Loss: 0.33811, Reg Loss: 0.16108\n",
      "Epoch 700/2000, Avg Loss: 0.32598, Reg Loss: 0.16192\n",
      "Epoch 800/2000, Avg Loss: 0.32403, Reg Loss: 0.16226\n",
      "Epoch 900/2000, Avg Loss: 0.34695, Reg Loss: 0.16845\n",
      "Epoch 1000/2000, Avg Loss: 0.31651, Reg Loss: 0.16399\n",
      "Epoch 1100/2000, Avg Loss: 0.30991, Reg Loss: 0.16366\n",
      "Epoch 1200/2000, Avg Loss: 0.30596, Reg Loss: 0.16401\n",
      "Epoch 1300/2000, Avg Loss: 0.32801, Reg Loss: 0.16433\n",
      "Epoch 1400/2000, Avg Loss: 0.29766, Reg Loss: 0.16412\n",
      "Epoch 1500/2000, Avg Loss: 0.30077, Reg Loss: 0.16079\n",
      "Epoch 1600/2000, Avg Loss: 0.28782, Reg Loss: 0.16075\n",
      "Epoch 1700/2000, Avg Loss: 0.29470, Reg Loss: 0.16112\n",
      "Epoch 1800/2000, Avg Loss: 0.27958, Reg Loss: 0.15866\n",
      "Epoch 1900/2000, Avg Loss: 0.28332, Reg Loss: 0.15904\n",
      "Epoch 2000/2000, Avg Loss: 0.27894, Reg Loss: 0.15842\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.8111, G-Mean = 0.6961, MCC = 0.4354, F1-score = 0.6159\n",
      "      SMOTEBoost: AUC = 0.8158, G-Mean = 0.7153, MCC = 0.4361, F1-score = 0.6433\n",
      "      RUSBoost: AUC = 0.7637, G-Mean = 0.5420, MCC = 0.2978, F1-score = 0.5873\n",
      "      OUBoost: AUC = 0.8165, G-Mean = 0.7063, MCC = 0.4426, F1-score = 0.6310\n",
      "      SVM: AUC = 0.8138, G-Mean = 0.6601, MCC = 0.4124, F1-score = 0.5753\n",
      "      SMOTE: AUC = 0.8113, G-Mean = 0.7285, MCC = 0.4558, F1-score = 0.6540\n",
      "      ADASYN: AUC = 0.8121, G-Mean = 0.7274, MCC = 0.4514, F1-score = 0.6556\n",
      "      bSMOTE: AUC = 0.8057, G-Mean = 0.7225, MCC = 0.4431, F1-score = 0.6518\n",
      "      ROS: AUC = 0.8134, G-Mean = 0.7126, MCC = 0.4239, F1-score = 0.6356\n",
      "      MWMOTE: AUC = 0.8106, G-Mean = 0.7351, MCC = 0.4665, F1-score = 0.6622\n",
      "      Trans(Direct): AUC = 0.8166, G-Mean = 0.7265, MCC = 0.4480, F1-score = 0.6504\n",
      "  Fold 9/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.47699, Reg Loss: 0.15681\n",
      "Epoch 200/2000, Avg Loss: 0.42478, Reg Loss: 0.15982\n",
      "Epoch 300/2000, Avg Loss: 0.38748, Reg Loss: 0.16152\n",
      "Epoch 400/2000, Avg Loss: 0.36548, Reg Loss: 0.15997\n",
      "Epoch 500/2000, Avg Loss: 0.36223, Reg Loss: 0.16096\n",
      "Epoch 600/2000, Avg Loss: 0.35103, Reg Loss: 0.15853\n",
      "Epoch 700/2000, Avg Loss: 0.34448, Reg Loss: 0.15769\n",
      "Epoch 800/2000, Avg Loss: 0.34278, Reg Loss: 0.15803\n",
      "Epoch 900/2000, Avg Loss: 0.34356, Reg Loss: 0.15724\n",
      "Epoch 1000/2000, Avg Loss: 0.33957, Reg Loss: 0.15906\n",
      "Epoch 1100/2000, Avg Loss: 0.32146, Reg Loss: 0.15631\n",
      "Epoch 1200/2000, Avg Loss: 0.31142, Reg Loss: 0.15940\n",
      "Epoch 1300/2000, Avg Loss: 0.29200, Reg Loss: 0.15738\n",
      "Epoch 1400/2000, Avg Loss: 0.28408, Reg Loss: 0.15560\n",
      "Epoch 1500/2000, Avg Loss: 0.28505, Reg Loss: 0.15578\n",
      "Epoch 1600/2000, Avg Loss: 0.27903, Reg Loss: 0.15564\n",
      "Epoch 1700/2000, Avg Loss: 0.29194, Reg Loss: 0.15615\n",
      "Epoch 1800/2000, Avg Loss: 0.26917, Reg Loss: 0.15377\n",
      "Epoch 1900/2000, Avg Loss: 0.26633, Reg Loss: 0.15227\n",
      "Epoch 2000/2000, Avg Loss: 0.26558, Reg Loss: 0.15146\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.8158, G-Mean = 0.7037, MCC = 0.4446, F1-score = 0.6242\n",
      "      SMOTEBoost: AUC = 0.8163, G-Mean = 0.7164, MCC = 0.4356, F1-score = 0.6434\n",
      "      RUSBoost: AUC = 0.7671, G-Mean = 0.5225, MCC = 0.2821, F1-score = 0.5812\n",
      "      OUBoost: AUC = 0.8167, G-Mean = 0.7095, MCC = 0.4447, F1-score = 0.6336\n",
      "      SVM: AUC = 0.8218, G-Mean = 0.6782, MCC = 0.4387, F1-score = 0.5969\n",
      "      SMOTE: AUC = 0.8162, G-Mean = 0.7323, MCC = 0.4609, F1-score = 0.6578\n",
      "      ADASYN: AUC = 0.8168, G-Mean = 0.7302, MCC = 0.4567, F1-score = 0.6591\n",
      "      bSMOTE: AUC = 0.8087, G-Mean = 0.7253, MCC = 0.4472, F1-score = 0.6546\n",
      "      ROS: AUC = 0.8204, G-Mean = 0.7202, MCC = 0.4385, F1-score = 0.6446\n",
      "      MWMOTE: AUC = 0.8155, G-Mean = 0.7358, MCC = 0.4661, F1-score = 0.6627\n",
      "      Trans(Direct): AUC = 0.8236, G-Mean = 0.7313, MCC = 0.4558, F1-score = 0.6557\n",
      "  Fold 10/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.49287, Reg Loss: 0.15487\n",
      "Epoch 200/2000, Avg Loss: 0.39934, Reg Loss: 0.16331\n",
      "Epoch 300/2000, Avg Loss: 0.35328, Reg Loss: 0.16227\n",
      "Epoch 400/2000, Avg Loss: 0.31155, Reg Loss: 0.16079\n",
      "Epoch 500/2000, Avg Loss: 0.29760, Reg Loss: 0.15915\n",
      "Epoch 600/2000, Avg Loss: 0.27931, Reg Loss: 0.15693\n",
      "Epoch 700/2000, Avg Loss: 0.26876, Reg Loss: 0.15503\n",
      "Epoch 800/2000, Avg Loss: 0.25593, Reg Loss: 0.15040\n",
      "Epoch 900/2000, Avg Loss: 0.25698, Reg Loss: 0.15327\n",
      "Epoch 1000/2000, Avg Loss: 0.24426, Reg Loss: 0.14888\n",
      "Epoch 1100/2000, Avg Loss: 0.24286, Reg Loss: 0.14769\n",
      "Epoch 1200/2000, Avg Loss: 0.24306, Reg Loss: 0.14745\n",
      "Epoch 1300/2000, Avg Loss: 0.23928, Reg Loss: 0.14632\n",
      "Epoch 1400/2000, Avg Loss: 0.23878, Reg Loss: 0.14656\n",
      "Epoch 1500/2000, Avg Loss: 0.23622, Reg Loss: 0.14473\n",
      "Epoch 1600/2000, Avg Loss: 0.23766, Reg Loss: 0.14466\n",
      "Epoch 1700/2000, Avg Loss: 0.23826, Reg Loss: 0.14491\n",
      "Epoch 1800/2000, Avg Loss: 0.28827, Reg Loss: 0.15715\n",
      "Epoch 1900/2000, Avg Loss: 0.27082, Reg Loss: 0.15258\n",
      "Epoch 2000/2000, Avg Loss: 0.26835, Reg Loss: 0.15491\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.8234, G-Mean = 0.7137, MCC = 0.4601, F1-score = 0.6359\n",
      "      SMOTEBoost: AUC = 0.8142, G-Mean = 0.7173, MCC = 0.4352, F1-score = 0.6435\n",
      "      RUSBoost: AUC = 0.7660, G-Mean = 0.4980, MCC = 0.2618, F1-score = 0.5746\n",
      "      OUBoost: AUC = 0.8166, G-Mean = 0.7090, MCC = 0.4407, F1-score = 0.6321\n",
      "      SVM: AUC = 0.8290, G-Mean = 0.6871, MCC = 0.4528, F1-score = 0.6080\n",
      "      SMOTE: AUC = 0.8226, G-Mean = 0.7355, MCC = 0.4657, F1-score = 0.6610\n",
      "      ADASYN: AUC = 0.8223, G-Mean = 0.7345, MCC = 0.4633, F1-score = 0.6632\n",
      "      bSMOTE: AUC = 0.8130, G-Mean = 0.7280, MCC = 0.4507, F1-score = 0.6568\n",
      "      ROS: AUC = 0.8266, G-Mean = 0.7236, MCC = 0.4434, F1-score = 0.6479\n",
      "      MWMOTE: AUC = 0.8218, G-Mean = 0.7387, MCC = 0.4703, F1-score = 0.6654\n",
      "      Trans(Direct): AUC = 0.8302, G-Mean = 0.7344, MCC = 0.4605, F1-score = 0.6590\n",
      "\n",
      "Starting experiment 6/10\n",
      "  Fold 1/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.48961, Reg Loss: 0.16199\n",
      "Epoch 200/2000, Avg Loss: 0.44388, Reg Loss: 0.16171\n",
      "Epoch 300/2000, Avg Loss: 0.37659, Reg Loss: 0.16713\n",
      "Epoch 400/2000, Avg Loss: 0.36230, Reg Loss: 0.17019\n",
      "Epoch 500/2000, Avg Loss: 0.32358, Reg Loss: 0.16694\n",
      "Epoch 600/2000, Avg Loss: 0.32762, Reg Loss: 0.16561\n",
      "Epoch 700/2000, Avg Loss: 0.30853, Reg Loss: 0.16519\n",
      "Epoch 800/2000, Avg Loss: 0.30795, Reg Loss: 0.16127\n",
      "Epoch 900/2000, Avg Loss: 0.29881, Reg Loss: 0.16572\n",
      "Epoch 1000/2000, Avg Loss: 0.29215, Reg Loss: 0.16399\n",
      "Epoch 1100/2000, Avg Loss: 0.27672, Reg Loss: 0.16260\n",
      "Epoch 1200/2000, Avg Loss: 0.26814, Reg Loss: 0.16294\n",
      "Epoch 1300/2000, Avg Loss: 0.25952, Reg Loss: 0.15942\n",
      "Epoch 1400/2000, Avg Loss: 0.29666, Reg Loss: 0.16531\n",
      "Epoch 1500/2000, Avg Loss: 0.27369, Reg Loss: 0.16017\n",
      "Epoch 1600/2000, Avg Loss: 0.27478, Reg Loss: 0.16283\n",
      "Epoch 1700/2000, Avg Loss: 0.25352, Reg Loss: 0.15861\n",
      "Epoch 1800/2000, Avg Loss: 0.25270, Reg Loss: 0.15775\n",
      "Epoch 1900/2000, Avg Loss: 0.25139, Reg Loss: 0.15655\n",
      "Epoch 2000/2000, Avg Loss: 0.24785, Reg Loss: 0.15636\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.8130, G-Mean = 0.7444, MCC = 0.5313, F1-score = 0.6800\n",
      "      SMOTEBoost: AUC = 0.7956, G-Mean = 0.6678, MCC = 0.4056, F1-score = 0.5833\n",
      "      RUSBoost: AUC = 0.8148, G-Mean = 0.6526, MCC = 0.3933, F1-score = 0.6329\n",
      "      OUBoost: AUC = 0.8089, G-Mean = 0.6254, MCC = 0.3658, F1-score = 0.5333\n",
      "      SVM: AUC = 0.8393, G-Mean = 0.6907, MCC = 0.4944, F1-score = 0.6222\n",
      "      SMOTE: AUC = 0.8385, G-Mean = 0.7097, MCC = 0.4296, F1-score = 0.6296\n",
      "      ADASYN: AUC = 0.8459, G-Mean = 0.7503, MCC = 0.4960, F1-score = 0.6786\n",
      "      bSMOTE: AUC = 0.8407, G-Mean = 0.7688, MCC = 0.5185, F1-score = 0.7000\n",
      "      ROS: AUC = 0.8504, G-Mean = 0.7185, MCC = 0.4537, F1-score = 0.6415\n",
      "      MWMOTE: AUC = 0.8600, G-Mean = 0.7409, MCC = 0.4733, F1-score = 0.6667\n",
      "      Trans(Direct): AUC = 0.8348, G-Mean = 0.6826, MCC = 0.3617, F1-score = 0.5965\n",
      "  Fold 2/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.48295, Reg Loss: 0.15020\n",
      "Epoch 200/2000, Avg Loss: 0.43716, Reg Loss: 0.14775\n",
      "Epoch 300/2000, Avg Loss: 0.38165, Reg Loss: 0.14956\n",
      "Epoch 400/2000, Avg Loss: 0.35146, Reg Loss: 0.14798\n",
      "Epoch 500/2000, Avg Loss: 0.33517, Reg Loss: 0.14723\n",
      "Epoch 600/2000, Avg Loss: 0.30472, Reg Loss: 0.14656\n",
      "Epoch 700/2000, Avg Loss: 0.28635, Reg Loss: 0.14594\n",
      "Epoch 800/2000, Avg Loss: 0.28137, Reg Loss: 0.14442\n",
      "Epoch 900/2000, Avg Loss: 0.27487, Reg Loss: 0.14314\n",
      "Epoch 1000/2000, Avg Loss: 0.25581, Reg Loss: 0.14308\n",
      "Epoch 1100/2000, Avg Loss: 0.24757, Reg Loss: 0.14129\n",
      "Epoch 1200/2000, Avg Loss: 0.24571, Reg Loss: 0.13979\n",
      "Epoch 1300/2000, Avg Loss: 0.24692, Reg Loss: 0.14239\n",
      "Epoch 1400/2000, Avg Loss: 0.23988, Reg Loss: 0.13862\n",
      "Epoch 1500/2000, Avg Loss: 0.23576, Reg Loss: 0.13761\n",
      "Epoch 1600/2000, Avg Loss: 0.23848, Reg Loss: 0.13749\n",
      "Epoch 1700/2000, Avg Loss: 0.23382, Reg Loss: 0.13724\n",
      "Epoch 1800/2000, Avg Loss: 0.22833, Reg Loss: 0.13674\n",
      "Epoch 1900/2000, Avg Loss: 0.22608, Reg Loss: 0.13576\n",
      "Epoch 2000/2000, Avg Loss: 0.22508, Reg Loss: 0.13425\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.8080, G-Mean = 0.7121, MCC = 0.4520, F1-score = 0.6363\n",
      "      SMOTEBoost: AUC = 0.7906, G-Mean = 0.6990, MCC = 0.4241, F1-score = 0.6195\n",
      "      RUSBoost: AUC = 0.7356, G-Mean = 0.5474, MCC = 0.2640, F1-score = 0.5831\n",
      "      OUBoost: AUC = 0.8030, G-Mean = 0.6878, MCC = 0.4309, F1-score = 0.6060\n",
      "      SVM: AUC = 0.8230, G-Mean = 0.6869, MCC = 0.4788, F1-score = 0.6155\n",
      "      SMOTE: AUC = 0.8217, G-Mean = 0.6915, MCC = 0.3849, F1-score = 0.6079\n",
      "      ADASYN: AUC = 0.8133, G-Mean = 0.7263, MCC = 0.4459, F1-score = 0.6496\n",
      "      bSMOTE: AUC = 0.8096, G-Mean = 0.7445, MCC = 0.4705, F1-score = 0.6726\n",
      "      ROS: AUC = 0.8304, G-Mean = 0.7105, MCC = 0.4247, F1-score = 0.6311\n",
      "      MWMOTE: AUC = 0.8130, G-Mean = 0.7163, MCC = 0.4285, F1-score = 0.6369\n",
      "      Trans(Direct): AUC = 0.8093, G-Mean = 0.6685, MCC = 0.3301, F1-score = 0.5816\n",
      "  Fold 3/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.53129, Reg Loss: 0.15187\n",
      "Epoch 200/2000, Avg Loss: 0.51935, Reg Loss: 0.15393\n",
      "Epoch 300/2000, Avg Loss: 0.47242, Reg Loss: 0.15316\n",
      "Epoch 400/2000, Avg Loss: 0.42423, Reg Loss: 0.15446\n",
      "Epoch 500/2000, Avg Loss: 0.41969, Reg Loss: 0.15601\n",
      "Epoch 600/2000, Avg Loss: 0.39132, Reg Loss: 0.15161\n",
      "Epoch 700/2000, Avg Loss: 0.37874, Reg Loss: 0.14994\n",
      "Epoch 800/2000, Avg Loss: 0.38338, Reg Loss: 0.15136\n",
      "Epoch 900/2000, Avg Loss: 0.35818, Reg Loss: 0.15161\n",
      "Epoch 1000/2000, Avg Loss: 0.35368, Reg Loss: 0.15240\n",
      "Epoch 1100/2000, Avg Loss: 0.35157, Reg Loss: 0.15161\n",
      "Epoch 1200/2000, Avg Loss: 0.34492, Reg Loss: 0.15115\n",
      "Epoch 1300/2000, Avg Loss: 0.34521, Reg Loss: 0.15234\n",
      "Epoch 1400/2000, Avg Loss: 0.36623, Reg Loss: 0.15484\n",
      "Epoch 1500/2000, Avg Loss: 0.34079, Reg Loss: 0.15386\n",
      "Epoch 1600/2000, Avg Loss: 0.32597, Reg Loss: 0.15413\n",
      "Epoch 1700/2000, Avg Loss: 0.33588, Reg Loss: 0.15368\n",
      "Epoch 1800/2000, Avg Loss: 0.29957, Reg Loss: 0.15206\n",
      "Epoch 1900/2000, Avg Loss: 0.29065, Reg Loss: 0.15136\n",
      "Epoch 2000/2000, Avg Loss: 0.29321, Reg Loss: 0.15088\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.8106, G-Mean = 0.7014, MCC = 0.4255, F1-score = 0.6217\n",
      "      SMOTEBoost: AUC = 0.7937, G-Mean = 0.7033, MCC = 0.4189, F1-score = 0.6241\n",
      "      RUSBoost: AUC = 0.7384, G-Mean = 0.4958, MCC = 0.2369, F1-score = 0.5712\n",
      "      OUBoost: AUC = 0.7974, G-Mean = 0.7023, MCC = 0.4377, F1-score = 0.6224\n",
      "      SVM: AUC = 0.8222, G-Mean = 0.6856, MCC = 0.4567, F1-score = 0.6103\n",
      "      SMOTE: AUC = 0.8142, G-Mean = 0.7139, MCC = 0.4225, F1-score = 0.6348\n",
      "      ADASYN: AUC = 0.8032, G-Mean = 0.7266, MCC = 0.4430, F1-score = 0.6518\n",
      "      bSMOTE: AUC = 0.7998, G-Mean = 0.7346, MCC = 0.4584, F1-score = 0.6674\n",
      "      ROS: AUC = 0.8163, G-Mean = 0.7102, MCC = 0.4172, F1-score = 0.6324\n",
      "      MWMOTE: AUC = 0.7970, G-Mean = 0.7020, MCC = 0.3967, F1-score = 0.6213\n",
      "      Trans(Direct): AUC = 0.8030, G-Mean = 0.7086, MCC = 0.4074, F1-score = 0.6301\n",
      "  Fold 4/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.46033, Reg Loss: 0.16230\n",
      "Epoch 200/2000, Avg Loss: 0.37981, Reg Loss: 0.16485\n",
      "Epoch 300/2000, Avg Loss: 0.35223, Reg Loss: 0.15998\n",
      "Epoch 400/2000, Avg Loss: 0.34934, Reg Loss: 0.15821\n",
      "Epoch 500/2000, Avg Loss: 0.31441, Reg Loss: 0.15519\n",
      "Epoch 600/2000, Avg Loss: 0.30456, Reg Loss: 0.15273\n",
      "Epoch 700/2000, Avg Loss: 0.32120, Reg Loss: 0.15717\n",
      "Epoch 800/2000, Avg Loss: 0.31458, Reg Loss: 0.15446\n",
      "Epoch 900/2000, Avg Loss: 0.28983, Reg Loss: 0.15683\n",
      "Epoch 1000/2000, Avg Loss: 0.27408, Reg Loss: 0.15446\n",
      "Epoch 1100/2000, Avg Loss: 0.26556, Reg Loss: 0.15254\n",
      "Epoch 1200/2000, Avg Loss: 0.28378, Reg Loss: 0.15251\n",
      "Epoch 1300/2000, Avg Loss: 0.26144, Reg Loss: 0.15201\n",
      "Epoch 1400/2000, Avg Loss: 0.24937, Reg Loss: 0.15126\n",
      "Epoch 1500/2000, Avg Loss: 0.24837, Reg Loss: 0.14940\n",
      "Epoch 1600/2000, Avg Loss: 0.25014, Reg Loss: 0.14820\n",
      "Epoch 1700/2000, Avg Loss: 0.26701, Reg Loss: 0.14781\n",
      "Epoch 1800/2000, Avg Loss: 0.24193, Reg Loss: 0.14631\n",
      "Epoch 1900/2000, Avg Loss: 0.24457, Reg Loss: 0.14767\n",
      "Epoch 2000/2000, Avg Loss: 0.24418, Reg Loss: 0.14664\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.8204, G-Mean = 0.7008, MCC = 0.4358, F1-score = 0.6225\n",
      "      SMOTEBoost: AUC = 0.8090, G-Mean = 0.7198, MCC = 0.4692, F1-score = 0.6490\n",
      "      RUSBoost: AUC = 0.7363, G-Mean = 0.5246, MCC = 0.2407, F1-score = 0.5703\n",
      "      OUBoost: AUC = 0.8139, G-Mean = 0.7133, MCC = 0.4756, F1-score = 0.6407\n",
      "      SVM: AUC = 0.8202, G-Mean = 0.6741, MCC = 0.4497, F1-score = 0.5973\n",
      "      SMOTE: AUC = 0.8219, G-Mean = 0.7180, MCC = 0.4326, F1-score = 0.6397\n",
      "      ADASYN: AUC = 0.8117, G-Mean = 0.7302, MCC = 0.4506, F1-score = 0.6555\n",
      "      bSMOTE: AUC = 0.8096, G-Mean = 0.7338, MCC = 0.4566, F1-score = 0.6644\n",
      "      ROS: AUC = 0.8180, G-Mean = 0.7079, MCC = 0.4145, F1-score = 0.6288\n",
      "      MWMOTE: AUC = 0.8087, G-Mean = 0.7093, MCC = 0.4103, F1-score = 0.6298\n",
      "      Trans(Direct): AUC = 0.8069, G-Mean = 0.7014, MCC = 0.3987, F1-score = 0.6208\n",
      "  Fold 5/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.47089, Reg Loss: 0.16664\n",
      "Epoch 200/2000, Avg Loss: 0.45359, Reg Loss: 0.16893\n",
      "Epoch 300/2000, Avg Loss: 0.39504, Reg Loss: 0.16426\n",
      "Epoch 400/2000, Avg Loss: 0.33787, Reg Loss: 0.16245\n",
      "Epoch 500/2000, Avg Loss: 0.38972, Reg Loss: 0.16441\n",
      "Epoch 600/2000, Avg Loss: 0.34239, Reg Loss: 0.16230\n",
      "Epoch 700/2000, Avg Loss: 0.33788, Reg Loss: 0.15877\n",
      "Epoch 800/2000, Avg Loss: 0.30454, Reg Loss: 0.15567\n",
      "Epoch 900/2000, Avg Loss: 0.30213, Reg Loss: 0.15685\n",
      "Epoch 1000/2000, Avg Loss: 0.29045, Reg Loss: 0.15622\n",
      "Epoch 1100/2000, Avg Loss: 0.28601, Reg Loss: 0.15548\n",
      "Epoch 1200/2000, Avg Loss: 0.28333, Reg Loss: 0.15566\n",
      "Epoch 1300/2000, Avg Loss: 0.29189, Reg Loss: 0.15457\n",
      "Epoch 1400/2000, Avg Loss: 0.29119, Reg Loss: 0.15617\n",
      "Epoch 1500/2000, Avg Loss: 0.28340, Reg Loss: 0.15401\n",
      "Epoch 1600/2000, Avg Loss: 0.27011, Reg Loss: 0.15312\n",
      "Epoch 1700/2000, Avg Loss: 0.27338, Reg Loss: 0.15248\n",
      "Epoch 1800/2000, Avg Loss: 0.26482, Reg Loss: 0.15008\n",
      "Epoch 1900/2000, Avg Loss: 0.27799, Reg Loss: 0.15232\n",
      "Epoch 2000/2000, Avg Loss: 0.26222, Reg Loss: 0.14934\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.8180, G-Mean = 0.6973, MCC = 0.4311, F1-score = 0.6180\n",
      "      SMOTEBoost: AUC = 0.8150, G-Mean = 0.7316, MCC = 0.4834, F1-score = 0.6615\n",
      "      RUSBoost: AUC = 0.7507, G-Mean = 0.4752, MCC = 0.2092, F1-score = 0.5613\n",
      "      OUBoost: AUC = 0.8157, G-Mean = 0.7284, MCC = 0.4929, F1-score = 0.6574\n",
      "      SVM: AUC = 0.8241, G-Mean = 0.6830, MCC = 0.4505, F1-score = 0.6061\n",
      "      SMOTE: AUC = 0.8282, G-Mean = 0.7318, MCC = 0.4565, F1-score = 0.6560\n",
      "      ADASYN: AUC = 0.8179, G-Mean = 0.7415, MCC = 0.4709, F1-score = 0.6687\n",
      "      bSMOTE: AUC = 0.8119, G-Mean = 0.7359, MCC = 0.4597, F1-score = 0.6669\n",
      "      ROS: AUC = 0.8204, G-Mean = 0.7139, MCC = 0.4230, F1-score = 0.6364\n",
      "      MWMOTE: AUC = 0.8121, G-Mean = 0.7227, MCC = 0.4346, F1-score = 0.6458\n",
      "      Trans(Direct): AUC = 0.8151, G-Mean = 0.7143, MCC = 0.4213, F1-score = 0.6363\n",
      "  Fold 6/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.50613, Reg Loss: 0.17284\n",
      "Epoch 200/2000, Avg Loss: 0.44740, Reg Loss: 0.17102\n",
      "Epoch 300/2000, Avg Loss: 0.40289, Reg Loss: 0.16858\n",
      "Epoch 400/2000, Avg Loss: 0.37727, Reg Loss: 0.17428\n",
      "Epoch 500/2000, Avg Loss: 0.36028, Reg Loss: 0.16903\n",
      "Epoch 600/2000, Avg Loss: 0.36627, Reg Loss: 0.16686\n",
      "Epoch 700/2000, Avg Loss: 0.33856, Reg Loss: 0.16787\n",
      "Epoch 800/2000, Avg Loss: 0.32019, Reg Loss: 0.16592\n",
      "Epoch 900/2000, Avg Loss: 0.30958, Reg Loss: 0.16512\n",
      "Epoch 1000/2000, Avg Loss: 0.30303, Reg Loss: 0.16396\n",
      "Epoch 1100/2000, Avg Loss: 0.29670, Reg Loss: 0.16330\n",
      "Epoch 1200/2000, Avg Loss: 0.29635, Reg Loss: 0.16204\n",
      "Epoch 1300/2000, Avg Loss: 0.29500, Reg Loss: 0.16168\n",
      "Epoch 1400/2000, Avg Loss: 0.29021, Reg Loss: 0.16338\n",
      "Epoch 1500/2000, Avg Loss: 0.28059, Reg Loss: 0.16138\n",
      "Epoch 1600/2000, Avg Loss: 0.28074, Reg Loss: 0.16068\n",
      "Epoch 1700/2000, Avg Loss: 0.27377, Reg Loss: 0.15962\n",
      "Epoch 1800/2000, Avg Loss: 0.27288, Reg Loss: 0.16145\n",
      "Epoch 1900/2000, Avg Loss: 0.27052, Reg Loss: 0.16012\n",
      "Epoch 2000/2000, Avg Loss: 0.25923, Reg Loss: 0.15874\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.8156, G-Mean = 0.6936, MCC = 0.4237, F1-score = 0.6131\n",
      "      SMOTEBoost: AUC = 0.8019, G-Mean = 0.7036, MCC = 0.4358, F1-score = 0.6261\n",
      "      RUSBoost: AUC = 0.7423, G-Mean = 0.4614, MCC = 0.2048, F1-score = 0.5590\n",
      "      OUBoost: AUC = 0.8049, G-Mean = 0.7057, MCC = 0.4610, F1-score = 0.6293\n",
      "      SVM: AUC = 0.8184, G-Mean = 0.6678, MCC = 0.4256, F1-score = 0.5866\n",
      "      SMOTE: AUC = 0.8231, G-Mean = 0.7298, MCC = 0.4508, F1-score = 0.6542\n",
      "      ADASYN: AUC = 0.8143, G-Mean = 0.7402, MCC = 0.4680, F1-score = 0.6684\n",
      "      bSMOTE: AUC = 0.8091, G-Mean = 0.7363, MCC = 0.4615, F1-score = 0.6685\n",
      "      ROS: AUC = 0.8200, G-Mean = 0.7213, MCC = 0.4354, F1-score = 0.6451\n",
      "      MWMOTE: AUC = 0.8069, G-Mean = 0.7291, MCC = 0.4468, F1-score = 0.6543\n",
      "      Trans(Direct): AUC = 0.8109, G-Mean = 0.7153, MCC = 0.4215, F1-score = 0.6378\n",
      "  Fold 7/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.47077, Reg Loss: 0.16754\n",
      "Epoch 200/2000, Avg Loss: 0.38848, Reg Loss: 0.16785\n",
      "Epoch 300/2000, Avg Loss: 0.38319, Reg Loss: 0.16463\n",
      "Epoch 400/2000, Avg Loss: 0.34470, Reg Loss: 0.16482\n",
      "Epoch 500/2000, Avg Loss: 0.32866, Reg Loss: 0.16495\n",
      "Epoch 600/2000, Avg Loss: 0.31878, Reg Loss: 0.16133\n",
      "Epoch 700/2000, Avg Loss: 0.29593, Reg Loss: 0.16174\n",
      "Epoch 800/2000, Avg Loss: 0.28270, Reg Loss: 0.15772\n",
      "Epoch 900/2000, Avg Loss: 0.30189, Reg Loss: 0.15790\n",
      "Epoch 1000/2000, Avg Loss: 0.28486, Reg Loss: 0.15813\n",
      "Epoch 1100/2000, Avg Loss: 0.26897, Reg Loss: 0.15467\n",
      "Epoch 1200/2000, Avg Loss: 0.27454, Reg Loss: 0.15721\n",
      "Epoch 1300/2000, Avg Loss: 0.26637, Reg Loss: 0.15387\n",
      "Epoch 1400/2000, Avg Loss: 0.26646, Reg Loss: 0.15238\n",
      "Epoch 1500/2000, Avg Loss: 0.27018, Reg Loss: 0.15289\n",
      "Epoch 1600/2000, Avg Loss: 0.26137, Reg Loss: 0.15418\n",
      "Epoch 1700/2000, Avg Loss: 0.26071, Reg Loss: 0.15267\n",
      "Epoch 1800/2000, Avg Loss: 0.26295, Reg Loss: 0.15104\n",
      "Epoch 1900/2000, Avg Loss: 0.25861, Reg Loss: 0.15210\n",
      "Epoch 2000/2000, Avg Loss: 0.25341, Reg Loss: 0.15001\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.8204, G-Mean = 0.6921, MCC = 0.4221, F1-score = 0.6112\n",
      "      SMOTEBoost: AUC = 0.8161, G-Mean = 0.7107, MCC = 0.4535, F1-score = 0.6358\n",
      "      RUSBoost: AUC = 0.7370, G-Mean = 0.3955, MCC = 0.1532, F1-score = 0.5512\n",
      "      OUBoost: AUC = 0.8157, G-Mean = 0.7069, MCC = 0.4626, F1-score = 0.6308\n",
      "      SVM: AUC = 0.8216, G-Mean = 0.6756, MCC = 0.4447, F1-score = 0.5980\n",
      "      SMOTE: AUC = 0.8251, G-Mean = 0.7314, MCC = 0.4540, F1-score = 0.6560\n",
      "      ADASYN: AUC = 0.8180, G-Mean = 0.7375, MCC = 0.4640, F1-score = 0.6647\n",
      "      bSMOTE: AUC = 0.8156, G-Mean = 0.7383, MCC = 0.4648, F1-score = 0.6698\n",
      "      ROS: AUC = 0.8216, G-Mean = 0.7213, MCC = 0.4361, F1-score = 0.6448\n",
      "      MWMOTE: AUC = 0.8099, G-Mean = 0.7308, MCC = 0.4506, F1-score = 0.6561\n",
      "      Trans(Direct): AUC = 0.8177, G-Mean = 0.7174, MCC = 0.4274, F1-score = 0.6402\n",
      "  Fold 8/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.49382, Reg Loss: 0.16373\n",
      "Epoch 200/2000, Avg Loss: 0.43364, Reg Loss: 0.16389\n",
      "Epoch 300/2000, Avg Loss: 0.41541, Reg Loss: 0.16160\n",
      "Epoch 400/2000, Avg Loss: 0.40464, Reg Loss: 0.16064\n",
      "Epoch 500/2000, Avg Loss: 0.37721, Reg Loss: 0.16127\n",
      "Epoch 600/2000, Avg Loss: 0.37131, Reg Loss: 0.16271\n",
      "Epoch 700/2000, Avg Loss: 0.35217, Reg Loss: 0.15954\n",
      "Epoch 800/2000, Avg Loss: 0.33630, Reg Loss: 0.15933\n",
      "Epoch 900/2000, Avg Loss: 0.32537, Reg Loss: 0.15761\n",
      "Epoch 1000/2000, Avg Loss: 0.31098, Reg Loss: 0.15531\n",
      "Epoch 1100/2000, Avg Loss: 0.31115, Reg Loss: 0.15560\n",
      "Epoch 1200/2000, Avg Loss: 0.30723, Reg Loss: 0.15473\n",
      "Epoch 1300/2000, Avg Loss: 0.32230, Reg Loss: 0.15702\n",
      "Epoch 1400/2000, Avg Loss: 0.30564, Reg Loss: 0.15440\n",
      "Epoch 1500/2000, Avg Loss: 0.30342, Reg Loss: 0.15351\n",
      "Epoch 1600/2000, Avg Loss: 0.30953, Reg Loss: 0.15289\n",
      "Epoch 1700/2000, Avg Loss: 0.30679, Reg Loss: 0.15260\n",
      "Epoch 1800/2000, Avg Loss: 0.32236, Reg Loss: 0.15302\n",
      "Epoch 1900/2000, Avg Loss: 0.29990, Reg Loss: 0.15161\n",
      "Epoch 2000/2000, Avg Loss: 0.30389, Reg Loss: 0.15385\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.8186, G-Mean = 0.6896, MCC = 0.4188, F1-score = 0.6077\n",
      "      SMOTEBoost: AUC = 0.8158, G-Mean = 0.7158, MCC = 0.4571, F1-score = 0.6410\n",
      "      RUSBoost: AUC = 0.7507, G-Mean = 0.4161, MCC = 0.1701, F1-score = 0.5546\n",
      "      OUBoost: AUC = 0.8160, G-Mean = 0.7104, MCC = 0.4613, F1-score = 0.6339\n",
      "      SVM: AUC = 0.8214, G-Mean = 0.6821, MCC = 0.4504, F1-score = 0.6049\n",
      "      SMOTE: AUC = 0.8227, G-Mean = 0.7270, MCC = 0.4442, F1-score = 0.6503\n",
      "      ADASYN: AUC = 0.8192, G-Mean = 0.7359, MCC = 0.4599, F1-score = 0.6621\n",
      "      bSMOTE: AUC = 0.8161, G-Mean = 0.7315, MCC = 0.4507, F1-score = 0.6615\n",
      "      ROS: AUC = 0.8230, G-Mean = 0.7218, MCC = 0.4355, F1-score = 0.6447\n",
      "      MWMOTE: AUC = 0.8167, G-Mean = 0.7312, MCC = 0.4501, F1-score = 0.6560\n",
      "      Trans(Direct): AUC = 0.8225, G-Mean = 0.7208, MCC = 0.4323, F1-score = 0.6435\n",
      "  Fold 9/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.44669, Reg Loss: 0.16685\n",
      "Epoch 200/2000, Avg Loss: 0.41388, Reg Loss: 0.16487\n",
      "Epoch 300/2000, Avg Loss: 0.40880, Reg Loss: 0.16617\n",
      "Epoch 400/2000, Avg Loss: 0.37565, Reg Loss: 0.16423\n",
      "Epoch 500/2000, Avg Loss: 0.34516, Reg Loss: 0.17703\n",
      "Epoch 600/2000, Avg Loss: 0.32277, Reg Loss: 0.17488\n",
      "Epoch 700/2000, Avg Loss: 0.29948, Reg Loss: 0.16882\n",
      "Epoch 800/2000, Avg Loss: 0.28720, Reg Loss: 0.16493\n",
      "Epoch 900/2000, Avg Loss: 0.27756, Reg Loss: 0.16618\n",
      "Epoch 1000/2000, Avg Loss: 0.28962, Reg Loss: 0.16192\n",
      "Epoch 1100/2000, Avg Loss: 0.26736, Reg Loss: 0.16179\n",
      "Epoch 1200/2000, Avg Loss: 0.26208, Reg Loss: 0.15818\n",
      "Epoch 1300/2000, Avg Loss: 0.25026, Reg Loss: 0.15638\n",
      "Epoch 1400/2000, Avg Loss: 0.24657, Reg Loss: 0.15681\n",
      "Epoch 1500/2000, Avg Loss: 0.24400, Reg Loss: 0.15406\n",
      "Epoch 1600/2000, Avg Loss: 0.26919, Reg Loss: 0.15883\n",
      "Epoch 1700/2000, Avg Loss: 0.24318, Reg Loss: 0.15707\n",
      "Epoch 1800/2000, Avg Loss: 0.23923, Reg Loss: 0.15320\n",
      "Epoch 1900/2000, Avg Loss: 0.23887, Reg Loss: 0.15184\n",
      "Epoch 2000/2000, Avg Loss: 0.24602, Reg Loss: 0.15369\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.8240, G-Mean = 0.7023, MCC = 0.4389, F1-score = 0.6225\n",
      "      SMOTEBoost: AUC = 0.8255, G-Mean = 0.7277, MCC = 0.4753, F1-score = 0.6541\n",
      "      RUSBoost: AUC = 0.7566, G-Mean = 0.3856, MCC = 0.1605, F1-score = 0.5502\n",
      "      OUBoost: AUC = 0.8269, G-Mean = 0.7252, MCC = 0.4840, F1-score = 0.6507\n",
      "      SVM: AUC = 0.8308, G-Mean = 0.6940, MCC = 0.4683, F1-score = 0.6193\n",
      "      SMOTE: AUC = 0.8307, G-Mean = 0.7344, MCC = 0.4576, F1-score = 0.6585\n",
      "      ADASYN: AUC = 0.8273, G-Mean = 0.7428, MCC = 0.4726, F1-score = 0.6697\n",
      "      bSMOTE: AUC = 0.8230, G-Mean = 0.7357, MCC = 0.4582, F1-score = 0.6656\n",
      "      ROS: AUC = 0.8332, G-Mean = 0.7347, MCC = 0.4592, F1-score = 0.6591\n",
      "      MWMOTE: AUC = 0.8235, G-Mean = 0.7390, MCC = 0.4643, F1-score = 0.6646\n",
      "      Trans(Direct): AUC = 0.8321, G-Mean = 0.7350, MCC = 0.4586, F1-score = 0.6594\n",
      "  Fold 10/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.44890, Reg Loss: 0.15209\n",
      "Epoch 200/2000, Avg Loss: 0.40877, Reg Loss: 0.15480\n",
      "Epoch 300/2000, Avg Loss: 0.40785, Reg Loss: 0.15335\n",
      "Epoch 400/2000, Avg Loss: 0.36284, Reg Loss: 0.14989\n",
      "Epoch 500/2000, Avg Loss: 0.34163, Reg Loss: 0.14943\n",
      "Epoch 600/2000, Avg Loss: 0.33315, Reg Loss: 0.14951\n",
      "Epoch 700/2000, Avg Loss: 0.31963, Reg Loss: 0.15051\n",
      "Epoch 800/2000, Avg Loss: 0.30520, Reg Loss: 0.14875\n",
      "Epoch 900/2000, Avg Loss: 0.30029, Reg Loss: 0.15228\n",
      "Epoch 1000/2000, Avg Loss: 0.29357, Reg Loss: 0.14934\n",
      "Epoch 1100/2000, Avg Loss: 0.29767, Reg Loss: 0.15015\n",
      "Epoch 1200/2000, Avg Loss: 0.28316, Reg Loss: 0.14864\n",
      "Epoch 1300/2000, Avg Loss: 0.27685, Reg Loss: 0.14901\n",
      "Epoch 1400/2000, Avg Loss: 0.28849, Reg Loss: 0.15020\n",
      "Epoch 1500/2000, Avg Loss: 0.27513, Reg Loss: 0.15164\n",
      "Epoch 1600/2000, Avg Loss: 0.27086, Reg Loss: 0.15237\n",
      "Epoch 1700/2000, Avg Loss: 0.25556, Reg Loss: 0.14942\n",
      "Epoch 1800/2000, Avg Loss: 0.24669, Reg Loss: 0.14797\n",
      "Epoch 1900/2000, Avg Loss: 0.24551, Reg Loss: 0.14849\n",
      "Epoch 2000/2000, Avg Loss: 0.24240, Reg Loss: 0.14718\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.8190, G-Mean = 0.7009, MCC = 0.4355, F1-score = 0.6202\n",
      "      SMOTEBoost: AUC = 0.8233, G-Mean = 0.7235, MCC = 0.4633, F1-score = 0.6487\n",
      "      RUSBoost: AUC = 0.7590, G-Mean = 0.3870, MCC = 0.1691, F1-score = 0.5505\n",
      "      OUBoost: AUC = 0.8243, G-Mean = 0.7252, MCC = 0.4795, F1-score = 0.6500\n",
      "      SVM: AUC = 0.8300, G-Mean = 0.6965, MCC = 0.4680, F1-score = 0.6214\n",
      "      SMOTE: AUC = 0.8276, G-Mean = 0.7404, MCC = 0.4694, F1-score = 0.6654\n",
      "      ADASYN: AUC = 0.8226, G-Mean = 0.7460, MCC = 0.4783, F1-score = 0.6729\n",
      "      bSMOTE: AUC = 0.8184, G-Mean = 0.7366, MCC = 0.4591, F1-score = 0.6657\n",
      "      ROS: AUC = 0.8310, G-Mean = 0.7406, MCC = 0.4698, F1-score = 0.6656\n",
      "      MWMOTE: AUC = 0.8181, G-Mean = 0.7377, MCC = 0.4610, F1-score = 0.6626\n",
      "      Trans(Direct): AUC = 0.8314, G-Mean = 0.7408, MCC = 0.4692, F1-score = 0.6659\n",
      "\n",
      "Starting experiment 7/10\n",
      "  Fold 1/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.49640, Reg Loss: 0.16920\n",
      "Epoch 200/2000, Avg Loss: 0.43982, Reg Loss: 0.15870\n",
      "Epoch 300/2000, Avg Loss: 0.38661, Reg Loss: 0.15842\n",
      "Epoch 400/2000, Avg Loss: 0.36298, Reg Loss: 0.16215\n",
      "Epoch 500/2000, Avg Loss: 0.33498, Reg Loss: 0.15993\n",
      "Epoch 600/2000, Avg Loss: 0.31385, Reg Loss: 0.16052\n",
      "Epoch 700/2000, Avg Loss: 0.29545, Reg Loss: 0.15846\n",
      "Epoch 800/2000, Avg Loss: 0.33516, Reg Loss: 0.16096\n",
      "Epoch 900/2000, Avg Loss: 0.27589, Reg Loss: 0.15605\n",
      "Epoch 1000/2000, Avg Loss: 0.26625, Reg Loss: 0.15560\n",
      "Epoch 1100/2000, Avg Loss: 0.26187, Reg Loss: 0.15389\n",
      "Epoch 1200/2000, Avg Loss: 0.26069, Reg Loss: 0.15365\n",
      "Epoch 1300/2000, Avg Loss: 0.25673, Reg Loss: 0.15322\n",
      "Epoch 1400/2000, Avg Loss: 0.25992, Reg Loss: 0.15204\n",
      "Epoch 1500/2000, Avg Loss: 0.25533, Reg Loss: 0.15458\n",
      "Epoch 1600/2000, Avg Loss: 0.24756, Reg Loss: 0.15025\n",
      "Epoch 1700/2000, Avg Loss: 0.25111, Reg Loss: 0.15238\n",
      "Epoch 1800/2000, Avg Loss: 0.24642, Reg Loss: 0.15022\n",
      "Epoch 1900/2000, Avg Loss: 0.26200, Reg Loss: 0.15140\n",
      "Epoch 2000/2000, Avg Loss: 0.24702, Reg Loss: 0.14895\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.8333, G-Mean = 0.6907, MCC = 0.4944, F1-score = 0.6222\n",
      "      SMOTEBoost: AUC = 0.8744, G-Mean = 0.7698, MCC = 0.5291, F1-score = 0.7018\n",
      "      RUSBoost: AUC = 0.8296, G-Mean = 0.5932, MCC = 0.3278, F1-score = 0.6024\n",
      "      OUBoost: AUC = 0.8785, G-Mean = 0.7888, MCC = 0.5761, F1-score = 0.7273\n",
      "      SVM: AUC = 0.8911, G-Mean = 0.7055, MCC = 0.5628, F1-score = 0.6512\n",
      "      SMOTE: AUC = 0.8778, G-Mean = 0.7869, MCC = 0.5948, F1-score = 0.7308\n",
      "      ADASYN: AUC = 0.8711, G-Mean = 0.8273, MCC = 0.6578, F1-score = 0.7778\n",
      "      bSMOTE: AUC = 0.8674, G-Mean = 0.8074, MCC = 0.6263, F1-score = 0.7547\n",
      "      ROS: AUC = 0.8822, G-Mean = 0.7779, MCC = 0.5688, F1-score = 0.7170\n",
      "      MWMOTE: AUC = 0.8681, G-Mean = 0.7958, MCC = 0.6219, F1-score = 0.7451\n",
      "      Trans(Direct): AUC = 0.8963, G-Mean = 0.8273, MCC = 0.6578, F1-score = 0.7778\n",
      "  Fold 2/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.45512, Reg Loss: 0.16347\n",
      "Epoch 200/2000, Avg Loss: 0.43510, Reg Loss: 0.15751\n",
      "Epoch 300/2000, Avg Loss: 0.39652, Reg Loss: 0.15602\n",
      "Epoch 400/2000, Avg Loss: 0.38089, Reg Loss: 0.15403\n",
      "Epoch 500/2000, Avg Loss: 0.39840, Reg Loss: 0.15404\n",
      "Epoch 600/2000, Avg Loss: 0.34884, Reg Loss: 0.15318\n",
      "Epoch 700/2000, Avg Loss: 0.33979, Reg Loss: 0.15179\n",
      "Epoch 800/2000, Avg Loss: 0.31578, Reg Loss: 0.15066\n",
      "Epoch 900/2000, Avg Loss: 0.32025, Reg Loss: 0.15129\n",
      "Epoch 1000/2000, Avg Loss: 0.31327, Reg Loss: 0.14959\n",
      "Epoch 1100/2000, Avg Loss: 0.29642, Reg Loss: 0.14798\n",
      "Epoch 1200/2000, Avg Loss: 0.29307, Reg Loss: 0.14817\n",
      "Epoch 1300/2000, Avg Loss: 0.29000, Reg Loss: 0.14775\n",
      "Epoch 1400/2000, Avg Loss: 0.28859, Reg Loss: 0.14701\n",
      "Epoch 1500/2000, Avg Loss: 0.28891, Reg Loss: 0.14571\n",
      "Epoch 1600/2000, Avg Loss: 0.29303, Reg Loss: 0.14915\n",
      "Epoch 1700/2000, Avg Loss: 0.28275, Reg Loss: 0.14744\n",
      "Epoch 1800/2000, Avg Loss: 0.27889, Reg Loss: 0.14763\n",
      "Epoch 1900/2000, Avg Loss: 0.26960, Reg Loss: 0.14692\n",
      "Epoch 2000/2000, Avg Loss: 0.27194, Reg Loss: 0.14624\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.8415, G-Mean = 0.6909, MCC = 0.4667, F1-score = 0.6172\n",
      "      SMOTEBoost: AUC = 0.8576, G-Mean = 0.7571, MCC = 0.5007, F1-score = 0.6893\n",
      "      RUSBoost: AUC = 0.7959, G-Mean = 0.6157, MCC = 0.3524, F1-score = 0.6137\n",
      "      OUBoost: AUC = 0.8726, G-Mean = 0.8033, MCC = 0.6044, F1-score = 0.7455\n",
      "      SVM: AUC = 0.8648, G-Mean = 0.7141, MCC = 0.5608, F1-score = 0.6589\n",
      "      SMOTE: AUC = 0.8530, G-Mean = 0.7631, MCC = 0.5407, F1-score = 0.6987\n",
      "      ADASYN: AUC = 0.8404, G-Mean = 0.7745, MCC = 0.5437, F1-score = 0.7109\n",
      "      bSMOTE: AUC = 0.8430, G-Mean = 0.7972, MCC = 0.5893, F1-score = 0.7380\n",
      "      ROS: AUC = 0.8493, G-Mean = 0.7690, MCC = 0.5377, F1-score = 0.7033\n",
      "      MWMOTE: AUC = 0.8293, G-Mean = 0.7228, MCC = 0.4687, F1-score = 0.6503\n",
      "      Trans(Direct): AUC = 0.8615, G-Mean = 0.7937, MCC = 0.5822, F1-score = 0.7337\n",
      "  Fold 3/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.55607, Reg Loss: 0.15310\n",
      "Epoch 200/2000, Avg Loss: 0.54688, Reg Loss: 0.15171\n",
      "Epoch 300/2000, Avg Loss: 0.53143, Reg Loss: 0.15209\n",
      "Epoch 400/2000, Avg Loss: 0.50987, Reg Loss: 0.15845\n",
      "Epoch 500/2000, Avg Loss: 0.56396, Reg Loss: 0.15963\n",
      "Epoch 600/2000, Avg Loss: 0.45145, Reg Loss: 0.15367\n",
      "Epoch 700/2000, Avg Loss: 0.37499, Reg Loss: 0.16040\n",
      "Epoch 800/2000, Avg Loss: 0.37166, Reg Loss: 0.15848\n",
      "Epoch 900/2000, Avg Loss: 0.32475, Reg Loss: 0.15678\n",
      "Epoch 1000/2000, Avg Loss: 0.30926, Reg Loss: 0.15621\n",
      "Epoch 1100/2000, Avg Loss: 0.29827, Reg Loss: 0.15680\n",
      "Epoch 1200/2000, Avg Loss: 0.29095, Reg Loss: 0.15438\n",
      "Epoch 1300/2000, Avg Loss: 0.29740, Reg Loss: 0.15436\n",
      "Epoch 1400/2000, Avg Loss: 0.28378, Reg Loss: 0.15373\n",
      "Epoch 1500/2000, Avg Loss: 0.27959, Reg Loss: 0.15277\n",
      "Epoch 1600/2000, Avg Loss: 0.27723, Reg Loss: 0.15234\n",
      "Epoch 1700/2000, Avg Loss: 0.27721, Reg Loss: 0.15217\n",
      "Epoch 1800/2000, Avg Loss: 0.27583, Reg Loss: 0.15089\n",
      "Epoch 1900/2000, Avg Loss: 0.27214, Reg Loss: 0.15064\n",
      "Epoch 2000/2000, Avg Loss: 0.27912, Reg Loss: 0.15031\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.8205, G-Mean = 0.6958, MCC = 0.4597, F1-score = 0.6206\n",
      "      SMOTEBoost: AUC = 0.8180, G-Mean = 0.7142, MCC = 0.4399, F1-score = 0.6364\n",
      "      RUSBoost: AUC = 0.7615, G-Mean = 0.5862, MCC = 0.3216, F1-score = 0.6007\n",
      "      OUBoost: AUC = 0.8352, G-Mean = 0.7475, MCC = 0.5177, F1-score = 0.6775\n",
      "      SVM: AUC = 0.8442, G-Mean = 0.6756, MCC = 0.4841, F1-score = 0.6059\n",
      "      SMOTE: AUC = 0.8393, G-Mean = 0.7522, MCC = 0.5148, F1-score = 0.6840\n",
      "      ADASYN: AUC = 0.8412, G-Mean = 0.7664, MCC = 0.5241, F1-score = 0.6999\n",
      "      bSMOTE: AUC = 0.8393, G-Mean = 0.7680, MCC = 0.5270, F1-score = 0.7036\n",
      "      ROS: AUC = 0.8378, G-Mean = 0.7531, MCC = 0.5051, F1-score = 0.6832\n",
      "      MWMOTE: AUC = 0.8291, G-Mean = 0.7256, MCC = 0.4629, F1-score = 0.6519\n",
      "      Trans(Direct): AUC = 0.8469, G-Mean = 0.7457, MCC = 0.4933, F1-score = 0.6743\n",
      "  Fold 4/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.49557, Reg Loss: 0.15097\n",
      "Epoch 200/2000, Avg Loss: 0.46577, Reg Loss: 0.15865\n",
      "Epoch 300/2000, Avg Loss: 0.41654, Reg Loss: 0.15756\n",
      "Epoch 400/2000, Avg Loss: 0.36763, Reg Loss: 0.15405\n",
      "Epoch 500/2000, Avg Loss: 0.36425, Reg Loss: 0.15500\n",
      "Epoch 600/2000, Avg Loss: 0.32714, Reg Loss: 0.15380\n",
      "Epoch 700/2000, Avg Loss: 0.31705, Reg Loss: 0.15388\n",
      "Epoch 800/2000, Avg Loss: 0.31470, Reg Loss: 0.15278\n",
      "Epoch 900/2000, Avg Loss: 0.30213, Reg Loss: 0.15394\n",
      "Epoch 1000/2000, Avg Loss: 0.29696, Reg Loss: 0.15240\n",
      "Epoch 1100/2000, Avg Loss: 0.28145, Reg Loss: 0.15015\n",
      "Epoch 1200/2000, Avg Loss: 0.27551, Reg Loss: 0.15030\n",
      "Epoch 1300/2000, Avg Loss: 0.26829, Reg Loss: 0.15074\n",
      "Epoch 1400/2000, Avg Loss: 0.28046, Reg Loss: 0.15350\n",
      "Epoch 1500/2000, Avg Loss: 0.27160, Reg Loss: 0.15142\n",
      "Epoch 1600/2000, Avg Loss: 0.26063, Reg Loss: 0.14912\n",
      "Epoch 1700/2000, Avg Loss: 0.25825, Reg Loss: 0.14899\n",
      "Epoch 1800/2000, Avg Loss: 0.24727, Reg Loss: 0.14750\n",
      "Epoch 1900/2000, Avg Loss: 0.24129, Reg Loss: 0.14802\n",
      "Epoch 2000/2000, Avg Loss: 0.24573, Reg Loss: 0.14661\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.8093, G-Mean = 0.7044, MCC = 0.4605, F1-score = 0.6291\n",
      "      SMOTEBoost: AUC = 0.8180, G-Mean = 0.7231, MCC = 0.4522, F1-score = 0.6490\n",
      "      RUSBoost: AUC = 0.7594, G-Mean = 0.5598, MCC = 0.3058, F1-score = 0.5934\n",
      "      OUBoost: AUC = 0.8260, G-Mean = 0.7336, MCC = 0.4802, F1-score = 0.6614\n",
      "      SVM: AUC = 0.8411, G-Mean = 0.6852, MCC = 0.4810, F1-score = 0.6145\n",
      "      SMOTE: AUC = 0.8376, G-Mean = 0.7572, MCC = 0.5178, F1-score = 0.6899\n",
      "      ADASYN: AUC = 0.8387, G-Mean = 0.7748, MCC = 0.5383, F1-score = 0.7096\n",
      "      bSMOTE: AUC = 0.8333, G-Mean = 0.7635, MCC = 0.5175, F1-score = 0.6994\n",
      "      ROS: AUC = 0.8357, G-Mean = 0.7536, MCC = 0.5018, F1-score = 0.6842\n",
      "      MWMOTE: AUC = 0.8245, G-Mean = 0.7345, MCC = 0.4741, F1-score = 0.6632\n",
      "      Trans(Direct): AUC = 0.8476, G-Mean = 0.7524, MCC = 0.5017, F1-score = 0.6827\n",
      "  Fold 5/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.47622, Reg Loss: 0.16062\n",
      "Epoch 200/2000, Avg Loss: 0.44574, Reg Loss: 0.15978\n",
      "Epoch 300/2000, Avg Loss: 0.38474, Reg Loss: 0.16128\n",
      "Epoch 400/2000, Avg Loss: 0.39009, Reg Loss: 0.15835\n",
      "Epoch 500/2000, Avg Loss: 0.35840, Reg Loss: 0.15806\n",
      "Epoch 600/2000, Avg Loss: 0.33360, Reg Loss: 0.15720\n",
      "Epoch 700/2000, Avg Loss: 0.36686, Reg Loss: 0.15868\n",
      "Epoch 800/2000, Avg Loss: 0.31757, Reg Loss: 0.15649\n",
      "Epoch 900/2000, Avg Loss: 0.30685, Reg Loss: 0.15641\n",
      "Epoch 1000/2000, Avg Loss: 0.31138, Reg Loss: 0.15599\n",
      "Epoch 1100/2000, Avg Loss: 0.29778, Reg Loss: 0.15371\n",
      "Epoch 1200/2000, Avg Loss: 0.29640, Reg Loss: 0.15355\n",
      "Epoch 1300/2000, Avg Loss: 0.29413, Reg Loss: 0.15302\n",
      "Epoch 1400/2000, Avg Loss: 0.28671, Reg Loss: 0.15124\n",
      "Epoch 1500/2000, Avg Loss: 0.28653, Reg Loss: 0.15187\n",
      "Epoch 1600/2000, Avg Loss: 0.27964, Reg Loss: 0.15018\n",
      "Epoch 1700/2000, Avg Loss: 0.27369, Reg Loss: 0.14839\n",
      "Epoch 1800/2000, Avg Loss: 0.26793, Reg Loss: 0.14987\n",
      "Epoch 1900/2000, Avg Loss: 0.26371, Reg Loss: 0.14863\n",
      "Epoch 2000/2000, Avg Loss: 0.26664, Reg Loss: 0.14863\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.8104, G-Mean = 0.7037, MCC = 0.4497, F1-score = 0.6269\n",
      "      SMOTEBoost: AUC = 0.8230, G-Mean = 0.7362, MCC = 0.4742, F1-score = 0.6640\n",
      "      RUSBoost: AUC = 0.7713, G-Mean = 0.5720, MCC = 0.3224, F1-score = 0.6000\n",
      "      OUBoost: AUC = 0.8287, G-Mean = 0.7306, MCC = 0.4749, F1-score = 0.6574\n",
      "      SVM: AUC = 0.8400, G-Mean = 0.7056, MCC = 0.5038, F1-score = 0.6377\n",
      "      SMOTE: AUC = 0.8350, G-Mean = 0.7615, MCC = 0.5222, F1-score = 0.6943\n",
      "      ADASYN: AUC = 0.8372, G-Mean = 0.7776, MCC = 0.5431, F1-score = 0.7125\n",
      "      bSMOTE: AUC = 0.8323, G-Mean = 0.7674, MCC = 0.5232, F1-score = 0.7033\n",
      "      ROS: AUC = 0.8345, G-Mean = 0.7587, MCC = 0.5094, F1-score = 0.6898\n",
      "      MWMOTE: AUC = 0.8245, G-Mean = 0.7416, MCC = 0.4851, F1-score = 0.6709\n",
      "      Trans(Direct): AUC = 0.8437, G-Mean = 0.7519, MCC = 0.4983, F1-score = 0.6817\n",
      "  Fold 6/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.52782, Reg Loss: 0.16012\n",
      "Epoch 200/2000, Avg Loss: 0.46153, Reg Loss: 0.16853\n",
      "Epoch 300/2000, Avg Loss: 0.43041, Reg Loss: 0.17034\n",
      "Epoch 400/2000, Avg Loss: 0.36823, Reg Loss: 0.16831\n",
      "Epoch 500/2000, Avg Loss: 0.33913, Reg Loss: 0.16572\n",
      "Epoch 600/2000, Avg Loss: 0.35089, Reg Loss: 0.16304\n",
      "Epoch 700/2000, Avg Loss: 0.31989, Reg Loss: 0.16316\n",
      "Epoch 800/2000, Avg Loss: 0.32550, Reg Loss: 0.16499\n",
      "Epoch 900/2000, Avg Loss: 0.31638, Reg Loss: 0.16263\n",
      "Epoch 1000/2000, Avg Loss: 0.29710, Reg Loss: 0.16137\n",
      "Epoch 1100/2000, Avg Loss: 0.31370, Reg Loss: 0.16462\n",
      "Epoch 1200/2000, Avg Loss: 0.29107, Reg Loss: 0.16062\n",
      "Epoch 1300/2000, Avg Loss: 0.28199, Reg Loss: 0.15952\n",
      "Epoch 1400/2000, Avg Loss: 0.27940, Reg Loss: 0.15913\n",
      "Epoch 1500/2000, Avg Loss: 0.28722, Reg Loss: 0.16063\n",
      "Epoch 1600/2000, Avg Loss: 0.27358, Reg Loss: 0.15889\n",
      "Epoch 1700/2000, Avg Loss: 0.27273, Reg Loss: 0.15914\n",
      "Epoch 1800/2000, Avg Loss: 0.26706, Reg Loss: 0.15775\n",
      "Epoch 1900/2000, Avg Loss: 0.26765, Reg Loss: 0.15767\n",
      "Epoch 2000/2000, Avg Loss: 0.26430, Reg Loss: 0.15868\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.8106, G-Mean = 0.6977, MCC = 0.4423, F1-score = 0.6197\n",
      "      SMOTEBoost: AUC = 0.8146, G-Mean = 0.7257, MCC = 0.4518, F1-score = 0.6510\n",
      "      RUSBoost: AUC = 0.7573, G-Mean = 0.5810, MCC = 0.3207, F1-score = 0.5996\n",
      "      OUBoost: AUC = 0.8220, G-Mean = 0.7241, MCC = 0.4597, F1-score = 0.6490\n",
      "      SVM: AUC = 0.8269, G-Mean = 0.6952, MCC = 0.4817, F1-score = 0.6236\n",
      "      SMOTE: AUC = 0.8214, G-Mean = 0.7465, MCC = 0.4899, F1-score = 0.6775\n",
      "      ADASYN: AUC = 0.8222, G-Mean = 0.7534, MCC = 0.4950, F1-score = 0.6860\n",
      "      bSMOTE: AUC = 0.8157, G-Mean = 0.7460, MCC = 0.4812, F1-score = 0.6806\n",
      "      ROS: AUC = 0.8212, G-Mean = 0.7380, MCC = 0.4685, F1-score = 0.6652\n",
      "      MWMOTE: AUC = 0.8098, G-Mean = 0.7238, MCC = 0.4473, F1-score = 0.6505\n",
      "      Trans(Direct): AUC = 0.8304, G-Mean = 0.7357, MCC = 0.4650, F1-score = 0.6626\n",
      "  Fold 7/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.52343, Reg Loss: 0.16129\n",
      "Epoch 200/2000, Avg Loss: 0.50530, Reg Loss: 0.16699\n",
      "Epoch 300/2000, Avg Loss: 0.51960, Reg Loss: 0.17185\n",
      "Epoch 400/2000, Avg Loss: 0.46077, Reg Loss: 0.17696\n",
      "Epoch 500/2000, Avg Loss: 0.41144, Reg Loss: 0.17859\n",
      "Epoch 600/2000, Avg Loss: 0.37648, Reg Loss: 0.17033\n",
      "Epoch 700/2000, Avg Loss: 0.36639, Reg Loss: 0.16731\n",
      "Epoch 800/2000, Avg Loss: 0.34204, Reg Loss: 0.16441\n",
      "Epoch 900/2000, Avg Loss: 0.33895, Reg Loss: 0.16341\n",
      "Epoch 1000/2000, Avg Loss: 0.34707, Reg Loss: 0.16405\n",
      "Epoch 1100/2000, Avg Loss: 0.31512, Reg Loss: 0.15853\n",
      "Epoch 1200/2000, Avg Loss: 0.34787, Reg Loss: 0.16254\n",
      "Epoch 1300/2000, Avg Loss: 0.43465, Reg Loss: 0.16157\n",
      "Epoch 1400/2000, Avg Loss: 0.34494, Reg Loss: 0.16613\n",
      "Epoch 1500/2000, Avg Loss: 0.33001, Reg Loss: 0.16166\n",
      "Epoch 1600/2000, Avg Loss: 0.32713, Reg Loss: 0.16019\n",
      "Epoch 1700/2000, Avg Loss: 0.31145, Reg Loss: 0.16048\n",
      "Epoch 1800/2000, Avg Loss: 0.30393, Reg Loss: 0.15810\n",
      "Epoch 1900/2000, Avg Loss: 0.30803, Reg Loss: 0.15893\n",
      "Epoch 2000/2000, Avg Loss: 0.30909, Reg Loss: 0.15778\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.8172, G-Mean = 0.6988, MCC = 0.4428, F1-score = 0.6208\n",
      "      SMOTEBoost: AUC = 0.8161, G-Mean = 0.7210, MCC = 0.4408, F1-score = 0.6452\n",
      "      RUSBoost: AUC = 0.7386, G-Mean = 0.5667, MCC = 0.3118, F1-score = 0.5956\n",
      "      OUBoost: AUC = 0.8248, G-Mean = 0.7265, MCC = 0.4617, F1-score = 0.6515\n",
      "      SVM: AUC = 0.8259, G-Mean = 0.6979, MCC = 0.4803, F1-score = 0.6260\n",
      "      SMOTE: AUC = 0.8210, G-Mean = 0.7427, MCC = 0.4803, F1-score = 0.6729\n",
      "      ADASYN: AUC = 0.8218, G-Mean = 0.7505, MCC = 0.4890, F1-score = 0.6833\n",
      "      bSMOTE: AUC = 0.8193, G-Mean = 0.7426, MCC = 0.4745, F1-score = 0.6772\n",
      "      ROS: AUC = 0.8194, G-Mean = 0.7355, MCC = 0.4619, F1-score = 0.6623\n",
      "      MWMOTE: AUC = 0.8129, G-Mean = 0.7258, MCC = 0.4487, F1-score = 0.6528\n",
      "      Trans(Direct): AUC = 0.8304, G-Mean = 0.7334, MCC = 0.4589, F1-score = 0.6601\n",
      "  Fold 8/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.45922, Reg Loss: 0.15982\n",
      "Epoch 200/2000, Avg Loss: 0.40137, Reg Loss: 0.15856\n",
      "Epoch 300/2000, Avg Loss: 0.39008, Reg Loss: 0.15699\n",
      "Epoch 400/2000, Avg Loss: 0.38675, Reg Loss: 0.15636\n",
      "Epoch 500/2000, Avg Loss: 0.36159, Reg Loss: 0.15633\n",
      "Epoch 600/2000, Avg Loss: 0.35115, Reg Loss: 0.15522\n",
      "Epoch 700/2000, Avg Loss: 0.33959, Reg Loss: 0.15425\n",
      "Epoch 800/2000, Avg Loss: 0.34820, Reg Loss: 0.15350\n",
      "Epoch 900/2000, Avg Loss: 0.33659, Reg Loss: 0.15313\n",
      "Epoch 1000/2000, Avg Loss: 0.33273, Reg Loss: 0.15446\n",
      "Epoch 1100/2000, Avg Loss: 0.32304, Reg Loss: 0.15576\n",
      "Epoch 1200/2000, Avg Loss: 0.31766, Reg Loss: 0.15406\n",
      "Epoch 1300/2000, Avg Loss: 0.31567, Reg Loss: 0.15540\n",
      "Epoch 1400/2000, Avg Loss: 0.30732, Reg Loss: 0.15617\n",
      "Epoch 1500/2000, Avg Loss: 0.29296, Reg Loss: 0.15621\n",
      "Epoch 1600/2000, Avg Loss: 0.27944, Reg Loss: 0.15263\n",
      "Epoch 1700/2000, Avg Loss: 0.30357, Reg Loss: 0.15190\n",
      "Epoch 1800/2000, Avg Loss: 0.27281, Reg Loss: 0.15055\n",
      "Epoch 1900/2000, Avg Loss: 0.31248, Reg Loss: 0.15761\n",
      "Epoch 2000/2000, Avg Loss: 0.26782, Reg Loss: 0.15401\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.8180, G-Mean = 0.6985, MCC = 0.4413, F1-score = 0.6197\n",
      "      SMOTEBoost: AUC = 0.8181, G-Mean = 0.7253, MCC = 0.4476, F1-score = 0.6494\n",
      "      RUSBoost: AUC = 0.7252, G-Mean = 0.5330, MCC = 0.2698, F1-score = 0.5823\n",
      "      OUBoost: AUC = 0.8281, G-Mean = 0.7272, MCC = 0.4632, F1-score = 0.6518\n",
      "      SVM: AUC = 0.8257, G-Mean = 0.7005, MCC = 0.4784, F1-score = 0.6277\n",
      "      SMOTE: AUC = 0.8239, G-Mean = 0.7467, MCC = 0.4865, F1-score = 0.6765\n",
      "      ADASYN: AUC = 0.8243, G-Mean = 0.7523, MCC = 0.4915, F1-score = 0.6841\n",
      "      bSMOTE: AUC = 0.8216, G-Mean = 0.7477, MCC = 0.4831, F1-score = 0.6815\n",
      "      ROS: AUC = 0.8201, G-Mean = 0.7379, MCC = 0.4661, F1-score = 0.6644\n",
      "      MWMOTE: AUC = 0.8173, G-Mean = 0.7306, MCC = 0.4562, F1-score = 0.6574\n",
      "      Trans(Direct): AUC = 0.8307, G-Mean = 0.7337, MCC = 0.4581, F1-score = 0.6595\n",
      "  Fold 9/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.43091, Reg Loss: 0.16327\n",
      "Epoch 200/2000, Avg Loss: 0.40909, Reg Loss: 0.16376\n",
      "Epoch 300/2000, Avg Loss: 0.40566, Reg Loss: 0.16257\n",
      "Epoch 400/2000, Avg Loss: 0.34759, Reg Loss: 0.15654\n",
      "Epoch 500/2000, Avg Loss: 0.35037, Reg Loss: 0.15872\n",
      "Epoch 600/2000, Avg Loss: 0.33044, Reg Loss: 0.15823\n",
      "Epoch 700/2000, Avg Loss: 0.36855, Reg Loss: 0.16668\n",
      "Epoch 800/2000, Avg Loss: 0.32260, Reg Loss: 0.16443\n",
      "Epoch 900/2000, Avg Loss: 0.32226, Reg Loss: 0.16311\n",
      "Epoch 1000/2000, Avg Loss: 0.33387, Reg Loss: 0.16324\n",
      "Epoch 1100/2000, Avg Loss: 0.32881, Reg Loss: 0.16312\n",
      "Epoch 1200/2000, Avg Loss: 0.29137, Reg Loss: 0.16118\n",
      "Epoch 1300/2000, Avg Loss: 0.28513, Reg Loss: 0.16120\n",
      "Epoch 1400/2000, Avg Loss: 0.27404, Reg Loss: 0.15893\n",
      "Epoch 1500/2000, Avg Loss: 0.29085, Reg Loss: 0.15952\n",
      "Epoch 1600/2000, Avg Loss: 0.26956, Reg Loss: 0.16103\n",
      "Epoch 1700/2000, Avg Loss: 0.37973, Reg Loss: 0.17407\n",
      "Epoch 1800/2000, Avg Loss: 0.30585, Reg Loss: 0.15943\n",
      "Epoch 1900/2000, Avg Loss: 0.27645, Reg Loss: 0.15446\n",
      "Epoch 2000/2000, Avg Loss: 0.25880, Reg Loss: 0.15214\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.8182, G-Mean = 0.6946, MCC = 0.4385, F1-score = 0.6151\n",
      "      SMOTEBoost: AUC = 0.8231, G-Mean = 0.7307, MCC = 0.4581, F1-score = 0.6554\n",
      "      RUSBoost: AUC = 0.7268, G-Mean = 0.5261, MCC = 0.2620, F1-score = 0.5782\n",
      "      OUBoost: AUC = 0.8307, G-Mean = 0.7291, MCC = 0.4655, F1-score = 0.6535\n",
      "      SVM: AUC = 0.8268, G-Mean = 0.6927, MCC = 0.4644, F1-score = 0.6172\n",
      "      SMOTE: AUC = 0.8220, G-Mean = 0.7420, MCC = 0.4774, F1-score = 0.6700\n",
      "      ADASYN: AUC = 0.8218, G-Mean = 0.7472, MCC = 0.4809, F1-score = 0.6770\n",
      "      bSMOTE: AUC = 0.8196, G-Mean = 0.7482, MCC = 0.4830, F1-score = 0.6810\n",
      "      ROS: AUC = 0.8219, G-Mean = 0.7376, MCC = 0.4656, F1-score = 0.6633\n",
      "      MWMOTE: AUC = 0.8148, G-Mean = 0.7312, MCC = 0.4557, F1-score = 0.6572\n",
      "      Trans(Direct): AUC = 0.8320, G-Mean = 0.7339, MCC = 0.4575, F1-score = 0.6590\n",
      "  Fold 10/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.50591, Reg Loss: 0.15842\n",
      "Epoch 200/2000, Avg Loss: 0.47599, Reg Loss: 0.16073\n",
      "Epoch 300/2000, Avg Loss: 0.43894, Reg Loss: 0.15789\n",
      "Epoch 400/2000, Avg Loss: 0.39366, Reg Loss: 0.15965\n",
      "Epoch 500/2000, Avg Loss: 0.38723, Reg Loss: 0.15951\n",
      "Epoch 600/2000, Avg Loss: 0.37632, Reg Loss: 0.15634\n",
      "Epoch 700/2000, Avg Loss: 0.37442, Reg Loss: 0.15647\n",
      "Epoch 800/2000, Avg Loss: 0.35121, Reg Loss: 0.15571\n",
      "Epoch 900/2000, Avg Loss: 0.33843, Reg Loss: 0.15583\n",
      "Epoch 1000/2000, Avg Loss: 0.32405, Reg Loss: 0.15298\n",
      "Epoch 1100/2000, Avg Loss: 0.31706, Reg Loss: 0.15276\n",
      "Epoch 1200/2000, Avg Loss: 0.31645, Reg Loss: 0.15143\n",
      "Epoch 1300/2000, Avg Loss: 0.30714, Reg Loss: 0.15061\n",
      "Epoch 1400/2000, Avg Loss: 0.30647, Reg Loss: 0.15013\n",
      "Epoch 1500/2000, Avg Loss: 0.29937, Reg Loss: 0.15000\n",
      "Epoch 1600/2000, Avg Loss: 0.29774, Reg Loss: 0.14952\n",
      "Epoch 1700/2000, Avg Loss: 0.29652, Reg Loss: 0.14887\n",
      "Epoch 1800/2000, Avg Loss: 0.29586, Reg Loss: 0.14856\n",
      "Epoch 1900/2000, Avg Loss: 0.30622, Reg Loss: 0.14969\n",
      "Epoch 2000/2000, Avg Loss: 0.29070, Reg Loss: 0.14863\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.8181, G-Mean = 0.6967, MCC = 0.4364, F1-score = 0.6167\n",
      "      SMOTEBoost: AUC = 0.8142, G-Mean = 0.7233, MCC = 0.4422, F1-score = 0.6465\n",
      "      RUSBoost: AUC = 0.7360, G-Mean = 0.5351, MCC = 0.2775, F1-score = 0.5830\n",
      "      OUBoost: AUC = 0.8252, G-Mean = 0.7258, MCC = 0.4572, F1-score = 0.6488\n",
      "      SVM: AUC = 0.8276, G-Mean = 0.6962, MCC = 0.4670, F1-score = 0.6208\n",
      "      SMOTE: AUC = 0.8224, G-Mean = 0.7448, MCC = 0.4815, F1-score = 0.6729\n",
      "      ADASYN: AUC = 0.8211, G-Mean = 0.7523, MCC = 0.4902, F1-score = 0.6823\n",
      "      bSMOTE: AUC = 0.8204, G-Mean = 0.7509, MCC = 0.4883, F1-score = 0.6837\n",
      "      ROS: AUC = 0.8222, G-Mean = 0.7390, MCC = 0.4673, F1-score = 0.6647\n",
      "      MWMOTE: AUC = 0.8122, G-Mean = 0.7316, MCC = 0.4564, F1-score = 0.6581\n",
      "      Trans(Direct): AUC = 0.8324, G-Mean = 0.7363, MCC = 0.4616, F1-score = 0.6618\n",
      "\n",
      "Starting experiment 8/10\n",
      "  Fold 1/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.49515, Reg Loss: 0.17343\n",
      "Epoch 200/2000, Avg Loss: 0.42933, Reg Loss: 0.16480\n",
      "Epoch 300/2000, Avg Loss: 0.41214, Reg Loss: 0.16353\n",
      "Epoch 400/2000, Avg Loss: 0.39254, Reg Loss: 0.16236\n",
      "Epoch 500/2000, Avg Loss: 0.38766, Reg Loss: 0.16188\n",
      "Epoch 600/2000, Avg Loss: 0.36850, Reg Loss: 0.16038\n",
      "Epoch 700/2000, Avg Loss: 0.37528, Reg Loss: 0.15966\n",
      "Epoch 800/2000, Avg Loss: 0.37204, Reg Loss: 0.16021\n",
      "Epoch 900/2000, Avg Loss: 0.36383, Reg Loss: 0.15837\n",
      "Epoch 1000/2000, Avg Loss: 0.36333, Reg Loss: 0.16013\n",
      "Epoch 1100/2000, Avg Loss: 0.35310, Reg Loss: 0.15739\n",
      "Epoch 1200/2000, Avg Loss: 0.35569, Reg Loss: 0.15980\n",
      "Epoch 1300/2000, Avg Loss: 0.36398, Reg Loss: 0.15917\n",
      "Epoch 1400/2000, Avg Loss: 0.34551, Reg Loss: 0.15844\n",
      "Epoch 1500/2000, Avg Loss: 0.33816, Reg Loss: 0.15666\n",
      "Epoch 1600/2000, Avg Loss: 0.33637, Reg Loss: 0.15664\n",
      "Epoch 1700/2000, Avg Loss: 0.33424, Reg Loss: 0.15521\n",
      "Epoch 1800/2000, Avg Loss: 0.32393, Reg Loss: 0.15704\n",
      "Epoch 1900/2000, Avg Loss: 0.31479, Reg Loss: 0.15388\n",
      "Epoch 2000/2000, Avg Loss: 0.31220, Reg Loss: 0.15217\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.7474, G-Mean = 0.6110, MCC = 0.2366, F1-score = 0.5091\n",
      "      SMOTEBoost: AUC = 0.7956, G-Mean = 0.7165, MCC = 0.4178, F1-score = 0.6462\n",
      "      RUSBoost: AUC = 0.6341, G-Mean = 0.2449, MCC = 0.1480, F1-score = 0.5347\n",
      "      OUBoost: AUC = 0.8285, G-Mean = 0.6831, MCC = 0.3536, F1-score = 0.6000\n",
      "      SVM: AUC = 0.7756, G-Mean = 0.6435, MCC = 0.3716, F1-score = 0.5532\n",
      "      SMOTE: AUC = 0.7711, G-Mean = 0.6532, MCC = 0.3059, F1-score = 0.5614\n",
      "      ADASYN: AUC = 0.7711, G-Mean = 0.6831, MCC = 0.3536, F1-score = 0.6000\n",
      "      bSMOTE: AUC = 0.7630, G-Mean = 0.6777, MCC = 0.3443, F1-score = 0.6061\n",
      "      ROS: AUC = 0.8000, G-Mean = 0.7018, MCC = 0.3879, F1-score = 0.6230\n",
      "      MWMOTE: AUC = 0.7630, G-Mean = 0.7024, MCC = 0.3957, F1-score = 0.6207\n",
      "      Trans(Direct): AUC = 0.7519, G-Mean = 0.6061, MCC = 0.2037, F1-score = 0.5161\n",
      "  Fold 2/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.49161, Reg Loss: 0.15604\n",
      "Epoch 200/2000, Avg Loss: 0.42979, Reg Loss: 0.15816\n",
      "Epoch 300/2000, Avg Loss: 0.41528, Reg Loss: 0.15812\n",
      "Epoch 400/2000, Avg Loss: 0.38486, Reg Loss: 0.16098\n",
      "Epoch 500/2000, Avg Loss: 0.34487, Reg Loss: 0.15630\n",
      "Epoch 600/2000, Avg Loss: 0.32377, Reg Loss: 0.15640\n",
      "Epoch 700/2000, Avg Loss: 0.31504, Reg Loss: 0.15676\n",
      "Epoch 800/2000, Avg Loss: 0.29467, Reg Loss: 0.15502\n",
      "Epoch 900/2000, Avg Loss: 0.28964, Reg Loss: 0.15441\n",
      "Epoch 1000/2000, Avg Loss: 0.28846, Reg Loss: 0.15279\n",
      "Epoch 1100/2000, Avg Loss: 0.27909, Reg Loss: 0.15066\n",
      "Epoch 1200/2000, Avg Loss: 0.27182, Reg Loss: 0.14914\n",
      "Epoch 1300/2000, Avg Loss: 0.27932, Reg Loss: 0.15045\n",
      "Epoch 1400/2000, Avg Loss: 0.28489, Reg Loss: 0.15104\n",
      "Epoch 1500/2000, Avg Loss: 0.26458, Reg Loss: 0.14983\n",
      "Epoch 1600/2000, Avg Loss: 0.26269, Reg Loss: 0.15075\n",
      "Epoch 1700/2000, Avg Loss: 0.24466, Reg Loss: 0.14795\n",
      "Epoch 1800/2000, Avg Loss: 0.24200, Reg Loss: 0.14766\n",
      "Epoch 1900/2000, Avg Loss: 0.23100, Reg Loss: 0.14497\n",
      "Epoch 2000/2000, Avg Loss: 0.23603, Reg Loss: 0.14574\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.8059, G-Mean = 0.6787, MCC = 0.4130, F1-score = 0.6024\n",
      "      SMOTEBoost: AUC = 0.8156, G-Mean = 0.7334, MCC = 0.4569, F1-score = 0.6624\n",
      "      RUSBoost: AUC = 0.6557, G-Mean = 0.3697, MCC = 0.1365, F1-score = 0.5292\n",
      "      OUBoost: AUC = 0.8322, G-Mean = 0.7052, MCC = 0.4161, F1-score = 0.6269\n",
      "      SVM: AUC = 0.8089, G-Mean = 0.6581, MCC = 0.4337, F1-score = 0.5789\n",
      "      SMOTE: AUC = 0.8048, G-Mean = 0.7008, MCC = 0.4086, F1-score = 0.6203\n",
      "      ADASYN: AUC = 0.8015, G-Mean = 0.7214, MCC = 0.4365, F1-score = 0.6455\n",
      "      bSMOTE: AUC = 0.7889, G-Mean = 0.7093, MCC = 0.4088, F1-score = 0.6364\n",
      "      ROS: AUC = 0.8178, G-Mean = 0.6995, MCC = 0.4042, F1-score = 0.6192\n",
      "      MWMOTE: AUC = 0.7956, G-Mean = 0.7310, MCC = 0.4576, F1-score = 0.6558\n",
      "      Trans(Direct): AUC = 0.7967, G-Mean = 0.6925, MCC = 0.3719, F1-score = 0.6140\n",
      "  Fold 3/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.48701, Reg Loss: 0.15448\n",
      "Epoch 200/2000, Avg Loss: 0.47292, Reg Loss: 0.15629\n",
      "Epoch 300/2000, Avg Loss: 0.43555, Reg Loss: 0.15176\n",
      "Epoch 400/2000, Avg Loss: 0.39616, Reg Loss: 0.15804\n",
      "Epoch 500/2000, Avg Loss: 0.36697, Reg Loss: 0.15907\n",
      "Epoch 600/2000, Avg Loss: 0.35857, Reg Loss: 0.15936\n",
      "Epoch 700/2000, Avg Loss: 0.34261, Reg Loss: 0.15943\n",
      "Epoch 800/2000, Avg Loss: 0.35528, Reg Loss: 0.16051\n",
      "Epoch 900/2000, Avg Loss: 0.33112, Reg Loss: 0.16342\n",
      "Epoch 1000/2000, Avg Loss: 0.30822, Reg Loss: 0.15893\n",
      "Epoch 1100/2000, Avg Loss: 0.29968, Reg Loss: 0.16028\n",
      "Epoch 1200/2000, Avg Loss: 0.28566, Reg Loss: 0.15489\n",
      "Epoch 1300/2000, Avg Loss: 0.28365, Reg Loss: 0.15585\n",
      "Epoch 1400/2000, Avg Loss: 0.27209, Reg Loss: 0.15392\n",
      "Epoch 1500/2000, Avg Loss: 0.27430, Reg Loss: 0.15347\n",
      "Epoch 1600/2000, Avg Loss: 0.28387, Reg Loss: 0.15522\n",
      "Epoch 1700/2000, Avg Loss: 0.26056, Reg Loss: 0.15247\n",
      "Epoch 1800/2000, Avg Loss: 0.26281, Reg Loss: 0.15242\n",
      "Epoch 1900/2000, Avg Loss: 0.25979, Reg Loss: 0.15177\n",
      "Epoch 2000/2000, Avg Loss: 0.25633, Reg Loss: 0.14982\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.8242, G-Mean = 0.7148, MCC = 0.4736, F1-score = 0.6452\n",
      "      SMOTEBoost: AUC = 0.8353, G-Mean = 0.7512, MCC = 0.5029, F1-score = 0.6852\n",
      "      RUSBoost: AUC = 0.7065, G-Mean = 0.4596, MCC = 0.2083, F1-score = 0.5579\n",
      "      OUBoost: AUC = 0.8451, G-Mean = 0.7254, MCC = 0.4651, F1-score = 0.6532\n",
      "      SVM: AUC = 0.8200, G-Mean = 0.6869, MCC = 0.4662, F1-score = 0.6126\n",
      "      SMOTE: AUC = 0.8141, G-Mean = 0.7173, MCC = 0.4377, F1-score = 0.6397\n",
      "      ADASYN: AUC = 0.8144, G-Mean = 0.7362, MCC = 0.4615, F1-score = 0.6631\n",
      "      bSMOTE: AUC = 0.8074, G-Mean = 0.7291, MCC = 0.4454, F1-score = 0.6576\n",
      "      ROS: AUC = 0.8262, G-Mean = 0.7292, MCC = 0.4615, F1-score = 0.6552\n",
      "      MWMOTE: AUC = 0.8094, G-Mean = 0.7503, MCC = 0.4924, F1-score = 0.6786\n",
      "      Trans(Direct): AUC = 0.8146, G-Mean = 0.7341, MCC = 0.4538, F1-score = 0.6622\n",
      "  Fold 4/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.45954, Reg Loss: 0.15940\n",
      "Epoch 200/2000, Avg Loss: 0.41051, Reg Loss: 0.16191\n",
      "Epoch 300/2000, Avg Loss: 0.35260, Reg Loss: 0.16317\n",
      "Epoch 400/2000, Avg Loss: 0.32829, Reg Loss: 0.16124\n",
      "Epoch 500/2000, Avg Loss: 0.32221, Reg Loss: 0.16186\n",
      "Epoch 600/2000, Avg Loss: 0.31492, Reg Loss: 0.16063\n",
      "Epoch 700/2000, Avg Loss: 0.32088, Reg Loss: 0.16253\n",
      "Epoch 800/2000, Avg Loss: 0.30785, Reg Loss: 0.15877\n",
      "Epoch 900/2000, Avg Loss: 0.29343, Reg Loss: 0.15817\n",
      "Epoch 1000/2000, Avg Loss: 0.29205, Reg Loss: 0.15548\n",
      "Epoch 1100/2000, Avg Loss: 0.27358, Reg Loss: 0.15655\n",
      "Epoch 1200/2000, Avg Loss: 0.26364, Reg Loss: 0.15339\n",
      "Epoch 1300/2000, Avg Loss: 0.26393, Reg Loss: 0.15091\n",
      "Epoch 1400/2000, Avg Loss: 0.25814, Reg Loss: 0.15004\n",
      "Epoch 1500/2000, Avg Loss: 0.25650, Reg Loss: 0.14934\n",
      "Epoch 1600/2000, Avg Loss: 0.25635, Reg Loss: 0.14823\n",
      "Epoch 1700/2000, Avg Loss: 0.25243, Reg Loss: 0.14711\n",
      "Epoch 1800/2000, Avg Loss: 0.25219, Reg Loss: 0.14665\n",
      "Epoch 1900/2000, Avg Loss: 0.28957, Reg Loss: 0.15103\n",
      "Epoch 2000/2000, Avg Loss: 0.25185, Reg Loss: 0.14658\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.8289, G-Mean = 0.7006, MCC = 0.4628, F1-score = 0.6283\n",
      "      SMOTEBoost: AUC = 0.8419, G-Mean = 0.7198, MCC = 0.4686, F1-score = 0.6472\n",
      "      RUSBoost: AUC = 0.7427, G-Mean = 0.5179, MCC = 0.2611, F1-score = 0.5806\n",
      "      OUBoost: AUC = 0.8498, G-Mean = 0.7022, MCC = 0.4479, F1-score = 0.6263\n",
      "      SVM: AUC = 0.8287, G-Mean = 0.6485, MCC = 0.4406, F1-score = 0.5676\n",
      "      SMOTE: AUC = 0.8274, G-Mean = 0.7324, MCC = 0.4705, F1-score = 0.6591\n",
      "      ADASYN: AUC = 0.8286, G-Mean = 0.7517, MCC = 0.4963, F1-score = 0.6825\n",
      "      bSMOTE: AUC = 0.8215, G-Mean = 0.7513, MCC = 0.4922, F1-score = 0.6841\n",
      "      ROS: AUC = 0.8346, G-Mean = 0.7197, MCC = 0.4558, F1-score = 0.6445\n",
      "      MWMOTE: AUC = 0.8248, G-Mean = 0.7594, MCC = 0.5180, F1-score = 0.6916\n",
      "      Trans(Direct): AUC = 0.8254, G-Mean = 0.7473, MCC = 0.4891, F1-score = 0.6793\n",
      "  Fold 5/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.46524, Reg Loss: 0.15740\n",
      "Epoch 200/2000, Avg Loss: 0.41375, Reg Loss: 0.16229\n",
      "Epoch 300/2000, Avg Loss: 0.37878, Reg Loss: 0.15818\n",
      "Epoch 400/2000, Avg Loss: 0.37089, Reg Loss: 0.16133\n",
      "Epoch 500/2000, Avg Loss: 0.32861, Reg Loss: 0.15856\n",
      "Epoch 600/2000, Avg Loss: 0.31459, Reg Loss: 0.15520\n",
      "Epoch 700/2000, Avg Loss: 0.30275, Reg Loss: 0.15405\n",
      "Epoch 800/2000, Avg Loss: 0.29350, Reg Loss: 0.15255\n",
      "Epoch 900/2000, Avg Loss: 0.28149, Reg Loss: 0.15128\n",
      "Epoch 1000/2000, Avg Loss: 0.28074, Reg Loss: 0.15106\n",
      "Epoch 1100/2000, Avg Loss: 0.27935, Reg Loss: 0.15026\n",
      "Epoch 1200/2000, Avg Loss: 0.27448, Reg Loss: 0.14828\n",
      "Epoch 1300/2000, Avg Loss: 0.27604, Reg Loss: 0.14851\n",
      "Epoch 1400/2000, Avg Loss: 0.27065, Reg Loss: 0.14787\n",
      "Epoch 1500/2000, Avg Loss: 0.26840, Reg Loss: 0.14638\n",
      "Epoch 1600/2000, Avg Loss: 0.26875, Reg Loss: 0.14922\n",
      "Epoch 1700/2000, Avg Loss: 0.25338, Reg Loss: 0.14852\n",
      "Epoch 1800/2000, Avg Loss: 0.28986, Reg Loss: 0.15400\n",
      "Epoch 1900/2000, Avg Loss: 0.25729, Reg Loss: 0.14855\n",
      "Epoch 2000/2000, Avg Loss: 0.25306, Reg Loss: 0.14581\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.8350, G-Mean = 0.7144, MCC = 0.4942, F1-score = 0.6473\n",
      "      SMOTEBoost: AUC = 0.8430, G-Mean = 0.7277, MCC = 0.4788, F1-score = 0.6559\n",
      "      RUSBoost: AUC = 0.7481, G-Mean = 0.5021, MCC = 0.2534, F1-score = 0.5763\n",
      "      OUBoost: AUC = 0.8516, G-Mean = 0.7089, MCC = 0.4592, F1-score = 0.6344\n",
      "      SVM: AUC = 0.8311, G-Mean = 0.6665, MCC = 0.4641, F1-score = 0.5902\n",
      "      SMOTE: AUC = 0.8323, G-Mean = 0.7380, MCC = 0.4777, F1-score = 0.6652\n",
      "      ADASYN: AUC = 0.8324, G-Mean = 0.7417, MCC = 0.4746, F1-score = 0.6706\n",
      "      bSMOTE: AUC = 0.8268, G-Mean = 0.7486, MCC = 0.4851, F1-score = 0.6806\n",
      "      ROS: AUC = 0.8359, G-Mean = 0.7240, MCC = 0.4593, F1-score = 0.6489\n",
      "      MWMOTE: AUC = 0.8293, G-Mean = 0.7557, MCC = 0.5091, F1-score = 0.6866\n",
      "      Trans(Direct): AUC = 0.8313, G-Mean = 0.7402, MCC = 0.4730, F1-score = 0.6701\n",
      "  Fold 6/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.53517, Reg Loss: 0.16577\n",
      "Epoch 200/2000, Avg Loss: 0.47152, Reg Loss: 0.16158\n",
      "Epoch 300/2000, Avg Loss: 0.43298, Reg Loss: 0.16182\n",
      "Epoch 400/2000, Avg Loss: 0.39940, Reg Loss: 0.15459\n",
      "Epoch 500/2000, Avg Loss: 0.37825, Reg Loss: 0.15623\n",
      "Epoch 600/2000, Avg Loss: 0.36901, Reg Loss: 0.15487\n",
      "Epoch 700/2000, Avg Loss: 0.37389, Reg Loss: 0.15522\n",
      "Epoch 800/2000, Avg Loss: 0.38152, Reg Loss: 0.15628\n",
      "Epoch 900/2000, Avg Loss: 0.33378, Reg Loss: 0.15702\n",
      "Epoch 1000/2000, Avg Loss: 0.33989, Reg Loss: 0.15540\n",
      "Epoch 1100/2000, Avg Loss: 0.32265, Reg Loss: 0.15462\n",
      "Epoch 1200/2000, Avg Loss: 0.31749, Reg Loss: 0.15372\n",
      "Epoch 1300/2000, Avg Loss: 0.30751, Reg Loss: 0.15253\n",
      "Epoch 1400/2000, Avg Loss: 0.31005, Reg Loss: 0.15294\n",
      "Epoch 1500/2000, Avg Loss: 0.30456, Reg Loss: 0.15290\n",
      "Epoch 1600/2000, Avg Loss: 0.27907, Reg Loss: 0.15054\n",
      "Epoch 1700/2000, Avg Loss: 0.27224, Reg Loss: 0.14938\n",
      "Epoch 1800/2000, Avg Loss: 0.27478, Reg Loss: 0.14844\n",
      "Epoch 1900/2000, Avg Loss: 0.26725, Reg Loss: 0.14656\n",
      "Epoch 2000/2000, Avg Loss: 0.26549, Reg Loss: 0.14572\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.8298, G-Mean = 0.7050, MCC = 0.4835, F1-score = 0.6357\n",
      "      SMOTEBoost: AUC = 0.8340, G-Mean = 0.7162, MCC = 0.4554, F1-score = 0.6410\n",
      "      RUSBoost: AUC = 0.7488, G-Mean = 0.4878, MCC = 0.2450, F1-score = 0.5725\n",
      "      OUBoost: AUC = 0.8439, G-Mean = 0.7008, MCC = 0.4458, F1-score = 0.6239\n",
      "      SVM: AUC = 0.8236, G-Mean = 0.6608, MCC = 0.4528, F1-score = 0.5828\n",
      "      SMOTE: AUC = 0.8223, G-Mean = 0.7204, MCC = 0.4433, F1-score = 0.6436\n",
      "      ADASYN: AUC = 0.8214, G-Mean = 0.7255, MCC = 0.4430, F1-score = 0.6508\n",
      "      bSMOTE: AUC = 0.8153, G-Mean = 0.7278, MCC = 0.4460, F1-score = 0.6549\n",
      "      ROS: AUC = 0.8267, G-Mean = 0.7122, MCC = 0.4338, F1-score = 0.6343\n",
      "      MWMOTE: AUC = 0.8170, G-Mean = 0.7500, MCC = 0.4958, F1-score = 0.6795\n",
      "      Trans(Direct): AUC = 0.8256, G-Mean = 0.7257, MCC = 0.4451, F1-score = 0.6520\n",
      "  Fold 7/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.54792, Reg Loss: 0.16241\n",
      "Epoch 200/2000, Avg Loss: 0.41692, Reg Loss: 0.16505\n",
      "Epoch 300/2000, Avg Loss: 0.39602, Reg Loss: 0.17069\n",
      "Epoch 400/2000, Avg Loss: 0.35993, Reg Loss: 0.16628\n",
      "Epoch 500/2000, Avg Loss: 0.33993, Reg Loss: 0.16567\n",
      "Epoch 600/2000, Avg Loss: 0.32387, Reg Loss: 0.16379\n",
      "Epoch 700/2000, Avg Loss: 0.31501, Reg Loss: 0.16384\n",
      "Epoch 800/2000, Avg Loss: 0.31122, Reg Loss: 0.16288\n",
      "Epoch 900/2000, Avg Loss: 0.30918, Reg Loss: 0.16244\n",
      "Epoch 1000/2000, Avg Loss: 0.30739, Reg Loss: 0.16026\n",
      "Epoch 1100/2000, Avg Loss: 0.30619, Reg Loss: 0.16187\n",
      "Epoch 1200/2000, Avg Loss: 0.29851, Reg Loss: 0.16071\n",
      "Epoch 1300/2000, Avg Loss: 0.29576, Reg Loss: 0.16097\n",
      "Epoch 1400/2000, Avg Loss: 0.29032, Reg Loss: 0.16135\n",
      "Epoch 1500/2000, Avg Loss: 0.28789, Reg Loss: 0.16080\n",
      "Epoch 1600/2000, Avg Loss: 0.29531, Reg Loss: 0.16096\n",
      "Epoch 1700/2000, Avg Loss: 0.28877, Reg Loss: 0.15925\n",
      "Epoch 1800/2000, Avg Loss: 0.29600, Reg Loss: 0.16058\n",
      "Epoch 1900/2000, Avg Loss: 0.28993, Reg Loss: 0.15952\n",
      "Epoch 2000/2000, Avg Loss: 0.29299, Reg Loss: 0.15947\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.8253, G-Mean = 0.7073, MCC = 0.4773, F1-score = 0.6368\n",
      "      SMOTEBoost: AUC = 0.8262, G-Mean = 0.7082, MCC = 0.4345, F1-score = 0.6329\n",
      "      RUSBoost: AUC = 0.7541, G-Mean = 0.4808, MCC = 0.2417, F1-score = 0.5706\n",
      "      OUBoost: AUC = 0.8359, G-Mean = 0.6980, MCC = 0.4318, F1-score = 0.6209\n",
      "      SVM: AUC = 0.8198, G-Mean = 0.6672, MCC = 0.4517, F1-score = 0.5891\n",
      "      SMOTE: AUC = 0.8187, G-Mean = 0.7165, MCC = 0.4335, F1-score = 0.6388\n",
      "      ADASYN: AUC = 0.8138, G-Mean = 0.7177, MCC = 0.4266, F1-score = 0.6426\n",
      "      bSMOTE: AUC = 0.8078, G-Mean = 0.7246, MCC = 0.4392, F1-score = 0.6522\n",
      "      ROS: AUC = 0.8193, G-Mean = 0.7039, MCC = 0.4144, F1-score = 0.6247\n",
      "      MWMOTE: AUC = 0.8075, G-Mean = 0.7377, MCC = 0.4706, F1-score = 0.6648\n",
      "      Trans(Direct): AUC = 0.8190, G-Mean = 0.7219, MCC = 0.4362, F1-score = 0.6482\n",
      "  Fold 8/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.54380, Reg Loss: 0.15806\n",
      "Epoch 200/2000, Avg Loss: 0.48911, Reg Loss: 0.15747\n",
      "Epoch 300/2000, Avg Loss: 0.43625, Reg Loss: 0.15507\n",
      "Epoch 400/2000, Avg Loss: 0.44133, Reg Loss: 0.15509\n",
      "Epoch 500/2000, Avg Loss: 0.40222, Reg Loss: 0.16292\n",
      "Epoch 600/2000, Avg Loss: 0.37718, Reg Loss: 0.16286\n",
      "Epoch 700/2000, Avg Loss: 0.36890, Reg Loss: 0.16033\n",
      "Epoch 800/2000, Avg Loss: 0.36144, Reg Loss: 0.16001\n",
      "Epoch 900/2000, Avg Loss: 0.35359, Reg Loss: 0.15722\n",
      "Epoch 1000/2000, Avg Loss: 0.39560, Reg Loss: 0.15925\n",
      "Epoch 1100/2000, Avg Loss: 0.34432, Reg Loss: 0.15612\n",
      "Epoch 1200/2000, Avg Loss: 0.33495, Reg Loss: 0.15619\n",
      "Epoch 1300/2000, Avg Loss: 0.33004, Reg Loss: 0.15450\n",
      "Epoch 1400/2000, Avg Loss: 0.33033, Reg Loss: 0.15600\n",
      "Epoch 1500/2000, Avg Loss: 0.31908, Reg Loss: 0.15495\n",
      "Epoch 1600/2000, Avg Loss: 0.31520, Reg Loss: 0.15433\n",
      "Epoch 1700/2000, Avg Loss: 0.31642, Reg Loss: 0.15288\n",
      "Epoch 1800/2000, Avg Loss: 0.29964, Reg Loss: 0.15292\n",
      "Epoch 1900/2000, Avg Loss: 0.29745, Reg Loss: 0.15368\n",
      "Epoch 2000/2000, Avg Loss: 0.29519, Reg Loss: 0.15210\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.8230, G-Mean = 0.7165, MCC = 0.4906, F1-score = 0.6472\n",
      "      SMOTEBoost: AUC = 0.8258, G-Mean = 0.7139, MCC = 0.4437, F1-score = 0.6387\n",
      "      RUSBoost: AUC = 0.7503, G-Mean = 0.4869, MCC = 0.2543, F1-score = 0.5731\n",
      "      OUBoost: AUC = 0.8343, G-Mean = 0.7023, MCC = 0.4370, F1-score = 0.6250\n",
      "      SVM: AUC = 0.8198, G-Mean = 0.6708, MCC = 0.4491, F1-score = 0.5920\n",
      "      SMOTE: AUC = 0.8230, G-Mean = 0.7209, MCC = 0.4396, F1-score = 0.6436\n",
      "      ADASYN: AUC = 0.8195, G-Mean = 0.7228, MCC = 0.4357, F1-score = 0.6482\n",
      "      bSMOTE: AUC = 0.8120, G-Mean = 0.7225, MCC = 0.4351, F1-score = 0.6503\n",
      "      ROS: AUC = 0.8217, G-Mean = 0.7089, MCC = 0.4210, F1-score = 0.6299\n",
      "      MWMOTE: AUC = 0.8137, G-Mean = 0.7375, MCC = 0.4695, F1-score = 0.6650\n",
      "      Trans(Direct): AUC = 0.8218, G-Mean = 0.7293, MCC = 0.4489, F1-score = 0.6558\n",
      "  Fold 9/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.54891, Reg Loss: 0.16378\n",
      "Epoch 200/2000, Avg Loss: 0.48507, Reg Loss: 0.16238\n",
      "Epoch 300/2000, Avg Loss: 0.42726, Reg Loss: 0.16286\n",
      "Epoch 400/2000, Avg Loss: 0.41021, Reg Loss: 0.16123\n",
      "Epoch 500/2000, Avg Loss: 0.40391, Reg Loss: 0.15995\n",
      "Epoch 600/2000, Avg Loss: 0.42762, Reg Loss: 0.16826\n",
      "Epoch 700/2000, Avg Loss: 0.35238, Reg Loss: 0.16607\n",
      "Epoch 800/2000, Avg Loss: 0.34379, Reg Loss: 0.16404\n",
      "Epoch 900/2000, Avg Loss: 0.34199, Reg Loss: 0.16506\n",
      "Epoch 1000/2000, Avg Loss: 0.32509, Reg Loss: 0.16249\n",
      "Epoch 1100/2000, Avg Loss: 0.32545, Reg Loss: 0.16270\n",
      "Epoch 1200/2000, Avg Loss: 0.34019, Reg Loss: 0.17128\n",
      "Epoch 1300/2000, Avg Loss: 0.31452, Reg Loss: 0.16871\n",
      "Epoch 1400/2000, Avg Loss: 0.29591, Reg Loss: 0.16446\n",
      "Epoch 1500/2000, Avg Loss: 0.28677, Reg Loss: 0.16446\n",
      "Epoch 1600/2000, Avg Loss: 0.28889, Reg Loss: 0.16618\n",
      "Epoch 1700/2000, Avg Loss: 0.27924, Reg Loss: 0.16457\n",
      "Epoch 1800/2000, Avg Loss: 0.27860, Reg Loss: 0.16483\n",
      "Epoch 1900/2000, Avg Loss: 0.27934, Reg Loss: 0.16195\n",
      "Epoch 2000/2000, Avg Loss: 0.27301, Reg Loss: 0.16226\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.8251, G-Mean = 0.7207, MCC = 0.4903, F1-score = 0.6506\n",
      "      SMOTEBoost: AUC = 0.8188, G-Mean = 0.7163, MCC = 0.4457, F1-score = 0.6418\n",
      "      RUSBoost: AUC = 0.7603, G-Mean = 0.4861, MCC = 0.2543, F1-score = 0.5719\n",
      "      OUBoost: AUC = 0.8301, G-Mean = 0.7046, MCC = 0.4359, F1-score = 0.6273\n",
      "      SVM: AUC = 0.8220, G-Mean = 0.6812, MCC = 0.4568, F1-score = 0.6030\n",
      "      SMOTE: AUC = 0.8239, G-Mean = 0.7207, MCC = 0.4380, F1-score = 0.6439\n",
      "      ADASYN: AUC = 0.8189, G-Mean = 0.7248, MCC = 0.4408, F1-score = 0.6514\n",
      "      bSMOTE: AUC = 0.8083, G-Mean = 0.7227, MCC = 0.4361, F1-score = 0.6510\n",
      "      ROS: AUC = 0.8215, G-Mean = 0.7132, MCC = 0.4276, F1-score = 0.6351\n",
      "      MWMOTE: AUC = 0.8133, G-Mean = 0.7392, MCC = 0.4728, F1-score = 0.6674\n",
      "      Trans(Direct): AUC = 0.8253, G-Mean = 0.7287, MCC = 0.4483, F1-score = 0.6559\n",
      "  Fold 10/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.47808, Reg Loss: 0.17197\n",
      "Epoch 200/2000, Avg Loss: 0.43879, Reg Loss: 0.17731\n",
      "Epoch 300/2000, Avg Loss: 0.40217, Reg Loss: 0.17687\n",
      "Epoch 400/2000, Avg Loss: 0.36308, Reg Loss: 0.16513\n",
      "Epoch 500/2000, Avg Loss: 0.36290, Reg Loss: 0.16840\n",
      "Epoch 600/2000, Avg Loss: 0.34799, Reg Loss: 0.16668\n",
      "Epoch 700/2000, Avg Loss: 0.33656, Reg Loss: 0.16384\n",
      "Epoch 800/2000, Avg Loss: 0.33141, Reg Loss: 0.16560\n",
      "Epoch 900/2000, Avg Loss: 0.33156, Reg Loss: 0.16455\n",
      "Epoch 1000/2000, Avg Loss: 0.31801, Reg Loss: 0.16500\n",
      "Epoch 1100/2000, Avg Loss: 0.32331, Reg Loss: 0.16476\n",
      "Epoch 1200/2000, Avg Loss: 0.34591, Reg Loss: 0.16738\n",
      "Epoch 1300/2000, Avg Loss: 0.32857, Reg Loss: 0.16677\n",
      "Epoch 1400/2000, Avg Loss: 0.29106, Reg Loss: 0.16425\n",
      "Epoch 1500/2000, Avg Loss: 0.28406, Reg Loss: 0.16370\n",
      "Epoch 1600/2000, Avg Loss: 0.27704, Reg Loss: 0.16232\n",
      "Epoch 1700/2000, Avg Loss: 0.28565, Reg Loss: 0.16270\n",
      "Epoch 1800/2000, Avg Loss: 0.27092, Reg Loss: 0.16103\n",
      "Epoch 1900/2000, Avg Loss: 0.28056, Reg Loss: 0.16116\n",
      "Epoch 2000/2000, Avg Loss: 0.27169, Reg Loss: 0.16196\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.8276, G-Mean = 0.7219, MCC = 0.4886, F1-score = 0.6509\n",
      "      SMOTEBoost: AUC = 0.8178, G-Mean = 0.7153, MCC = 0.4407, F1-score = 0.6397\n",
      "      RUSBoost: AUC = 0.7695, G-Mean = 0.5039, MCC = 0.2749, F1-score = 0.5797\n",
      "      OUBoost: AUC = 0.8321, G-Mean = 0.7065, MCC = 0.4373, F1-score = 0.6287\n",
      "      SVM: AUC = 0.8290, G-Mean = 0.6850, MCC = 0.4576, F1-score = 0.6067\n",
      "      SMOTE: AUC = 0.8300, G-Mean = 0.7270, MCC = 0.4485, F1-score = 0.6507\n",
      "      ADASYN: AUC = 0.8242, G-Mean = 0.7332, MCC = 0.4577, F1-score = 0.6609\n",
      "      bSMOTE: AUC = 0.8146, G-Mean = 0.7280, MCC = 0.4460, F1-score = 0.6566\n",
      "      ROS: AUC = 0.8287, G-Mean = 0.7231, MCC = 0.4448, F1-score = 0.6462\n",
      "      MWMOTE: AUC = 0.8210, G-Mean = 0.7465, MCC = 0.4855, F1-score = 0.6753\n",
      "      Trans(Direct): AUC = 0.8320, G-Mean = 0.7396, MCC = 0.4684, F1-score = 0.6678\n",
      "\n",
      "Starting experiment 9/10\n",
      "  Fold 1/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.46544, Reg Loss: 0.16954\n",
      "Epoch 200/2000, Avg Loss: 0.44023, Reg Loss: 0.16974\n",
      "Epoch 300/2000, Avg Loss: 0.38240, Reg Loss: 0.17082\n",
      "Epoch 400/2000, Avg Loss: 0.34364, Reg Loss: 0.16748\n",
      "Epoch 500/2000, Avg Loss: 0.32620, Reg Loss: 0.16393\n",
      "Epoch 600/2000, Avg Loss: 0.30926, Reg Loss: 0.16380\n",
      "Epoch 700/2000, Avg Loss: 0.30547, Reg Loss: 0.16485\n",
      "Epoch 800/2000, Avg Loss: 0.28543, Reg Loss: 0.16037\n",
      "Epoch 900/2000, Avg Loss: 0.27490, Reg Loss: 0.15912\n",
      "Epoch 1000/2000, Avg Loss: 0.26689, Reg Loss: 0.15992\n",
      "Epoch 1100/2000, Avg Loss: 0.25820, Reg Loss: 0.15678\n",
      "Epoch 1200/2000, Avg Loss: 0.25646, Reg Loss: 0.15710\n",
      "Epoch 1300/2000, Avg Loss: 0.25253, Reg Loss: 0.15625\n",
      "Epoch 1400/2000, Avg Loss: 0.25125, Reg Loss: 0.15406\n",
      "Epoch 1500/2000, Avg Loss: 0.24919, Reg Loss: 0.15440\n",
      "Epoch 1600/2000, Avg Loss: 0.25096, Reg Loss: 0.15386\n",
      "Epoch 1700/2000, Avg Loss: 0.24188, Reg Loss: 0.15298\n",
      "Epoch 1800/2000, Avg Loss: 0.24711, Reg Loss: 0.15270\n",
      "Epoch 1900/2000, Avg Loss: 0.23995, Reg Loss: 0.15283\n",
      "Epoch 2000/2000, Avg Loss: 0.23783, Reg Loss: 0.15198\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.7515, G-Mean = 0.6110, MCC = 0.3095, F1-score = 0.5106\n",
      "      SMOTEBoost: AUC = 0.7974, G-Mean = 0.7097, MCC = 0.4296, F1-score = 0.6296\n",
      "      RUSBoost: AUC = 0.7978, G-Mean = 0.6667, MCC = 0.4096, F1-score = 0.6410\n",
      "      OUBoost: AUC = 0.7930, G-Mean = 0.6749, MCC = 0.3869, F1-score = 0.5882\n",
      "      SVM: AUC = 0.8015, G-Mean = 0.5292, MCC = 0.1994, F1-score = 0.4091\n",
      "      SMOTE: AUC = 0.7963, G-Mean = 0.6583, MCC = 0.3386, F1-score = 0.5660\n",
      "      ADASYN: AUC = 0.7822, G-Mean = 0.6325, MCC = 0.2714, F1-score = 0.5357\n",
      "      bSMOTE: AUC = 0.7752, G-Mean = 0.6622, MCC = 0.3275, F1-score = 0.5714\n",
      "      ROS: AUC = 0.7941, G-Mean = 0.6622, MCC = 0.3275, F1-score = 0.5714\n",
      "      MWMOTE: AUC = 0.7919, G-Mean = 0.6885, MCC = 0.3961, F1-score = 0.6038\n",
      "      Trans(Direct): AUC = 0.8104, G-Mean = 0.7185, MCC = 0.4537, F1-score = 0.6415\n",
      "  Fold 2/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.42652, Reg Loss: 0.16492\n",
      "Epoch 200/2000, Avg Loss: 0.36297, Reg Loss: 0.16523\n",
      "Epoch 300/2000, Avg Loss: 0.34232, Reg Loss: 0.16619\n",
      "Epoch 400/2000, Avg Loss: 0.32495, Reg Loss: 0.16268\n",
      "Epoch 500/2000, Avg Loss: 0.31798, Reg Loss: 0.16317\n",
      "Epoch 600/2000, Avg Loss: 0.28949, Reg Loss: 0.16102\n",
      "Epoch 700/2000, Avg Loss: 0.27751, Reg Loss: 0.15869\n",
      "Epoch 800/2000, Avg Loss: 0.27493, Reg Loss: 0.15942\n",
      "Epoch 900/2000, Avg Loss: 0.27316, Reg Loss: 0.15852\n",
      "Epoch 1000/2000, Avg Loss: 0.26975, Reg Loss: 0.15673\n",
      "Epoch 1100/2000, Avg Loss: 0.25549, Reg Loss: 0.15735\n",
      "Epoch 1200/2000, Avg Loss: 0.24845, Reg Loss: 0.15358\n",
      "Epoch 1300/2000, Avg Loss: 0.25533, Reg Loss: 0.15390\n",
      "Epoch 1400/2000, Avg Loss: 0.25130, Reg Loss: 0.15473\n",
      "Epoch 1500/2000, Avg Loss: 0.24351, Reg Loss: 0.15288\n",
      "Epoch 1600/2000, Avg Loss: 0.24922, Reg Loss: 0.15526\n",
      "Epoch 1700/2000, Avg Loss: 0.24624, Reg Loss: 0.15474\n",
      "Epoch 1800/2000, Avg Loss: 0.22476, Reg Loss: 0.15163\n",
      "Epoch 1900/2000, Avg Loss: 0.24066, Reg Loss: 0.15263\n",
      "Epoch 2000/2000, Avg Loss: 0.21631, Reg Loss: 0.15031\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.7957, G-Mean = 0.6471, MCC = 0.3864, F1-score = 0.5597\n",
      "      SMOTEBoost: AUC = 0.8157, G-Mean = 0.7300, MCC = 0.4628, F1-score = 0.6541\n",
      "      RUSBoost: AUC = 0.7170, G-Mean = 0.4558, MCC = 0.2788, F1-score = 0.5878\n",
      "      OUBoost: AUC = 0.8187, G-Mean = 0.7116, MCC = 0.4491, F1-score = 0.6337\n",
      "      SVM: AUC = 0.8130, G-Mean = 0.6061, MCC = 0.3059, F1-score = 0.5045\n",
      "      SMOTE: AUC = 0.8052, G-Mean = 0.6658, MCC = 0.3394, F1-score = 0.5761\n",
      "      ADASYN: AUC = 0.8004, G-Mean = 0.6674, MCC = 0.3335, F1-score = 0.5782\n",
      "      bSMOTE: AUC = 0.7950, G-Mean = 0.6820, MCC = 0.3577, F1-score = 0.5972\n",
      "      ROS: AUC = 0.8067, G-Mean = 0.6630, MCC = 0.3233, F1-score = 0.5738\n",
      "      MWMOTE: AUC = 0.7974, G-Mean = 0.6809, MCC = 0.3682, F1-score = 0.5950\n",
      "      Trans(Direct): AUC = 0.8133, G-Mean = 0.7008, MCC = 0.4036, F1-score = 0.6208\n",
      "  Fold 3/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.47463, Reg Loss: 0.15588\n",
      "Epoch 200/2000, Avg Loss: 0.47099, Reg Loss: 0.15310\n",
      "Epoch 300/2000, Avg Loss: 0.39786, Reg Loss: 0.14928\n",
      "Epoch 400/2000, Avg Loss: 0.36005, Reg Loss: 0.15092\n",
      "Epoch 500/2000, Avg Loss: 0.32426, Reg Loss: 0.14415\n",
      "Epoch 600/2000, Avg Loss: 0.30510, Reg Loss: 0.14430\n",
      "Epoch 700/2000, Avg Loss: 0.29178, Reg Loss: 0.14369\n",
      "Epoch 800/2000, Avg Loss: 0.29426, Reg Loss: 0.14363\n",
      "Epoch 900/2000, Avg Loss: 0.28503, Reg Loss: 0.14146\n",
      "Epoch 1000/2000, Avg Loss: 0.28390, Reg Loss: 0.14040\n",
      "Epoch 1100/2000, Avg Loss: 0.28357, Reg Loss: 0.13937\n",
      "Epoch 1200/2000, Avg Loss: 0.28410, Reg Loss: 0.13899\n",
      "Epoch 1300/2000, Avg Loss: 0.29097, Reg Loss: 0.14038\n",
      "Epoch 1400/2000, Avg Loss: 0.27598, Reg Loss: 0.13783\n",
      "Epoch 1500/2000, Avg Loss: 0.27949, Reg Loss: 0.13788\n",
      "Epoch 1600/2000, Avg Loss: 0.27375, Reg Loss: 0.13722\n",
      "Epoch 1700/2000, Avg Loss: 0.27378, Reg Loss: 0.13642\n",
      "Epoch 1800/2000, Avg Loss: 0.26792, Reg Loss: 0.13528\n",
      "Epoch 1900/2000, Avg Loss: 0.27062, Reg Loss: 0.13544\n",
      "Epoch 2000/2000, Avg Loss: 0.26787, Reg Loss: 0.13529\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.8221, G-Mean = 0.6943, MCC = 0.4496, F1-score = 0.6155\n",
      "      SMOTEBoost: AUC = 0.8211, G-Mean = 0.7420, MCC = 0.4791, F1-score = 0.6689\n",
      "      RUSBoost: AUC = 0.7330, G-Mean = 0.4707, MCC = 0.2778, F1-score = 0.5845\n",
      "      OUBoost: AUC = 0.8290, G-Mean = 0.7245, MCC = 0.4610, F1-score = 0.6485\n",
      "      SVM: AUC = 0.8385, G-Mean = 0.6852, MCC = 0.4507, F1-score = 0.6085\n",
      "      SMOTE: AUC = 0.8336, G-Mean = 0.7027, MCC = 0.4035, F1-score = 0.6206\n",
      "      ADASYN: AUC = 0.8259, G-Mean = 0.6986, MCC = 0.3916, F1-score = 0.6178\n",
      "      bSMOTE: AUC = 0.8201, G-Mean = 0.7046, MCC = 0.4014, F1-score = 0.6270\n",
      "      ROS: AUC = 0.8356, G-Mean = 0.7043, MCC = 0.3997, F1-score = 0.6230\n",
      "      MWMOTE: AUC = 0.8230, G-Mean = 0.7150, MCC = 0.4275, F1-score = 0.6362\n",
      "      Trans(Direct): AUC = 0.8407, G-Mean = 0.7261, MCC = 0.4463, F1-score = 0.6504\n",
      "  Fold 4/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.46805, Reg Loss: 0.16150\n",
      "Epoch 200/2000, Avg Loss: 0.43352, Reg Loss: 0.16519\n",
      "Epoch 300/2000, Avg Loss: 0.42219, Reg Loss: 0.16226\n",
      "Epoch 400/2000, Avg Loss: 0.40460, Reg Loss: 0.16292\n",
      "Epoch 500/2000, Avg Loss: 0.36994, Reg Loss: 0.16260\n",
      "Epoch 600/2000, Avg Loss: 0.37021, Reg Loss: 0.16059\n",
      "Epoch 700/2000, Avg Loss: 0.36143, Reg Loss: 0.16125\n",
      "Epoch 800/2000, Avg Loss: 0.35842, Reg Loss: 0.16077\n",
      "Epoch 900/2000, Avg Loss: 0.36705, Reg Loss: 0.16474\n",
      "Epoch 1000/2000, Avg Loss: 0.30867, Reg Loss: 0.15919\n",
      "Epoch 1100/2000, Avg Loss: 0.30781, Reg Loss: 0.15801\n",
      "Epoch 1200/2000, Avg Loss: 0.28365, Reg Loss: 0.15480\n",
      "Epoch 1300/2000, Avg Loss: 0.28862, Reg Loss: 0.15498\n",
      "Epoch 1400/2000, Avg Loss: 0.27345, Reg Loss: 0.15341\n",
      "Epoch 1500/2000, Avg Loss: 0.27048, Reg Loss: 0.15321\n",
      "Epoch 1600/2000, Avg Loss: 0.26130, Reg Loss: 0.15162\n",
      "Epoch 1700/2000, Avg Loss: 0.27949, Reg Loss: 0.15413\n",
      "Epoch 1800/2000, Avg Loss: 0.25959, Reg Loss: 0.15201\n",
      "Epoch 1900/2000, Avg Loss: 0.25515, Reg Loss: 0.15162\n",
      "Epoch 2000/2000, Avg Loss: 0.25295, Reg Loss: 0.15037\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.8186, G-Mean = 0.7056, MCC = 0.4589, F1-score = 0.6283\n",
      "      SMOTEBoost: AUC = 0.8189, G-Mean = 0.7368, MCC = 0.4693, F1-score = 0.6624\n",
      "      RUSBoost: AUC = 0.7366, G-Mean = 0.4142, MCC = 0.2453, F1-score = 0.5720\n",
      "      OUBoost: AUC = 0.8256, G-Mean = 0.7186, MCC = 0.4473, F1-score = 0.6409\n",
      "      SVM: AUC = 0.8315, G-Mean = 0.6924, MCC = 0.4560, F1-score = 0.6164\n",
      "      SMOTE: AUC = 0.8285, G-Mean = 0.7167, MCC = 0.4270, F1-score = 0.6376\n",
      "      ADASYN: AUC = 0.8193, G-Mean = 0.7198, MCC = 0.4302, F1-score = 0.6430\n",
      "      bSMOTE: AUC = 0.8134, G-Mean = 0.7200, MCC = 0.4290, F1-score = 0.6448\n",
      "      ROS: AUC = 0.8293, G-Mean = 0.7158, MCC = 0.4210, F1-score = 0.6367\n",
      "      MWMOTE: AUC = 0.8180, G-Mean = 0.7334, MCC = 0.4612, F1-score = 0.6582\n",
      "      Trans(Direct): AUC = 0.8387, G-Mean = 0.7387, MCC = 0.4677, F1-score = 0.6652\n",
      "  Fold 5/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.48000, Reg Loss: 0.16107\n",
      "Epoch 200/2000, Avg Loss: 0.45433, Reg Loss: 0.15487\n",
      "Epoch 300/2000, Avg Loss: 0.39482, Reg Loss: 0.15971\n",
      "Epoch 400/2000, Avg Loss: 0.36256, Reg Loss: 0.15922\n",
      "Epoch 500/2000, Avg Loss: 0.37351, Reg Loss: 0.15571\n",
      "Epoch 600/2000, Avg Loss: 0.32038, Reg Loss: 0.15507\n",
      "Epoch 700/2000, Avg Loss: 0.33280, Reg Loss: 0.15792\n",
      "Epoch 800/2000, Avg Loss: 0.30079, Reg Loss: 0.15573\n",
      "Epoch 900/2000, Avg Loss: 0.29831, Reg Loss: 0.15565\n",
      "Epoch 1000/2000, Avg Loss: 0.28845, Reg Loss: 0.15542\n",
      "Epoch 1100/2000, Avg Loss: 0.28593, Reg Loss: 0.15429\n",
      "Epoch 1200/2000, Avg Loss: 0.27342, Reg Loss: 0.15273\n",
      "Epoch 1300/2000, Avg Loss: 0.26852, Reg Loss: 0.15146\n",
      "Epoch 1400/2000, Avg Loss: 0.26578, Reg Loss: 0.15062\n",
      "Epoch 1500/2000, Avg Loss: 0.27577, Reg Loss: 0.15242\n",
      "Epoch 1600/2000, Avg Loss: 0.24798, Reg Loss: 0.14913\n",
      "Epoch 1700/2000, Avg Loss: 0.25104, Reg Loss: 0.14991\n",
      "Epoch 1800/2000, Avg Loss: 0.24879, Reg Loss: 0.14815\n",
      "Epoch 1900/2000, Avg Loss: 0.24490, Reg Loss: 0.14593\n",
      "Epoch 2000/2000, Avg Loss: 0.24148, Reg Loss: 0.14466\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.8193, G-Mean = 0.7159, MCC = 0.4744, F1-score = 0.6411\n",
      "      SMOTEBoost: AUC = 0.8210, G-Mean = 0.7293, MCC = 0.4520, F1-score = 0.6549\n",
      "      RUSBoost: AUC = 0.7530, G-Mean = 0.4524, MCC = 0.2709, F1-score = 0.5814\n",
      "      OUBoost: AUC = 0.8261, G-Mean = 0.7189, MCC = 0.4423, F1-score = 0.6418\n",
      "      SVM: AUC = 0.8341, G-Mean = 0.6993, MCC = 0.4605, F1-score = 0.6239\n",
      "      SMOTE: AUC = 0.8308, G-Mean = 0.7251, MCC = 0.4411, F1-score = 0.6478\n",
      "      ADASYN: AUC = 0.8221, G-Mean = 0.7255, MCC = 0.4396, F1-score = 0.6499\n",
      "      bSMOTE: AUC = 0.8186, G-Mean = 0.7248, MCC = 0.4376, F1-score = 0.6513\n",
      "      ROS: AUC = 0.8304, G-Mean = 0.7301, MCC = 0.4473, F1-score = 0.6537\n",
      "      MWMOTE: AUC = 0.8222, G-Mean = 0.7322, MCC = 0.4564, F1-score = 0.6578\n",
      "      Trans(Direct): AUC = 0.8410, G-Mean = 0.7406, MCC = 0.4695, F1-score = 0.6677\n",
      "  Fold 6/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.46536, Reg Loss: 0.16165\n",
      "Epoch 200/2000, Avg Loss: 0.46882, Reg Loss: 0.16134\n",
      "Epoch 300/2000, Avg Loss: 0.40028, Reg Loss: 0.15964\n",
      "Epoch 400/2000, Avg Loss: 0.38381, Reg Loss: 0.15952\n",
      "Epoch 500/2000, Avg Loss: 0.36698, Reg Loss: 0.15999\n",
      "Epoch 600/2000, Avg Loss: 0.36347, Reg Loss: 0.15862\n",
      "Epoch 700/2000, Avg Loss: 0.35188, Reg Loss: 0.15477\n",
      "Epoch 800/2000, Avg Loss: 0.33172, Reg Loss: 0.15312\n",
      "Epoch 900/2000, Avg Loss: 0.33229, Reg Loss: 0.15242\n",
      "Epoch 1000/2000, Avg Loss: 0.32423, Reg Loss: 0.15996\n",
      "Epoch 1100/2000, Avg Loss: 0.31947, Reg Loss: 0.16241\n",
      "Epoch 1200/2000, Avg Loss: 0.29406, Reg Loss: 0.15881\n",
      "Epoch 1300/2000, Avg Loss: 0.28536, Reg Loss: 0.15581\n",
      "Epoch 1400/2000, Avg Loss: 0.28286, Reg Loss: 0.15411\n",
      "Epoch 1500/2000, Avg Loss: 0.28260, Reg Loss: 0.15393\n",
      "Epoch 1600/2000, Avg Loss: 0.27911, Reg Loss: 0.15682\n",
      "Epoch 1700/2000, Avg Loss: 0.28382, Reg Loss: 0.15670\n",
      "Epoch 1800/2000, Avg Loss: 0.28085, Reg Loss: 0.15417\n",
      "Epoch 1900/2000, Avg Loss: 0.27843, Reg Loss: 0.15408\n",
      "Epoch 2000/2000, Avg Loss: 0.27469, Reg Loss: 0.15410\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.8157, G-Mean = 0.7142, MCC = 0.4696, F1-score = 0.6388\n",
      "      SMOTEBoost: AUC = 0.8206, G-Mean = 0.7339, MCC = 0.4661, F1-score = 0.6611\n",
      "      RUSBoost: AUC = 0.7661, G-Mean = 0.4824, MCC = 0.2983, F1-score = 0.5917\n",
      "      OUBoost: AUC = 0.8322, G-Mean = 0.7282, MCC = 0.4671, F1-score = 0.6548\n",
      "      SVM: AUC = 0.8285, G-Mean = 0.6925, MCC = 0.4554, F1-score = 0.6162\n",
      "      SMOTE: AUC = 0.8275, G-Mean = 0.7212, MCC = 0.4322, F1-score = 0.6437\n",
      "      ADASYN: AUC = 0.8200, G-Mean = 0.7293, MCC = 0.4458, F1-score = 0.6545\n",
      "      bSMOTE: AUC = 0.8155, G-Mean = 0.7225, MCC = 0.4340, F1-score = 0.6506\n",
      "      ROS: AUC = 0.8281, G-Mean = 0.7303, MCC = 0.4479, F1-score = 0.6539\n",
      "      MWMOTE: AUC = 0.8174, G-Mean = 0.7296, MCC = 0.4499, F1-score = 0.6559\n",
      "      Trans(Direct): AUC = 0.8378, G-Mean = 0.7430, MCC = 0.4732, F1-score = 0.6710\n",
      "  Fold 7/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.47700, Reg Loss: 0.16004\n",
      "Epoch 200/2000, Avg Loss: 0.44725, Reg Loss: 0.16606\n",
      "Epoch 300/2000, Avg Loss: 0.41971, Reg Loss: 0.16154\n",
      "Epoch 400/2000, Avg Loss: 0.37847, Reg Loss: 0.15536\n",
      "Epoch 500/2000, Avg Loss: 0.35385, Reg Loss: 0.15533\n",
      "Epoch 600/2000, Avg Loss: 0.35313, Reg Loss: 0.15352\n",
      "Epoch 700/2000, Avg Loss: 0.34394, Reg Loss: 0.15607\n",
      "Epoch 800/2000, Avg Loss: 0.30874, Reg Loss: 0.15428\n",
      "Epoch 900/2000, Avg Loss: 0.30727, Reg Loss: 0.15234\n",
      "Epoch 1000/2000, Avg Loss: 0.29466, Reg Loss: 0.15208\n",
      "Epoch 1100/2000, Avg Loss: 0.29306, Reg Loss: 0.15371\n",
      "Epoch 1200/2000, Avg Loss: 0.27827, Reg Loss: 0.15273\n",
      "Epoch 1300/2000, Avg Loss: 0.29373, Reg Loss: 0.15222\n",
      "Epoch 1400/2000, Avg Loss: 0.27150, Reg Loss: 0.15237\n",
      "Epoch 1500/2000, Avg Loss: 0.26719, Reg Loss: 0.15200\n",
      "Epoch 1600/2000, Avg Loss: 0.26833, Reg Loss: 0.15118\n",
      "Epoch 1700/2000, Avg Loss: 0.26538, Reg Loss: 0.14916\n",
      "Epoch 1800/2000, Avg Loss: 0.26648, Reg Loss: 0.14951\n",
      "Epoch 1900/2000, Avg Loss: 0.26042, Reg Loss: 0.14852\n",
      "Epoch 2000/2000, Avg Loss: 0.26033, Reg Loss: 0.14735\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.8174, G-Mean = 0.7097, MCC = 0.4542, F1-score = 0.6328\n",
      "      SMOTEBoost: AUC = 0.8249, G-Mean = 0.7377, MCC = 0.4719, F1-score = 0.6652\n",
      "      RUSBoost: AUC = 0.7770, G-Mean = 0.4960, MCC = 0.3001, F1-score = 0.5922\n",
      "      OUBoost: AUC = 0.8350, G-Mean = 0.7311, MCC = 0.4734, F1-score = 0.6583\n",
      "      SVM: AUC = 0.8272, G-Mean = 0.6923, MCC = 0.4531, F1-score = 0.6156\n",
      "      SMOTE: AUC = 0.8244, G-Mean = 0.7199, MCC = 0.4289, F1-score = 0.6422\n",
      "      ADASYN: AUC = 0.8156, G-Mean = 0.7268, MCC = 0.4405, F1-score = 0.6515\n",
      "      bSMOTE: AUC = 0.8135, G-Mean = 0.7224, MCC = 0.4334, F1-score = 0.6496\n",
      "      ROS: AUC = 0.8281, G-Mean = 0.7318, MCC = 0.4515, F1-score = 0.6557\n",
      "      MWMOTE: AUC = 0.8128, G-Mean = 0.7243, MCC = 0.4392, F1-score = 0.6493\n",
      "      Trans(Direct): AUC = 0.8393, G-Mean = 0.7467, MCC = 0.4797, F1-score = 0.6751\n",
      "  Fold 8/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.50637, Reg Loss: 0.16057\n",
      "Epoch 200/2000, Avg Loss: 0.47158, Reg Loss: 0.16238\n",
      "Epoch 300/2000, Avg Loss: 0.42135, Reg Loss: 0.16049\n",
      "Epoch 400/2000, Avg Loss: 0.39267, Reg Loss: 0.16411\n",
      "Epoch 500/2000, Avg Loss: 0.36225, Reg Loss: 0.16372\n",
      "Epoch 600/2000, Avg Loss: 0.34255, Reg Loss: 0.16225\n",
      "Epoch 700/2000, Avg Loss: 0.34700, Reg Loss: 0.16164\n",
      "Epoch 800/2000, Avg Loss: 0.31228, Reg Loss: 0.16082\n",
      "Epoch 900/2000, Avg Loss: 0.29628, Reg Loss: 0.16040\n",
      "Epoch 1000/2000, Avg Loss: 0.28706, Reg Loss: 0.16140\n",
      "Epoch 1100/2000, Avg Loss: 0.27666, Reg Loss: 0.16145\n",
      "Epoch 1200/2000, Avg Loss: 0.27582, Reg Loss: 0.16138\n",
      "Epoch 1300/2000, Avg Loss: 0.26811, Reg Loss: 0.16068\n",
      "Epoch 1400/2000, Avg Loss: 0.26315, Reg Loss: 0.15866\n",
      "Epoch 1500/2000, Avg Loss: 0.25738, Reg Loss: 0.15771\n",
      "Epoch 1600/2000, Avg Loss: 0.25601, Reg Loss: 0.15686\n",
      "Epoch 1700/2000, Avg Loss: 0.27605, Reg Loss: 0.15788\n",
      "Epoch 1800/2000, Avg Loss: 0.25105, Reg Loss: 0.15422\n",
      "Epoch 1900/2000, Avg Loss: 0.25241, Reg Loss: 0.15431\n",
      "Epoch 2000/2000, Avg Loss: 0.25090, Reg Loss: 0.15304\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.8194, G-Mean = 0.7151, MCC = 0.4609, F1-score = 0.6386\n",
      "      SMOTEBoost: AUC = 0.8255, G-Mean = 0.7359, MCC = 0.4662, F1-score = 0.6627\n",
      "      RUSBoost: AUC = 0.7713, G-Mean = 0.4975, MCC = 0.2922, F1-score = 0.5879\n",
      "      OUBoost: AUC = 0.8345, G-Mean = 0.7340, MCC = 0.4762, F1-score = 0.6608\n",
      "      SVM: AUC = 0.8292, G-Mean = 0.6947, MCC = 0.4645, F1-score = 0.6201\n",
      "      SMOTE: AUC = 0.8279, G-Mean = 0.7279, MCC = 0.4443, F1-score = 0.6512\n",
      "      ADASYN: AUC = 0.8194, G-Mean = 0.7352, MCC = 0.4560, F1-score = 0.6606\n",
      "      bSMOTE: AUC = 0.8157, G-Mean = 0.7300, MCC = 0.4471, F1-score = 0.6574\n",
      "      ROS: AUC = 0.8299, G-Mean = 0.7333, MCC = 0.4556, F1-score = 0.6571\n",
      "      MWMOTE: AUC = 0.8168, G-Mean = 0.7330, MCC = 0.4548, F1-score = 0.6587\n",
      "      Trans(Direct): AUC = 0.8401, G-Mean = 0.7514, MCC = 0.4888, F1-score = 0.6800\n",
      "  Fold 9/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.46880, Reg Loss: 0.16397\n",
      "Epoch 200/2000, Avg Loss: 0.41480, Reg Loss: 0.16374\n",
      "Epoch 300/2000, Avg Loss: 0.37097, Reg Loss: 0.16112\n",
      "Epoch 400/2000, Avg Loss: 0.34142, Reg Loss: 0.15932\n",
      "Epoch 500/2000, Avg Loss: 0.32622, Reg Loss: 0.15851\n",
      "Epoch 600/2000, Avg Loss: 0.41120, Reg Loss: 0.16160\n",
      "Epoch 700/2000, Avg Loss: 0.34592, Reg Loss: 0.16157\n",
      "Epoch 800/2000, Avg Loss: 0.31140, Reg Loss: 0.15700\n",
      "Epoch 900/2000, Avg Loss: 0.28461, Reg Loss: 0.15827\n",
      "Epoch 1000/2000, Avg Loss: 0.26808, Reg Loss: 0.15707\n",
      "Epoch 1100/2000, Avg Loss: 0.26335, Reg Loss: 0.15771\n",
      "Epoch 1200/2000, Avg Loss: 0.26318, Reg Loss: 0.15549\n",
      "Epoch 1300/2000, Avg Loss: 0.26352, Reg Loss: 0.15678\n",
      "Epoch 1400/2000, Avg Loss: 0.25478, Reg Loss: 0.15429\n",
      "Epoch 1500/2000, Avg Loss: 0.25460, Reg Loss: 0.15472\n",
      "Epoch 1600/2000, Avg Loss: 0.25035, Reg Loss: 0.15519\n",
      "Epoch 1700/2000, Avg Loss: 0.24790, Reg Loss: 0.15332\n",
      "Epoch 1800/2000, Avg Loss: 0.24878, Reg Loss: 0.15391\n",
      "Epoch 1900/2000, Avg Loss: 0.24984, Reg Loss: 0.15384\n",
      "Epoch 2000/2000, Avg Loss: 0.24645, Reg Loss: 0.15314\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.8191, G-Mean = 0.7117, MCC = 0.4507, F1-score = 0.6335\n",
      "      SMOTEBoost: AUC = 0.8216, G-Mean = 0.7358, MCC = 0.4647, F1-score = 0.6619\n",
      "      RUSBoost: AUC = 0.7586, G-Mean = 0.4875, MCC = 0.2751, F1-score = 0.5812\n",
      "      OUBoost: AUC = 0.8296, G-Mean = 0.7342, MCC = 0.4735, F1-score = 0.6602\n",
      "      SVM: AUC = 0.8244, G-Mean = 0.6895, MCC = 0.4486, F1-score = 0.6122\n",
      "      SMOTE: AUC = 0.8268, G-Mean = 0.7262, MCC = 0.4402, F1-score = 0.6494\n",
      "      ADASYN: AUC = 0.8186, G-Mean = 0.7340, MCC = 0.4546, F1-score = 0.6601\n",
      "      bSMOTE: AUC = 0.8151, G-Mean = 0.7281, MCC = 0.4447, F1-score = 0.6563\n",
      "      ROS: AUC = 0.8269, G-Mean = 0.7298, MCC = 0.4481, F1-score = 0.6535\n",
      "      MWMOTE: AUC = 0.8170, G-Mean = 0.7333, MCC = 0.4556, F1-score = 0.6596\n",
      "      Trans(Direct): AUC = 0.8357, G-Mean = 0.7439, MCC = 0.4736, F1-score = 0.6715\n",
      "  Fold 10/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.49294, Reg Loss: 0.15732\n",
      "Epoch 200/2000, Avg Loss: 0.45497, Reg Loss: 0.15823\n",
      "Epoch 300/2000, Avg Loss: 0.41836, Reg Loss: 0.15343\n",
      "Epoch 400/2000, Avg Loss: 0.40479, Reg Loss: 0.15314\n",
      "Epoch 500/2000, Avg Loss: 0.35261, Reg Loss: 0.15573\n",
      "Epoch 600/2000, Avg Loss: 0.34373, Reg Loss: 0.15452\n",
      "Epoch 700/2000, Avg Loss: 0.32621, Reg Loss: 0.15409\n",
      "Epoch 800/2000, Avg Loss: 0.30294, Reg Loss: 0.15439\n",
      "Epoch 900/2000, Avg Loss: 0.29242, Reg Loss: 0.15264\n",
      "Epoch 1000/2000, Avg Loss: 0.28838, Reg Loss: 0.15173\n",
      "Epoch 1100/2000, Avg Loss: 0.27653, Reg Loss: 0.15207\n",
      "Epoch 1200/2000, Avg Loss: 0.27079, Reg Loss: 0.15121\n",
      "Epoch 1300/2000, Avg Loss: 0.26514, Reg Loss: 0.15027\n",
      "Epoch 1400/2000, Avg Loss: 0.26458, Reg Loss: 0.15178\n",
      "Epoch 1500/2000, Avg Loss: 0.25744, Reg Loss: 0.14983\n",
      "Epoch 1600/2000, Avg Loss: 0.25861, Reg Loss: 0.15041\n",
      "Epoch 1700/2000, Avg Loss: 0.25761, Reg Loss: 0.14955\n",
      "Epoch 1800/2000, Avg Loss: 0.24954, Reg Loss: 0.14776\n",
      "Epoch 1900/2000, Avg Loss: 0.25930, Reg Loss: 0.14986\n",
      "Epoch 2000/2000, Avg Loss: 0.24604, Reg Loss: 0.14563\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.8204, G-Mean = 0.7061, MCC = 0.4444, F1-score = 0.6267\n",
      "      SMOTEBoost: AUC = 0.8253, G-Mean = 0.7372, MCC = 0.4707, F1-score = 0.6637\n",
      "      RUSBoost: AUC = 0.7639, G-Mean = 0.5084, MCC = 0.2864, F1-score = 0.5858\n",
      "      OUBoost: AUC = 0.8334, G-Mean = 0.7375, MCC = 0.4841, F1-score = 0.6650\n",
      "      SVM: AUC = 0.8266, G-Mean = 0.6864, MCC = 0.4516, F1-score = 0.6095\n",
      "      SMOTE: AUC = 0.8266, G-Mean = 0.7320, MCC = 0.4505, F1-score = 0.6556\n",
      "      ADASYN: AUC = 0.8187, G-Mean = 0.7375, MCC = 0.4610, F1-score = 0.6640\n",
      "      bSMOTE: AUC = 0.8154, G-Mean = 0.7272, MCC = 0.4428, F1-score = 0.6552\n",
      "      ROS: AUC = 0.8268, G-Mean = 0.7343, MCC = 0.4563, F1-score = 0.6584\n",
      "      MWMOTE: AUC = 0.8177, G-Mean = 0.7344, MCC = 0.4567, F1-score = 0.6603\n",
      "      Trans(Direct): AUC = 0.8380, G-Mean = 0.7508, MCC = 0.4862, F1-score = 0.6789\n",
      "\n",
      "Starting experiment 10/10\n",
      "  Fold 1/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.47605, Reg Loss: 0.15087\n",
      "Epoch 200/2000, Avg Loss: 0.43215, Reg Loss: 0.15670\n",
      "Epoch 300/2000, Avg Loss: 0.38484, Reg Loss: 0.15328\n",
      "Epoch 400/2000, Avg Loss: 0.34525, Reg Loss: 0.15080\n",
      "Epoch 500/2000, Avg Loss: 0.32210, Reg Loss: 0.14895\n",
      "Epoch 600/2000, Avg Loss: 0.32582, Reg Loss: 0.14680\n",
      "Epoch 700/2000, Avg Loss: 0.31005, Reg Loss: 0.14483\n",
      "Epoch 800/2000, Avg Loss: 0.29446, Reg Loss: 0.14446\n",
      "Epoch 900/2000, Avg Loss: 0.28598, Reg Loss: 0.14522\n",
      "Epoch 1000/2000, Avg Loss: 0.28364, Reg Loss: 0.14495\n",
      "Epoch 1100/2000, Avg Loss: 0.27863, Reg Loss: 0.14451\n",
      "Epoch 1200/2000, Avg Loss: 0.28232, Reg Loss: 0.14410\n",
      "Epoch 1300/2000, Avg Loss: 0.27193, Reg Loss: 0.14275\n",
      "Epoch 1400/2000, Avg Loss: 0.26272, Reg Loss: 0.14392\n",
      "Epoch 1500/2000, Avg Loss: 0.26667, Reg Loss: 0.14373\n",
      "Epoch 1600/2000, Avg Loss: 0.26418, Reg Loss: 0.14444\n",
      "Epoch 1700/2000, Avg Loss: 0.25845, Reg Loss: 0.14358\n",
      "Epoch 1800/2000, Avg Loss: 0.25172, Reg Loss: 0.14370\n",
      "Epoch 1900/2000, Avg Loss: 0.27386, Reg Loss: 0.14550\n",
      "Epoch 2000/2000, Avg Loss: 0.24968, Reg Loss: 0.14326\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.7719, G-Mean = 0.6885, MCC = 0.3961, F1-score = 0.6038\n",
      "      SMOTEBoost: AUC = 0.8163, G-Mean = 0.7303, MCC = 0.4427, F1-score = 0.6557\n",
      "      RUSBoost: AUC = 0.6044, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.5192\n",
      "      OUBoost: AUC = 0.8067, G-Mean = 0.7024, MCC = 0.3957, F1-score = 0.6207\n",
      "      SVM: AUC = 0.8748, G-Mean = 0.7659, MCC = 0.5632, F1-score = 0.7059\n",
      "      SMOTE: AUC = 0.8378, G-Mean = 0.7659, MCC = 0.5115, F1-score = 0.6984\n",
      "      ADASYN: AUC = 0.8341, G-Mean = 0.7888, MCC = 0.5621, F1-score = 0.7273\n",
      "      bSMOTE: AUC = 0.8156, G-Mean = 0.7444, MCC = 0.4723, F1-score = 0.6769\n",
      "      ROS: AUC = 0.8489, G-Mean = 0.7765, MCC = 0.5317, F1-score = 0.7097\n",
      "      MWMOTE: AUC = 0.8111, G-Mean = 0.7221, MCC = 0.4344, F1-score = 0.6567\n",
      "      Trans(Direct): AUC = 0.8548, G-Mean = 0.7722, MCC = 0.5267, F1-score = 0.7077\n",
      "  Fold 2/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.49990, Reg Loss: 0.16280\n",
      "Epoch 200/2000, Avg Loss: 0.44695, Reg Loss: 0.16545\n",
      "Epoch 300/2000, Avg Loss: 0.39636, Reg Loss: 0.16367\n",
      "Epoch 400/2000, Avg Loss: 0.38863, Reg Loss: 0.16152\n",
      "Epoch 500/2000, Avg Loss: 0.40763, Reg Loss: 0.16498\n",
      "Epoch 600/2000, Avg Loss: 0.38178, Reg Loss: 0.15700\n",
      "Epoch 700/2000, Avg Loss: 0.35378, Reg Loss: 0.15780\n",
      "Epoch 800/2000, Avg Loss: 0.35525, Reg Loss: 0.15782\n",
      "Epoch 900/2000, Avg Loss: 0.33309, Reg Loss: 0.15948\n",
      "Epoch 1000/2000, Avg Loss: 0.32531, Reg Loss: 0.16037\n",
      "Epoch 1100/2000, Avg Loss: 0.31139, Reg Loss: 0.15850\n",
      "Epoch 1200/2000, Avg Loss: 0.30763, Reg Loss: 0.15866\n",
      "Epoch 1300/2000, Avg Loss: 0.29797, Reg Loss: 0.15740\n",
      "Epoch 1400/2000, Avg Loss: 0.36034, Reg Loss: 0.16054\n",
      "Epoch 1500/2000, Avg Loss: 0.29473, Reg Loss: 0.15707\n",
      "Epoch 1600/2000, Avg Loss: 0.28615, Reg Loss: 0.15591\n",
      "Epoch 1700/2000, Avg Loss: 0.27777, Reg Loss: 0.15526\n",
      "Epoch 1800/2000, Avg Loss: 0.31333, Reg Loss: 0.15716\n",
      "Epoch 1900/2000, Avg Loss: 0.27844, Reg Loss: 0.15438\n",
      "Epoch 2000/2000, Avg Loss: 0.27348, Reg Loss: 0.15321\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.8137, G-Mean = 0.7122, MCC = 0.4503, F1-score = 0.6352\n",
      "      SMOTEBoost: AUC = 0.8072, G-Mean = 0.7244, MCC = 0.4482, F1-score = 0.6486\n",
      "      RUSBoost: AUC = 0.6426, G-Mean = 0.1388, MCC = 0.0416, F1-score = 0.5222\n",
      "      OUBoost: AUC = 0.8130, G-Mean = 0.7040, MCC = 0.4207, F1-score = 0.6241\n",
      "      SVM: AUC = 0.8680, G-Mean = 0.7121, MCC = 0.4966, F1-score = 0.6418\n",
      "      SMOTE: AUC = 0.8444, G-Mean = 0.7527, MCC = 0.4991, F1-score = 0.6825\n",
      "      ADASYN: AUC = 0.8463, G-Mean = 0.7937, MCC = 0.5735, F1-score = 0.7321\n",
      "      bSMOTE: AUC = 0.8300, G-Mean = 0.7616, MCC = 0.5062, F1-score = 0.6944\n",
      "      ROS: AUC = 0.8578, G-Mean = 0.7924, MCC = 0.5700, F1-score = 0.7298\n",
      "      MWMOTE: AUC = 0.8259, G-Mean = 0.7411, MCC = 0.4705, F1-score = 0.6732\n",
      "      Trans(Direct): AUC = 0.8615, G-Mean = 0.7948, MCC = 0.5722, F1-score = 0.7332\n",
      "  Fold 3/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.50117, Reg Loss: 0.15607\n",
      "Epoch 200/2000, Avg Loss: 0.47433, Reg Loss: 0.15899\n",
      "Epoch 300/2000, Avg Loss: 0.42552, Reg Loss: 0.16272\n",
      "Epoch 400/2000, Avg Loss: 0.43439, Reg Loss: 0.16365\n",
      "Epoch 500/2000, Avg Loss: 0.41482, Reg Loss: 0.16683\n",
      "Epoch 600/2000, Avg Loss: 0.39962, Reg Loss: 0.17006\n",
      "Epoch 700/2000, Avg Loss: 0.34616, Reg Loss: 0.16626\n",
      "Epoch 800/2000, Avg Loss: 0.39814, Reg Loss: 0.16463\n",
      "Epoch 900/2000, Avg Loss: 0.34277, Reg Loss: 0.16044\n",
      "Epoch 1000/2000, Avg Loss: 0.31347, Reg Loss: 0.16002\n",
      "Epoch 1100/2000, Avg Loss: 0.31294, Reg Loss: 0.16190\n",
      "Epoch 1200/2000, Avg Loss: 0.28884, Reg Loss: 0.16460\n",
      "Epoch 1300/2000, Avg Loss: 0.28464, Reg Loss: 0.16575\n",
      "Epoch 1400/2000, Avg Loss: 0.26332, Reg Loss: 0.15881\n",
      "Epoch 1500/2000, Avg Loss: 0.25976, Reg Loss: 0.15692\n",
      "Epoch 1600/2000, Avg Loss: 0.24953, Reg Loss: 0.15300\n",
      "Epoch 1700/2000, Avg Loss: 0.24855, Reg Loss: 0.15147\n",
      "Epoch 1800/2000, Avg Loss: 0.24734, Reg Loss: 0.15154\n",
      "Epoch 1900/2000, Avg Loss: 0.25069, Reg Loss: 0.14978\n",
      "Epoch 2000/2000, Avg Loss: 0.24092, Reg Loss: 0.14952\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.8348, G-Mean = 0.7280, MCC = 0.4733, F1-score = 0.6538\n",
      "      SMOTEBoost: AUC = 0.8190, G-Mean = 0.7383, MCC = 0.4693, F1-score = 0.6652\n",
      "      RUSBoost: AUC = 0.6895, G-Mean = 0.3095, MCC = 0.1678, F1-score = 0.5622\n",
      "      OUBoost: AUC = 0.8300, G-Mean = 0.7127, MCC = 0.4280, F1-score = 0.6346\n",
      "      SVM: AUC = 0.8683, G-Mean = 0.7499, MCC = 0.5580, F1-score = 0.6893\n",
      "      SMOTE: AUC = 0.8427, G-Mean = 0.7663, MCC = 0.5259, F1-score = 0.7001\n",
      "      ADASYN: AUC = 0.8496, G-Mean = 0.7857, MCC = 0.5636, F1-score = 0.7261\n",
      "      bSMOTE: AUC = 0.8314, G-Mean = 0.7539, MCC = 0.4942, F1-score = 0.6884\n",
      "      ROS: AUC = 0.8642, G-Mean = 0.7727, MCC = 0.5311, F1-score = 0.7088\n",
      "      MWMOTE: AUC = 0.8326, G-Mean = 0.7478, MCC = 0.4829, F1-score = 0.6811\n",
      "      Trans(Direct): AUC = 0.8627, G-Mean = 0.7743, MCC = 0.5325, F1-score = 0.7110\n",
      "  Fold 4/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.52911, Reg Loss: 0.15595\n",
      "Epoch 200/2000, Avg Loss: 0.49892, Reg Loss: 0.15455\n",
      "Epoch 300/2000, Avg Loss: 0.49434, Reg Loss: 0.15424\n",
      "Epoch 400/2000, Avg Loss: 0.46170, Reg Loss: 0.15313\n",
      "Epoch 500/2000, Avg Loss: 0.40625, Reg Loss: 0.15049\n",
      "Epoch 600/2000, Avg Loss: 0.38352, Reg Loss: 0.14891\n",
      "Epoch 700/2000, Avg Loss: 0.35540, Reg Loss: 0.14844\n",
      "Epoch 800/2000, Avg Loss: 0.34340, Reg Loss: 0.14762\n",
      "Epoch 900/2000, Avg Loss: 0.34246, Reg Loss: 0.14907\n",
      "Epoch 1000/2000, Avg Loss: 0.32909, Reg Loss: 0.15140\n",
      "Epoch 1100/2000, Avg Loss: 0.36976, Reg Loss: 0.14994\n",
      "Epoch 1200/2000, Avg Loss: 0.31051, Reg Loss: 0.14940\n",
      "Epoch 1300/2000, Avg Loss: 0.30132, Reg Loss: 0.15052\n",
      "Epoch 1400/2000, Avg Loss: 0.29223, Reg Loss: 0.14741\n",
      "Epoch 1500/2000, Avg Loss: 0.29196, Reg Loss: 0.14825\n",
      "Epoch 1600/2000, Avg Loss: 0.30877, Reg Loss: 0.14928\n",
      "Epoch 1700/2000, Avg Loss: 0.28406, Reg Loss: 0.14576\n",
      "Epoch 1800/2000, Avg Loss: 0.28224, Reg Loss: 0.14499\n",
      "Epoch 1900/2000, Avg Loss: 0.28277, Reg Loss: 0.14568\n",
      "Epoch 2000/2000, Avg Loss: 0.28555, Reg Loss: 0.14417\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.8374, G-Mean = 0.7300, MCC = 0.4811, F1-score = 0.6570\n",
      "      SMOTEBoost: AUC = 0.8320, G-Mean = 0.7333, MCC = 0.4654, F1-score = 0.6593\n",
      "      RUSBoost: AUC = 0.7106, G-Mean = 0.3752, MCC = 0.2112, F1-score = 0.5728\n",
      "      OUBoost: AUC = 0.8315, G-Mean = 0.7185, MCC = 0.4471, F1-score = 0.6426\n",
      "      SVM: AUC = 0.8629, G-Mean = 0.7009, MCC = 0.4992, F1-score = 0.6295\n",
      "      SMOTE: AUC = 0.8485, G-Mean = 0.7792, MCC = 0.5526, F1-score = 0.7160\n",
      "      ADASYN: AUC = 0.8509, G-Mean = 0.7841, MCC = 0.5608, F1-score = 0.7232\n",
      "      bSMOTE: AUC = 0.8393, G-Mean = 0.7602, MCC = 0.5087, F1-score = 0.6949\n",
      "      ROS: AUC = 0.8600, G-Mean = 0.7580, MCC = 0.5163, F1-score = 0.6916\n",
      "      MWMOTE: AUC = 0.8389, G-Mean = 0.7530, MCC = 0.4981, F1-score = 0.6868\n",
      "      Trans(Direct): AUC = 0.8629, G-Mean = 0.7633, MCC = 0.5151, F1-score = 0.6969\n",
      "  Fold 5/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.50707, Reg Loss: 0.17451\n",
      "Epoch 200/2000, Avg Loss: 0.47871, Reg Loss: 0.17467\n",
      "Epoch 300/2000, Avg Loss: 0.41376, Reg Loss: 0.17523\n",
      "Epoch 400/2000, Avg Loss: 0.41419, Reg Loss: 0.17049\n",
      "Epoch 500/2000, Avg Loss: 0.36996, Reg Loss: 0.17483\n",
      "Epoch 600/2000, Avg Loss: 0.36562, Reg Loss: 0.17219\n",
      "Epoch 700/2000, Avg Loss: 0.37492, Reg Loss: 0.17561\n",
      "Epoch 800/2000, Avg Loss: 0.35636, Reg Loss: 0.17783\n",
      "Epoch 900/2000, Avg Loss: 0.34507, Reg Loss: 0.17386\n",
      "Epoch 1000/2000, Avg Loss: 0.33782, Reg Loss: 0.17425\n",
      "Epoch 1100/2000, Avg Loss: 0.37375, Reg Loss: 0.17039\n",
      "Epoch 1200/2000, Avg Loss: 0.33778, Reg Loss: 0.17482\n",
      "Epoch 1300/2000, Avg Loss: 0.31582, Reg Loss: 0.16825\n",
      "Epoch 1400/2000, Avg Loss: 0.32491, Reg Loss: 0.17134\n",
      "Epoch 1500/2000, Avg Loss: 0.33144, Reg Loss: 0.16914\n",
      "Epoch 1600/2000, Avg Loss: 0.29188, Reg Loss: 0.16692\n",
      "Epoch 1700/2000, Avg Loss: 0.29113, Reg Loss: 0.16425\n",
      "Epoch 1800/2000, Avg Loss: 0.31465, Reg Loss: 0.17618\n",
      "Epoch 1900/2000, Avg Loss: 0.28613, Reg Loss: 0.16327\n",
      "Epoch 2000/2000, Avg Loss: 0.28549, Reg Loss: 0.16392\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.8326, G-Mean = 0.7263, MCC = 0.4684, F1-score = 0.6519\n",
      "      SMOTEBoost: AUC = 0.8207, G-Mean = 0.7363, MCC = 0.4677, F1-score = 0.6629\n",
      "      RUSBoost: AUC = 0.6829, G-Mean = 0.3001, MCC = 0.1690, F1-score = 0.5621\n",
      "      OUBoost: AUC = 0.8204, G-Mean = 0.7150, MCC = 0.4390, F1-score = 0.6377\n",
      "      SVM: AUC = 0.8460, G-Mean = 0.7009, MCC = 0.4806, F1-score = 0.6272\n",
      "      SMOTE: AUC = 0.8327, G-Mean = 0.7657, MCC = 0.5238, F1-score = 0.6995\n",
      "      ADASYN: AUC = 0.8323, G-Mean = 0.7636, MCC = 0.5182, F1-score = 0.6992\n",
      "      bSMOTE: AUC = 0.8231, G-Mean = 0.7445, MCC = 0.4766, F1-score = 0.6765\n",
      "      ROS: AUC = 0.8396, G-Mean = 0.7448, MCC = 0.4866, F1-score = 0.6758\n",
      "      MWMOTE: AUC = 0.8236, G-Mean = 0.7428, MCC = 0.4761, F1-score = 0.6740\n",
      "      Trans(Direct): AUC = 0.8490, G-Mean = 0.7526, MCC = 0.4926, F1-score = 0.6845\n",
      "  Fold 6/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.51366, Reg Loss: 0.16112\n",
      "Epoch 200/2000, Avg Loss: 0.43399, Reg Loss: 0.17150\n",
      "Epoch 300/2000, Avg Loss: 0.42559, Reg Loss: 0.16825\n",
      "Epoch 400/2000, Avg Loss: 0.41405, Reg Loss: 0.16767\n",
      "Epoch 500/2000, Avg Loss: 0.39811, Reg Loss: 0.16735\n",
      "Epoch 600/2000, Avg Loss: 0.38885, Reg Loss: 0.17028\n",
      "Epoch 700/2000, Avg Loss: 0.35029, Reg Loss: 0.16557\n",
      "Epoch 800/2000, Avg Loss: 0.34424, Reg Loss: 0.16255\n",
      "Epoch 900/2000, Avg Loss: 0.31619, Reg Loss: 0.16081\n",
      "Epoch 1000/2000, Avg Loss: 0.31079, Reg Loss: 0.16368\n",
      "Epoch 1100/2000, Avg Loss: 0.30090, Reg Loss: 0.16494\n",
      "Epoch 1200/2000, Avg Loss: 0.29016, Reg Loss: 0.16154\n",
      "Epoch 1300/2000, Avg Loss: 0.28842, Reg Loss: 0.16119\n",
      "Epoch 1400/2000, Avg Loss: 0.29830, Reg Loss: 0.16141\n",
      "Epoch 1500/2000, Avg Loss: 0.27904, Reg Loss: 0.15906\n",
      "Epoch 1600/2000, Avg Loss: 0.27985, Reg Loss: 0.15862\n",
      "Epoch 1700/2000, Avg Loss: 0.27865, Reg Loss: 0.15872\n",
      "Epoch 1800/2000, Avg Loss: 0.27081, Reg Loss: 0.15593\n",
      "Epoch 1900/2000, Avg Loss: 0.26414, Reg Loss: 0.15521\n",
      "Epoch 2000/2000, Avg Loss: 0.30026, Reg Loss: 0.15699\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.8288, G-Mean = 0.7250, MCC = 0.4659, F1-score = 0.6502\n",
      "      SMOTEBoost: AUC = 0.8229, G-Mean = 0.7358, MCC = 0.4653, F1-score = 0.6635\n",
      "      RUSBoost: AUC = 0.6919, G-Mean = 0.3436, MCC = 0.1899, F1-score = 0.5664\n",
      "      OUBoost: AUC = 0.8230, G-Mean = 0.7225, MCC = 0.4503, F1-score = 0.6464\n",
      "      SVM: AUC = 0.8394, G-Mean = 0.7081, MCC = 0.4891, F1-score = 0.6360\n",
      "      SMOTE: AUC = 0.8262, G-Mean = 0.7567, MCC = 0.5046, F1-score = 0.6884\n",
      "      ADASYN: AUC = 0.8274, G-Mean = 0.7533, MCC = 0.4965, F1-score = 0.6865\n",
      "      bSMOTE: AUC = 0.8144, G-Mean = 0.7357, MCC = 0.4584, F1-score = 0.6659\n",
      "      ROS: AUC = 0.8310, G-Mean = 0.7440, MCC = 0.4827, F1-score = 0.6743\n",
      "      MWMOTE: AUC = 0.8183, G-Mean = 0.7376, MCC = 0.4648, F1-score = 0.6672\n",
      "      Trans(Direct): AUC = 0.8399, G-Mean = 0.7440, MCC = 0.4782, F1-score = 0.6734\n",
      "  Fold 7/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.47936, Reg Loss: 0.17627\n",
      "Epoch 200/2000, Avg Loss: 0.42291, Reg Loss: 0.16773\n",
      "Epoch 300/2000, Avg Loss: 0.37178, Reg Loss: 0.16479\n",
      "Epoch 400/2000, Avg Loss: 0.33823, Reg Loss: 0.16179\n",
      "Epoch 500/2000, Avg Loss: 0.34145, Reg Loss: 0.16379\n",
      "Epoch 600/2000, Avg Loss: 0.35067, Reg Loss: 0.16683\n",
      "Epoch 700/2000, Avg Loss: 0.33066, Reg Loss: 0.16546\n",
      "Epoch 800/2000, Avg Loss: 0.31945, Reg Loss: 0.16295\n",
      "Epoch 900/2000, Avg Loss: 0.31551, Reg Loss: 0.16437\n",
      "Epoch 1000/2000, Avg Loss: 0.31548, Reg Loss: 0.16296\n",
      "Epoch 1100/2000, Avg Loss: 0.29825, Reg Loss: 0.16071\n",
      "Epoch 1200/2000, Avg Loss: 0.29474, Reg Loss: 0.16050\n",
      "Epoch 1300/2000, Avg Loss: 0.29154, Reg Loss: 0.15823\n",
      "Epoch 1400/2000, Avg Loss: 0.29182, Reg Loss: 0.15816\n",
      "Epoch 1500/2000, Avg Loss: 0.28848, Reg Loss: 0.15847\n",
      "Epoch 1600/2000, Avg Loss: 0.30961, Reg Loss: 0.16104\n",
      "Epoch 1700/2000, Avg Loss: 0.28361, Reg Loss: 0.15799\n",
      "Epoch 1800/2000, Avg Loss: 0.39161, Reg Loss: 0.17043\n",
      "Epoch 1900/2000, Avg Loss: 0.32047, Reg Loss: 0.16588\n",
      "Epoch 2000/2000, Avg Loss: 0.31066, Reg Loss: 0.16365\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.8356, G-Mean = 0.7246, MCC = 0.4707, F1-score = 0.6506\n",
      "      SMOTEBoost: AUC = 0.8221, G-Mean = 0.7352, MCC = 0.4633, F1-score = 0.6623\n",
      "      RUSBoost: AUC = 0.7037, G-Mean = 0.3753, MCC = 0.2165, F1-score = 0.5732\n",
      "      OUBoost: AUC = 0.8231, G-Mean = 0.7176, MCC = 0.4425, F1-score = 0.6403\n",
      "      SVM: AUC = 0.8404, G-Mean = 0.6967, MCC = 0.4647, F1-score = 0.6210\n",
      "      SMOTE: AUC = 0.8278, G-Mean = 0.7445, MCC = 0.4824, F1-score = 0.6732\n",
      "      ADASYN: AUC = 0.8298, G-Mean = 0.7445, MCC = 0.4804, F1-score = 0.6751\n",
      "      bSMOTE: AUC = 0.8192, G-Mean = 0.7351, MCC = 0.4574, F1-score = 0.6644\n",
      "      ROS: AUC = 0.8332, G-Mean = 0.7323, MCC = 0.4606, F1-score = 0.6596\n",
      "      MWMOTE: AUC = 0.8228, G-Mean = 0.7353, MCC = 0.4612, F1-score = 0.6637\n",
      "      Trans(Direct): AUC = 0.8405, G-Mean = 0.7408, MCC = 0.4713, F1-score = 0.6692\n",
      "  Fold 8/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.49183, Reg Loss: 0.16520\n",
      "Epoch 200/2000, Avg Loss: 0.40847, Reg Loss: 0.16542\n",
      "Epoch 300/2000, Avg Loss: 0.36741, Reg Loss: 0.16141\n",
      "Epoch 400/2000, Avg Loss: 0.33360, Reg Loss: 0.16282\n",
      "Epoch 500/2000, Avg Loss: 0.35935, Reg Loss: 0.16204\n",
      "Epoch 600/2000, Avg Loss: 0.31331, Reg Loss: 0.15932\n",
      "Epoch 700/2000, Avg Loss: 0.31078, Reg Loss: 0.15935\n",
      "Epoch 800/2000, Avg Loss: 0.29323, Reg Loss: 0.15945\n",
      "Epoch 900/2000, Avg Loss: 0.28557, Reg Loss: 0.15710\n",
      "Epoch 1000/2000, Avg Loss: 0.27465, Reg Loss: 0.15708\n",
      "Epoch 1100/2000, Avg Loss: 0.26172, Reg Loss: 0.15391\n",
      "Epoch 1200/2000, Avg Loss: 0.25714, Reg Loss: 0.15207\n",
      "Epoch 1300/2000, Avg Loss: 0.25642, Reg Loss: 0.15135\n",
      "Epoch 1400/2000, Avg Loss: 0.25564, Reg Loss: 0.15023\n",
      "Epoch 1500/2000, Avg Loss: 0.31866, Reg Loss: 0.15842\n",
      "Epoch 1600/2000, Avg Loss: 0.25358, Reg Loss: 0.15199\n",
      "Epoch 1700/2000, Avg Loss: 0.24685, Reg Loss: 0.14972\n",
      "Epoch 1800/2000, Avg Loss: 0.25082, Reg Loss: 0.15001\n",
      "Epoch 1900/2000, Avg Loss: 0.24403, Reg Loss: 0.14811\n",
      "Epoch 2000/2000, Avg Loss: 0.24418, Reg Loss: 0.14719\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.8381, G-Mean = 0.7231, MCC = 0.4724, F1-score = 0.6491\n",
      "      SMOTEBoost: AUC = 0.8219, G-Mean = 0.7348, MCC = 0.4646, F1-score = 0.6613\n",
      "      RUSBoost: AUC = 0.7143, G-Mean = 0.4151, MCC = 0.2471, F1-score = 0.5838\n",
      "      OUBoost: AUC = 0.8247, G-Mean = 0.7189, MCC = 0.4486, F1-score = 0.6419\n",
      "      SVM: AUC = 0.8373, G-Mean = 0.6902, MCC = 0.4580, F1-score = 0.6131\n",
      "      SMOTE: AUC = 0.8277, G-Mean = 0.7369, MCC = 0.4683, F1-score = 0.6631\n",
      "      ADASYN: AUC = 0.8280, G-Mean = 0.7433, MCC = 0.4780, F1-score = 0.6726\n",
      "      bSMOTE: AUC = 0.8190, G-Mean = 0.7325, MCC = 0.4535, F1-score = 0.6601\n",
      "      ROS: AUC = 0.8321, G-Mean = 0.7326, MCC = 0.4606, F1-score = 0.6590\n",
      "      MWMOTE: AUC = 0.8221, G-Mean = 0.7300, MCC = 0.4526, F1-score = 0.6562\n",
      "      Trans(Direct): AUC = 0.8419, G-Mean = 0.7412, MCC = 0.4729, F1-score = 0.6689\n",
      "  Fold 9/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.51674, Reg Loss: 0.15841\n",
      "Epoch 200/2000, Avg Loss: 0.49041, Reg Loss: 0.16063\n",
      "Epoch 300/2000, Avg Loss: 0.41375, Reg Loss: 0.16155\n",
      "Epoch 400/2000, Avg Loss: 0.37870, Reg Loss: 0.16220\n",
      "Epoch 500/2000, Avg Loss: 0.36794, Reg Loss: 0.16218\n",
      "Epoch 600/2000, Avg Loss: 0.33571, Reg Loss: 0.16470\n",
      "Epoch 700/2000, Avg Loss: 0.31461, Reg Loss: 0.16273\n",
      "Epoch 800/2000, Avg Loss: 0.30759, Reg Loss: 0.16184\n",
      "Epoch 900/2000, Avg Loss: 0.29734, Reg Loss: 0.16059\n",
      "Epoch 1000/2000, Avg Loss: 0.29164, Reg Loss: 0.15971\n",
      "Epoch 1100/2000, Avg Loss: 0.29382, Reg Loss: 0.16222\n",
      "Epoch 1200/2000, Avg Loss: 0.28867, Reg Loss: 0.16086\n",
      "Epoch 1300/2000, Avg Loss: 0.28397, Reg Loss: 0.15879\n",
      "Epoch 1400/2000, Avg Loss: 0.28281, Reg Loss: 0.15819\n",
      "Epoch 1500/2000, Avg Loss: 0.28253, Reg Loss: 0.15765\n",
      "Epoch 1600/2000, Avg Loss: 0.27816, Reg Loss: 0.15787\n",
      "Epoch 1700/2000, Avg Loss: 0.27892, Reg Loss: 0.15694\n",
      "Epoch 1800/2000, Avg Loss: 0.28189, Reg Loss: 0.15628\n",
      "Epoch 1900/2000, Avg Loss: 0.35771, Reg Loss: 0.16309\n",
      "Epoch 2000/2000, Avg Loss: 0.26973, Reg Loss: 0.16079\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.8245, G-Mean = 0.7122, MCC = 0.4517, F1-score = 0.6347\n",
      "      SMOTEBoost: AUC = 0.8163, G-Mean = 0.7349, MCC = 0.4632, F1-score = 0.6606\n",
      "      RUSBoost: AUC = 0.7214, G-Mean = 0.4224, MCC = 0.2479, F1-score = 0.5813\n",
      "      OUBoost: AUC = 0.8181, G-Mean = 0.7150, MCC = 0.4397, F1-score = 0.6364\n",
      "      SVM: AUC = 0.8307, G-Mean = 0.6802, MCC = 0.4349, F1-score = 0.5994\n",
      "      SMOTE: AUC = 0.8211, G-Mean = 0.7258, MCC = 0.4455, F1-score = 0.6497\n",
      "      ADASYN: AUC = 0.8212, G-Mean = 0.7406, MCC = 0.4721, F1-score = 0.6696\n",
      "      bSMOTE: AUC = 0.8133, G-Mean = 0.7302, MCC = 0.4484, F1-score = 0.6573\n",
      "      ROS: AUC = 0.8252, G-Mean = 0.7185, MCC = 0.4330, F1-score = 0.6413\n",
      "      MWMOTE: AUC = 0.8193, G-Mean = 0.7260, MCC = 0.4436, F1-score = 0.6514\n",
      "      Trans(Direct): AUC = 0.8347, G-Mean = 0.7297, MCC = 0.4496, F1-score = 0.6549\n",
      "  Fold 10/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.45191, Reg Loss: 0.16881\n",
      "Epoch 200/2000, Avg Loss: 0.37802, Reg Loss: 0.16641\n",
      "Epoch 300/2000, Avg Loss: 0.35002, Reg Loss: 0.16805\n",
      "Epoch 400/2000, Avg Loss: 0.32344, Reg Loss: 0.16800\n",
      "Epoch 500/2000, Avg Loss: 0.31430, Reg Loss: 0.16559\n",
      "Epoch 600/2000, Avg Loss: 0.29273, Reg Loss: 0.16247\n",
      "Epoch 700/2000, Avg Loss: 0.30116, Reg Loss: 0.16720\n",
      "Epoch 800/2000, Avg Loss: 0.27095, Reg Loss: 0.16303\n",
      "Epoch 900/2000, Avg Loss: 0.27189, Reg Loss: 0.16150\n",
      "Epoch 1000/2000, Avg Loss: 0.26367, Reg Loss: 0.15830\n",
      "Epoch 1100/2000, Avg Loss: 0.26575, Reg Loss: 0.15819\n",
      "Epoch 1200/2000, Avg Loss: 0.26955, Reg Loss: 0.15930\n",
      "Epoch 1300/2000, Avg Loss: 0.26173, Reg Loss: 0.15663\n",
      "Epoch 1400/2000, Avg Loss: 0.26228, Reg Loss: 0.15524\n",
      "Epoch 1500/2000, Avg Loss: 0.24689, Reg Loss: 0.15349\n",
      "Epoch 1600/2000, Avg Loss: 0.24440, Reg Loss: 0.15171\n",
      "Epoch 1700/2000, Avg Loss: 0.26694, Reg Loss: 0.15558\n",
      "Epoch 1800/2000, Avg Loss: 0.25231, Reg Loss: 0.15094\n",
      "Epoch 1900/2000, Avg Loss: 0.25305, Reg Loss: 0.15052\n",
      "Epoch 2000/2000, Avg Loss: 0.25317, Reg Loss: 0.14965\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.8250, G-Mean = 0.7113, MCC = 0.4577, F1-score = 0.6349\n",
      "      SMOTEBoost: AUC = 0.8179, G-Mean = 0.7298, MCC = 0.4538, F1-score = 0.6538\n",
      "      RUSBoost: AUC = 0.7286, G-Mean = 0.4193, MCC = 0.2409, F1-score = 0.5770\n",
      "      OUBoost: AUC = 0.8193, G-Mean = 0.7176, MCC = 0.4456, F1-score = 0.6394\n",
      "      SVM: AUC = 0.8310, G-Mean = 0.6833, MCC = 0.4459, F1-score = 0.6046\n",
      "      SMOTE: AUC = 0.8236, G-Mean = 0.7297, MCC = 0.4518, F1-score = 0.6537\n",
      "      ADASYN: AUC = 0.8241, G-Mean = 0.7449, MCC = 0.4792, F1-score = 0.6739\n",
      "      bSMOTE: AUC = 0.8175, G-Mean = 0.7348, MCC = 0.4572, F1-score = 0.6623\n",
      "      ROS: AUC = 0.8275, G-Mean = 0.7229, MCC = 0.4399, F1-score = 0.6460\n",
      "      MWMOTE: AUC = 0.8227, G-Mean = 0.7318, MCC = 0.4535, F1-score = 0.6575\n",
      "      Trans(Direct): AUC = 0.8343, G-Mean = 0.7322, MCC = 0.4542, F1-score = 0.6572\n",
      "\n",
      "Final Averaged Results Across Experiments:\n",
      "  AdaBoost:\n",
      "    AUC: 0.8218\n",
      "    G-Mean: 0.7103\n",
      "    MCC: 0.4566\n",
      "    F1-score: 0.6332\n",
      "  SMOTEBoost:\n",
      "    AUC: 0.8205\n",
      "    G-Mean: 0.7288\n",
      "    MCC: 0.4606\n",
      "    F1-score: 0.6548\n",
      "  RUSBoost:\n",
      "    AUC: 0.7561\n",
      "    G-Mean: 0.5071\n",
      "    MCC: 0.2714\n",
      "    F1-score: 0.5806\n",
      "  OUBoost:\n",
      "    AUC: 0.8276\n",
      "    G-Mean: 0.7248\n",
      "    MCC: 0.4674\n",
      "    F1-score: 0.6499\n",
      "  SVM:\n",
      "    AUC: 0.8290\n",
      "    G-Mean: 0.6904\n",
      "    MCC: 0.4589\n",
      "    F1-score: 0.6136\n",
      "  SMOTE:\n",
      "    AUC: 0.8249\n",
      "    G-Mean: 0.7356\n",
      "    MCC: 0.4629\n",
      "    F1-score: 0.6610\n",
      "  ADASYN:\n",
      "    AUC: 0.8211\n",
      "    G-Mean: 0.7418\n",
      "    MCC: 0.4722\n",
      "    F1-score: 0.6703\n",
      "  bSMOTE:\n",
      "    AUC: 0.8156\n",
      "    G-Mean: 0.7368\n",
      "    MCC: 0.4628\n",
      "    F1-score: 0.6666\n",
      "  ROS:\n",
      "    AUC: 0.8275\n",
      "    G-Mean: 0.7325\n",
      "    MCC: 0.4572\n",
      "    F1-score: 0.6572\n",
      "  MWMOTE:\n",
      "    AUC: 0.8185\n",
      "    G-Mean: 0.7360\n",
      "    MCC: 0.4631\n",
      "    F1-score: 0.6627\n",
      "  Trans(Direct):\n",
      "    AUC: 0.8322\n",
      "    G-Mean: 0.7401\n",
      "    MCC: 0.4690\n",
      "    F1-score: 0.6671\n",
      "\n",
      "Final results saved to /data4/oldrain123/oldrain123/results/real_results/pima_final_results.csv\n",
      "\n",
      "Method: AdaBoost\n",
      "  AUC: 0.8218  0.0050\n",
      "  G-Mean: 0.7103  0.0083\n",
      "  MCC: 0.4566  0.0186\n",
      "  F1-score: 0.6332  0.0109\n",
      "\n",
      "Method: SMOTEBoost\n",
      "  AUC: 0.8205  0.0048\n",
      "  G-Mean: 0.7288  0.0081\n",
      "  MCC: 0.4606  0.0163\n",
      "  F1-score: 0.6548  0.0094\n",
      "\n",
      "Method: RUSBoost\n",
      "  AUC: 0.7561  0.0201\n",
      "  G-Mean: 0.5071  0.0592\n",
      "  MCC: 0.2714  0.0454\n",
      "  F1-score: 0.5806  0.0147\n",
      "\n",
      "Method: OUBoost\n",
      "  AUC: 0.8276  0.0060\n",
      "  G-Mean: 0.7248  0.0115\n",
      "  MCC: 0.4674  0.0227\n",
      "  F1-score: 0.6499  0.0140\n",
      "\n",
      "Method: SVM\n",
      "  AUC: 0.8290  0.0012\n",
      "  G-Mean: 0.6904  0.0077\n",
      "  MCC: 0.4589  0.0124\n",
      "  F1-score: 0.6136  0.0097\n",
      "\n",
      "Method: SMOTE\n",
      "  AUC: 0.8249  0.0026\n",
      "  G-Mean: 0.7356  0.0055\n",
      "  MCC: 0.4629  0.0117\n",
      "  F1-score: 0.6610  0.0070\n",
      "\n",
      "Method: ADASYN\n",
      "  AUC: 0.8211  0.0026\n",
      "  G-Mean: 0.7418  0.0068\n",
      "  MCC: 0.4722  0.0124\n",
      "  F1-score: 0.6703  0.0083\n",
      "\n",
      "Method: bSMOTE\n",
      "  AUC: 0.8156  0.0032\n",
      "  G-Mean: 0.7368  0.0074\n",
      "  MCC: 0.4628  0.0145\n",
      "  F1-score: 0.6666  0.0090\n",
      "\n",
      "Method: ROS\n",
      "  AUC: 0.8275  0.0036\n",
      "  G-Mean: 0.7325  0.0073\n",
      "  MCC: 0.4572  0.0114\n",
      "  F1-score: 0.6572  0.0082\n",
      "\n",
      "Method: MWMOTE\n",
      "  AUC: 0.8185  0.0031\n",
      "  G-Mean: 0.7360  0.0056\n",
      "  MCC: 0.4631  0.0124\n",
      "  F1-score: 0.6627  0.0070\n",
      "\n",
      "Method: Trans(Direct)\n",
      "  AUC: 0.8322  0.0028\n",
      "  G-Mean: 0.7401  0.0055\n",
      "  MCC: 0.4690  0.0109\n",
      "  F1-score: 0.6671  0.0073\n"
     ]
    }
   ],
   "source": [
    "# pima\n",
    "data_name = 'pima'\n",
    "dataframe = pd.read_csv(f\"{data_path}{data_name}.dat\")\n",
    "results = run_experiment(dataframe, device, h_dim=256, num_layers=10, beta=0.3, lr = 0.001, save_path=save_path, data_name = data_name)\n",
    "\n",
    "for method, metrics in results.items():\n",
    "    print(f\"\\nMethod: {method}\")\n",
    "    for metric, values in metrics.items():\n",
    "        mean_value = np.mean(values)\n",
    "        std_value = np.std(values)\n",
    "        print(f\"  {metric}: {mean_value:.4f}  {std_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (213, 9)\n",
      "Class distribution: Counter({np.int64(0): 162, np.int64(1): 51})\n",
      "\n",
      "Starting experiment 1/10\n",
      "  Fold 1/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.27251, Reg Loss: 0.31265\n",
      "Epoch 200/2000, Avg Loss: 0.19615, Reg Loss: 0.31696\n",
      "Epoch 300/2000, Avg Loss: 0.16760, Reg Loss: 0.30553\n",
      "Epoch 400/2000, Avg Loss: 0.14533, Reg Loss: 0.30166\n",
      "Epoch 500/2000, Avg Loss: 0.15223, Reg Loss: 0.30075\n",
      "Epoch 600/2000, Avg Loss: 0.12104, Reg Loss: 0.31112\n",
      "Epoch 700/2000, Avg Loss: 0.12560, Reg Loss: 0.31115\n",
      "Epoch 800/2000, Avg Loss: 0.11309, Reg Loss: 0.29660\n",
      "Epoch 900/2000, Avg Loss: 0.11050, Reg Loss: 0.31387\n",
      "Epoch 1000/2000, Avg Loss: 0.11335, Reg Loss: 0.29589\n",
      "Epoch 1100/2000, Avg Loss: 0.10395, Reg Loss: 0.29034\n",
      "Epoch 1200/2000, Avg Loss: 0.10648, Reg Loss: 0.28794\n",
      "Epoch 1300/2000, Avg Loss: 0.09280, Reg Loss: 0.28364\n",
      "Epoch 1400/2000, Avg Loss: 0.10498, Reg Loss: 0.28982\n",
      "Epoch 1500/2000, Avg Loss: 0.08492, Reg Loss: 0.28056\n",
      "Epoch 1600/2000, Avg Loss: 0.08725, Reg Loss: 0.27980\n",
      "Epoch 1700/2000, Avg Loss: 0.09088, Reg Loss: 0.27980\n",
      "Epoch 1800/2000, Avg Loss: 0.07878, Reg Loss: 0.27925\n",
      "Epoch 1900/2000, Avg Loss: 0.09455, Reg Loss: 0.27639\n",
      "Epoch 2000/2000, Avg Loss: 0.09747, Reg Loss: 0.29036\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.9882, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      SMOTEBoost: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      RUSBoost: AUC = 1.0000, G-Mean = 0.9393, MCC = 0.7939, F1-score = 0.8333\n",
      "      OUBoost: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      SVM: AUC = 1.0000, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      SMOTE: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      ADASYN: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      bSMOTE: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      ROS: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      MWMOTE: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      Trans(Direct): AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "  Fold 2/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.23586, Reg Loss: 0.29880\n",
      "Epoch 200/2000, Avg Loss: 0.19403, Reg Loss: 0.29992\n",
      "Epoch 300/2000, Avg Loss: 0.16964, Reg Loss: 0.29865\n",
      "Epoch 400/2000, Avg Loss: 0.15646, Reg Loss: 0.29917\n",
      "Epoch 500/2000, Avg Loss: 0.14220, Reg Loss: 0.29329\n",
      "Epoch 600/2000, Avg Loss: 0.14154, Reg Loss: 0.28018\n",
      "Epoch 700/2000, Avg Loss: 0.12034, Reg Loss: 0.27937\n",
      "Epoch 800/2000, Avg Loss: 0.12151, Reg Loss: 0.28460\n",
      "Epoch 900/2000, Avg Loss: 0.10870, Reg Loss: 0.29405\n",
      "Epoch 1000/2000, Avg Loss: 0.09187, Reg Loss: 0.28981\n",
      "Epoch 1100/2000, Avg Loss: 0.09934, Reg Loss: 0.28825\n",
      "Epoch 1200/2000, Avg Loss: 0.09581, Reg Loss: 0.27800\n",
      "Epoch 1300/2000, Avg Loss: 0.10911, Reg Loss: 0.28056\n",
      "Epoch 1400/2000, Avg Loss: 0.09599, Reg Loss: 0.26941\n",
      "Epoch 1500/2000, Avg Loss: 0.11141, Reg Loss: 0.27466\n",
      "Epoch 1600/2000, Avg Loss: 0.08704, Reg Loss: 0.27055\n",
      "Epoch 1700/2000, Avg Loss: 0.08790, Reg Loss: 0.25641\n",
      "Epoch 1800/2000, Avg Loss: 0.09580, Reg Loss: 0.26348\n",
      "Epoch 1900/2000, Avg Loss: 0.08399, Reg Loss: 0.25699\n",
      "Epoch 2000/2000, Avg Loss: 0.09595, Reg Loss: 0.25845\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.9941, G-Mean = 0.9323, MCC = 0.8774, F1-score = 0.8990\n",
      "      SMOTEBoost: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      RUSBoost: AUC = 0.9706, G-Mean = 0.7122, MCC = 0.5248, F1-score = 0.6341\n",
      "      OUBoost: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      SVM: AUC = 0.9941, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      SMOTE: AUC = 1.0000, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      ADASYN: AUC = 1.0000, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      bSMOTE: AUC = 0.9941, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      ROS: AUC = 1.0000, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      MWMOTE: AUC = 1.0000, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      Trans(Direct): AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "  Fold 3/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.22233, Reg Loss: 0.29449\n",
      "Epoch 200/2000, Avg Loss: 0.18461, Reg Loss: 0.28198\n",
      "Epoch 300/2000, Avg Loss: 0.15591, Reg Loss: 0.28607\n",
      "Epoch 400/2000, Avg Loss: 0.14379, Reg Loss: 0.28406\n",
      "Epoch 500/2000, Avg Loss: 0.12395, Reg Loss: 0.27603\n",
      "Epoch 600/2000, Avg Loss: 0.11628, Reg Loss: 0.27124\n",
      "Epoch 700/2000, Avg Loss: 0.13299, Reg Loss: 0.29164\n",
      "Epoch 800/2000, Avg Loss: 0.12999, Reg Loss: 0.26215\n",
      "Epoch 900/2000, Avg Loss: 0.12989, Reg Loss: 0.28305\n",
      "Epoch 1000/2000, Avg Loss: 0.14094, Reg Loss: 0.27829\n",
      "Epoch 1100/2000, Avg Loss: 0.10630, Reg Loss: 0.27428\n",
      "Epoch 1200/2000, Avg Loss: 0.13133, Reg Loss: 0.26515\n",
      "Epoch 1300/2000, Avg Loss: 0.09299, Reg Loss: 0.25027\n",
      "Epoch 1400/2000, Avg Loss: 0.10289, Reg Loss: 0.25326\n",
      "Epoch 1500/2000, Avg Loss: 0.09724, Reg Loss: 0.25532\n",
      "Epoch 1600/2000, Avg Loss: 0.12502, Reg Loss: 0.25347\n",
      "Epoch 1700/2000, Avg Loss: 0.09047, Reg Loss: 0.23930\n",
      "Epoch 1800/2000, Avg Loss: 0.09920, Reg Loss: 0.24258\n",
      "Epoch 1900/2000, Avg Loss: 0.08406, Reg Loss: 0.24862\n",
      "Epoch 2000/2000, Avg Loss: 0.08493, Reg Loss: 0.22990\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.9579, G-Mean = 0.9162, MCC = 0.8419, F1-score = 0.8771\n",
      "      SMOTEBoost: AUC = 0.9931, G-Mean = 0.9710, MCC = 0.9619, F1-score = 0.9697\n",
      "      RUSBoost: AUC = 0.9665, G-Mean = 0.7635, MCC = 0.5735, F1-score = 0.6727\n",
      "      OUBoost: AUC = 0.9965, G-Mean = 0.9894, MCC = 0.9655, F1-score = 0.9744\n",
      "      SVM: AUC = 0.9857, G-Mean = 0.8909, MCC = 0.8364, F1-score = 0.8704\n",
      "      SMOTE: AUC = 0.9896, G-Mean = 0.9261, MCC = 0.8800, F1-score = 0.9074\n",
      "      ADASYN: AUC = 0.9896, G-Mean = 0.9261, MCC = 0.8800, F1-score = 0.9074\n",
      "      bSMOTE: AUC = 0.9891, G-Mean = 0.9261, MCC = 0.8800, F1-score = 0.9074\n",
      "      ROS: AUC = 0.9896, G-Mean = 0.9261, MCC = 0.8800, F1-score = 0.9074\n",
      "      MWMOTE: AUC = 0.9896, G-Mean = 0.9261, MCC = 0.8800, F1-score = 0.9074\n",
      "      Trans(Direct): AUC = 0.9896, G-Mean = 0.9613, MCC = 0.9236, F1-score = 0.9444\n",
      "  Fold 4/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.22388, Reg Loss: 0.35260\n",
      "Epoch 200/2000, Avg Loss: 0.20018, Reg Loss: 0.35231\n",
      "Epoch 300/2000, Avg Loss: 0.21728, Reg Loss: 0.34250\n",
      "Epoch 400/2000, Avg Loss: 0.16707, Reg Loss: 0.33561\n",
      "Epoch 500/2000, Avg Loss: 0.14244, Reg Loss: 0.34109\n",
      "Epoch 600/2000, Avg Loss: 0.13760, Reg Loss: 0.32670\n",
      "Epoch 700/2000, Avg Loss: 0.11384, Reg Loss: 0.33035\n",
      "Epoch 800/2000, Avg Loss: 0.11391, Reg Loss: 0.34095\n",
      "Epoch 900/2000, Avg Loss: 0.10818, Reg Loss: 0.33988\n",
      "Epoch 1000/2000, Avg Loss: 0.10977, Reg Loss: 0.31819\n",
      "Epoch 1100/2000, Avg Loss: 0.08726, Reg Loss: 0.32436\n",
      "Epoch 1200/2000, Avg Loss: 0.08582, Reg Loss: 0.32978\n",
      "Epoch 1300/2000, Avg Loss: 0.09282, Reg Loss: 0.32989\n",
      "Epoch 1400/2000, Avg Loss: 0.09956, Reg Loss: 0.32392\n",
      "Epoch 1500/2000, Avg Loss: 0.09613, Reg Loss: 0.32620\n",
      "Epoch 1600/2000, Avg Loss: 0.10149, Reg Loss: 0.31802\n",
      "Epoch 1700/2000, Avg Loss: 0.08757, Reg Loss: 0.31370\n",
      "Epoch 1800/2000, Avg Loss: 0.13238, Reg Loss: 0.32799\n",
      "Epoch 1900/2000, Avg Loss: 0.10921, Reg Loss: 0.32114\n",
      "Epoch 2000/2000, Avg Loss: 0.12991, Reg Loss: 0.30898\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.9184, G-Mean = 0.8808, MCC = 0.8140, F1-score = 0.8453\n",
      "      SMOTEBoost: AUC = 0.9917, G-Mean = 0.9703, MCC = 0.9424, F1-score = 0.9545\n",
      "      RUSBoost: AUC = 0.9561, G-Mean = 0.7799, MCC = 0.5767, F1-score = 0.6712\n",
      "      OUBoost: AUC = 0.9974, G-Mean = 0.9759, MCC = 0.9217, F1-score = 0.9391\n",
      "      SVM: AUC = 0.9861, G-Mean = 0.9102, MCC = 0.8483, F1-score = 0.8801\n",
      "      SMOTE: AUC = 0.9922, G-Mean = 0.9366, MCC = 0.8810, F1-score = 0.9078\n",
      "      ADASYN: AUC = 0.9891, G-Mean = 0.9366, MCC = 0.8810, F1-score = 0.9078\n",
      "      bSMOTE: AUC = 0.9887, G-Mean = 0.9366, MCC = 0.8810, F1-score = 0.9078\n",
      "      ROS: AUC = 0.9891, G-Mean = 0.9366, MCC = 0.8810, F1-score = 0.9078\n",
      "      MWMOTE: AUC = 0.9891, G-Mean = 0.9366, MCC = 0.8810, F1-score = 0.9078\n",
      "      Trans(Direct): AUC = 0.9891, G-Mean = 0.9630, MCC = 0.9137, F1-score = 0.9356\n",
      "  Fold 5/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.23917, Reg Loss: 0.33619\n",
      "Epoch 200/2000, Avg Loss: 0.19738, Reg Loss: 0.33514\n",
      "Epoch 300/2000, Avg Loss: 0.17446, Reg Loss: 0.33157\n",
      "Epoch 400/2000, Avg Loss: 0.15176, Reg Loss: 0.32006\n",
      "Epoch 500/2000, Avg Loss: 0.12090, Reg Loss: 0.31672\n",
      "Epoch 600/2000, Avg Loss: 0.11581, Reg Loss: 0.31249\n",
      "Epoch 700/2000, Avg Loss: 0.11476, Reg Loss: 0.30263\n",
      "Epoch 800/2000, Avg Loss: 0.11447, Reg Loss: 0.30430\n",
      "Epoch 900/2000, Avg Loss: 0.09992, Reg Loss: 0.30363\n",
      "Epoch 1000/2000, Avg Loss: 0.10650, Reg Loss: 0.30691\n",
      "Epoch 1100/2000, Avg Loss: 0.11394, Reg Loss: 0.28761\n",
      "Epoch 1200/2000, Avg Loss: 0.08781, Reg Loss: 0.27986\n",
      "Epoch 1300/2000, Avg Loss: 0.10450, Reg Loss: 0.29223\n",
      "Epoch 1400/2000, Avg Loss: 0.09522, Reg Loss: 0.28229\n",
      "Epoch 1500/2000, Avg Loss: 0.08765, Reg Loss: 0.27274\n",
      "Epoch 1600/2000, Avg Loss: 0.09150, Reg Loss: 0.25776\n",
      "Epoch 1700/2000, Avg Loss: 0.09092, Reg Loss: 0.28213\n",
      "Epoch 1800/2000, Avg Loss: 0.08384, Reg Loss: 0.26798\n",
      "Epoch 1900/2000, Avg Loss: 0.09609, Reg Loss: 0.27298\n",
      "Epoch 2000/2000, Avg Loss: 0.08078, Reg Loss: 0.27799\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.9222, G-Mean = 0.8917, MCC = 0.8093, F1-score = 0.8429\n",
      "      SMOTEBoost: AUC = 0.9933, G-Mean = 0.9699, MCC = 0.9307, F1-score = 0.9455\n",
      "      RUSBoost: AUC = 0.9612, G-Mean = 0.7897, MCC = 0.5786, F1-score = 0.6703\n",
      "      OUBoost: AUC = 0.9979, G-Mean = 0.9744, MCC = 0.9142, F1-score = 0.9331\n",
      "      SVM: AUC = 0.9839, G-Mean = 0.9218, MCC = 0.8554, F1-score = 0.8859\n",
      "      SMOTE: AUC = 0.9912, G-Mean = 0.9430, MCC = 0.8816, F1-score = 0.9081\n",
      "      ADASYN: AUC = 0.9862, G-Mean = 0.9430, MCC = 0.8816, F1-score = 0.9081\n",
      "      bSMOTE: AUC = 0.9860, G-Mean = 0.9430, MCC = 0.8816, F1-score = 0.9081\n",
      "      ROS: AUC = 0.9862, G-Mean = 0.9430, MCC = 0.8816, F1-score = 0.9081\n",
      "      MWMOTE: AUC = 0.9862, G-Mean = 0.9430, MCC = 0.8816, F1-score = 0.9081\n",
      "      Trans(Direct): AUC = 0.9862, G-Mean = 0.9641, MCC = 0.9077, F1-score = 0.9303\n",
      "  Fold 6/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.24427, Reg Loss: 0.32017\n",
      "Epoch 200/2000, Avg Loss: 0.19834, Reg Loss: 0.31137\n",
      "Epoch 300/2000, Avg Loss: 0.17257, Reg Loss: 0.30751\n",
      "Epoch 400/2000, Avg Loss: 0.15210, Reg Loss: 0.31165\n",
      "Epoch 500/2000, Avg Loss: 0.13222, Reg Loss: 0.30457\n",
      "Epoch 600/2000, Avg Loss: 0.12203, Reg Loss: 0.30481\n",
      "Epoch 700/2000, Avg Loss: 0.11690, Reg Loss: 0.30057\n",
      "Epoch 800/2000, Avg Loss: 0.10778, Reg Loss: 0.29439\n",
      "Epoch 900/2000, Avg Loss: 0.10905, Reg Loss: 0.30395\n",
      "Epoch 1000/2000, Avg Loss: 0.10090, Reg Loss: 0.30886\n",
      "Epoch 1100/2000, Avg Loss: 0.10253, Reg Loss: 0.30031\n",
      "Epoch 1200/2000, Avg Loss: 0.10347, Reg Loss: 0.29961\n",
      "Epoch 1300/2000, Avg Loss: 0.09874, Reg Loss: 0.30791\n",
      "Epoch 1400/2000, Avg Loss: 0.13343, Reg Loss: 0.29456\n",
      "Epoch 1500/2000, Avg Loss: 0.09145, Reg Loss: 0.29941\n",
      "Epoch 1600/2000, Avg Loss: 0.09533, Reg Loss: 0.28990\n",
      "Epoch 1700/2000, Avg Loss: 0.08372, Reg Loss: 0.28490\n",
      "Epoch 1800/2000, Avg Loss: 0.09979, Reg Loss: 0.28699\n",
      "Epoch 1900/2000, Avg Loss: 0.08146, Reg Loss: 0.28742\n",
      "Epoch 2000/2000, Avg Loss: 0.09360, Reg Loss: 0.28832\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.9185, G-Mean = 0.8921, MCC = 0.8190, F1-score = 0.8506\n",
      "      SMOTEBoost: AUC = 0.9674, G-Mean = 0.9573, MCC = 0.9202, F1-score = 0.9360\n",
      "      RUSBoost: AUC = 0.9385, G-Mean = 0.7976, MCC = 0.5882, F1-score = 0.6798\n",
      "      OUBoost: AUC = 0.9712, G-Mean = 0.9611, MCC = 0.9064, F1-score = 0.9257\n",
      "      SVM: AUC = 0.9762, G-Mean = 0.9173, MCC = 0.8575, F1-score = 0.8864\n",
      "      SMOTE: AUC = 0.9823, G-Mean = 0.9349, MCC = 0.8793, F1-score = 0.9049\n",
      "      ADASYN: AUC = 0.9823, G-Mean = 0.9349, MCC = 0.8793, F1-score = 0.9049\n",
      "      bSMOTE: AUC = 0.9821, G-Mean = 0.9349, MCC = 0.8793, F1-score = 0.9049\n",
      "      ROS: AUC = 0.9865, G-Mean = 0.9349, MCC = 0.8793, F1-score = 0.9049\n",
      "      MWMOTE: AUC = 0.9865, G-Mean = 0.9349, MCC = 0.8793, F1-score = 0.9049\n",
      "      Trans(Direct): AUC = 0.9802, G-Mean = 0.9525, MCC = 0.9011, F1-score = 0.9234\n",
      "  Fold 7/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.26712, Reg Loss: 0.35485\n",
      "Epoch 200/2000, Avg Loss: 0.21217, Reg Loss: 0.32719\n",
      "Epoch 300/2000, Avg Loss: 0.20064, Reg Loss: 0.34229\n",
      "Epoch 400/2000, Avg Loss: 0.14224, Reg Loss: 0.33361\n",
      "Epoch 500/2000, Avg Loss: 0.12880, Reg Loss: 0.32058\n",
      "Epoch 600/2000, Avg Loss: 0.16097, Reg Loss: 0.33625\n",
      "Epoch 700/2000, Avg Loss: 0.12098, Reg Loss: 0.32543\n",
      "Epoch 800/2000, Avg Loss: 0.12490, Reg Loss: 0.32671\n",
      "Epoch 900/2000, Avg Loss: 0.12174, Reg Loss: 0.32626\n",
      "Epoch 1000/2000, Avg Loss: 0.11467, Reg Loss: 0.32460\n",
      "Epoch 1100/2000, Avg Loss: 0.11049, Reg Loss: 0.32538\n",
      "Epoch 1200/2000, Avg Loss: 0.11604, Reg Loss: 0.32252\n",
      "Epoch 1300/2000, Avg Loss: 0.09148, Reg Loss: 0.32174\n",
      "Epoch 1400/2000, Avg Loss: 0.13342, Reg Loss: 0.32662\n",
      "Epoch 1500/2000, Avg Loss: 0.10736, Reg Loss: 0.31462\n",
      "Epoch 1600/2000, Avg Loss: 0.10034, Reg Loss: 0.31328\n",
      "Epoch 1700/2000, Avg Loss: 0.11953, Reg Loss: 0.31866\n",
      "Epoch 1800/2000, Avg Loss: 0.12772, Reg Loss: 0.31921\n",
      "Epoch 1900/2000, Avg Loss: 0.11275, Reg Loss: 0.32253\n",
      "Epoch 2000/2000, Avg Loss: 0.10235, Reg Loss: 0.31791\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.8971, G-Mean = 0.8718, MCC = 0.7853, F1-score = 0.8243\n",
      "      SMOTEBoost: AUC = 0.9685, G-Mean = 0.9443, MCC = 0.8941, F1-score = 0.9166\n",
      "      RUSBoost: AUC = 0.9446, G-Mean = 0.8073, MCC = 0.5964, F1-score = 0.6847\n",
      "      OUBoost: AUC = 0.9699, G-Mean = 0.9475, MCC = 0.8823, F1-score = 0.9078\n",
      "      SVM: AUC = 0.9778, G-Mean = 0.9246, MCC = 0.8612, F1-score = 0.8896\n",
      "      SMOTE: AUC = 0.9812, G-Mean = 0.9396, MCC = 0.8799, F1-score = 0.9055\n",
      "      ADASYN: AUC = 0.9812, G-Mean = 0.9396, MCC = 0.8799, F1-score = 0.9055\n",
      "      bSMOTE: AUC = 0.9828, G-Mean = 0.9396, MCC = 0.8799, F1-score = 0.9055\n",
      "      ROS: AUC = 0.9866, G-Mean = 0.9396, MCC = 0.8799, F1-score = 0.9055\n",
      "      MWMOTE: AUC = 0.9830, G-Mean = 0.9396, MCC = 0.8799, F1-score = 0.9055\n",
      "      Trans(Direct): AUC = 0.9795, G-Mean = 0.9500, MCC = 0.8853, F1-score = 0.9105\n",
      "  Fold 8/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.23108, Reg Loss: 0.31345\n",
      "Epoch 200/2000, Avg Loss: 0.17940, Reg Loss: 0.29490\n",
      "Epoch 300/2000, Avg Loss: 0.15141, Reg Loss: 0.30505\n",
      "Epoch 400/2000, Avg Loss: 0.13196, Reg Loss: 0.30470\n",
      "Epoch 500/2000, Avg Loss: 0.11504, Reg Loss: 0.29230\n",
      "Epoch 600/2000, Avg Loss: 0.11045, Reg Loss: 0.28355\n",
      "Epoch 700/2000, Avg Loss: 0.11860, Reg Loss: 0.28586\n",
      "Epoch 800/2000, Avg Loss: 0.10866, Reg Loss: 0.27148\n",
      "Epoch 900/2000, Avg Loss: 0.09890, Reg Loss: 0.28346\n",
      "Epoch 1000/2000, Avg Loss: 0.10293, Reg Loss: 0.27789\n",
      "Epoch 1100/2000, Avg Loss: 0.09041, Reg Loss: 0.28905\n",
      "Epoch 1200/2000, Avg Loss: 0.11744, Reg Loss: 0.27695\n",
      "Epoch 1300/2000, Avg Loss: 0.12316, Reg Loss: 0.30520\n",
      "Epoch 1400/2000, Avg Loss: 0.09881, Reg Loss: 0.28289\n",
      "Epoch 1500/2000, Avg Loss: 0.11342, Reg Loss: 0.29211\n",
      "Epoch 1600/2000, Avg Loss: 0.10061, Reg Loss: 0.28276\n",
      "Epoch 1700/2000, Avg Loss: 0.09553, Reg Loss: 0.26715\n",
      "Epoch 1800/2000, Avg Loss: 0.09715, Reg Loss: 0.27296\n",
      "Epoch 1900/2000, Avg Loss: 0.11779, Reg Loss: 0.28740\n",
      "Epoch 2000/2000, Avg Loss: 0.09135, Reg Loss: 0.27762\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.9061, G-Mean = 0.8839, MCC = 0.7976, F1-score = 0.8349\n",
      "      SMOTEBoost: AUC = 0.9724, G-Mean = 0.9473, MCC = 0.8928, F1-score = 0.9157\n",
      "      RUSBoost: AUC = 0.9515, G-Mean = 0.8191, MCC = 0.6109, F1-score = 0.6953\n",
      "      OUBoost: AUC = 0.9737, G-Mean = 0.9501, MCC = 0.8825, F1-score = 0.9079\n",
      "      SVM: AUC = 0.9759, G-Mean = 0.9300, MCC = 0.8641, F1-score = 0.8920\n",
      "      SMOTE: AUC = 0.9773, G-Mean = 0.9391, MCC = 0.8688, F1-score = 0.8965\n",
      "      ADASYN: AUC = 0.9742, G-Mean = 0.9391, MCC = 0.8688, F1-score = 0.8965\n",
      "      bSMOTE: AUC = 0.9772, G-Mean = 0.9391, MCC = 0.8688, F1-score = 0.8965\n",
      "      ROS: AUC = 0.9836, G-Mean = 0.9391, MCC = 0.8688, F1-score = 0.8965\n",
      "      MWMOTE: AUC = 0.9742, G-Mean = 0.9391, MCC = 0.8688, F1-score = 0.8965\n",
      "      Trans(Direct): AUC = 0.9789, G-Mean = 0.9482, MCC = 0.8734, F1-score = 0.9009\n",
      "  Fold 9/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.20682, Reg Loss: 0.30858\n",
      "Epoch 200/2000, Avg Loss: 0.18296, Reg Loss: 0.30451\n",
      "Epoch 300/2000, Avg Loss: 0.15869, Reg Loss: 0.29325\n",
      "Epoch 400/2000, Avg Loss: 0.15082, Reg Loss: 0.30333\n",
      "Epoch 500/2000, Avg Loss: 0.12881, Reg Loss: 0.29788\n",
      "Epoch 600/2000, Avg Loss: 0.11561, Reg Loss: 0.28378\n",
      "Epoch 700/2000, Avg Loss: 0.11389, Reg Loss: 0.28899\n",
      "Epoch 800/2000, Avg Loss: 0.11725, Reg Loss: 0.28339\n",
      "Epoch 900/2000, Avg Loss: 0.11125, Reg Loss: 0.28341\n",
      "Epoch 1000/2000, Avg Loss: 0.10403, Reg Loss: 0.28014\n",
      "Epoch 1100/2000, Avg Loss: 0.10018, Reg Loss: 0.27019\n",
      "Epoch 1200/2000, Avg Loss: 0.08613, Reg Loss: 0.27683\n",
      "Epoch 1300/2000, Avg Loss: 0.10684, Reg Loss: 0.27746\n",
      "Epoch 1400/2000, Avg Loss: 0.09162, Reg Loss: 0.26082\n",
      "Epoch 1500/2000, Avg Loss: 0.07933, Reg Loss: 0.26418\n",
      "Epoch 1600/2000, Avg Loss: 0.08343, Reg Loss: 0.26843\n",
      "Epoch 1700/2000, Avg Loss: 0.08372, Reg Loss: 0.25661\n",
      "Epoch 1800/2000, Avg Loss: 0.09694, Reg Loss: 0.25512\n",
      "Epoch 1900/2000, Avg Loss: 0.08093, Reg Loss: 0.26010\n",
      "Epoch 2000/2000, Avg Loss: 0.09422, Reg Loss: 0.26024\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.9096, G-Mean = 0.8819, MCC = 0.7910, F1-score = 0.8310\n",
      "      SMOTEBoost: AUC = 0.9699, G-Mean = 0.9459, MCC = 0.8815, F1-score = 0.9065\n",
      "      RUSBoost: AUC = 0.9499, G-Mean = 0.8202, MCC = 0.6082, F1-score = 0.6921\n",
      "      OUBoost: AUC = 0.9711, G-Mean = 0.9484, MCC = 0.8723, F1-score = 0.8996\n",
      "      SVM: AUC = 0.9730, G-Mean = 0.9100, MCC = 0.8328, F1-score = 0.8670\n",
      "      SMOTE: AUC = 0.9771, G-Mean = 0.9423, MCC = 0.8704, F1-score = 0.8979\n",
      "      ADASYN: AUC = 0.9743, G-Mean = 0.9310, MCC = 0.8542, F1-score = 0.8857\n",
      "      bSMOTE: AUC = 0.9769, G-Mean = 0.9423, MCC = 0.8704, F1-score = 0.8979\n",
      "      ROS: AUC = 0.9826, G-Mean = 0.9423, MCC = 0.8704, F1-score = 0.8979\n",
      "      MWMOTE: AUC = 0.9729, G-Mean = 0.9423, MCC = 0.8704, F1-score = 0.8979\n",
      "      Trans(Direct): AUC = 0.9785, G-Mean = 0.9504, MCC = 0.8746, F1-score = 0.9018\n",
      "  Fold 10/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.26755, Reg Loss: 0.29921\n",
      "Epoch 200/2000, Avg Loss: 0.18008, Reg Loss: 0.28212\n",
      "Epoch 300/2000, Avg Loss: 0.15233, Reg Loss: 0.26452\n",
      "Epoch 400/2000, Avg Loss: 0.18953, Reg Loss: 0.27621\n",
      "Epoch 500/2000, Avg Loss: 0.16815, Reg Loss: 0.27123\n",
      "Epoch 600/2000, Avg Loss: 0.13462, Reg Loss: 0.26574\n",
      "Epoch 700/2000, Avg Loss: 0.12160, Reg Loss: 0.27048\n",
      "Epoch 800/2000, Avg Loss: 0.11340, Reg Loss: 0.25854\n",
      "Epoch 900/2000, Avg Loss: 0.09491, Reg Loss: 0.24820\n",
      "Epoch 1000/2000, Avg Loss: 0.11683, Reg Loss: 0.27388\n",
      "Epoch 1100/2000, Avg Loss: 0.10182, Reg Loss: 0.24899\n",
      "Epoch 1200/2000, Avg Loss: 0.09620, Reg Loss: 0.24617\n",
      "Epoch 1300/2000, Avg Loss: 0.08915, Reg Loss: 0.25270\n",
      "Epoch 1400/2000, Avg Loss: 0.08983, Reg Loss: 0.23822\n",
      "Epoch 1500/2000, Avg Loss: 0.10614, Reg Loss: 0.26579\n",
      "Epoch 1600/2000, Avg Loss: 0.08041, Reg Loss: 0.24152\n",
      "Epoch 1700/2000, Avg Loss: 0.08573, Reg Loss: 0.24995\n",
      "Epoch 1800/2000, Avg Loss: 0.10294, Reg Loss: 0.23883\n",
      "Epoch 1900/2000, Avg Loss: 0.07982, Reg Loss: 0.24457\n",
      "Epoch 2000/2000, Avg Loss: 0.09968, Reg Loss: 0.24780\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.9086, G-Mean = 0.8832, MCC = 0.7986, F1-score = 0.8368\n",
      "      SMOTEBoost: AUC = 0.9729, G-Mean = 0.9513, MCC = 0.8933, F1-score = 0.9159\n",
      "      RUSBoost: AUC = 0.9550, G-Mean = 0.8317, MCC = 0.6264, F1-score = 0.7062\n",
      "      OUBoost: AUC = 0.9740, G-Mean = 0.9536, MCC = 0.8851, F1-score = 0.9097\n",
      "      SVM: AUC = 0.9757, G-Mean = 0.9190, MCC = 0.8496, F1-score = 0.8803\n",
      "      SMOTE: AUC = 0.9794, G-Mean = 0.9481, MCC = 0.8834, F1-score = 0.9081\n",
      "      ADASYN: AUC = 0.9769, G-Mean = 0.9379, MCC = 0.8688, F1-score = 0.8972\n",
      "      bSMOTE: AUC = 0.9792, G-Mean = 0.9481, MCC = 0.8834, F1-score = 0.9081\n",
      "      ROS: AUC = 0.9844, G-Mean = 0.9481, MCC = 0.8834, F1-score = 0.9081\n",
      "      MWMOTE: AUC = 0.9756, G-Mean = 0.9481, MCC = 0.8834, F1-score = 0.9081\n",
      "      Trans(Direct): AUC = 0.9806, G-Mean = 0.9554, MCC = 0.8871, F1-score = 0.9116\n",
      "\n",
      "Starting experiment 2/10\n",
      "  Fold 1/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.22976, Reg Loss: 0.31694\n",
      "Epoch 200/2000, Avg Loss: 0.20781, Reg Loss: 0.31733\n",
      "Epoch 300/2000, Avg Loss: 0.16463, Reg Loss: 0.30442\n",
      "Epoch 400/2000, Avg Loss: 0.16673, Reg Loss: 0.31172\n",
      "Epoch 500/2000, Avg Loss: 0.13228, Reg Loss: 0.29978\n",
      "Epoch 600/2000, Avg Loss: 0.12959, Reg Loss: 0.30151\n",
      "Epoch 700/2000, Avg Loss: 0.11424, Reg Loss: 0.30898\n",
      "Epoch 800/2000, Avg Loss: 0.11860, Reg Loss: 0.30076\n",
      "Epoch 900/2000, Avg Loss: 0.21708, Reg Loss: 0.31773\n",
      "Epoch 1000/2000, Avg Loss: 0.11464, Reg Loss: 0.28776\n",
      "Epoch 1100/2000, Avg Loss: 0.10759, Reg Loss: 0.30327\n",
      "Epoch 1200/2000, Avg Loss: 0.14010, Reg Loss: 0.31365\n",
      "Epoch 1300/2000, Avg Loss: 0.12096, Reg Loss: 0.32283\n",
      "Epoch 1400/2000, Avg Loss: 0.10829, Reg Loss: 0.29950\n",
      "Epoch 1500/2000, Avg Loss: 0.08613, Reg Loss: 0.29700\n",
      "Epoch 1600/2000, Avg Loss: 0.10185, Reg Loss: 0.29706\n",
      "Epoch 1700/2000, Avg Loss: 0.08813, Reg Loss: 0.29264\n",
      "Epoch 1800/2000, Avg Loss: 0.08335, Reg Loss: 0.28998\n",
      "Epoch 1900/2000, Avg Loss: 0.07875, Reg Loss: 0.28415\n",
      "Epoch 2000/2000, Avg Loss: 0.10009, Reg Loss: 0.29078\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.8706, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "      SMOTEBoost: AUC = 0.8706, G-Mean = 0.7515, MCC = 0.5880, F1-score = 0.6667\n",
      "      RUSBoost: AUC = 0.9059, G-Mean = 0.8117, MCC = 0.5610, F1-score = 0.6667\n",
      "      OUBoost: AUC = 0.8824, G-Mean = 0.7515, MCC = 0.5880, F1-score = 0.6667\n",
      "      SVM: AUC = 0.9529, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      SMOTE: AUC = 0.9529, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      ADASYN: AUC = 0.9529, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      bSMOTE: AUC = 0.9529, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      ROS: AUC = 0.9529, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "      MWMOTE: AUC = 0.9529, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      Trans(Direct): AUC = 0.9529, G-Mean = 0.8402, MCC = 0.6421, F1-score = 0.7273\n",
      "  Fold 2/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.28010, Reg Loss: 0.39085\n",
      "Epoch 200/2000, Avg Loss: 0.21968, Reg Loss: 0.39362\n",
      "Epoch 300/2000, Avg Loss: 0.22262, Reg Loss: 0.39036\n",
      "Epoch 400/2000, Avg Loss: 0.17287, Reg Loss: 0.38178\n",
      "Epoch 500/2000, Avg Loss: 0.17434, Reg Loss: 0.37520\n",
      "Epoch 600/2000, Avg Loss: 0.16079, Reg Loss: 0.36610\n",
      "Epoch 700/2000, Avg Loss: 0.14985, Reg Loss: 0.35716\n",
      "Epoch 800/2000, Avg Loss: 0.13176, Reg Loss: 0.35334\n",
      "Epoch 900/2000, Avg Loss: 0.11493, Reg Loss: 0.35651\n",
      "Epoch 1000/2000, Avg Loss: 0.13651, Reg Loss: 0.35352\n",
      "Epoch 1100/2000, Avg Loss: 0.11726, Reg Loss: 0.34321\n",
      "Epoch 1200/2000, Avg Loss: 0.10927, Reg Loss: 0.34237\n",
      "Epoch 1300/2000, Avg Loss: 0.10351, Reg Loss: 0.34018\n",
      "Epoch 1400/2000, Avg Loss: 0.11159, Reg Loss: 0.34790\n",
      "Epoch 1500/2000, Avg Loss: 0.10056, Reg Loss: 0.32946\n",
      "Epoch 1600/2000, Avg Loss: 0.11445, Reg Loss: 0.34179\n",
      "Epoch 1700/2000, Avg Loss: 0.09975, Reg Loss: 0.32953\n",
      "Epoch 1800/2000, Avg Loss: 0.08726, Reg Loss: 0.32629\n",
      "Epoch 1900/2000, Avg Loss: 0.08737, Reg Loss: 0.32463\n",
      "Epoch 2000/2000, Avg Loss: 0.08765, Reg Loss: 0.32373\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.9353, G-Mean = 0.9339, MCC = 0.8706, F1-score = 0.9000\n",
      "      SMOTEBoost: AUC = 0.9353, G-Mean = 0.8295, MCC = 0.6527, F1-score = 0.7179\n",
      "      RUSBoost: AUC = 0.9529, G-Mean = 0.8080, MCC = 0.5517, F1-score = 0.6458\n",
      "      OUBoost: AUC = 0.9412, G-Mean = 0.8454, MCC = 0.6909, F1-score = 0.7500\n",
      "      SVM: AUC = 0.9765, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      SMOTE: AUC = 0.9765, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      ADASYN: AUC = 0.9765, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      bSMOTE: AUC = 0.9765, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      ROS: AUC = 0.9765, G-Mean = 0.9339, MCC = 0.8706, F1-score = 0.9000\n",
      "      MWMOTE: AUC = 0.9765, G-Mean = 0.9323, MCC = 0.8774, F1-score = 0.8990\n",
      "      Trans(Direct): AUC = 0.9765, G-Mean = 0.9201, MCC = 0.8210, F1-score = 0.8636\n",
      "  Fold 3/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.21704, Reg Loss: 0.31245\n",
      "Epoch 200/2000, Avg Loss: 0.20856, Reg Loss: 0.31200\n",
      "Epoch 300/2000, Avg Loss: 0.16076, Reg Loss: 0.29051\n",
      "Epoch 400/2000, Avg Loss: 0.16043, Reg Loss: 0.30278\n",
      "Epoch 500/2000, Avg Loss: 0.12691, Reg Loss: 0.29597\n",
      "Epoch 600/2000, Avg Loss: 0.11735, Reg Loss: 0.29894\n",
      "Epoch 700/2000, Avg Loss: 0.11584, Reg Loss: 0.28140\n",
      "Epoch 800/2000, Avg Loss: 0.11523, Reg Loss: 0.29218\n",
      "Epoch 900/2000, Avg Loss: 0.11112, Reg Loss: 0.30191\n",
      "Epoch 1000/2000, Avg Loss: 0.10633, Reg Loss: 0.29445\n",
      "Epoch 1100/2000, Avg Loss: 0.10806, Reg Loss: 0.27877\n",
      "Epoch 1200/2000, Avg Loss: 0.09640, Reg Loss: 0.27612\n",
      "Epoch 1300/2000, Avg Loss: 0.09541, Reg Loss: 0.29001\n",
      "Epoch 1400/2000, Avg Loss: 0.09865, Reg Loss: 0.28444\n",
      "Epoch 1500/2000, Avg Loss: 0.11710, Reg Loss: 0.29041\n",
      "Epoch 1600/2000, Avg Loss: 0.12044, Reg Loss: 0.30415\n",
      "Epoch 1700/2000, Avg Loss: 0.09045, Reg Loss: 0.26352\n",
      "Epoch 1800/2000, Avg Loss: 0.10143, Reg Loss: 0.27781\n",
      "Epoch 1900/2000, Avg Loss: 0.10005, Reg Loss: 0.26946\n",
      "Epoch 2000/2000, Avg Loss: 0.10837, Reg Loss: 0.28122\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.9360, G-Mean = 0.9344, MCC = 0.8504, F1-score = 0.8857\n",
      "      SMOTEBoost: AUC = 0.9291, G-Mean = 0.8648, MCC = 0.7052, F1-score = 0.7643\n",
      "      RUSBoost: AUC = 0.8957, G-Mean = 0.7592, MCC = 0.5072, F1-score = 0.6210\n",
      "      OUBoost: AUC = 0.9434, G-Mean = 0.8754, MCC = 0.7307, F1-score = 0.7857\n",
      "      SVM: AUC = 0.9531, G-Mean = 0.9433, MCC = 0.8931, F1-score = 0.9153\n",
      "      SMOTE: AUC = 0.9635, G-Mean = 0.9433, MCC = 0.8931, F1-score = 0.9153\n",
      "      ADASYN: AUC = 0.9496, G-Mean = 0.9319, MCC = 0.8684, F1-score = 0.8963\n",
      "      bSMOTE: AUC = 0.9565, G-Mean = 0.9319, MCC = 0.8684, F1-score = 0.8963\n",
      "      ROS: AUC = 0.9670, G-Mean = 0.9230, MCC = 0.8257, F1-score = 0.8667\n",
      "      MWMOTE: AUC = 0.9531, G-Mean = 0.9220, MCC = 0.8303, F1-score = 0.8660\n",
      "      Trans(Direct): AUC = 0.9635, G-Mean = 0.9139, MCC = 0.7927, F1-score = 0.8424\n",
      "  Fold 4/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.23410, Reg Loss: 0.29660\n",
      "Epoch 200/2000, Avg Loss: 0.19190, Reg Loss: 0.30224\n",
      "Epoch 300/2000, Avg Loss: 0.16580, Reg Loss: 0.29536\n",
      "Epoch 400/2000, Avg Loss: 0.14715, Reg Loss: 0.28813\n",
      "Epoch 500/2000, Avg Loss: 0.13282, Reg Loss: 0.28049\n",
      "Epoch 600/2000, Avg Loss: 0.11258, Reg Loss: 0.28208\n",
      "Epoch 700/2000, Avg Loss: 0.12570, Reg Loss: 0.25539\n",
      "Epoch 800/2000, Avg Loss: 0.11230, Reg Loss: 0.26267\n",
      "Epoch 900/2000, Avg Loss: 0.12654, Reg Loss: 0.27004\n",
      "Epoch 1000/2000, Avg Loss: 0.10066, Reg Loss: 0.26687\n",
      "Epoch 1100/2000, Avg Loss: 0.09226, Reg Loss: 0.26457\n",
      "Epoch 1200/2000, Avg Loss: 0.08914, Reg Loss: 0.26324\n",
      "Epoch 1300/2000, Avg Loss: 0.12549, Reg Loss: 0.26933\n",
      "Epoch 1400/2000, Avg Loss: 0.10733, Reg Loss: 0.27107\n",
      "Epoch 1500/2000, Avg Loss: 0.09905, Reg Loss: 0.26373\n",
      "Epoch 1600/2000, Avg Loss: 0.10070, Reg Loss: 0.24806\n",
      "Epoch 1700/2000, Avg Loss: 0.10527, Reg Loss: 0.26674\n",
      "Epoch 1800/2000, Avg Loss: 0.09726, Reg Loss: 0.26471\n",
      "Epoch 1900/2000, Avg Loss: 0.09281, Reg Loss: 0.26004\n",
      "Epoch 2000/2000, Avg Loss: 0.08813, Reg Loss: 0.25588\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.9426, G-Mean = 0.9173, MCC = 0.8222, F1-score = 0.8643\n",
      "      SMOTEBoost: AUC = 0.9468, G-Mean = 0.8907, MCC = 0.7499, F1-score = 0.8005\n",
      "      RUSBoost: AUC = 0.8999, G-Mean = 0.7225, MCC = 0.4688, F1-score = 0.5908\n",
      "      OUBoost: AUC = 0.9513, G-Mean = 0.8819, MCC = 0.7261, F1-score = 0.7816\n",
      "      SVM: AUC = 0.9617, G-Mean = 0.9240, MCC = 0.8542, F1-score = 0.8865\n",
      "      SMOTE: AUC = 0.9695, G-Mean = 0.9495, MCC = 0.8908, F1-score = 0.9138\n",
      "      ADASYN: AUC = 0.9559, G-Mean = 0.9410, MCC = 0.8723, F1-score = 0.8995\n",
      "      bSMOTE: AUC = 0.9643, G-Mean = 0.9410, MCC = 0.8723, F1-score = 0.8995\n",
      "      ROS: AUC = 0.9721, G-Mean = 0.9343, MCC = 0.8403, F1-score = 0.8773\n",
      "      MWMOTE: AUC = 0.9585, G-Mean = 0.9336, MCC = 0.8437, F1-score = 0.8768\n",
      "      Trans(Direct): AUC = 0.9695, G-Mean = 0.9192, MCC = 0.7922, F1-score = 0.8402\n",
      "  Fold 5/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.24897, Reg Loss: 0.30092\n",
      "Epoch 200/2000, Avg Loss: 0.21255, Reg Loss: 0.29492\n",
      "Epoch 300/2000, Avg Loss: 0.21038, Reg Loss: 0.29103\n",
      "Epoch 400/2000, Avg Loss: 0.15973, Reg Loss: 0.29175\n",
      "Epoch 500/2000, Avg Loss: 0.14440, Reg Loss: 0.27963\n",
      "Epoch 600/2000, Avg Loss: 0.13005, Reg Loss: 0.27690\n",
      "Epoch 700/2000, Avg Loss: 0.16014, Reg Loss: 0.28229\n",
      "Epoch 800/2000, Avg Loss: 0.11941, Reg Loss: 0.26635\n",
      "Epoch 900/2000, Avg Loss: 0.11372, Reg Loss: 0.27932\n",
      "Epoch 1000/2000, Avg Loss: 0.11337, Reg Loss: 0.28050\n",
      "Epoch 1100/2000, Avg Loss: 0.09889, Reg Loss: 0.27013\n",
      "Epoch 1200/2000, Avg Loss: 0.11539, Reg Loss: 0.27793\n",
      "Epoch 1300/2000, Avg Loss: 0.10130, Reg Loss: 0.27308\n",
      "Epoch 1400/2000, Avg Loss: 0.08946, Reg Loss: 0.25534\n",
      "Epoch 1500/2000, Avg Loss: 0.11255, Reg Loss: 0.26335\n",
      "Epoch 1600/2000, Avg Loss: 0.11396, Reg Loss: 0.25071\n",
      "Epoch 1700/2000, Avg Loss: 0.11813, Reg Loss: 0.26631\n",
      "Epoch 1800/2000, Avg Loss: 0.12521, Reg Loss: 0.26321\n",
      "Epoch 1900/2000, Avg Loss: 0.09953, Reg Loss: 0.27054\n",
      "Epoch 2000/2000, Avg Loss: 0.08999, Reg Loss: 0.24948\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.9479, G-Mean = 0.9275, MCC = 0.8345, F1-score = 0.8732\n",
      "      SMOTEBoost: AUC = 0.9550, G-Mean = 0.9062, MCC = 0.7767, F1-score = 0.8222\n",
      "      RUSBoost: AUC = 0.9187, G-Mean = 0.7438, MCC = 0.4923, F1-score = 0.6060\n",
      "      OUBoost: AUC = 0.9586, G-Mean = 0.8858, MCC = 0.7234, F1-score = 0.7791\n",
      "      SVM: AUC = 0.9668, G-Mean = 0.9328, MCC = 0.8601, F1-score = 0.8910\n",
      "      SMOTE: AUC = 0.9706, G-Mean = 0.9533, MCC = 0.8894, F1-score = 0.9128\n",
      "      ADASYN: AUC = 0.9598, G-Mean = 0.9465, MCC = 0.8746, F1-score = 0.9014\n",
      "      bSMOTE: AUC = 0.9689, G-Mean = 0.9465, MCC = 0.8746, F1-score = 0.9014\n",
      "      ROS: AUC = 0.9727, G-Mean = 0.9411, MCC = 0.8490, F1-score = 0.8836\n",
      "      MWMOTE: AUC = 0.9568, G-Mean = 0.9405, MCC = 0.8517, F1-score = 0.8832\n",
      "      Trans(Direct): AUC = 0.9731, G-Mean = 0.9290, MCC = 0.8105, F1-score = 0.8539\n",
      "  Fold 6/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.21040, Reg Loss: 0.30794\n",
      "Epoch 200/2000, Avg Loss: 0.17251, Reg Loss: 0.29802\n",
      "Epoch 300/2000, Avg Loss: 0.15191, Reg Loss: 0.30684\n",
      "Epoch 400/2000, Avg Loss: 0.15610, Reg Loss: 0.29478\n",
      "Epoch 500/2000, Avg Loss: 0.12957, Reg Loss: 0.30043\n",
      "Epoch 600/2000, Avg Loss: 0.12466, Reg Loss: 0.28775\n",
      "Epoch 700/2000, Avg Loss: 0.10150, Reg Loss: 0.29204\n",
      "Epoch 800/2000, Avg Loss: 0.12740, Reg Loss: 0.28401\n",
      "Epoch 900/2000, Avg Loss: 0.12209, Reg Loss: 0.29451\n",
      "Epoch 1000/2000, Avg Loss: 0.11038, Reg Loss: 0.29104\n",
      "Epoch 1100/2000, Avg Loss: 0.12934, Reg Loss: 0.30447\n",
      "Epoch 1200/2000, Avg Loss: 0.09206, Reg Loss: 0.27382\n",
      "Epoch 1300/2000, Avg Loss: 0.09246, Reg Loss: 0.27539\n",
      "Epoch 1400/2000, Avg Loss: 0.11911, Reg Loss: 0.29321\n",
      "Epoch 1500/2000, Avg Loss: 0.08983, Reg Loss: 0.28851\n",
      "Epoch 1600/2000, Avg Loss: 0.09321, Reg Loss: 0.27564\n",
      "Epoch 1700/2000, Avg Loss: 0.11739, Reg Loss: 0.28254\n",
      "Epoch 1800/2000, Avg Loss: 0.12311, Reg Loss: 0.29555\n",
      "Epoch 1900/2000, Avg Loss: 0.11339, Reg Loss: 0.28712\n",
      "Epoch 2000/2000, Avg Loss: 0.10187, Reg Loss: 0.26807\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.9066, G-Mean = 0.8783, MCC = 0.7922, F1-score = 0.8229\n",
      "      SMOTEBoost: AUC = 0.9625, G-Mean = 0.9042, MCC = 0.7918, F1-score = 0.8334\n",
      "      RUSBoost: AUC = 0.9281, G-Mean = 0.7377, MCC = 0.4833, F1-score = 0.5976\n",
      "      OUBoost: AUC = 0.9655, G-Mean = 0.8673, MCC = 0.7246, F1-score = 0.7743\n",
      "      SVM: AUC = 0.9724, G-Mean = 0.9264, MCC = 0.8614, F1-score = 0.8907\n",
      "      SMOTE: AUC = 0.9755, G-Mean = 0.9235, MCC = 0.8629, F1-score = 0.8857\n",
      "      ADASYN: AUC = 0.9665, G-Mean = 0.9378, MCC = 0.8734, F1-score = 0.8993\n",
      "      bSMOTE: AUC = 0.9741, G-Mean = 0.9178, MCC = 0.8505, F1-score = 0.8762\n",
      "      ROS: AUC = 0.9772, G-Mean = 0.9134, MCC = 0.8292, F1-score = 0.8614\n",
      "      MWMOTE: AUC = 0.9640, G-Mean = 0.9328, MCC = 0.8544, F1-score = 0.8842\n",
      "      Trans(Direct): AUC = 0.9776, G-Mean = 0.9233, MCC = 0.8200, F1-score = 0.8598\n",
      "  Fold 7/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.20198, Reg Loss: 0.29299\n",
      "Epoch 200/2000, Avg Loss: 0.16531, Reg Loss: 0.27952\n",
      "Epoch 300/2000, Avg Loss: 0.14979, Reg Loss: 0.27723\n",
      "Epoch 400/2000, Avg Loss: 0.11984, Reg Loss: 0.26786\n",
      "Epoch 500/2000, Avg Loss: 0.11376, Reg Loss: 0.26601\n",
      "Epoch 600/2000, Avg Loss: 0.11479, Reg Loss: 0.26078\n",
      "Epoch 700/2000, Avg Loss: 0.12181, Reg Loss: 0.25472\n",
      "Epoch 800/2000, Avg Loss: 0.10195, Reg Loss: 0.25690\n",
      "Epoch 900/2000, Avg Loss: 0.09513, Reg Loss: 0.25502\n",
      "Epoch 1000/2000, Avg Loss: 0.08589, Reg Loss: 0.24562\n",
      "Epoch 1100/2000, Avg Loss: 0.10873, Reg Loss: 0.25062\n",
      "Epoch 1200/2000, Avg Loss: 0.09501, Reg Loss: 0.25161\n",
      "Epoch 1300/2000, Avg Loss: 0.08955, Reg Loss: 0.24463\n",
      "Epoch 1400/2000, Avg Loss: 0.08665, Reg Loss: 0.24582\n",
      "Epoch 1500/2000, Avg Loss: 0.07595, Reg Loss: 0.24794\n",
      "Epoch 1600/2000, Avg Loss: 0.10613, Reg Loss: 0.26389\n",
      "Epoch 1700/2000, Avg Loss: 0.09007, Reg Loss: 0.24943\n",
      "Epoch 1800/2000, Avg Loss: 0.09214, Reg Loss: 0.23150\n",
      "Epoch 1900/2000, Avg Loss: 0.10276, Reg Loss: 0.24285\n",
      "Epoch 2000/2000, Avg Loss: 0.08907, Reg Loss: 0.25527\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.9199, G-Mean = 0.8957, MCC = 0.8219, F1-score = 0.8482\n",
      "      SMOTEBoost: AUC = 0.9678, G-Mean = 0.9179, MCC = 0.8216, F1-score = 0.8572\n",
      "      RUSBoost: AUC = 0.9383, G-Mean = 0.7659, MCC = 0.5272, F1-score = 0.6312\n",
      "      OUBoost: AUC = 0.9704, G-Mean = 0.8862, MCC = 0.7639, F1-score = 0.8065\n",
      "      SVM: AUC = 0.9763, G-Mean = 0.9219, MCC = 0.8623, F1-score = 0.8904\n",
      "      SMOTE: AUC = 0.9790, G-Mean = 0.9193, MCC = 0.8636, F1-score = 0.8862\n",
      "      ADASYN: AUC = 0.9713, G-Mean = 0.9316, MCC = 0.8726, F1-score = 0.8978\n",
      "      bSMOTE: AUC = 0.9778, G-Mean = 0.9145, MCC = 0.8530, F1-score = 0.8780\n",
      "      ROS: AUC = 0.9805, G-Mean = 0.9107, MCC = 0.8347, F1-score = 0.8653\n",
      "      MWMOTE: AUC = 0.9692, G-Mean = 0.9273, MCC = 0.8563, F1-score = 0.8848\n",
      "      Trans(Direct): AUC = 0.9808, G-Mean = 0.9342, MCC = 0.8457, F1-score = 0.8798\n",
      "  Fold 8/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.23450, Reg Loss: 0.31010\n",
      "Epoch 200/2000, Avg Loss: 0.19751, Reg Loss: 0.29289\n",
      "Epoch 300/2000, Avg Loss: 0.17208, Reg Loss: 0.30857\n",
      "Epoch 400/2000, Avg Loss: 0.11927, Reg Loss: 0.27761\n",
      "Epoch 500/2000, Avg Loss: 0.12343, Reg Loss: 0.28314\n",
      "Epoch 600/2000, Avg Loss: 0.11111, Reg Loss: 0.27021\n",
      "Epoch 700/2000, Avg Loss: 0.10299, Reg Loss: 0.26693\n",
      "Epoch 800/2000, Avg Loss: 0.10796, Reg Loss: 0.28189\n",
      "Epoch 900/2000, Avg Loss: 0.08923, Reg Loss: 0.26457\n",
      "Epoch 1000/2000, Avg Loss: 0.09661, Reg Loss: 0.27105\n",
      "Epoch 1100/2000, Avg Loss: 0.07834, Reg Loss: 0.27226\n",
      "Epoch 1200/2000, Avg Loss: 0.08469, Reg Loss: 0.25833\n",
      "Epoch 1300/2000, Avg Loss: 0.08319, Reg Loss: 0.27648\n",
      "Epoch 1400/2000, Avg Loss: 0.09134, Reg Loss: 0.27707\n",
      "Epoch 1500/2000, Avg Loss: 0.11427, Reg Loss: 0.27291\n",
      "Epoch 1600/2000, Avg Loss: 0.06870, Reg Loss: 0.26527\n",
      "Epoch 1700/2000, Avg Loss: 0.09793, Reg Loss: 0.26892\n",
      "Epoch 1800/2000, Avg Loss: 0.09522, Reg Loss: 0.28352\n",
      "Epoch 1900/2000, Avg Loss: 0.09509, Reg Loss: 0.25900\n",
      "Epoch 2000/2000, Avg Loss: 0.08187, Reg Loss: 0.25595\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.9299, G-Mean = 0.9087, MCC = 0.8441, F1-score = 0.8672\n",
      "      SMOTEBoost: AUC = 0.9672, G-Mean = 0.9242, MCC = 0.8294, F1-score = 0.8637\n",
      "      RUSBoost: AUC = 0.9460, G-Mean = 0.7829, MCC = 0.5504, F1-score = 0.6485\n",
      "      OUBoost: AUC = 0.9725, G-Mean = 0.8965, MCC = 0.7789, F1-score = 0.8193\n",
      "      SVM: AUC = 0.9793, G-Mean = 0.9316, MCC = 0.8795, F1-score = 0.9041\n",
      "      SMOTE: AUC = 0.9816, G-Mean = 0.9294, MCC = 0.8806, F1-score = 0.9004\n",
      "      ADASYN: AUC = 0.9748, G-Mean = 0.9401, MCC = 0.8886, F1-score = 0.9106\n",
      "      bSMOTE: AUC = 0.9806, G-Mean = 0.9252, MCC = 0.8714, F1-score = 0.8932\n",
      "      ROS: AUC = 0.9829, G-Mean = 0.9218, MCC = 0.8554, F1-score = 0.8821\n",
      "      MWMOTE: AUC = 0.9730, G-Mean = 0.9364, MCC = 0.8743, F1-score = 0.8992\n",
      "      Trans(Direct): AUC = 0.9832, G-Mean = 0.9425, MCC = 0.8650, F1-score = 0.8948\n",
      "  Fold 9/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.23461, Reg Loss: 0.34564\n",
      "Epoch 200/2000, Avg Loss: 0.20717, Reg Loss: 0.34970\n",
      "Epoch 300/2000, Avg Loss: 0.16386, Reg Loss: 0.33400\n",
      "Epoch 400/2000, Avg Loss: 0.12914, Reg Loss: 0.33126\n",
      "Epoch 500/2000, Avg Loss: 0.15417, Reg Loss: 0.32968\n",
      "Epoch 600/2000, Avg Loss: 0.11470, Reg Loss: 0.32695\n",
      "Epoch 700/2000, Avg Loss: 0.12684, Reg Loss: 0.32507\n",
      "Epoch 800/2000, Avg Loss: 0.10432, Reg Loss: 0.32145\n",
      "Epoch 900/2000, Avg Loss: 0.10973, Reg Loss: 0.31901\n",
      "Epoch 1000/2000, Avg Loss: 0.09296, Reg Loss: 0.32333\n",
      "Epoch 1100/2000, Avg Loss: 0.09871, Reg Loss: 0.31142\n",
      "Epoch 1200/2000, Avg Loss: 0.08989, Reg Loss: 0.30984\n",
      "Epoch 1300/2000, Avg Loss: 0.09245, Reg Loss: 0.32341\n",
      "Epoch 1400/2000, Avg Loss: 0.08061, Reg Loss: 0.31381\n",
      "Epoch 1500/2000, Avg Loss: 0.09266, Reg Loss: 0.30925\n",
      "Epoch 1600/2000, Avg Loss: 0.10068, Reg Loss: 0.31490\n",
      "Epoch 1700/2000, Avg Loss: 0.09201, Reg Loss: 0.30666\n",
      "Epoch 1800/2000, Avg Loss: 0.11106, Reg Loss: 0.31530\n",
      "Epoch 1900/2000, Avg Loss: 0.07967, Reg Loss: 0.31713\n",
      "Epoch 2000/2000, Avg Loss: 0.08718, Reg Loss: 0.32337\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.8933, G-Mean = 0.8575, MCC = 0.7948, F1-score = 0.8079\n",
      "      SMOTEBoost: AUC = 0.9639, G-Mean = 0.9291, MCC = 0.8354, F1-score = 0.8687\n",
      "      RUSBoost: AUC = 0.9507, G-Mean = 0.7880, MCC = 0.5544, F1-score = 0.6505\n",
      "      OUBoost: AUC = 0.9756, G-Mean = 0.9045, MCC = 0.7906, F1-score = 0.8293\n",
      "      SVM: AUC = 0.9774, G-Mean = 0.8961, MCC = 0.8274, F1-score = 0.8592\n",
      "      SMOTE: AUC = 0.9823, G-Mean = 0.9224, MCC = 0.8647, F1-score = 0.8892\n",
      "      ADASYN: AUC = 0.9763, G-Mean = 0.9319, MCC = 0.8718, F1-score = 0.8983\n",
      "      bSMOTE: AUC = 0.9813, G-Mean = 0.9186, MCC = 0.8565, F1-score = 0.8829\n",
      "      ROS: AUC = 0.9834, G-Mean = 0.9156, MCC = 0.8423, F1-score = 0.8730\n",
      "      MWMOTE: AUC = 0.9732, G-Mean = 0.9286, MCC = 0.8591, F1-score = 0.8882\n",
      "      Trans(Direct): AUC = 0.9837, G-Mean = 0.9453, MCC = 0.8671, F1-score = 0.8964\n",
      "  Fold 10/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.23846, Reg Loss: 0.30773\n",
      "Epoch 200/2000, Avg Loss: 0.19093, Reg Loss: 0.31786\n",
      "Epoch 300/2000, Avg Loss: 0.17748, Reg Loss: 0.31660\n",
      "Epoch 400/2000, Avg Loss: 0.15669, Reg Loss: 0.32214\n",
      "Epoch 500/2000, Avg Loss: 0.13991, Reg Loss: 0.32288\n",
      "Epoch 600/2000, Avg Loss: 0.12821, Reg Loss: 0.31120\n",
      "Epoch 700/2000, Avg Loss: 0.11000, Reg Loss: 0.31654\n",
      "Epoch 800/2000, Avg Loss: 0.10943, Reg Loss: 0.30890\n",
      "Epoch 900/2000, Avg Loss: 0.11139, Reg Loss: 0.29831\n",
      "Epoch 1000/2000, Avg Loss: 0.10697, Reg Loss: 0.30260\n",
      "Epoch 1100/2000, Avg Loss: 0.10583, Reg Loss: 0.30236\n",
      "Epoch 1200/2000, Avg Loss: 0.09838, Reg Loss: 0.29915\n",
      "Epoch 1300/2000, Avg Loss: 0.11363, Reg Loss: 0.29522\n",
      "Epoch 1400/2000, Avg Loss: 0.08599, Reg Loss: 0.28426\n",
      "Epoch 1500/2000, Avg Loss: 0.09137, Reg Loss: 0.28827\n",
      "Epoch 1600/2000, Avg Loss: 0.08929, Reg Loss: 0.28532\n",
      "Epoch 1700/2000, Avg Loss: 0.12593, Reg Loss: 0.31106\n",
      "Epoch 1800/2000, Avg Loss: 0.11877, Reg Loss: 0.29266\n",
      "Epoch 1900/2000, Avg Loss: 0.10886, Reg Loss: 0.29944\n",
      "Epoch 2000/2000, Avg Loss: 0.12544, Reg Loss: 0.30226\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.8939, G-Mean = 0.8612, MCC = 0.8021, F1-score = 0.8160\n",
      "      SMOTEBoost: AUC = 0.9662, G-Mean = 0.9228, MCC = 0.8256, F1-score = 0.8618\n",
      "      RUSBoost: AUC = 0.9481, G-Mean = 0.7754, MCC = 0.5385, F1-score = 0.6381\n",
      "      OUBoost: AUC = 0.9780, G-Mean = 0.9035, MCC = 0.7983, F1-score = 0.8353\n",
      "      SVM: AUC = 0.9784, G-Mean = 0.9034, MCC = 0.8331, F1-score = 0.8642\n",
      "      SMOTE: AUC = 0.9840, G-Mean = 0.9270, MCC = 0.8666, F1-score = 0.8912\n",
      "      ADASYN: AUC = 0.9786, G-Mean = 0.9355, MCC = 0.8730, F1-score = 0.8994\n",
      "      bSMOTE: AUC = 0.9832, G-Mean = 0.9236, MCC = 0.8592, F1-score = 0.8855\n",
      "      ROS: AUC = 0.9851, G-Mean = 0.9209, MCC = 0.8464, F1-score = 0.8766\n",
      "      MWMOTE: AUC = 0.9759, G-Mean = 0.9326, MCC = 0.8615, F1-score = 0.8903\n",
      "      Trans(Direct): AUC = 0.9853, G-Mean = 0.9476, MCC = 0.8688, F1-score = 0.8977\n",
      "\n",
      "Starting experiment 3/10\n",
      "  Fold 1/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.23738, Reg Loss: 0.28960\n",
      "Epoch 200/2000, Avg Loss: 0.23253, Reg Loss: 0.29543\n",
      "Epoch 300/2000, Avg Loss: 0.19284, Reg Loss: 0.28963\n",
      "Epoch 400/2000, Avg Loss: 0.16155, Reg Loss: 0.27096\n",
      "Epoch 500/2000, Avg Loss: 0.15211, Reg Loss: 0.28080\n",
      "Epoch 600/2000, Avg Loss: 0.14590, Reg Loss: 0.27506\n",
      "Epoch 700/2000, Avg Loss: 0.15611, Reg Loss: 0.28371\n",
      "Epoch 800/2000, Avg Loss: 0.11051, Reg Loss: 0.27006\n",
      "Epoch 900/2000, Avg Loss: 0.11533, Reg Loss: 0.26635\n",
      "Epoch 1000/2000, Avg Loss: 0.09292, Reg Loss: 0.25328\n",
      "Epoch 1100/2000, Avg Loss: 0.12985, Reg Loss: 0.26245\n",
      "Epoch 1200/2000, Avg Loss: 0.11199, Reg Loss: 0.25606\n",
      "Epoch 1300/2000, Avg Loss: 0.07975, Reg Loss: 0.25776\n",
      "Epoch 1400/2000, Avg Loss: 0.10524, Reg Loss: 0.26722\n",
      "Epoch 1500/2000, Avg Loss: 0.10528, Reg Loss: 0.25749\n",
      "Epoch 1600/2000, Avg Loss: 0.08762, Reg Loss: 0.25389\n",
      "Epoch 1700/2000, Avg Loss: 0.09815, Reg Loss: 0.24962\n",
      "Epoch 1800/2000, Avg Loss: 0.07464, Reg Loss: 0.23921\n",
      "Epoch 1900/2000, Avg Loss: 0.07972, Reg Loss: 0.24162\n",
      "Epoch 2000/2000, Avg Loss: 0.07773, Reg Loss: 0.24146\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.9706, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      SMOTEBoost: AUC = 1.0000, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      RUSBoost: AUC = 0.8588, G-Mean = 0.6860, MCC = 0.4100, F1-score = 0.5263\n",
      "      OUBoost: AUC = 1.0000, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      SVM: AUC = 1.0000, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      SMOTE: AUC = 1.0000, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      ADASYN: AUC = 0.9882, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      bSMOTE: AUC = 1.0000, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      ROS: AUC = 1.0000, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      MWMOTE: AUC = 1.0000, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      Trans(Direct): AUC = 1.0000, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "  Fold 2/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.22153, Reg Loss: 0.32122\n",
      "Epoch 200/2000, Avg Loss: 0.17127, Reg Loss: 0.30003\n",
      "Epoch 300/2000, Avg Loss: 0.15057, Reg Loss: 0.29877\n",
      "Epoch 400/2000, Avg Loss: 0.13943, Reg Loss: 0.29613\n",
      "Epoch 500/2000, Avg Loss: 0.11568, Reg Loss: 0.28888\n",
      "Epoch 600/2000, Avg Loss: 0.13827, Reg Loss: 0.29732\n",
      "Epoch 700/2000, Avg Loss: 0.11147, Reg Loss: 0.28300\n",
      "Epoch 800/2000, Avg Loss: 0.11282, Reg Loss: 0.28539\n",
      "Epoch 900/2000, Avg Loss: 0.10421, Reg Loss: 0.29343\n",
      "Epoch 1000/2000, Avg Loss: 0.10424, Reg Loss: 0.29721\n",
      "Epoch 1100/2000, Avg Loss: 0.08123, Reg Loss: 0.28286\n",
      "Epoch 1200/2000, Avg Loss: 0.09413, Reg Loss: 0.28141\n",
      "Epoch 1300/2000, Avg Loss: 0.09827, Reg Loss: 0.28911\n",
      "Epoch 1400/2000, Avg Loss: 0.10721, Reg Loss: 0.27892\n",
      "Epoch 1500/2000, Avg Loss: 0.11485, Reg Loss: 0.28873\n",
      "Epoch 1600/2000, Avg Loss: 0.12238, Reg Loss: 0.28444\n",
      "Epoch 1700/2000, Avg Loss: 0.10872, Reg Loss: 0.29889\n",
      "Epoch 1800/2000, Avg Loss: 0.10244, Reg Loss: 0.28476\n",
      "Epoch 1900/2000, Avg Loss: 0.09594, Reg Loss: 0.28115\n",
      "Epoch 2000/2000, Avg Loss: 0.09778, Reg Loss: 0.28533\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.9853, G-Mean = 0.9851, MCC = 0.9428, F1-score = 0.9545\n",
      "      SMOTEBoost: AUC = 1.0000, G-Mean = 0.9323, MCC = 0.8774, F1-score = 0.8990\n",
      "      RUSBoost: AUC = 0.8706, G-Mean = 0.7967, MCC = 0.5637, F1-score = 0.6478\n",
      "      OUBoost: AUC = 0.9882, G-Mean = 0.9547, MCC = 0.8397, F1-score = 0.8712\n",
      "      SVM: AUC = 1.0000, G-Mean = 0.9851, MCC = 0.9428, F1-score = 0.9545\n",
      "      SMOTE: AUC = 1.0000, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      ADASYN: AUC = 0.9941, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      bSMOTE: AUC = 1.0000, G-Mean = 0.9851, MCC = 0.9428, F1-score = 0.9545\n",
      "      ROS: AUC = 1.0000, G-Mean = 0.9851, MCC = 0.9428, F1-score = 0.9545\n",
      "      MWMOTE: AUC = 1.0000, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      Trans(Direct): AUC = 1.0000, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "  Fold 3/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.21050, Reg Loss: 0.30388\n",
      "Epoch 200/2000, Avg Loss: 0.18139, Reg Loss: 0.29217\n",
      "Epoch 300/2000, Avg Loss: 0.15977, Reg Loss: 0.29276\n",
      "Epoch 400/2000, Avg Loss: 0.14207, Reg Loss: 0.28643\n",
      "Epoch 500/2000, Avg Loss: 0.12724, Reg Loss: 0.28180\n",
      "Epoch 600/2000, Avg Loss: 0.13262, Reg Loss: 0.29164\n",
      "Epoch 700/2000, Avg Loss: 0.11108, Reg Loss: 0.29781\n",
      "Epoch 800/2000, Avg Loss: 0.12203, Reg Loss: 0.29079\n",
      "Epoch 900/2000, Avg Loss: 0.14014, Reg Loss: 0.27957\n",
      "Epoch 1000/2000, Avg Loss: 0.13034, Reg Loss: 0.29330\n",
      "Epoch 1100/2000, Avg Loss: 0.10361, Reg Loss: 0.28749\n",
      "Epoch 1200/2000, Avg Loss: 0.09985, Reg Loss: 0.28101\n",
      "Epoch 1300/2000, Avg Loss: 0.08666, Reg Loss: 0.27559\n",
      "Epoch 1400/2000, Avg Loss: 0.09017, Reg Loss: 0.27829\n",
      "Epoch 1500/2000, Avg Loss: 0.08991, Reg Loss: 0.28604\n",
      "Epoch 1600/2000, Avg Loss: 0.09410, Reg Loss: 0.27128\n",
      "Epoch 1700/2000, Avg Loss: 0.08396, Reg Loss: 0.27847\n",
      "Epoch 1800/2000, Avg Loss: 0.09692, Reg Loss: 0.26690\n",
      "Epoch 1900/2000, Avg Loss: 0.09080, Reg Loss: 0.26413\n",
      "Epoch 2000/2000, Avg Loss: 0.08797, Reg Loss: 0.26408\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.9902, G-Mean = 0.9900, MCC = 0.9619, F1-score = 0.9697\n",
      "      SMOTEBoost: AUC = 1.0000, G-Mean = 0.9549, MCC = 0.9183, F1-score = 0.9327\n",
      "      RUSBoost: AUC = 0.9137, G-Mean = 0.8539, MCC = 0.6746, F1-score = 0.7395\n",
      "      OUBoost: AUC = 0.9922, G-Mean = 0.9698, MCC = 0.8932, F1-score = 0.9141\n",
      "      SVM: AUC = 1.0000, G-Mean = 0.9900, MCC = 0.9619, F1-score = 0.9697\n",
      "      SMOTE: AUC = 1.0000, G-Mean = 0.9801, MCC = 0.9237, F1-score = 0.9394\n",
      "      ADASYN: AUC = 0.9961, G-Mean = 0.9801, MCC = 0.9237, F1-score = 0.9394\n",
      "      bSMOTE: AUC = 1.0000, G-Mean = 0.9900, MCC = 0.9619, F1-score = 0.9697\n",
      "      ROS: AUC = 1.0000, G-Mean = 0.9900, MCC = 0.9619, F1-score = 0.9697\n",
      "      MWMOTE: AUC = 1.0000, G-Mean = 0.9801, MCC = 0.9237, F1-score = 0.9394\n",
      "      Trans(Direct): AUC = 1.0000, G-Mean = 0.9801, MCC = 0.9237, F1-score = 0.9394\n",
      "  Fold 4/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.28427, Reg Loss: 0.31223\n",
      "Epoch 200/2000, Avg Loss: 0.18129, Reg Loss: 0.30157\n",
      "Epoch 300/2000, Avg Loss: 0.18031, Reg Loss: 0.30764\n",
      "Epoch 400/2000, Avg Loss: 0.14754, Reg Loss: 0.30353\n",
      "Epoch 500/2000, Avg Loss: 0.13505, Reg Loss: 0.30037\n",
      "Epoch 600/2000, Avg Loss: 0.12896, Reg Loss: 0.30924\n",
      "Epoch 700/2000, Avg Loss: 0.13436, Reg Loss: 0.29958\n",
      "Epoch 800/2000, Avg Loss: 0.13000, Reg Loss: 0.30004\n",
      "Epoch 900/2000, Avg Loss: 0.10203, Reg Loss: 0.28975\n",
      "Epoch 1000/2000, Avg Loss: 0.13118, Reg Loss: 0.29998\n",
      "Epoch 1100/2000, Avg Loss: 0.10563, Reg Loss: 0.29110\n",
      "Epoch 1200/2000, Avg Loss: 0.10122, Reg Loss: 0.29329\n",
      "Epoch 1300/2000, Avg Loss: 0.10306, Reg Loss: 0.28989\n",
      "Epoch 1400/2000, Avg Loss: 0.10125, Reg Loss: 0.28789\n",
      "Epoch 1500/2000, Avg Loss: 0.08594, Reg Loss: 0.28196\n",
      "Epoch 1600/2000, Avg Loss: 0.08238, Reg Loss: 0.28273\n",
      "Epoch 1700/2000, Avg Loss: 0.09725, Reg Loss: 0.28688\n",
      "Epoch 1800/2000, Avg Loss: 0.09641, Reg Loss: 0.29080\n",
      "Epoch 1900/2000, Avg Loss: 0.09670, Reg Loss: 0.27551\n",
      "Epoch 2000/2000, Avg Loss: 0.09196, Reg Loss: 0.28648\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.9926, G-Mean = 0.9925, MCC = 0.9714, F1-score = 0.9773\n",
      "      SMOTEBoost: AUC = 1.0000, G-Mean = 0.9661, MCC = 0.9387, F1-score = 0.9495\n",
      "      RUSBoost: AUC = 0.9353, G-Mean = 0.8658, MCC = 0.6841, F1-score = 0.7470\n",
      "      OUBoost: AUC = 0.9941, G-Mean = 0.9694, MCC = 0.8908, F1-score = 0.9129\n",
      "      SVM: AUC = 1.0000, G-Mean = 0.9661, MCC = 0.9383, F1-score = 0.9495\n",
      "      SMOTE: AUC = 1.0000, G-Mean = 0.9851, MCC = 0.9428, F1-score = 0.9545\n",
      "      ADASYN: AUC = 0.9971, G-Mean = 0.9771, MCC = 0.9138, F1-score = 0.9318\n",
      "      bSMOTE: AUC = 1.0000, G-Mean = 0.9846, MCC = 0.9424, F1-score = 0.9545\n",
      "      ROS: AUC = 1.0000, G-Mean = 0.9925, MCC = 0.9714, F1-score = 0.9773\n",
      "      MWMOTE: AUC = 1.0000, G-Mean = 0.9771, MCC = 0.9138, F1-score = 0.9318\n",
      "      Trans(Direct): AUC = 1.0000, G-Mean = 0.9771, MCC = 0.9138, F1-score = 0.9318\n",
      "  Fold 5/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.26141, Reg Loss: 0.30527\n",
      "Epoch 200/2000, Avg Loss: 0.17318, Reg Loss: 0.27573\n",
      "Epoch 300/2000, Avg Loss: 0.17543, Reg Loss: 0.28246\n",
      "Epoch 400/2000, Avg Loss: 0.15517, Reg Loss: 0.27338\n",
      "Epoch 500/2000, Avg Loss: 0.12399, Reg Loss: 0.26482\n",
      "Epoch 600/2000, Avg Loss: 0.11179, Reg Loss: 0.24742\n",
      "Epoch 700/2000, Avg Loss: 0.11183, Reg Loss: 0.26167\n",
      "Epoch 800/2000, Avg Loss: 0.10076, Reg Loss: 0.25455\n",
      "Epoch 900/2000, Avg Loss: 0.11545, Reg Loss: 0.26435\n",
      "Epoch 1000/2000, Avg Loss: 0.09635, Reg Loss: 0.25617\n",
      "Epoch 1100/2000, Avg Loss: 0.09419, Reg Loss: 0.23868\n",
      "Epoch 1200/2000, Avg Loss: 0.09589, Reg Loss: 0.25466\n",
      "Epoch 1300/2000, Avg Loss: 0.09426, Reg Loss: 0.24291\n",
      "Epoch 1400/2000, Avg Loss: 0.08816, Reg Loss: 0.23416\n",
      "Epoch 1500/2000, Avg Loss: 0.08527, Reg Loss: 0.23983\n",
      "Epoch 1600/2000, Avg Loss: 0.09299, Reg Loss: 0.24265\n",
      "Epoch 1700/2000, Avg Loss: 0.07355, Reg Loss: 0.23161\n",
      "Epoch 1800/2000, Avg Loss: 0.08279, Reg Loss: 0.24423\n",
      "Epoch 1900/2000, Avg Loss: 0.07576, Reg Loss: 0.23460\n",
      "Epoch 2000/2000, Avg Loss: 0.07731, Reg Loss: 0.23038\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.9279, G-Mean = 0.9165, MCC = 0.8593, F1-score = 0.8818\n",
      "      SMOTEBoost: AUC = 0.9850, G-Mean = 0.9600, MCC = 0.9091, F1-score = 0.9263\n",
      "      RUSBoost: AUC = 0.9307, G-Mean = 0.8729, MCC = 0.6898, F1-score = 0.7514\n",
      "      OUBoost: AUC = 0.9828, G-Mean = 0.9626, MCC = 0.8708, F1-score = 0.8970\n",
      "      SVM: AUC = 0.9875, G-Mean = 0.9402, MCC = 0.8779, F1-score = 0.9051\n",
      "      SMOTE: AUC = 0.9900, G-Mean = 0.9554, MCC = 0.8815, F1-score = 0.9091\n",
      "      ADASYN: AUC = 0.9876, G-Mean = 0.9490, MCC = 0.8583, F1-score = 0.8909\n",
      "      bSMOTE: AUC = 0.9900, G-Mean = 0.9748, MCC = 0.9120, F1-score = 0.9303\n",
      "      ROS: AUC = 0.9900, G-Mean = 0.9811, MCC = 0.9352, F1-score = 0.9485\n",
      "      MWMOTE: AUC = 0.9900, G-Mean = 0.9490, MCC = 0.8583, F1-score = 0.8909\n",
      "      Trans(Direct): AUC = 0.9900, G-Mean = 0.9490, MCC = 0.8583, F1-score = 0.8909\n",
      "  Fold 6/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.24746, Reg Loss: 0.31636\n",
      "Epoch 200/2000, Avg Loss: 0.19681, Reg Loss: 0.30629\n",
      "Epoch 300/2000, Avg Loss: 0.15654, Reg Loss: 0.29580\n",
      "Epoch 400/2000, Avg Loss: 0.17503, Reg Loss: 0.30214\n",
      "Epoch 500/2000, Avg Loss: 0.13681, Reg Loss: 0.30836\n",
      "Epoch 600/2000, Avg Loss: 0.11447, Reg Loss: 0.29241\n",
      "Epoch 700/2000, Avg Loss: 0.13021, Reg Loss: 0.28807\n",
      "Epoch 800/2000, Avg Loss: 0.10403, Reg Loss: 0.29218\n",
      "Epoch 900/2000, Avg Loss: 0.11511, Reg Loss: 0.29917\n",
      "Epoch 1000/2000, Avg Loss: 0.10228, Reg Loss: 0.28552\n",
      "Epoch 1100/2000, Avg Loss: 0.10617, Reg Loss: 0.26846\n",
      "Epoch 1200/2000, Avg Loss: 0.11939, Reg Loss: 0.28770\n",
      "Epoch 1300/2000, Avg Loss: 0.10355, Reg Loss: 0.26891\n",
      "Epoch 1400/2000, Avg Loss: 0.09773, Reg Loss: 0.28140\n",
      "Epoch 1500/2000, Avg Loss: 0.09016, Reg Loss: 0.27610\n",
      "Epoch 1600/2000, Avg Loss: 0.10575, Reg Loss: 0.27590\n",
      "Epoch 1700/2000, Avg Loss: 0.09872, Reg Loss: 0.27925\n",
      "Epoch 1800/2000, Avg Loss: 0.09095, Reg Loss: 0.26802\n",
      "Epoch 1900/2000, Avg Loss: 0.07460, Reg Loss: 0.26335\n",
      "Epoch 2000/2000, Avg Loss: 0.09254, Reg Loss: 0.27192\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.9326, G-Mean = 0.9197, MCC = 0.8478, F1-score = 0.8737\n",
      "      SMOTEBoost: AUC = 0.9875, G-Mean = 0.9502, MCC = 0.8763, F1-score = 0.9001\n",
      "      RUSBoost: AUC = 0.9423, G-Mean = 0.8718, MCC = 0.6824, F1-score = 0.7452\n",
      "      OUBoost: AUC = 0.9857, G-Mean = 0.9581, MCC = 0.8574, F1-score = 0.8864\n",
      "      SVM: AUC = 0.9854, G-Mean = 0.9449, MCC = 0.8789, F1-score = 0.9057\n",
      "      SMOTE: AUC = 0.9854, G-Mean = 0.9575, MCC = 0.8819, F1-score = 0.9091\n",
      "      ADASYN: AUC = 0.9793, G-Mean = 0.9522, MCC = 0.8626, F1-score = 0.8939\n",
      "      bSMOTE: AUC = 0.9854, G-Mean = 0.9737, MCC = 0.9073, F1-score = 0.9268\n",
      "      ROS: AUC = 0.9854, G-Mean = 0.9790, MCC = 0.9267, F1-score = 0.9419\n",
      "      MWMOTE: AUC = 0.9813, G-Mean = 0.9522, MCC = 0.8626, F1-score = 0.8939\n",
      "      Trans(Direct): AUC = 0.9896, G-Mean = 0.9468, MCC = 0.8470, F1-score = 0.8813\n",
      "  Fold 7/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.23684, Reg Loss: 0.31758\n",
      "Epoch 200/2000, Avg Loss: 0.22156, Reg Loss: 0.30731\n",
      "Epoch 300/2000, Avg Loss: 0.16898, Reg Loss: 0.29903\n",
      "Epoch 400/2000, Avg Loss: 0.15777, Reg Loss: 0.29788\n",
      "Epoch 500/2000, Avg Loss: 0.13732, Reg Loss: 0.28841\n",
      "Epoch 600/2000, Avg Loss: 0.13166, Reg Loss: 0.28349\n",
      "Epoch 700/2000, Avg Loss: 0.16465, Reg Loss: 0.30989\n",
      "Epoch 800/2000, Avg Loss: 0.09879, Reg Loss: 0.28825\n",
      "Epoch 900/2000, Avg Loss: 0.11868, Reg Loss: 0.30012\n",
      "Epoch 1000/2000, Avg Loss: 0.10294, Reg Loss: 0.28661\n",
      "Epoch 1100/2000, Avg Loss: 0.11360, Reg Loss: 0.29327\n",
      "Epoch 1200/2000, Avg Loss: 0.11422, Reg Loss: 0.29882\n",
      "Epoch 1300/2000, Avg Loss: 0.10215, Reg Loss: 0.29219\n",
      "Epoch 1400/2000, Avg Loss: 0.09539, Reg Loss: 0.29029\n",
      "Epoch 1500/2000, Avg Loss: 0.10095, Reg Loss: 0.27788\n",
      "Epoch 1600/2000, Avg Loss: 0.08551, Reg Loss: 0.27390\n",
      "Epoch 1700/2000, Avg Loss: 0.10674, Reg Loss: 0.28360\n",
      "Epoch 1800/2000, Avg Loss: 0.09341, Reg Loss: 0.27650\n",
      "Epoch 1900/2000, Avg Loss: 0.09442, Reg Loss: 0.27407\n",
      "Epoch 2000/2000, Avg Loss: 0.08643, Reg Loss: 0.27390\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.9422, G-Mean = 0.9311, MCC = 0.8696, F1-score = 0.8918\n",
      "      SMOTEBoost: AUC = 0.9893, G-Mean = 0.9528, MCC = 0.8774, F1-score = 0.9014\n",
      "      RUSBoost: AUC = 0.9407, G-Mean = 0.8709, MCC = 0.6771, F1-score = 0.7408\n",
      "      OUBoost: AUC = 0.9877, G-Mean = 0.9641, MCC = 0.8778, F1-score = 0.9026\n",
      "      SVM: AUC = 0.9839, G-Mean = 0.9336, MCC = 0.8587, F1-score = 0.8906\n",
      "      SMOTE: AUC = 0.9839, G-Mean = 0.9591, MCC = 0.8822, F1-score = 0.9091\n",
      "      ADASYN: AUC = 0.9805, G-Mean = 0.9399, MCC = 0.8447, F1-score = 0.8805\n",
      "      bSMOTE: AUC = 0.9839, G-Mean = 0.9583, MCC = 0.8831, F1-score = 0.9087\n",
      "      ROS: AUC = 0.9839, G-Mean = 0.9628, MCC = 0.8997, F1-score = 0.9216\n",
      "      MWMOTE: AUC = 0.9821, G-Mean = 0.9545, MCC = 0.8656, F1-score = 0.8961\n",
      "      Trans(Direct): AUC = 0.9875, G-Mean = 0.9498, MCC = 0.8523, F1-score = 0.8853\n",
      "  Fold 8/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.23081, Reg Loss: 0.33455\n",
      "Epoch 200/2000, Avg Loss: 0.20772, Reg Loss: 0.32658\n",
      "Epoch 300/2000, Avg Loss: 0.16284, Reg Loss: 0.33776\n",
      "Epoch 400/2000, Avg Loss: 0.15491, Reg Loss: 0.32638\n",
      "Epoch 500/2000, Avg Loss: 0.14442, Reg Loss: 0.32815\n",
      "Epoch 600/2000, Avg Loss: 0.13926, Reg Loss: 0.33703\n",
      "Epoch 700/2000, Avg Loss: 0.12429, Reg Loss: 0.31359\n",
      "Epoch 800/2000, Avg Loss: 0.12358, Reg Loss: 0.32524\n",
      "Epoch 900/2000, Avg Loss: 0.12596, Reg Loss: 0.31292\n",
      "Epoch 1000/2000, Avg Loss: 0.11042, Reg Loss: 0.29850\n",
      "Epoch 1100/2000, Avg Loss: 0.08680, Reg Loss: 0.30050\n",
      "Epoch 1200/2000, Avg Loss: 0.10697, Reg Loss: 0.31526\n",
      "Epoch 1300/2000, Avg Loss: 0.09107, Reg Loss: 0.28872\n",
      "Epoch 1400/2000, Avg Loss: 0.11657, Reg Loss: 0.32404\n",
      "Epoch 1500/2000, Avg Loss: 0.08273, Reg Loss: 0.30290\n",
      "Epoch 1600/2000, Avg Loss: 0.08975, Reg Loss: 0.29847\n",
      "Epoch 1700/2000, Avg Loss: 0.10265, Reg Loss: 0.29286\n",
      "Epoch 1800/2000, Avg Loss: 0.08965, Reg Loss: 0.28978\n",
      "Epoch 1900/2000, Avg Loss: 0.09106, Reg Loss: 0.28893\n",
      "Epoch 2000/2000, Avg Loss: 0.10695, Reg Loss: 0.30580\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.9244, G-Mean = 0.9116, MCC = 0.8522, F1-score = 0.8741\n",
      "      SMOTEBoost: AUC = 0.9906, G-Mean = 0.9587, MCC = 0.8927, F1-score = 0.9137\n",
      "      RUSBoost: AUC = 0.9481, G-Mean = 0.8790, MCC = 0.6913, F1-score = 0.7524\n",
      "      OUBoost: AUC = 0.9892, G-Mean = 0.9686, MCC = 0.8931, F1-score = 0.9148\n",
      "      SVM: AUC = 0.9859, G-Mean = 0.9287, MCC = 0.8599, F1-score = 0.8904\n",
      "      SMOTE: AUC = 0.9859, G-Mean = 0.9510, MCC = 0.8804, F1-score = 0.9066\n",
      "      ADASYN: AUC = 0.9829, G-Mean = 0.9342, MCC = 0.8476, F1-score = 0.8816\n",
      "      bSMOTE: AUC = 0.9859, G-Mean = 0.9503, MCC = 0.8811, F1-score = 0.9062\n",
      "      ROS: AUC = 0.9859, G-Mean = 0.9543, MCC = 0.8957, F1-score = 0.9176\n",
      "      MWMOTE: AUC = 0.9844, G-Mean = 0.9470, MCC = 0.8659, F1-score = 0.8952\n",
      "      Trans(Direct): AUC = 0.9891, G-Mean = 0.9429, MCC = 0.8542, F1-score = 0.8857\n",
      "  Fold 9/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.25328, Reg Loss: 0.39547\n",
      "Epoch 200/2000, Avg Loss: 0.20886, Reg Loss: 0.38872\n",
      "Epoch 300/2000, Avg Loss: 0.18321, Reg Loss: 0.38872\n",
      "Epoch 400/2000, Avg Loss: 0.18101, Reg Loss: 0.37761\n",
      "Epoch 500/2000, Avg Loss: 0.18128, Reg Loss: 0.38834\n",
      "Epoch 600/2000, Avg Loss: 0.15667, Reg Loss: 0.38375\n",
      "Epoch 700/2000, Avg Loss: 0.14860, Reg Loss: 0.38723\n",
      "Epoch 800/2000, Avg Loss: 0.13910, Reg Loss: 0.36913\n",
      "Epoch 900/2000, Avg Loss: 0.15358, Reg Loss: 0.35652\n",
      "Epoch 1000/2000, Avg Loss: 0.12123, Reg Loss: 0.36412\n",
      "Epoch 1100/2000, Avg Loss: 0.11171, Reg Loss: 0.35306\n",
      "Epoch 1200/2000, Avg Loss: 0.12350, Reg Loss: 0.35176\n",
      "Epoch 1300/2000, Avg Loss: 0.10570, Reg Loss: 0.33892\n",
      "Epoch 1400/2000, Avg Loss: 0.11563, Reg Loss: 0.35407\n",
      "Epoch 1500/2000, Avg Loss: 0.12150, Reg Loss: 0.34660\n",
      "Epoch 1600/2000, Avg Loss: 0.11397, Reg Loss: 0.35230\n",
      "Epoch 1700/2000, Avg Loss: 0.10020, Reg Loss: 0.35048\n",
      "Epoch 1800/2000, Avg Loss: 0.10832, Reg Loss: 0.34032\n",
      "Epoch 1900/2000, Avg Loss: 0.15846, Reg Loss: 0.36385\n",
      "Epoch 2000/2000, Avg Loss: 0.11510, Reg Loss: 0.35630\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.8960, G-Mean = 0.8783, MCC = 0.8031, F1-score = 0.8325\n",
      "      SMOTEBoost: AUC = 0.9778, G-Mean = 0.9516, MCC = 0.8900, F1-score = 0.9109\n",
      "      RUSBoost: AUC = 0.9365, G-Mean = 0.8709, MCC = 0.6760, F1-score = 0.7429\n",
      "      OUBoost: AUC = 0.9779, G-Mean = 0.9603, MCC = 0.8902, F1-score = 0.9119\n",
      "      SVM: AUC = 0.9792, G-Mean = 0.9089, MCC = 0.8291, F1-score = 0.8655\n",
      "      SMOTE: AUC = 0.9806, G-Mean = 0.9415, MCC = 0.8645, F1-score = 0.8947\n",
      "      ADASYN: AUC = 0.9779, G-Mean = 0.9267, MCC = 0.8353, F1-score = 0.8725\n",
      "      bSMOTE: AUC = 0.9819, G-Mean = 0.9409, MCC = 0.8652, F1-score = 0.8944\n",
      "      ROS: AUC = 0.9819, G-Mean = 0.9445, MCC = 0.8781, F1-score = 0.9045\n",
      "      MWMOTE: AUC = 0.9792, G-Mean = 0.9380, MCC = 0.8516, F1-score = 0.8846\n",
      "      Trans(Direct): AUC = 0.9861, G-Mean = 0.9344, MCC = 0.8412, F1-score = 0.8762\n",
      "  Fold 10/10 - Experiment 3/10\n",
      "Epoch 100/2000, Avg Loss: 0.27392, Reg Loss: 0.34257\n",
      "Epoch 200/2000, Avg Loss: 0.20957, Reg Loss: 0.33519\n",
      "Epoch 300/2000, Avg Loss: 0.18139, Reg Loss: 0.33540\n",
      "Epoch 400/2000, Avg Loss: 0.15536, Reg Loss: 0.31881\n",
      "Epoch 500/2000, Avg Loss: 0.16103, Reg Loss: 0.32363\n",
      "Epoch 600/2000, Avg Loss: 0.15395, Reg Loss: 0.32186\n",
      "Epoch 700/2000, Avg Loss: 0.13601, Reg Loss: 0.32331\n",
      "Epoch 800/2000, Avg Loss: 0.15151, Reg Loss: 0.34344\n",
      "Epoch 900/2000, Avg Loss: 0.12537, Reg Loss: 0.32466\n",
      "Epoch 1000/2000, Avg Loss: 0.13081, Reg Loss: 0.31425\n",
      "Epoch 1100/2000, Avg Loss: 0.10959, Reg Loss: 0.30483\n",
      "Epoch 1200/2000, Avg Loss: 0.11189, Reg Loss: 0.32000\n",
      "Epoch 1300/2000, Avg Loss: 0.13250, Reg Loss: 0.31910\n",
      "Epoch 1400/2000, Avg Loss: 0.11650, Reg Loss: 0.31814\n",
      "Epoch 1500/2000, Avg Loss: 0.12404, Reg Loss: 0.31235\n",
      "Epoch 1600/2000, Avg Loss: 0.11873, Reg Loss: 0.31326\n",
      "Epoch 1700/2000, Avg Loss: 0.11797, Reg Loss: 0.31613\n",
      "Epoch 1800/2000, Avg Loss: 0.10474, Reg Loss: 0.30664\n",
      "Epoch 1900/2000, Avg Loss: 0.09626, Reg Loss: 0.29461\n",
      "Epoch 2000/2000, Avg Loss: 0.08718, Reg Loss: 0.30749\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.9052, G-Mean = 0.8799, MCC = 0.8096, F1-score = 0.8381\n",
      "      SMOTEBoost: AUC = 0.9800, G-Mean = 0.9499, MCC = 0.8800, F1-score = 0.9032\n",
      "      RUSBoost: AUC = 0.9391, G-Mean = 0.8704, MCC = 0.6729, F1-score = 0.7400\n",
      "      OUBoost: AUC = 0.9764, G-Mean = 0.9578, MCC = 0.8803, F1-score = 0.9040\n",
      "      SVM: AUC = 0.9812, G-Mean = 0.9180, MCC = 0.8462, F1-score = 0.8790\n",
      "      SMOTE: AUC = 0.9825, G-Mean = 0.9474, MCC = 0.8781, F1-score = 0.9053\n",
      "      ADASYN: AUC = 0.9801, G-Mean = 0.9340, MCC = 0.8518, F1-score = 0.8853\n",
      "      bSMOTE: AUC = 0.9838, G-Mean = 0.9469, MCC = 0.8787, F1-score = 0.9049\n",
      "      ROS: AUC = 0.9838, G-Mean = 0.9500, MCC = 0.8903, F1-score = 0.9140\n",
      "      MWMOTE: AUC = 0.9812, G-Mean = 0.9442, MCC = 0.8664, F1-score = 0.8962\n",
      "      Trans(Direct): AUC = 0.9875, G-Mean = 0.9409, MCC = 0.8571, F1-score = 0.8886\n",
      "\n",
      "Starting experiment 4/10\n",
      "  Fold 1/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.24067, Reg Loss: 0.29945\n",
      "Epoch 200/2000, Avg Loss: 0.18070, Reg Loss: 0.31996\n",
      "Epoch 300/2000, Avg Loss: 0.17914, Reg Loss: 0.31750\n",
      "Epoch 400/2000, Avg Loss: 0.13736, Reg Loss: 0.30706\n",
      "Epoch 500/2000, Avg Loss: 0.13042, Reg Loss: 0.31070\n",
      "Epoch 600/2000, Avg Loss: 0.11750, Reg Loss: 0.30710\n",
      "Epoch 700/2000, Avg Loss: 0.13300, Reg Loss: 0.31436\n",
      "Epoch 800/2000, Avg Loss: 0.11414, Reg Loss: 0.30179\n",
      "Epoch 900/2000, Avg Loss: 0.10554, Reg Loss: 0.30339\n",
      "Epoch 1000/2000, Avg Loss: 0.09760, Reg Loss: 0.29675\n",
      "Epoch 1100/2000, Avg Loss: 0.11455, Reg Loss: 0.29826\n",
      "Epoch 1200/2000, Avg Loss: 0.09930, Reg Loss: 0.29608\n",
      "Epoch 1300/2000, Avg Loss: 0.09060, Reg Loss: 0.29342\n",
      "Epoch 1400/2000, Avg Loss: 0.08696, Reg Loss: 0.28140\n",
      "Epoch 1500/2000, Avg Loss: 0.08629, Reg Loss: 0.28888\n",
      "Epoch 1600/2000, Avg Loss: 0.08615, Reg Loss: 0.28131\n",
      "Epoch 1700/2000, Avg Loss: 0.08575, Reg Loss: 0.28169\n",
      "Epoch 1800/2000, Avg Loss: 0.09202, Reg Loss: 0.27517\n",
      "Epoch 1900/2000, Avg Loss: 0.08134, Reg Loss: 0.28095\n",
      "Epoch 2000/2000, Avg Loss: 0.08674, Reg Loss: 0.27513\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.9000, G-Mean = 0.7746, MCC = 0.7327, F1-score = 0.7500\n",
      "      SMOTEBoost: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      RUSBoost: AUC = 0.9765, G-Mean = 0.8745, MCC = 0.6518, F1-score = 0.7143\n",
      "      OUBoost: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      SVM: AUC = 1.0000, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      SMOTE: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      ADASYN: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      bSMOTE: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      ROS: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      MWMOTE: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      Trans(Direct): AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "  Fold 2/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.20660, Reg Loss: 0.32594\n",
      "Epoch 200/2000, Avg Loss: 0.18708, Reg Loss: 0.33607\n",
      "Epoch 300/2000, Avg Loss: 0.16329, Reg Loss: 0.33092\n",
      "Epoch 400/2000, Avg Loss: 0.14169, Reg Loss: 0.32389\n",
      "Epoch 500/2000, Avg Loss: 0.13105, Reg Loss: 0.33457\n",
      "Epoch 600/2000, Avg Loss: 0.11841, Reg Loss: 0.31346\n",
      "Epoch 700/2000, Avg Loss: 0.10523, Reg Loss: 0.32352\n",
      "Epoch 800/2000, Avg Loss: 0.12418, Reg Loss: 0.31195\n",
      "Epoch 900/2000, Avg Loss: 0.13099, Reg Loss: 0.30548\n",
      "Epoch 1000/2000, Avg Loss: 0.13393, Reg Loss: 0.29496\n",
      "Epoch 1100/2000, Avg Loss: 0.09283, Reg Loss: 0.30285\n",
      "Epoch 1200/2000, Avg Loss: 0.09629, Reg Loss: 0.30491\n",
      "Epoch 1300/2000, Avg Loss: 0.10464, Reg Loss: 0.28241\n",
      "Epoch 1400/2000, Avg Loss: 0.08959, Reg Loss: 0.28392\n",
      "Epoch 1500/2000, Avg Loss: 0.07220, Reg Loss: 0.27084\n",
      "Epoch 1600/2000, Avg Loss: 0.10670, Reg Loss: 0.27857\n",
      "Epoch 1700/2000, Avg Loss: 0.08065, Reg Loss: 0.28767\n",
      "Epoch 1800/2000, Avg Loss: 0.07797, Reg Loss: 0.27221\n",
      "Epoch 1900/2000, Avg Loss: 0.09183, Reg Loss: 0.28927\n",
      "Epoch 2000/2000, Avg Loss: 0.06894, Reg Loss: 0.27616\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.9000, G-Mean = 0.8345, MCC = 0.8010, F1-score = 0.8194\n",
      "      SMOTEBoost: AUC = 1.0000, G-Mean = 0.8873, MCC = 0.8663, F1-score = 0.8750\n",
      "      RUSBoost: AUC = 0.9588, G-Mean = 0.8910, MCC = 0.6846, F1-score = 0.7418\n",
      "      OUBoost: AUC = 1.0000, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      SVM: AUC = 0.9765, G-Mean = 0.7540, MCC = 0.6429, F1-score = 0.6944\n",
      "      SMOTE: AUC = 0.9765, G-Mean = 0.8068, MCC = 0.7083, F1-score = 0.7500\n",
      "      ADASYN: AUC = 0.9765, G-Mean = 0.8068, MCC = 0.7083, F1-score = 0.7500\n",
      "      bSMOTE: AUC = 0.9824, G-Mean = 0.8068, MCC = 0.7083, F1-score = 0.7500\n",
      "      ROS: AUC = 0.9765, G-Mean = 0.7169, MCC = 0.6029, F1-score = 0.6429\n",
      "      MWMOTE: AUC = 0.9765, G-Mean = 0.8068, MCC = 0.7083, F1-score = 0.7500\n",
      "      Trans(Direct): AUC = 0.9765, G-Mean = 0.8757, MCC = 0.7940, F1-score = 0.8333\n",
      "  Fold 3/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.23128, Reg Loss: 0.32091\n",
      "Epoch 200/2000, Avg Loss: 0.18385, Reg Loss: 0.29884\n",
      "Epoch 300/2000, Avg Loss: 0.20288, Reg Loss: 0.31825\n",
      "Epoch 400/2000, Avg Loss: 0.16854, Reg Loss: 0.30372\n",
      "Epoch 500/2000, Avg Loss: 0.14791, Reg Loss: 0.29954\n",
      "Epoch 600/2000, Avg Loss: 0.16373, Reg Loss: 0.31600\n",
      "Epoch 700/2000, Avg Loss: 0.13525, Reg Loss: 0.30546\n",
      "Epoch 800/2000, Avg Loss: 0.15767, Reg Loss: 0.32059\n",
      "Epoch 900/2000, Avg Loss: 0.12229, Reg Loss: 0.29659\n",
      "Epoch 1000/2000, Avg Loss: 0.13732, Reg Loss: 0.30676\n",
      "Epoch 1100/2000, Avg Loss: 0.10613, Reg Loss: 0.29116\n",
      "Epoch 1200/2000, Avg Loss: 0.11271, Reg Loss: 0.31205\n",
      "Epoch 1300/2000, Avg Loss: 0.10187, Reg Loss: 0.28179\n",
      "Epoch 1400/2000, Avg Loss: 0.11405, Reg Loss: 0.29396\n",
      "Epoch 1500/2000, Avg Loss: 0.10148, Reg Loss: 0.29560\n",
      "Epoch 1600/2000, Avg Loss: 0.13861, Reg Loss: 0.30413\n",
      "Epoch 1700/2000, Avg Loss: 0.11858, Reg Loss: 0.29337\n",
      "Epoch 1800/2000, Avg Loss: 0.10366, Reg Loss: 0.29259\n",
      "Epoch 1900/2000, Avg Loss: 0.09779, Reg Loss: 0.29140\n",
      "Epoch 2000/2000, Avg Loss: 0.09321, Reg Loss: 0.28299\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.8951, G-Mean = 0.8510, MCC = 0.7909, F1-score = 0.8241\n",
      "      SMOTEBoost: AUC = 0.9896, G-Mean = 0.9143, MCC = 0.8764, F1-score = 0.8910\n",
      "      RUSBoost: AUC = 0.9691, G-Mean = 0.8440, MCC = 0.6262, F1-score = 0.7050\n",
      "      OUBoost: AUC = 0.9965, G-Mean = 0.9542, MCC = 0.9219, F1-score = 0.9373\n",
      "      SVM: AUC = 0.9808, G-Mean = 0.8070, MCC = 0.7238, F1-score = 0.7660\n",
      "      SMOTE: AUC = 0.9739, G-Mean = 0.8606, MCC = 0.7710, F1-score = 0.8077\n",
      "      ADASYN: AUC = 0.9739, G-Mean = 0.8606, MCC = 0.7710, F1-score = 0.8077\n",
      "      bSMOTE: AUC = 0.9778, G-Mean = 0.8606, MCC = 0.7710, F1-score = 0.8077\n",
      "      ROS: AUC = 0.9739, G-Mean = 0.8007, MCC = 0.7007, F1-score = 0.7363\n",
      "      MWMOTE: AUC = 0.9670, G-Mean = 0.8606, MCC = 0.7710, F1-score = 0.8077\n",
      "      Trans(Direct): AUC = 0.9739, G-Mean = 0.9066, MCC = 0.8281, F1-score = 0.8632\n",
      "  Fold 4/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.20561, Reg Loss: 0.31322\n",
      "Epoch 200/2000, Avg Loss: 0.16231, Reg Loss: 0.30616\n",
      "Epoch 300/2000, Avg Loss: 0.15431, Reg Loss: 0.30540\n",
      "Epoch 400/2000, Avg Loss: 0.14829, Reg Loss: 0.29153\n",
      "Epoch 500/2000, Avg Loss: 0.13756, Reg Loss: 0.29950\n",
      "Epoch 600/2000, Avg Loss: 0.12388, Reg Loss: 0.29001\n",
      "Epoch 700/2000, Avg Loss: 0.10492, Reg Loss: 0.28510\n",
      "Epoch 800/2000, Avg Loss: 0.11859, Reg Loss: 0.27409\n",
      "Epoch 900/2000, Avg Loss: 0.10710, Reg Loss: 0.27245\n",
      "Epoch 1000/2000, Avg Loss: 0.10148, Reg Loss: 0.26771\n",
      "Epoch 1100/2000, Avg Loss: 0.08267, Reg Loss: 0.25762\n",
      "Epoch 1200/2000, Avg Loss: 0.09281, Reg Loss: 0.26376\n",
      "Epoch 1300/2000, Avg Loss: 0.08971, Reg Loss: 0.26145\n",
      "Epoch 1400/2000, Avg Loss: 0.08437, Reg Loss: 0.26858\n",
      "Epoch 1500/2000, Avg Loss: 0.09939, Reg Loss: 0.27703\n",
      "Epoch 1600/2000, Avg Loss: 0.08739, Reg Loss: 0.26580\n",
      "Epoch 1700/2000, Avg Loss: 0.14439, Reg Loss: 0.28567\n",
      "Epoch 1800/2000, Avg Loss: 0.08633, Reg Loss: 0.25457\n",
      "Epoch 1900/2000, Avg Loss: 0.08751, Reg Loss: 0.26566\n",
      "Epoch 2000/2000, Avg Loss: 0.08364, Reg Loss: 0.25117\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.9182, G-Mean = 0.8547, MCC = 0.7776, F1-score = 0.8181\n",
      "      SMOTEBoost: AUC = 0.9859, G-Mean = 0.9196, MCC = 0.8549, F1-score = 0.8766\n",
      "      RUSBoost: AUC = 0.9643, G-Mean = 0.8495, MCC = 0.6311, F1-score = 0.7073\n",
      "      OUBoost: AUC = 0.9849, G-Mean = 0.9495, MCC = 0.8891, F1-score = 0.9113\n",
      "      SVM: AUC = 0.9856, G-Mean = 0.8552, MCC = 0.7929, F1-score = 0.8245\n",
      "      SMOTE: AUC = 0.9773, G-Mean = 0.8875, MCC = 0.7992, F1-score = 0.8330\n",
      "      ADASYN: AUC = 0.9742, G-Mean = 0.8875, MCC = 0.7992, F1-score = 0.8330\n",
      "      bSMOTE: AUC = 0.9771, G-Mean = 0.8875, MCC = 0.7992, F1-score = 0.8330\n",
      "      ROS: AUC = 0.9804, G-Mean = 0.8426, MCC = 0.7465, F1-score = 0.7795\n",
      "      MWMOTE: AUC = 0.9690, G-Mean = 0.8875, MCC = 0.7992, F1-score = 0.8330\n",
      "      Trans(Direct): AUC = 0.9804, G-Mean = 0.9220, MCC = 0.8421, F1-score = 0.8747\n",
      "  Fold 5/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.24851, Reg Loss: 0.29755\n",
      "Epoch 200/2000, Avg Loss: 0.21822, Reg Loss: 0.29065\n",
      "Epoch 300/2000, Avg Loss: 0.16443, Reg Loss: 0.28392\n",
      "Epoch 400/2000, Avg Loss: 0.16693, Reg Loss: 0.27950\n",
      "Epoch 500/2000, Avg Loss: 0.14446, Reg Loss: 0.28145\n",
      "Epoch 600/2000, Avg Loss: 0.13584, Reg Loss: 0.28512\n",
      "Epoch 700/2000, Avg Loss: 0.13167, Reg Loss: 0.27534\n",
      "Epoch 800/2000, Avg Loss: 0.11287, Reg Loss: 0.28183\n",
      "Epoch 900/2000, Avg Loss: 0.12944, Reg Loss: 0.28521\n",
      "Epoch 1000/2000, Avg Loss: 0.10144, Reg Loss: 0.28095\n",
      "Epoch 1100/2000, Avg Loss: 0.09419, Reg Loss: 0.27773\n",
      "Epoch 1200/2000, Avg Loss: 0.11168, Reg Loss: 0.26440\n",
      "Epoch 1300/2000, Avg Loss: 0.11049, Reg Loss: 0.29064\n",
      "Epoch 1400/2000, Avg Loss: 0.09264, Reg Loss: 0.28026\n",
      "Epoch 1500/2000, Avg Loss: 0.09338, Reg Loss: 0.26179\n",
      "Epoch 1600/2000, Avg Loss: 0.09959, Reg Loss: 0.26028\n",
      "Epoch 1700/2000, Avg Loss: 0.10418, Reg Loss: 0.26387\n",
      "Epoch 1800/2000, Avg Loss: 0.09662, Reg Loss: 0.26459\n",
      "Epoch 1900/2000, Avg Loss: 0.09940, Reg Loss: 0.26244\n",
      "Epoch 2000/2000, Avg Loss: 0.08715, Reg Loss: 0.26438\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.9083, G-Mean = 0.8570, MCC = 0.7696, F1-score = 0.8144\n",
      "      SMOTEBoost: AUC = 0.9812, G-Mean = 0.9293, MCC = 0.8607, F1-score = 0.8831\n",
      "      RUSBoost: AUC = 0.9652, G-Mean = 0.8732, MCC = 0.6816, F1-score = 0.7477\n",
      "      OUBoost: AUC = 0.9879, G-Mean = 0.9533, MCC = 0.8880, F1-score = 0.9109\n",
      "      SVM: AUC = 0.9885, G-Mean = 0.8778, MCC = 0.8111, F1-score = 0.8414\n",
      "      SMOTE: AUC = 0.9818, G-Mean = 0.9037, MCC = 0.8162, F1-score = 0.8483\n",
      "      ADASYN: AUC = 0.9743, G-Mean = 0.9037, MCC = 0.8162, F1-score = 0.8483\n",
      "      bSMOTE: AUC = 0.9817, G-Mean = 0.9037, MCC = 0.8162, F1-score = 0.8483\n",
      "      ROS: AUC = 0.9843, G-Mean = 0.8677, MCC = 0.7740, F1-score = 0.8054\n",
      "      MWMOTE: AUC = 0.9702, G-Mean = 0.8971, MCC = 0.7975, F1-score = 0.8331\n",
      "      Trans(Direct): AUC = 0.9843, G-Mean = 0.9312, MCC = 0.8504, F1-score = 0.8816\n",
      "  Fold 6/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.26746, Reg Loss: 0.30661\n",
      "Epoch 200/2000, Avg Loss: 0.22302, Reg Loss: 0.31221\n",
      "Epoch 300/2000, Avg Loss: 0.19325, Reg Loss: 0.31389\n",
      "Epoch 400/2000, Avg Loss: 0.14528, Reg Loss: 0.28294\n",
      "Epoch 500/2000, Avg Loss: 0.15477, Reg Loss: 0.29463\n",
      "Epoch 600/2000, Avg Loss: 0.13454, Reg Loss: 0.29974\n",
      "Epoch 700/2000, Avg Loss: 0.11642, Reg Loss: 0.29214\n",
      "Epoch 800/2000, Avg Loss: 0.12673, Reg Loss: 0.27198\n",
      "Epoch 900/2000, Avg Loss: 0.11653, Reg Loss: 0.29191\n",
      "Epoch 1000/2000, Avg Loss: 0.12830, Reg Loss: 0.28974\n",
      "Epoch 1100/2000, Avg Loss: 0.12193, Reg Loss: 0.29387\n",
      "Epoch 1200/2000, Avg Loss: 0.13923, Reg Loss: 0.28490\n",
      "Epoch 1300/2000, Avg Loss: 0.12783, Reg Loss: 0.29188\n",
      "Epoch 1400/2000, Avg Loss: 0.10252, Reg Loss: 0.26811\n",
      "Epoch 1500/2000, Avg Loss: 0.09177, Reg Loss: 0.27112\n",
      "Epoch 1600/2000, Avg Loss: 0.08049, Reg Loss: 0.25072\n",
      "Epoch 1700/2000, Avg Loss: 0.09797, Reg Loss: 0.27178\n",
      "Epoch 1800/2000, Avg Loss: 0.07356, Reg Loss: 0.26312\n",
      "Epoch 1900/2000, Avg Loss: 0.08776, Reg Loss: 0.26256\n",
      "Epoch 2000/2000, Avg Loss: 0.08820, Reg Loss: 0.27328\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.9069, G-Mean = 0.8632, MCC = 0.7859, F1-score = 0.8269\n",
      "      SMOTEBoost: AUC = 0.9698, G-Mean = 0.9235, MCC = 0.8619, F1-score = 0.8841\n",
      "      RUSBoost: AUC = 0.9616, G-Mean = 0.8768, MCC = 0.7126, F1-score = 0.7712\n",
      "      OUBoost: AUC = 0.9795, G-Mean = 0.9435, MCC = 0.8846, F1-score = 0.9072\n",
      "      SVM: AUC = 0.9904, G-Mean = 0.8806, MCC = 0.8205, F1-score = 0.8493\n",
      "      SMOTE: AUC = 0.9828, G-Mean = 0.9021, MCC = 0.8248, F1-score = 0.8550\n",
      "      ADASYN: AUC = 0.9786, G-Mean = 0.9021, MCC = 0.8248, F1-score = 0.8550\n",
      "      bSMOTE: AUC = 0.9847, G-Mean = 0.9021, MCC = 0.8248, F1-score = 0.8550\n",
      "      ROS: AUC = 0.9869, G-Mean = 0.8722, MCC = 0.7896, F1-score = 0.8193\n",
      "      MWMOTE: AUC = 0.9751, G-Mean = 0.8967, MCC = 0.8092, F1-score = 0.8424\n",
      "      Trans(Direct): AUC = 0.9869, G-Mean = 0.9251, MCC = 0.8533, F1-score = 0.8828\n",
      "  Fold 7/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.22406, Reg Loss: 0.30897\n",
      "Epoch 200/2000, Avg Loss: 0.18672, Reg Loss: 0.28534\n",
      "Epoch 300/2000, Avg Loss: 0.16598, Reg Loss: 0.29200\n",
      "Epoch 400/2000, Avg Loss: 0.14121, Reg Loss: 0.29300\n",
      "Epoch 500/2000, Avg Loss: 0.13613, Reg Loss: 0.28896\n",
      "Epoch 600/2000, Avg Loss: 0.11764, Reg Loss: 0.28838\n",
      "Epoch 700/2000, Avg Loss: 0.12420, Reg Loss: 0.27886\n",
      "Epoch 800/2000, Avg Loss: 0.12001, Reg Loss: 0.27094\n",
      "Epoch 900/2000, Avg Loss: 0.11069, Reg Loss: 0.27529\n",
      "Epoch 1000/2000, Avg Loss: 0.14594, Reg Loss: 0.28899\n",
      "Epoch 1100/2000, Avg Loss: 0.10802, Reg Loss: 0.27798\n",
      "Epoch 1200/2000, Avg Loss: 0.10386, Reg Loss: 0.27670\n",
      "Epoch 1300/2000, Avg Loss: 0.10424, Reg Loss: 0.27331\n",
      "Epoch 1400/2000, Avg Loss: 0.11272, Reg Loss: 0.27121\n",
      "Epoch 1500/2000, Avg Loss: 0.08962, Reg Loss: 0.26197\n",
      "Epoch 1600/2000, Avg Loss: 0.11076, Reg Loss: 0.28476\n",
      "Epoch 1700/2000, Avg Loss: 0.11598, Reg Loss: 0.28366\n",
      "Epoch 1800/2000, Avg Loss: 0.10224, Reg Loss: 0.27194\n",
      "Epoch 1900/2000, Avg Loss: 0.09198, Reg Loss: 0.26603\n",
      "Epoch 2000/2000, Avg Loss: 0.12795, Reg Loss: 0.26031\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.9202, G-Mean = 0.8828, MCC = 0.8165, F1-score = 0.8516\n",
      "      SMOTEBoost: AUC = 0.9741, G-Mean = 0.9344, MCC = 0.8816, F1-score = 0.9006\n",
      "      RUSBoost: AUC = 0.9617, G-Mean = 0.8700, MCC = 0.6946, F1-score = 0.7563\n",
      "      OUBoost: AUC = 0.9824, G-Mean = 0.9515, MCC = 0.9011, F1-score = 0.9205\n",
      "      SVM: AUC = 0.9918, G-Mean = 0.8826, MCC = 0.8273, F1-score = 0.8550\n",
      "      SMOTE: AUC = 0.9852, G-Mean = 0.9161, MCC = 0.8498, F1-score = 0.8757\n",
      "      ADASYN: AUC = 0.9817, G-Mean = 0.9161, MCC = 0.8498, F1-score = 0.8757\n",
      "      bSMOTE: AUC = 0.9869, G-Mean = 0.9161, MCC = 0.8498, F1-score = 0.8757\n",
      "      ROS: AUC = 0.9888, G-Mean = 0.8904, MCC = 0.8197, F1-score = 0.8451\n",
      "      MWMOTE: AUC = 0.9787, G-Mean = 0.9114, MCC = 0.8365, F1-score = 0.8649\n",
      "      Trans(Direct): AUC = 0.9888, G-Mean = 0.9358, MCC = 0.8743, F1-score = 0.8995\n",
      "  Fold 8/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.23713, Reg Loss: 0.30042\n",
      "Epoch 200/2000, Avg Loss: 0.21640, Reg Loss: 0.31539\n",
      "Epoch 300/2000, Avg Loss: 0.17850, Reg Loss: 0.30993\n",
      "Epoch 400/2000, Avg Loss: 0.15689, Reg Loss: 0.30997\n",
      "Epoch 500/2000, Avg Loss: 0.12983, Reg Loss: 0.29876\n",
      "Epoch 600/2000, Avg Loss: 0.13811, Reg Loss: 0.29007\n",
      "Epoch 700/2000, Avg Loss: 0.14551, Reg Loss: 0.28017\n",
      "Epoch 800/2000, Avg Loss: 0.12986, Reg Loss: 0.29982\n",
      "Epoch 900/2000, Avg Loss: 0.10786, Reg Loss: 0.28102\n",
      "Epoch 1000/2000, Avg Loss: 0.10443, Reg Loss: 0.27780\n",
      "Epoch 1100/2000, Avg Loss: 0.12504, Reg Loss: 0.28619\n",
      "Epoch 1200/2000, Avg Loss: 0.14344, Reg Loss: 0.28187\n",
      "Epoch 1300/2000, Avg Loss: 0.10035, Reg Loss: 0.27506\n",
      "Epoch 1400/2000, Avg Loss: 0.10264, Reg Loss: 0.28396\n",
      "Epoch 1500/2000, Avg Loss: 0.08486, Reg Loss: 0.27391\n",
      "Epoch 1600/2000, Avg Loss: 0.08974, Reg Loss: 0.27202\n",
      "Epoch 1700/2000, Avg Loss: 0.08814, Reg Loss: 0.27267\n",
      "Epoch 1800/2000, Avg Loss: 0.11526, Reg Loss: 0.27764\n",
      "Epoch 1900/2000, Avg Loss: 0.09342, Reg Loss: 0.26311\n",
      "Epoch 2000/2000, Avg Loss: 0.09694, Reg Loss: 0.27414\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.9099, G-Mean = 0.8770, MCC = 0.7940, F1-score = 0.8360\n",
      "      SMOTEBoost: AUC = 0.9711, G-Mean = 0.9345, MCC = 0.8702, F1-score = 0.8922\n",
      "      RUSBoost: AUC = 0.9634, G-Mean = 0.8739, MCC = 0.6968, F1-score = 0.7579\n",
      "      OUBoost: AUC = 0.9815, G-Mean = 0.9495, MCC = 0.8873, F1-score = 0.9096\n",
      "      SVM: AUC = 0.9866, G-Mean = 0.8892, MCC = 0.8227, F1-score = 0.8523\n",
      "      SMOTE: AUC = 0.9824, G-Mean = 0.9185, MCC = 0.8424, F1-score = 0.8704\n",
      "      ADASYN: AUC = 0.9761, G-Mean = 0.9185, MCC = 0.8424, F1-score = 0.8704\n",
      "      bSMOTE: AUC = 0.9823, G-Mean = 0.9185, MCC = 0.8424, F1-score = 0.8704\n",
      "      ROS: AUC = 0.9871, G-Mean = 0.8961, MCC = 0.8160, F1-score = 0.8436\n",
      "      MWMOTE: AUC = 0.9735, G-Mean = 0.9144, MCC = 0.8307, F1-score = 0.8610\n",
      "      Trans(Direct): AUC = 0.9840, G-Mean = 0.9358, MCC = 0.8638, F1-score = 0.8913\n",
      "  Fold 9/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.22823, Reg Loss: 0.30005\n",
      "Epoch 200/2000, Avg Loss: 0.19881, Reg Loss: 0.30009\n",
      "Epoch 300/2000, Avg Loss: 0.19294, Reg Loss: 0.29982\n",
      "Epoch 400/2000, Avg Loss: 0.14441, Reg Loss: 0.28440\n",
      "Epoch 500/2000, Avg Loss: 0.15722, Reg Loss: 0.28596\n",
      "Epoch 600/2000, Avg Loss: 0.14133, Reg Loss: 0.28236\n",
      "Epoch 700/2000, Avg Loss: 0.12188, Reg Loss: 0.28551\n",
      "Epoch 800/2000, Avg Loss: 0.13846, Reg Loss: 0.29100\n",
      "Epoch 900/2000, Avg Loss: 0.11379, Reg Loss: 0.28594\n",
      "Epoch 1000/2000, Avg Loss: 0.13270, Reg Loss: 0.26906\n",
      "Epoch 1100/2000, Avg Loss: 0.14607, Reg Loss: 0.28938\n",
      "Epoch 1200/2000, Avg Loss: 0.14358, Reg Loss: 0.28380\n",
      "Epoch 1300/2000, Avg Loss: 0.08360, Reg Loss: 0.26767\n",
      "Epoch 1400/2000, Avg Loss: 0.09986, Reg Loss: 0.27338\n",
      "Epoch 1500/2000, Avg Loss: 0.10923, Reg Loss: 0.27229\n",
      "Epoch 1600/2000, Avg Loss: 0.09546, Reg Loss: 0.26007\n",
      "Epoch 1700/2000, Avg Loss: 0.08523, Reg Loss: 0.26605\n",
      "Epoch 1800/2000, Avg Loss: 0.07674, Reg Loss: 0.26759\n",
      "Epoch 1900/2000, Avg Loss: 0.07106, Reg Loss: 0.25748\n",
      "Epoch 2000/2000, Avg Loss: 0.09084, Reg Loss: 0.27357\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.9199, G-Mean = 0.8907, MCC = 0.8169, F1-score = 0.8543\n",
      "      SMOTEBoost: AUC = 0.9743, G-Mean = 0.9418, MCC = 0.8847, F1-score = 0.9042\n",
      "      RUSBoost: AUC = 0.9675, G-Mean = 0.8807, MCC = 0.7073, F1-score = 0.7663\n",
      "      OUBoost: AUC = 0.9836, G-Mean = 0.9480, MCC = 0.8766, F1-score = 0.9011\n",
      "      SVM: AUC = 0.9881, G-Mean = 0.9015, MCC = 0.8424, F1-score = 0.8687\n",
      "      SMOTE: AUC = 0.9844, G-Mean = 0.9276, MCC = 0.8599, F1-score = 0.8848\n",
      "      ADASYN: AUC = 0.9788, G-Mean = 0.9276, MCC = 0.8599, F1-score = 0.8848\n",
      "      bSMOTE: AUC = 0.9843, G-Mean = 0.9276, MCC = 0.8599, F1-score = 0.8848\n",
      "      ROS: AUC = 0.9885, G-Mean = 0.9076, MCC = 0.8365, F1-score = 0.8610\n",
      "      MWMOTE: AUC = 0.9765, G-Mean = 0.9239, MCC = 0.8495, F1-score = 0.8764\n",
      "      Trans(Direct): AUC = 0.9857, G-Mean = 0.9429, MCC = 0.8789, F1-score = 0.9033\n",
      "  Fold 10/10 - Experiment 4/10\n",
      "Epoch 100/2000, Avg Loss: 0.29791, Reg Loss: 0.33013\n",
      "Epoch 200/2000, Avg Loss: 0.23087, Reg Loss: 0.33013\n",
      "Epoch 300/2000, Avg Loss: 0.18830, Reg Loss: 0.32048\n",
      "Epoch 400/2000, Avg Loss: 0.18551, Reg Loss: 0.33158\n",
      "Epoch 500/2000, Avg Loss: 0.17505, Reg Loss: 0.32599\n",
      "Epoch 600/2000, Avg Loss: 0.16064, Reg Loss: 0.33345\n",
      "Epoch 700/2000, Avg Loss: 0.13932, Reg Loss: 0.31537\n",
      "Epoch 800/2000, Avg Loss: 0.14519, Reg Loss: 0.31311\n",
      "Epoch 900/2000, Avg Loss: 0.11563, Reg Loss: 0.31275\n",
      "Epoch 1000/2000, Avg Loss: 0.13322, Reg Loss: 0.32879\n",
      "Epoch 1100/2000, Avg Loss: 0.11349, Reg Loss: 0.31355\n",
      "Epoch 1200/2000, Avg Loss: 0.10639, Reg Loss: 0.31585\n",
      "Epoch 1300/2000, Avg Loss: 0.14069, Reg Loss: 0.31033\n",
      "Epoch 1400/2000, Avg Loss: 0.12506, Reg Loss: 0.31309\n",
      "Epoch 1500/2000, Avg Loss: 0.10172, Reg Loss: 0.30845\n",
      "Epoch 1600/2000, Avg Loss: 0.11042, Reg Loss: 0.31575\n",
      "Epoch 1700/2000, Avg Loss: 0.08931, Reg Loss: 0.30287\n",
      "Epoch 1800/2000, Avg Loss: 0.10699, Reg Loss: 0.31165\n",
      "Epoch 1900/2000, Avg Loss: 0.09000, Reg Loss: 0.30659\n",
      "Epoch 2000/2000, Avg Loss: 0.07854, Reg Loss: 0.30617\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.9160, G-Mean = 0.8853, MCC = 0.7988, F1-score = 0.8416\n",
      "      SMOTEBoost: AUC = 0.9706, G-Mean = 0.9412, MCC = 0.8752, F1-score = 0.8971\n",
      "      RUSBoost: AUC = 0.9620, G-Mean = 0.8717, MCC = 0.6898, F1-score = 0.7522\n",
      "      OUBoost: AUC = 0.9852, G-Mean = 0.9500, MCC = 0.8773, F1-score = 0.9019\n",
      "      SVM: AUC = 0.9868, G-Mean = 0.9082, MCC = 0.8465, F1-score = 0.8727\n",
      "      SMOTE: AUC = 0.9859, G-Mean = 0.9316, MCC = 0.8623, F1-score = 0.8873\n",
      "      ADASYN: AUC = 0.9809, G-Mean = 0.9316, MCC = 0.8623, F1-score = 0.8873\n",
      "      bSMOTE: AUC = 0.9858, G-Mean = 0.9316, MCC = 0.8623, F1-score = 0.8873\n",
      "      ROS: AUC = 0.9897, G-Mean = 0.9137, MCC = 0.8412, F1-score = 0.8658\n",
      "      MWMOTE: AUC = 0.9788, G-Mean = 0.9284, MCC = 0.8530, F1-score = 0.8797\n",
      "      Trans(Direct): AUC = 0.9872, G-Mean = 0.9454, MCC = 0.8794, F1-score = 0.9039\n",
      "\n",
      "Starting experiment 5/10\n",
      "  Fold 1/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.23600, Reg Loss: 0.30858\n",
      "Epoch 200/2000, Avg Loss: 0.21124, Reg Loss: 0.32980\n",
      "Epoch 300/2000, Avg Loss: 0.18975, Reg Loss: 0.32222\n",
      "Epoch 400/2000, Avg Loss: 0.15359, Reg Loss: 0.32372\n",
      "Epoch 500/2000, Avg Loss: 0.15173, Reg Loss: 0.32666\n",
      "Epoch 600/2000, Avg Loss: 0.14381, Reg Loss: 0.31580\n",
      "Epoch 700/2000, Avg Loss: 0.11605, Reg Loss: 0.31128\n",
      "Epoch 800/2000, Avg Loss: 0.11509, Reg Loss: 0.30531\n",
      "Epoch 900/2000, Avg Loss: 0.11332, Reg Loss: 0.33711\n",
      "Epoch 1000/2000, Avg Loss: 0.10503, Reg Loss: 0.30914\n",
      "Epoch 1100/2000, Avg Loss: 0.10321, Reg Loss: 0.30916\n",
      "Epoch 1200/2000, Avg Loss: 0.10422, Reg Loss: 0.31471\n",
      "Epoch 1300/2000, Avg Loss: 0.09649, Reg Loss: 0.30054\n",
      "Epoch 1400/2000, Avg Loss: 0.09467, Reg Loss: 0.31479\n",
      "Epoch 1500/2000, Avg Loss: 0.09510, Reg Loss: 0.31800\n",
      "Epoch 1600/2000, Avg Loss: 0.10201, Reg Loss: 0.32633\n",
      "Epoch 1700/2000, Avg Loss: 0.09502, Reg Loss: 0.31456\n",
      "Epoch 1800/2000, Avg Loss: 0.09655, Reg Loss: 0.29646\n",
      "Epoch 1900/2000, Avg Loss: 0.09411, Reg Loss: 0.32225\n",
      "Epoch 2000/2000, Avg Loss: 0.08153, Reg Loss: 0.31014\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.8118, G-Mean = 0.8117, MCC = 0.5610, F1-score = 0.6667\n",
      "      SMOTEBoost: AUC = 0.9529, G-Mean = 0.9075, MCC = 0.7174, F1-score = 0.7692\n",
      "      RUSBoost: AUC = 0.9118, G-Mean = 0.8117, MCC = 0.5610, F1-score = 0.6667\n",
      "      OUBoost: AUC = 1.0000, G-Mean = 0.9393, MCC = 0.7939, F1-score = 0.8333\n",
      "      SVM: AUC = 0.9765, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "      SMOTE: AUC = 0.9647, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "      ADASYN: AUC = 0.9647, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "      bSMOTE: AUC = 0.9647, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "      ROS: AUC = 0.9647, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "      MWMOTE: AUC = 0.9529, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      Trans(Direct): AUC = 0.9647, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "  Fold 2/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.23041, Reg Loss: 0.31710\n",
      "Epoch 200/2000, Avg Loss: 0.19039, Reg Loss: 0.31053\n",
      "Epoch 300/2000, Avg Loss: 0.16615, Reg Loss: 0.30557\n",
      "Epoch 400/2000, Avg Loss: 0.13447, Reg Loss: 0.30406\n",
      "Epoch 500/2000, Avg Loss: 0.13894, Reg Loss: 0.29430\n",
      "Epoch 600/2000, Avg Loss: 0.11703, Reg Loss: 0.30200\n",
      "Epoch 700/2000, Avg Loss: 0.11163, Reg Loss: 0.30188\n",
      "Epoch 800/2000, Avg Loss: 0.10312, Reg Loss: 0.28616\n",
      "Epoch 900/2000, Avg Loss: 0.09963, Reg Loss: 0.28717\n",
      "Epoch 1000/2000, Avg Loss: 0.09342, Reg Loss: 0.28363\n",
      "Epoch 1100/2000, Avg Loss: 0.08608, Reg Loss: 0.26926\n",
      "Epoch 1200/2000, Avg Loss: 0.08860, Reg Loss: 0.27560\n",
      "Epoch 1300/2000, Avg Loss: 0.09355, Reg Loss: 0.29360\n",
      "Epoch 1400/2000, Avg Loss: 0.08531, Reg Loss: 0.28154\n",
      "Epoch 1500/2000, Avg Loss: 0.09781, Reg Loss: 0.28460\n",
      "Epoch 1600/2000, Avg Loss: 0.08614, Reg Loss: 0.27185\n",
      "Epoch 1700/2000, Avg Loss: 0.08054, Reg Loss: 0.27442\n",
      "Epoch 1800/2000, Avg Loss: 0.07976, Reg Loss: 0.27232\n",
      "Epoch 1900/2000, Avg Loss: 0.10246, Reg Loss: 0.27566\n",
      "Epoch 2000/2000, Avg Loss: 0.08354, Reg Loss: 0.25912\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.7912, G-Mean = 0.7816, MCC = 0.5745, F1-score = 0.6667\n",
      "      SMOTEBoost: AUC = 0.8941, G-Mean = 0.8175, MCC = 0.5999, F1-score = 0.6846\n",
      "      RUSBoost: AUC = 0.9235, G-Mean = 0.8397, MCC = 0.6511, F1-score = 0.7333\n",
      "      OUBoost: AUC = 0.9529, G-Mean = 0.8898, MCC = 0.7180, F1-score = 0.7803\n",
      "      SVM: AUC = 0.9471, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "      SMOTE: AUC = 0.9588, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "      ADASYN: AUC = 0.9647, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "      bSMOTE: AUC = 0.9647, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "      ROS: AUC = 0.9647, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "      MWMOTE: AUC = 0.9588, G-Mean = 0.9189, MCC = 0.8134, F1-score = 0.8545\n",
      "      Trans(Direct): AUC = 0.9588, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "  Fold 3/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.25249, Reg Loss: 0.31766\n",
      "Epoch 200/2000, Avg Loss: 0.23989, Reg Loss: 0.31497\n",
      "Epoch 300/2000, Avg Loss: 0.19309, Reg Loss: 0.31262\n",
      "Epoch 400/2000, Avg Loss: 0.14837, Reg Loss: 0.31012\n",
      "Epoch 500/2000, Avg Loss: 0.13988, Reg Loss: 0.31466\n",
      "Epoch 600/2000, Avg Loss: 0.11985, Reg Loss: 0.29450\n",
      "Epoch 700/2000, Avg Loss: 0.13413, Reg Loss: 0.30176\n",
      "Epoch 800/2000, Avg Loss: 0.14298, Reg Loss: 0.29237\n",
      "Epoch 900/2000, Avg Loss: 0.13485, Reg Loss: 0.30102\n",
      "Epoch 1000/2000, Avg Loss: 0.11594, Reg Loss: 0.29396\n",
      "Epoch 1100/2000, Avg Loss: 0.13672, Reg Loss: 0.28610\n",
      "Epoch 1200/2000, Avg Loss: 0.15133, Reg Loss: 0.29875\n",
      "Epoch 1300/2000, Avg Loss: 0.11535, Reg Loss: 0.28705\n",
      "Epoch 1400/2000, Avg Loss: 0.09550, Reg Loss: 0.27379\n",
      "Epoch 1500/2000, Avg Loss: 0.12602, Reg Loss: 0.26189\n",
      "Epoch 1600/2000, Avg Loss: 0.10059, Reg Loss: 0.27503\n",
      "Epoch 1700/2000, Avg Loss: 0.11102, Reg Loss: 0.27514\n",
      "Epoch 1800/2000, Avg Loss: 0.09781, Reg Loss: 0.25974\n",
      "Epoch 1900/2000, Avg Loss: 0.09523, Reg Loss: 0.26842\n",
      "Epoch 2000/2000, Avg Loss: 0.09687, Reg Loss: 0.26692\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.8608, G-Mean = 0.8544, MCC = 0.7163, F1-score = 0.7778\n",
      "      SMOTEBoost: AUC = 0.9225, G-Mean = 0.8678, MCC = 0.6987, F1-score = 0.7641\n",
      "      RUSBoost: AUC = 0.9490, G-Mean = 0.8931, MCC = 0.7674, F1-score = 0.8222\n",
      "      OUBoost: AUC = 0.9686, G-Mean = 0.9159, MCC = 0.7775, F1-score = 0.8279\n",
      "      SVM: AUC = 0.9612, G-Mean = 0.8731, MCC = 0.7511, F1-score = 0.8111\n",
      "      SMOTE: AUC = 0.9691, G-Mean = 0.8731, MCC = 0.7511, F1-score = 0.8111\n",
      "      ADASYN: AUC = 0.9730, G-Mean = 0.8731, MCC = 0.7511, F1-score = 0.8111\n",
      "      bSMOTE: AUC = 0.9730, G-Mean = 0.8731, MCC = 0.7511, F1-score = 0.8111\n",
      "      ROS: AUC = 0.9730, G-Mean = 0.8731, MCC = 0.7511, F1-score = 0.8111\n",
      "      MWMOTE: AUC = 0.9691, G-Mean = 0.9072, MCC = 0.7992, F1-score = 0.8475\n",
      "      Trans(Direct): AUC = 0.9691, G-Mean = 0.8731, MCC = 0.7511, F1-score = 0.8111\n",
      "  Fold 4/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.25804, Reg Loss: 0.30282\n",
      "Epoch 200/2000, Avg Loss: 0.19520, Reg Loss: 0.29087\n",
      "Epoch 300/2000, Avg Loss: 0.16837, Reg Loss: 0.30392\n",
      "Epoch 400/2000, Avg Loss: 0.13937, Reg Loss: 0.28778\n",
      "Epoch 500/2000, Avg Loss: 0.11983, Reg Loss: 0.28620\n",
      "Epoch 600/2000, Avg Loss: 0.13380, Reg Loss: 0.28718\n",
      "Epoch 700/2000, Avg Loss: 0.14475, Reg Loss: 0.28883\n",
      "Epoch 800/2000, Avg Loss: 0.12366, Reg Loss: 0.28599\n",
      "Epoch 900/2000, Avg Loss: 0.10140, Reg Loss: 0.26974\n",
      "Epoch 1000/2000, Avg Loss: 0.11073, Reg Loss: 0.27302\n",
      "Epoch 1100/2000, Avg Loss: 0.12140, Reg Loss: 0.28662\n",
      "Epoch 1200/2000, Avg Loss: 0.09421, Reg Loss: 0.26915\n",
      "Epoch 1300/2000, Avg Loss: 0.10432, Reg Loss: 0.25922\n",
      "Epoch 1400/2000, Avg Loss: 0.08448, Reg Loss: 0.25878\n",
      "Epoch 1500/2000, Avg Loss: 0.09283, Reg Loss: 0.25314\n",
      "Epoch 1600/2000, Avg Loss: 0.11196, Reg Loss: 0.25556\n",
      "Epoch 1700/2000, Avg Loss: 0.09189, Reg Loss: 0.26850\n",
      "Epoch 1800/2000, Avg Loss: 0.10192, Reg Loss: 0.25024\n",
      "Epoch 1900/2000, Avg Loss: 0.09063, Reg Loss: 0.25225\n",
      "Epoch 2000/2000, Avg Loss: 0.09481, Reg Loss: 0.25191\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.8706, G-Mean = 0.8644, MCC = 0.7542, F1-score = 0.8056\n",
      "      SMOTEBoost: AUC = 0.9419, G-Mean = 0.9008, MCC = 0.7741, F1-score = 0.8231\n",
      "      RUSBoost: AUC = 0.9618, G-Mean = 0.8574, MCC = 0.6966, F1-score = 0.7637\n",
      "      OUBoost: AUC = 0.9765, G-Mean = 0.9369, MCC = 0.8331, F1-score = 0.8709\n",
      "      SVM: AUC = 0.9709, G-Mean = 0.8784, MCC = 0.7802, F1-score = 0.8306\n",
      "      SMOTE: AUC = 0.9768, G-Mean = 0.9048, MCC = 0.8133, F1-score = 0.8583\n",
      "      ADASYN: AUC = 0.9797, G-Mean = 0.9048, MCC = 0.8133, F1-score = 0.8583\n",
      "      bSMOTE: AUC = 0.9797, G-Mean = 0.9048, MCC = 0.8133, F1-score = 0.8583\n",
      "      ROS: AUC = 0.9797, G-Mean = 0.9048, MCC = 0.8133, F1-score = 0.8583\n",
      "      MWMOTE: AUC = 0.9768, G-Mean = 0.9304, MCC = 0.8494, F1-score = 0.8856\n",
      "      Trans(Direct): AUC = 0.9768, G-Mean = 0.9048, MCC = 0.8133, F1-score = 0.8583\n",
      "  Fold 5/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.23005, Reg Loss: 0.29524\n",
      "Epoch 200/2000, Avg Loss: 0.19615, Reg Loss: 0.30378\n",
      "Epoch 300/2000, Avg Loss: 0.17074, Reg Loss: 0.29620\n",
      "Epoch 400/2000, Avg Loss: 0.14378, Reg Loss: 0.27662\n",
      "Epoch 500/2000, Avg Loss: 0.13238, Reg Loss: 0.27933\n",
      "Epoch 600/2000, Avg Loss: 0.12390, Reg Loss: 0.28414\n",
      "Epoch 700/2000, Avg Loss: 0.10155, Reg Loss: 0.27570\n",
      "Epoch 800/2000, Avg Loss: 0.11016, Reg Loss: 0.26197\n",
      "Epoch 900/2000, Avg Loss: 0.11656, Reg Loss: 0.27063\n",
      "Epoch 1000/2000, Avg Loss: 0.09719, Reg Loss: 0.26294\n",
      "Epoch 1100/2000, Avg Loss: 0.11572, Reg Loss: 0.26772\n",
      "Epoch 1200/2000, Avg Loss: 0.09958, Reg Loss: 0.25448\n",
      "Epoch 1300/2000, Avg Loss: 0.11354, Reg Loss: 0.27044\n",
      "Epoch 1400/2000, Avg Loss: 0.10335, Reg Loss: 0.27696\n",
      "Epoch 1500/2000, Avg Loss: 0.09236, Reg Loss: 0.27077\n",
      "Epoch 1600/2000, Avg Loss: 0.08380, Reg Loss: 0.25899\n",
      "Epoch 1700/2000, Avg Loss: 0.11055, Reg Loss: 0.25645\n",
      "Epoch 1800/2000, Avg Loss: 0.09573, Reg Loss: 0.25618\n",
      "Epoch 1900/2000, Avg Loss: 0.10239, Reg Loss: 0.26522\n",
      "Epoch 2000/2000, Avg Loss: 0.13405, Reg Loss: 0.25215\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.8940, G-Mean = 0.8852, MCC = 0.7801, F1-score = 0.8263\n",
      "      SMOTEBoost: AUC = 0.9535, G-Mean = 0.9207, MCC = 0.8192, F1-score = 0.8585\n",
      "      RUSBoost: AUC = 0.9694, G-Mean = 0.8517, MCC = 0.6745, F1-score = 0.7443\n",
      "      OUBoost: AUC = 0.9812, G-Mean = 0.9496, MCC = 0.8665, F1-score = 0.8967\n",
      "      SVM: AUC = 0.9692, G-Mean = 0.8760, MCC = 0.7717, F1-score = 0.8244\n",
      "      SMOTE: AUC = 0.9764, G-Mean = 0.9175, MCC = 0.8274, F1-score = 0.8685\n",
      "      ADASYN: AUC = 0.9813, G-Mean = 0.9175, MCC = 0.8274, F1-score = 0.8685\n",
      "      bSMOTE: AUC = 0.9813, G-Mean = 0.9175, MCC = 0.8274, F1-score = 0.8685\n",
      "      ROS: AUC = 0.9763, G-Mean = 0.9175, MCC = 0.8274, F1-score = 0.8685\n",
      "      MWMOTE: AUC = 0.9789, G-Mean = 0.9380, MCC = 0.8563, F1-score = 0.8903\n",
      "      Trans(Direct): AUC = 0.9739, G-Mean = 0.9175, MCC = 0.8274, F1-score = 0.8685\n",
      "  Fold 6/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.24763, Reg Loss: 0.29735\n",
      "Epoch 200/2000, Avg Loss: 0.20406, Reg Loss: 0.28636\n",
      "Epoch 300/2000, Avg Loss: 0.18172, Reg Loss: 0.29057\n",
      "Epoch 400/2000, Avg Loss: 0.17499, Reg Loss: 0.28554\n",
      "Epoch 500/2000, Avg Loss: 0.16031, Reg Loss: 0.28870\n",
      "Epoch 600/2000, Avg Loss: 0.15447, Reg Loss: 0.27335\n",
      "Epoch 700/2000, Avg Loss: 0.16299, Reg Loss: 0.28803\n",
      "Epoch 800/2000, Avg Loss: 0.14083, Reg Loss: 0.27816\n",
      "Epoch 900/2000, Avg Loss: 0.12334, Reg Loss: 0.25488\n",
      "Epoch 1000/2000, Avg Loss: 0.11142, Reg Loss: 0.26194\n",
      "Epoch 1100/2000, Avg Loss: 0.12634, Reg Loss: 0.26739\n",
      "Epoch 1200/2000, Avg Loss: 0.10085, Reg Loss: 0.26246\n",
      "Epoch 1300/2000, Avg Loss: 0.10245, Reg Loss: 0.26612\n",
      "Epoch 1400/2000, Avg Loss: 0.10881, Reg Loss: 0.25682\n",
      "Epoch 1500/2000, Avg Loss: 0.11482, Reg Loss: 0.25326\n",
      "Epoch 1600/2000, Avg Loss: 0.09508, Reg Loss: 0.25493\n",
      "Epoch 1700/2000, Avg Loss: 0.08293, Reg Loss: 0.25779\n",
      "Epoch 1800/2000, Avg Loss: 0.09280, Reg Loss: 0.25016\n",
      "Epoch 1900/2000, Avg Loss: 0.10227, Reg Loss: 0.25319\n",
      "Epoch 2000/2000, Avg Loss: 0.08168, Reg Loss: 0.24416\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.9116, G-Mean = 0.9043, MCC = 0.8168, F1-score = 0.8552\n",
      "      SMOTEBoost: AUC = 0.9612, G-Mean = 0.9339, MCC = 0.8494, F1-score = 0.8821\n",
      "      RUSBoost: AUC = 0.9724, G-Mean = 0.8541, MCC = 0.6697, F1-score = 0.7393\n",
      "      OUBoost: AUC = 0.9843, G-Mean = 0.9580, MCC = 0.8887, F1-score = 0.9139\n",
      "      SVM: AUC = 0.9723, G-Mean = 0.8790, MCC = 0.7877, F1-score = 0.8352\n",
      "      SMOTE: AUC = 0.9783, G-Mean = 0.9089, MCC = 0.8124, F1-score = 0.8571\n",
      "      ADASYN: AUC = 0.9823, G-Mean = 0.9260, MCC = 0.8368, F1-score = 0.8753\n",
      "      bSMOTE: AUC = 0.9823, G-Mean = 0.9260, MCC = 0.8368, F1-score = 0.8753\n",
      "      ROS: AUC = 0.9802, G-Mean = 0.9260, MCC = 0.8368, F1-score = 0.8753\n",
      "      MWMOTE: AUC = 0.9783, G-Mean = 0.9260, MCC = 0.8365, F1-score = 0.8753\n",
      "      Trans(Direct): AUC = 0.9762, G-Mean = 0.9260, MCC = 0.8368, F1-score = 0.8753\n",
      "  Fold 7/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.21132, Reg Loss: 0.28849\n",
      "Epoch 200/2000, Avg Loss: 0.20639, Reg Loss: 0.28961\n",
      "Epoch 300/2000, Avg Loss: 0.15357, Reg Loss: 0.29045\n",
      "Epoch 400/2000, Avg Loss: 0.14424, Reg Loss: 0.28495\n",
      "Epoch 500/2000, Avg Loss: 0.13208, Reg Loss: 0.27874\n",
      "Epoch 600/2000, Avg Loss: 0.13152, Reg Loss: 0.28629\n",
      "Epoch 700/2000, Avg Loss: 0.12848, Reg Loss: 0.28066\n",
      "Epoch 800/2000, Avg Loss: 0.11811, Reg Loss: 0.28691\n",
      "Epoch 900/2000, Avg Loss: 0.10698, Reg Loss: 0.28090\n",
      "Epoch 1000/2000, Avg Loss: 0.10761, Reg Loss: 0.28592\n",
      "Epoch 1100/2000, Avg Loss: 0.08751, Reg Loss: 0.26004\n",
      "Epoch 1200/2000, Avg Loss: 0.13331, Reg Loss: 0.26379\n",
      "Epoch 1300/2000, Avg Loss: 0.10777, Reg Loss: 0.25104\n",
      "Epoch 1400/2000, Avg Loss: 0.11093, Reg Loss: 0.26036\n",
      "Epoch 1500/2000, Avg Loss: 0.11943, Reg Loss: 0.26644\n",
      "Epoch 1600/2000, Avg Loss: 0.10262, Reg Loss: 0.26654\n",
      "Epoch 1700/2000, Avg Loss: 0.07733, Reg Loss: 0.27080\n",
      "Epoch 1800/2000, Avg Loss: 0.09041, Reg Loss: 0.26456\n",
      "Epoch 1900/2000, Avg Loss: 0.09079, Reg Loss: 0.25943\n",
      "Epoch 2000/2000, Avg Loss: 0.08054, Reg Loss: 0.26228\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.9153, G-Mean = 0.9087, MCC = 0.8130, F1-score = 0.8521\n",
      "      SMOTEBoost: AUC = 0.9632, G-Mean = 0.9341, MCC = 0.8410, F1-score = 0.8751\n",
      "      RUSBoost: AUC = 0.9710, G-Mean = 0.8450, MCC = 0.6502, F1-score = 0.7230\n",
      "      OUBoost: AUC = 0.9848, G-Mean = 0.9547, MCC = 0.8747, F1-score = 0.9024\n",
      "      SVM: AUC = 0.9762, G-Mean = 0.8918, MCC = 0.8014, F1-score = 0.8457\n",
      "      SMOTE: AUC = 0.9814, G-Mean = 0.9174, MCC = 0.8226, F1-score = 0.8645\n",
      "      ADASYN: AUC = 0.9831, G-Mean = 0.9320, MCC = 0.8435, F1-score = 0.8801\n",
      "      bSMOTE: AUC = 0.9831, G-Mean = 0.9320, MCC = 0.8435, F1-score = 0.8801\n",
      "      ROS: AUC = 0.9831, G-Mean = 0.9320, MCC = 0.8435, F1-score = 0.8801\n",
      "      MWMOTE: AUC = 0.9725, G-Mean = 0.9320, MCC = 0.8433, F1-score = 0.8801\n",
      "      Trans(Direct): AUC = 0.9796, G-Mean = 0.9320, MCC = 0.8435, F1-score = 0.8801\n",
      "  Fold 8/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.23880, Reg Loss: 0.29460\n",
      "Epoch 200/2000, Avg Loss: 0.19813, Reg Loss: 0.28954\n",
      "Epoch 300/2000, Avg Loss: 0.15138, Reg Loss: 0.27028\n",
      "Epoch 400/2000, Avg Loss: 0.13755, Reg Loss: 0.27309\n",
      "Epoch 500/2000, Avg Loss: 0.11629, Reg Loss: 0.26606\n",
      "Epoch 600/2000, Avg Loss: 0.13402, Reg Loss: 0.26491\n",
      "Epoch 700/2000, Avg Loss: 0.11654, Reg Loss: 0.27388\n",
      "Epoch 800/2000, Avg Loss: 0.09597, Reg Loss: 0.27086\n",
      "Epoch 900/2000, Avg Loss: 0.11078, Reg Loss: 0.25540\n",
      "Epoch 1000/2000, Avg Loss: 0.09264, Reg Loss: 0.25658\n",
      "Epoch 1100/2000, Avg Loss: 0.10574, Reg Loss: 0.26276\n",
      "Epoch 1200/2000, Avg Loss: 0.09988, Reg Loss: 0.26206\n",
      "Epoch 1300/2000, Avg Loss: 0.10878, Reg Loss: 0.25942\n",
      "Epoch 1400/2000, Avg Loss: 0.10395, Reg Loss: 0.26034\n",
      "Epoch 1500/2000, Avg Loss: 0.09608, Reg Loss: 0.24361\n",
      "Epoch 1600/2000, Avg Loss: 0.10148, Reg Loss: 0.24778\n",
      "Epoch 1700/2000, Avg Loss: 0.09480, Reg Loss: 0.24537\n",
      "Epoch 1800/2000, Avg Loss: 0.08614, Reg Loss: 0.25413\n",
      "Epoch 1900/2000, Avg Loss: 0.10133, Reg Loss: 0.25975\n",
      "Epoch 2000/2000, Avg Loss: 0.09264, Reg Loss: 0.24386\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.9259, G-Mean = 0.9202, MCC = 0.8364, F1-score = 0.8706\n",
      "      SMOTEBoost: AUC = 0.9678, G-Mean = 0.9423, MCC = 0.8608, F1-score = 0.8907\n",
      "      RUSBoost: AUC = 0.9746, G-Mean = 0.8563, MCC = 0.6677, F1-score = 0.7368\n",
      "      OUBoost: AUC = 0.9867, G-Mean = 0.9604, MCC = 0.8904, F1-score = 0.9146\n",
      "      SVM: AUC = 0.9792, G-Mean = 0.9053, MCC = 0.8263, F1-score = 0.8650\n",
      "      SMOTE: AUC = 0.9837, G-Mean = 0.9277, MCC = 0.8448, F1-score = 0.8814\n",
      "      ADASYN: AUC = 0.9852, G-Mean = 0.9405, MCC = 0.8631, F1-score = 0.8951\n",
      "      bSMOTE: AUC = 0.9852, G-Mean = 0.9405, MCC = 0.8631, F1-score = 0.8951\n",
      "      ROS: AUC = 0.9852, G-Mean = 0.9405, MCC = 0.8631, F1-score = 0.8951\n",
      "      MWMOTE: AUC = 0.9759, G-Mean = 0.9405, MCC = 0.8629, F1-score = 0.8951\n",
      "      Trans(Direct): AUC = 0.9822, G-Mean = 0.9405, MCC = 0.8631, F1-score = 0.8951\n",
      "  Fold 9/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.26494, Reg Loss: 0.32612\n",
      "Epoch 200/2000, Avg Loss: 0.23604, Reg Loss: 0.32348\n",
      "Epoch 300/2000, Avg Loss: 0.18246, Reg Loss: 0.31881\n",
      "Epoch 400/2000, Avg Loss: 0.16737, Reg Loss: 0.30819\n",
      "Epoch 500/2000, Avg Loss: 0.15054, Reg Loss: 0.31605\n",
      "Epoch 600/2000, Avg Loss: 0.12377, Reg Loss: 0.30819\n",
      "Epoch 700/2000, Avg Loss: 0.14569, Reg Loss: 0.31411\n",
      "Epoch 800/2000, Avg Loss: 0.09674, Reg Loss: 0.31227\n",
      "Epoch 900/2000, Avg Loss: 0.12872, Reg Loss: 0.30250\n",
      "Epoch 1000/2000, Avg Loss: 0.13145, Reg Loss: 0.30603\n",
      "Epoch 1100/2000, Avg Loss: 0.14396, Reg Loss: 0.31377\n",
      "Epoch 1200/2000, Avg Loss: 0.09563, Reg Loss: 0.29148\n",
      "Epoch 1300/2000, Avg Loss: 0.14657, Reg Loss: 0.30344\n",
      "Epoch 1400/2000, Avg Loss: 0.11291, Reg Loss: 0.28895\n",
      "Epoch 1500/2000, Avg Loss: 0.11340, Reg Loss: 0.29003\n",
      "Epoch 1600/2000, Avg Loss: 0.09993, Reg Loss: 0.28353\n",
      "Epoch 1700/2000, Avg Loss: 0.09161, Reg Loss: 0.26911\n",
      "Epoch 1800/2000, Avg Loss: 0.11025, Reg Loss: 0.28290\n",
      "Epoch 1900/2000, Avg Loss: 0.09613, Reg Loss: 0.27975\n",
      "Epoch 2000/2000, Avg Loss: 0.09331, Reg Loss: 0.28322\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.9342, G-Mean = 0.9040, MCC = 0.8246, F1-score = 0.8572\n",
      "      SMOTEBoost: AUC = 0.9658, G-Mean = 0.9452, MCC = 0.8634, F1-score = 0.8927\n",
      "      RUSBoost: AUC = 0.9712, G-Mean = 0.8574, MCC = 0.6652, F1-score = 0.7343\n",
      "      OUBoost: AUC = 0.9840, G-Mean = 0.9613, MCC = 0.8896, F1-score = 0.9140\n",
      "      SVM: AUC = 0.9815, G-Mean = 0.9158, MCC = 0.8456, F1-score = 0.8800\n",
      "      SMOTE: AUC = 0.9855, G-Mean = 0.9358, MCC = 0.8621, F1-score = 0.8946\n",
      "      ADASYN: AUC = 0.9868, G-Mean = 0.9471, MCC = 0.8783, F1-score = 0.9067\n",
      "      bSMOTE: AUC = 0.9868, G-Mean = 0.9471, MCC = 0.8783, F1-score = 0.9067\n",
      "      ROS: AUC = 0.9868, G-Mean = 0.9471, MCC = 0.8783, F1-score = 0.9067\n",
      "      MWMOTE: AUC = 0.9786, G-Mean = 0.9471, MCC = 0.8781, F1-score = 0.9067\n",
      "      Trans(Direct): AUC = 0.9841, G-Mean = 0.9471, MCC = 0.8783, F1-score = 0.9067\n",
      "  Fold 10/10 - Experiment 5/10\n",
      "Epoch 100/2000, Avg Loss: 0.20393, Reg Loss: 0.31296\n",
      "Epoch 200/2000, Avg Loss: 0.16140, Reg Loss: 0.30278\n",
      "Epoch 300/2000, Avg Loss: 0.16574, Reg Loss: 0.29503\n",
      "Epoch 400/2000, Avg Loss: 0.14489, Reg Loss: 0.29940\n",
      "Epoch 500/2000, Avg Loss: 0.12567, Reg Loss: 0.28770\n",
      "Epoch 600/2000, Avg Loss: 0.11568, Reg Loss: 0.28714\n",
      "Epoch 700/2000, Avg Loss: 0.09808, Reg Loss: 0.28337\n",
      "Epoch 800/2000, Avg Loss: 0.09603, Reg Loss: 0.27267\n",
      "Epoch 900/2000, Avg Loss: 0.10347, Reg Loss: 0.27532\n",
      "Epoch 1000/2000, Avg Loss: 0.09647, Reg Loss: 0.25610\n",
      "Epoch 1100/2000, Avg Loss: 0.07803, Reg Loss: 0.26494\n",
      "Epoch 1200/2000, Avg Loss: 0.09084, Reg Loss: 0.25826\n",
      "Epoch 1300/2000, Avg Loss: 0.11118, Reg Loss: 0.27228\n",
      "Epoch 1400/2000, Avg Loss: 0.12839, Reg Loss: 0.28879\n",
      "Epoch 1500/2000, Avg Loss: 0.13346, Reg Loss: 0.28100\n",
      "Epoch 1600/2000, Avg Loss: 0.09039, Reg Loss: 0.28455\n",
      "Epoch 1700/2000, Avg Loss: 0.10531, Reg Loss: 0.27993\n",
      "Epoch 1800/2000, Avg Loss: 0.09443, Reg Loss: 0.26541\n",
      "Epoch 1900/2000, Avg Loss: 0.09980, Reg Loss: 0.25599\n",
      "Epoch 2000/2000, Avg Loss: 0.10079, Reg Loss: 0.26772\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.9276, G-Mean = 0.9002, MCC = 0.8159, F1-score = 0.8515\n",
      "      SMOTEBoost: AUC = 0.9692, G-Mean = 0.9475, MCC = 0.8655, F1-score = 0.8944\n",
      "      RUSBoost: AUC = 0.9735, G-Mean = 0.8685, MCC = 0.6871, F1-score = 0.7518\n",
      "      OUBoost: AUC = 0.9843, G-Mean = 0.9620, MCC = 0.8891, F1-score = 0.9135\n",
      "      SVM: AUC = 0.9809, G-Mean = 0.9211, MCC = 0.8494, F1-score = 0.8829\n",
      "      SMOTE: AUC = 0.9845, G-Mean = 0.9390, MCC = 0.8642, F1-score = 0.8961\n",
      "      ADASYN: AUC = 0.9856, G-Mean = 0.9492, MCC = 0.8789, F1-score = 0.9070\n",
      "      bSMOTE: AUC = 0.9856, G-Mean = 0.9492, MCC = 0.8789, F1-score = 0.9070\n",
      "      ROS: AUC = 0.9856, G-Mean = 0.9492, MCC = 0.8789, F1-score = 0.9070\n",
      "      MWMOTE: AUC = 0.9745, G-Mean = 0.9493, MCC = 0.8787, F1-score = 0.9070\n",
      "      Trans(Direct): AUC = 0.9832, G-Mean = 0.9492, MCC = 0.8789, F1-score = 0.9070\n",
      "\n",
      "Starting experiment 6/10\n",
      "  Fold 1/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.23900, Reg Loss: 0.30061\n",
      "Epoch 200/2000, Avg Loss: 0.22157, Reg Loss: 0.30546\n",
      "Epoch 300/2000, Avg Loss: 0.16860, Reg Loss: 0.28753\n",
      "Epoch 400/2000, Avg Loss: 0.13793, Reg Loss: 0.27798\n",
      "Epoch 500/2000, Avg Loss: 0.13442, Reg Loss: 0.27526\n",
      "Epoch 600/2000, Avg Loss: 0.11788, Reg Loss: 0.27638\n",
      "Epoch 700/2000, Avg Loss: 0.10973, Reg Loss: 0.27253\n",
      "Epoch 800/2000, Avg Loss: 0.13400, Reg Loss: 0.28652\n",
      "Epoch 900/2000, Avg Loss: 0.10357, Reg Loss: 0.27887\n",
      "Epoch 1000/2000, Avg Loss: 0.12391, Reg Loss: 0.27846\n",
      "Epoch 1100/2000, Avg Loss: 0.11271, Reg Loss: 0.27262\n",
      "Epoch 1200/2000, Avg Loss: 0.11525, Reg Loss: 0.26076\n",
      "Epoch 1300/2000, Avg Loss: 0.11512, Reg Loss: 0.26994\n",
      "Epoch 1400/2000, Avg Loss: 0.10322, Reg Loss: 0.27608\n",
      "Epoch 1500/2000, Avg Loss: 0.07458, Reg Loss: 0.25558\n",
      "Epoch 1600/2000, Avg Loss: 0.08151, Reg Loss: 0.25816\n",
      "Epoch 1700/2000, Avg Loss: 0.08931, Reg Loss: 0.25078\n",
      "Epoch 1800/2000, Avg Loss: 0.12693, Reg Loss: 0.26388\n",
      "Epoch 1900/2000, Avg Loss: 0.09508, Reg Loss: 0.25186\n",
      "Epoch 2000/2000, Avg Loss: 0.08206, Reg Loss: 0.25492\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      SMOTEBoost: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      RUSBoost: AUC = 1.0000, G-Mean = 0.9075, MCC = 0.7174, F1-score = 0.7692\n",
      "      OUBoost: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      SVM: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      SMOTE: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      ADASYN: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      bSMOTE: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      ROS: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      MWMOTE: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      Trans(Direct): AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "  Fold 2/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.26676, Reg Loss: 0.31899\n",
      "Epoch 200/2000, Avg Loss: 0.19444, Reg Loss: 0.30831\n",
      "Epoch 300/2000, Avg Loss: 0.16831, Reg Loss: 0.28869\n",
      "Epoch 400/2000, Avg Loss: 0.15851, Reg Loss: 0.30385\n",
      "Epoch 500/2000, Avg Loss: 0.13408, Reg Loss: 0.29119\n",
      "Epoch 600/2000, Avg Loss: 0.12886, Reg Loss: 0.29396\n",
      "Epoch 700/2000, Avg Loss: 0.12614, Reg Loss: 0.29184\n",
      "Epoch 800/2000, Avg Loss: 0.10291, Reg Loss: 0.29165\n",
      "Epoch 900/2000, Avg Loss: 0.10712, Reg Loss: 0.29206\n",
      "Epoch 1000/2000, Avg Loss: 0.09789, Reg Loss: 0.28462\n",
      "Epoch 1100/2000, Avg Loss: 0.09329, Reg Loss: 0.27268\n",
      "Epoch 1200/2000, Avg Loss: 0.08875, Reg Loss: 0.26981\n",
      "Epoch 1300/2000, Avg Loss: 0.09483, Reg Loss: 0.27423\n",
      "Epoch 1400/2000, Avg Loss: 0.07346, Reg Loss: 0.26888\n",
      "Epoch 1500/2000, Avg Loss: 0.08487, Reg Loss: 0.26320\n",
      "Epoch 1600/2000, Avg Loss: 0.07837, Reg Loss: 0.26490\n",
      "Epoch 1700/2000, Avg Loss: 0.08452, Reg Loss: 0.25451\n",
      "Epoch 1800/2000, Avg Loss: 0.09709, Reg Loss: 0.27544\n",
      "Epoch 1900/2000, Avg Loss: 0.08455, Reg Loss: 0.26457\n",
      "Epoch 2000/2000, Avg Loss: 0.08719, Reg Loss: 0.26603\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.9000, G-Mean = 0.8873, MCC = 0.8663, F1-score = 0.8750\n",
      "      SMOTEBoost: AUC = 0.9176, G-Mean = 0.8873, MCC = 0.8663, F1-score = 0.8750\n",
      "      RUSBoost: AUC = 0.9471, G-Mean = 0.8876, MCC = 0.7293, F1-score = 0.7846\n",
      "      OUBoost: AUC = 0.9353, G-Mean = 0.8873, MCC = 0.8663, F1-score = 0.8750\n",
      "      SVM: AUC = 0.9941, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      SMOTE: AUC = 0.9941, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      ADASYN: AUC = 0.9941, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      bSMOTE: AUC = 0.9941, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      ROS: AUC = 0.9941, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      MWMOTE: AUC = 1.0000, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      Trans(Direct): AUC = 1.0000, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "  Fold 3/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.31850, Reg Loss: 0.31036\n",
      "Epoch 200/2000, Avg Loss: 0.26411, Reg Loss: 0.33580\n",
      "Epoch 300/2000, Avg Loss: 0.22416, Reg Loss: 0.31052\n",
      "Epoch 400/2000, Avg Loss: 0.21322, Reg Loss: 0.31623\n",
      "Epoch 500/2000, Avg Loss: 0.19010, Reg Loss: 0.31214\n",
      "Epoch 600/2000, Avg Loss: 0.14927, Reg Loss: 0.29672\n",
      "Epoch 700/2000, Avg Loss: 0.14921, Reg Loss: 0.29672\n",
      "Epoch 800/2000, Avg Loss: 0.16093, Reg Loss: 0.30549\n",
      "Epoch 900/2000, Avg Loss: 0.14660, Reg Loss: 0.30019\n",
      "Epoch 1000/2000, Avg Loss: 0.10951, Reg Loss: 0.30108\n",
      "Epoch 1100/2000, Avg Loss: 0.12117, Reg Loss: 0.29277\n",
      "Epoch 1200/2000, Avg Loss: 0.12161, Reg Loss: 0.29670\n",
      "Epoch 1300/2000, Avg Loss: 0.10816, Reg Loss: 0.26806\n",
      "Epoch 1400/2000, Avg Loss: 0.10474, Reg Loss: 0.27926\n",
      "Epoch 1500/2000, Avg Loss: 0.09400, Reg Loss: 0.28061\n",
      "Epoch 1600/2000, Avg Loss: 0.09009, Reg Loss: 0.27942\n",
      "Epoch 1700/2000, Avg Loss: 0.11465, Reg Loss: 0.28174\n",
      "Epoch 1800/2000, Avg Loss: 0.09723, Reg Loss: 0.27846\n",
      "Epoch 1900/2000, Avg Loss: 0.09702, Reg Loss: 0.28747\n",
      "Epoch 2000/2000, Avg Loss: 0.09053, Reg Loss: 0.27982\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.9229, G-Mean = 0.9143, MCC = 0.8764, F1-score = 0.8910\n",
      "      SMOTEBoost: AUC = 0.9451, G-Mean = 0.9143, MCC = 0.8764, F1-score = 0.8910\n",
      "      RUSBoost: AUC = 0.8710, G-Mean = 0.8417, MCC = 0.6560, F1-score = 0.7336\n",
      "      OUBoost: AUC = 0.9569, G-Mean = 0.9143, MCC = 0.8764, F1-score = 0.8910\n",
      "      SVM: AUC = 0.9891, G-Mean = 0.9542, MCC = 0.9219, F1-score = 0.9373\n",
      "      SMOTE: AUC = 0.9857, G-Mean = 0.9433, MCC = 0.8931, F1-score = 0.9153\n",
      "      ADASYN: AUC = 0.9752, G-Mean = 0.9433, MCC = 0.8931, F1-score = 0.9153\n",
      "      bSMOTE: AUC = 0.9857, G-Mean = 0.9433, MCC = 0.8931, F1-score = 0.9153\n",
      "      ROS: AUC = 0.9857, G-Mean = 0.9433, MCC = 0.8931, F1-score = 0.9153\n",
      "      MWMOTE: AUC = 0.9792, G-Mean = 0.9433, MCC = 0.8931, F1-score = 0.9153\n",
      "      Trans(Direct): AUC = 0.9896, G-Mean = 0.9433, MCC = 0.8931, F1-score = 0.9153\n",
      "  Fold 4/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.25878, Reg Loss: 0.31994\n",
      "Epoch 200/2000, Avg Loss: 0.20770, Reg Loss: 0.30729\n",
      "Epoch 300/2000, Avg Loss: 0.18384, Reg Loss: 0.31197\n",
      "Epoch 400/2000, Avg Loss: 0.15949, Reg Loss: 0.29624\n",
      "Epoch 500/2000, Avg Loss: 0.15888, Reg Loss: 0.28790\n",
      "Epoch 600/2000, Avg Loss: 0.11920, Reg Loss: 0.29927\n",
      "Epoch 700/2000, Avg Loss: 0.15796, Reg Loss: 0.27967\n",
      "Epoch 800/2000, Avg Loss: 0.10577, Reg Loss: 0.28069\n",
      "Epoch 900/2000, Avg Loss: 0.11012, Reg Loss: 0.27863\n",
      "Epoch 1000/2000, Avg Loss: 0.10126, Reg Loss: 0.28623\n",
      "Epoch 1100/2000, Avg Loss: 0.10040, Reg Loss: 0.27216\n",
      "Epoch 1200/2000, Avg Loss: 0.09537, Reg Loss: 0.27012\n",
      "Epoch 1300/2000, Avg Loss: 0.08830, Reg Loss: 0.26722\n",
      "Epoch 1400/2000, Avg Loss: 0.11313, Reg Loss: 0.29388\n",
      "Epoch 1500/2000, Avg Loss: 0.10623, Reg Loss: 0.27480\n",
      "Epoch 1600/2000, Avg Loss: 0.11743, Reg Loss: 0.27052\n",
      "Epoch 1700/2000, Avg Loss: 0.10317, Reg Loss: 0.26654\n",
      "Epoch 1800/2000, Avg Loss: 0.10222, Reg Loss: 0.27087\n",
      "Epoch 1900/2000, Avg Loss: 0.09550, Reg Loss: 0.25479\n",
      "Epoch 2000/2000, Avg Loss: 0.07886, Reg Loss: 0.27059\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.8844, G-Mean = 0.8732, MCC = 0.8030, F1-score = 0.8349\n",
      "      SMOTEBoost: AUC = 0.9588, G-Mean = 0.9357, MCC = 0.9073, F1-score = 0.9183\n",
      "      RUSBoost: AUC = 0.8876, G-Mean = 0.8188, MCC = 0.6131, F1-score = 0.6973\n",
      "      OUBoost: AUC = 0.9676, G-Mean = 0.9357, MCC = 0.9073, F1-score = 0.9183\n",
      "      SVM: AUC = 0.9856, G-Mean = 0.9032, MCC = 0.8372, F1-score = 0.8697\n",
      "      SMOTE: AUC = 0.9830, G-Mean = 0.9240, MCC = 0.8542, F1-score = 0.8865\n",
      "      ADASYN: AUC = 0.9752, G-Mean = 0.9240, MCC = 0.8542, F1-score = 0.8865\n",
      "      bSMOTE: AUC = 0.9830, G-Mean = 0.9240, MCC = 0.8542, F1-score = 0.8865\n",
      "      ROS: AUC = 0.9830, G-Mean = 0.8950, MCC = 0.8156, F1-score = 0.8532\n",
      "      MWMOTE: AUC = 0.9781, G-Mean = 0.9240, MCC = 0.8542, F1-score = 0.8865\n",
      "      Trans(Direct): AUC = 0.9859, G-Mean = 0.9240, MCC = 0.8542, F1-score = 0.8865\n",
      "  Fold 5/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.20344, Reg Loss: 0.33680\n",
      "Epoch 200/2000, Avg Loss: 0.17874, Reg Loss: 0.33652\n",
      "Epoch 300/2000, Avg Loss: 0.14546, Reg Loss: 0.32853\n",
      "Epoch 400/2000, Avg Loss: 0.13881, Reg Loss: 0.32944\n",
      "Epoch 500/2000, Avg Loss: 0.12076, Reg Loss: 0.31232\n",
      "Epoch 600/2000, Avg Loss: 0.12448, Reg Loss: 0.32276\n",
      "Epoch 700/2000, Avg Loss: 0.11503, Reg Loss: 0.30470\n",
      "Epoch 800/2000, Avg Loss: 0.10445, Reg Loss: 0.29100\n",
      "Epoch 900/2000, Avg Loss: 0.11101, Reg Loss: 0.29450\n",
      "Epoch 1000/2000, Avg Loss: 0.12273, Reg Loss: 0.29936\n",
      "Epoch 1100/2000, Avg Loss: 0.10223, Reg Loss: 0.28307\n",
      "Epoch 1200/2000, Avg Loss: 0.08981, Reg Loss: 0.27119\n",
      "Epoch 1300/2000, Avg Loss: 0.09974, Reg Loss: 0.28673\n",
      "Epoch 1400/2000, Avg Loss: 0.09434, Reg Loss: 0.27489\n",
      "Epoch 1500/2000, Avg Loss: 0.08366, Reg Loss: 0.27892\n",
      "Epoch 1600/2000, Avg Loss: 0.09008, Reg Loss: 0.27400\n",
      "Epoch 1700/2000, Avg Loss: 0.08229, Reg Loss: 0.28437\n",
      "Epoch 1800/2000, Avg Loss: 0.09828, Reg Loss: 0.28489\n",
      "Epoch 1900/2000, Avg Loss: 0.08835, Reg Loss: 0.26951\n",
      "Epoch 2000/2000, Avg Loss: 0.07918, Reg Loss: 0.27242\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.8812, G-Mean = 0.8718, MCC = 0.7899, F1-score = 0.8279\n",
      "      SMOTEBoost: AUC = 0.9646, G-Mean = 0.9357, MCC = 0.8839, F1-score = 0.9013\n",
      "      RUSBoost: AUC = 0.8963, G-Mean = 0.8353, MCC = 0.6330, F1-score = 0.7117\n",
      "      OUBoost: AUC = 0.9691, G-Mean = 0.9159, MCC = 0.8531, F1-score = 0.8801\n",
      "      SVM: AUC = 0.9760, G-Mean = 0.9162, MCC = 0.8465, F1-score = 0.8775\n",
      "      SMOTE: AUC = 0.9739, G-Mean = 0.9124, MCC = 0.8309, F1-score = 0.8692\n",
      "      ADASYN: AUC = 0.9676, G-Mean = 0.8892, MCC = 0.8000, F1-score = 0.8425\n",
      "      bSMOTE: AUC = 0.9739, G-Mean = 0.9124, MCC = 0.8309, F1-score = 0.8692\n",
      "      ROS: AUC = 0.9739, G-Mean = 0.8892, MCC = 0.8000, F1-score = 0.8425\n",
      "      MWMOTE: AUC = 0.9700, G-Mean = 0.9124, MCC = 0.8309, F1-score = 0.8692\n",
      "      Trans(Direct): AUC = 0.9762, G-Mean = 0.9328, MCC = 0.8601, F1-score = 0.8910\n",
      "  Fold 6/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.22723, Reg Loss: 0.30576\n",
      "Epoch 200/2000, Avg Loss: 0.20030, Reg Loss: 0.31079\n",
      "Epoch 300/2000, Avg Loss: 0.17728, Reg Loss: 0.31090\n",
      "Epoch 400/2000, Avg Loss: 0.13860, Reg Loss: 0.30499\n",
      "Epoch 500/2000, Avg Loss: 0.12843, Reg Loss: 0.30210\n",
      "Epoch 600/2000, Avg Loss: 0.12336, Reg Loss: 0.29301\n",
      "Epoch 700/2000, Avg Loss: 0.13054, Reg Loss: 0.29986\n",
      "Epoch 800/2000, Avg Loss: 0.11166, Reg Loss: 0.29045\n",
      "Epoch 900/2000, Avg Loss: 0.10107, Reg Loss: 0.29399\n",
      "Epoch 1000/2000, Avg Loss: 0.08750, Reg Loss: 0.28604\n",
      "Epoch 1100/2000, Avg Loss: 0.09971, Reg Loss: 0.26657\n",
      "Epoch 1200/2000, Avg Loss: 0.08999, Reg Loss: 0.27927\n",
      "Epoch 1300/2000, Avg Loss: 0.08890, Reg Loss: 0.29445\n",
      "Epoch 1400/2000, Avg Loss: 0.09083, Reg Loss: 0.28082\n",
      "Epoch 1500/2000, Avg Loss: 0.10723, Reg Loss: 0.28810\n",
      "Epoch 1600/2000, Avg Loss: 0.09673, Reg Loss: 0.28613\n",
      "Epoch 1700/2000, Avg Loss: 0.10193, Reg Loss: 0.28823\n",
      "Epoch 1800/2000, Avg Loss: 0.09169, Reg Loss: 0.29479\n",
      "Epoch 1900/2000, Avg Loss: 0.08762, Reg Loss: 0.28646\n",
      "Epoch 2000/2000, Avg Loss: 0.08712, Reg Loss: 0.28696\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.9010, G-Mean = 0.8931, MCC = 0.8249, F1-score = 0.8566\n",
      "      SMOTEBoost: AUC = 0.9705, G-Mean = 0.9464, MCC = 0.9033, F1-score = 0.9177\n",
      "      RUSBoost: AUC = 0.8990, G-Mean = 0.8140, MCC = 0.6006, F1-score = 0.6856\n",
      "      OUBoost: AUC = 0.9743, G-Mean = 0.9299, MCC = 0.8776, F1-score = 0.9001\n",
      "      SVM: AUC = 0.9800, G-Mean = 0.9302, MCC = 0.8721, F1-score = 0.8980\n",
      "      SMOTE: AUC = 0.9782, G-Mean = 0.9270, MCC = 0.8591, F1-score = 0.8910\n",
      "      ADASYN: AUC = 0.9730, G-Mean = 0.9076, MCC = 0.8333, F1-score = 0.8688\n",
      "      bSMOTE: AUC = 0.9782, G-Mean = 0.9270, MCC = 0.8591, F1-score = 0.8910\n",
      "      ROS: AUC = 0.9782, G-Mean = 0.9076, MCC = 0.8333, F1-score = 0.8688\n",
      "      MWMOTE: AUC = 0.9750, G-Mean = 0.9270, MCC = 0.8591, F1-score = 0.8910\n",
      "      Trans(Direct): AUC = 0.9802, G-Mean = 0.9440, MCC = 0.8835, F1-score = 0.9092\n",
      "  Fold 7/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.21215, Reg Loss: 0.29166\n",
      "Epoch 200/2000, Avg Loss: 0.17463, Reg Loss: 0.28373\n",
      "Epoch 300/2000, Avg Loss: 0.17408, Reg Loss: 0.29467\n",
      "Epoch 400/2000, Avg Loss: 0.14112, Reg Loss: 0.28720\n",
      "Epoch 500/2000, Avg Loss: 0.13565, Reg Loss: 0.27160\n",
      "Epoch 600/2000, Avg Loss: 0.13887, Reg Loss: 0.25957\n",
      "Epoch 700/2000, Avg Loss: 0.11977, Reg Loss: 0.26649\n",
      "Epoch 800/2000, Avg Loss: 0.12191, Reg Loss: 0.27262\n",
      "Epoch 900/2000, Avg Loss: 0.09393, Reg Loss: 0.26442\n",
      "Epoch 1000/2000, Avg Loss: 0.10521, Reg Loss: 0.26470\n",
      "Epoch 1100/2000, Avg Loss: 0.10596, Reg Loss: 0.26269\n",
      "Epoch 1200/2000, Avg Loss: 0.09510, Reg Loss: 0.25252\n",
      "Epoch 1300/2000, Avg Loss: 0.12819, Reg Loss: 0.25037\n",
      "Epoch 1400/2000, Avg Loss: 0.08574, Reg Loss: 0.25284\n",
      "Epoch 1500/2000, Avg Loss: 0.08663, Reg Loss: 0.24512\n",
      "Epoch 1600/2000, Avg Loss: 0.08251, Reg Loss: 0.25196\n",
      "Epoch 1700/2000, Avg Loss: 0.09015, Reg Loss: 0.24137\n",
      "Epoch 1800/2000, Avg Loss: 0.07872, Reg Loss: 0.24998\n",
      "Epoch 1900/2000, Avg Loss: 0.09662, Reg Loss: 0.24502\n",
      "Epoch 2000/2000, Avg Loss: 0.08683, Reg Loss: 0.25002\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.9009, G-Mean = 0.8933, MCC = 0.8310, F1-score = 0.8612\n",
      "      SMOTEBoost: AUC = 0.9747, G-Mean = 0.9540, MCC = 0.9171, F1-score = 0.9295\n",
      "      RUSBoost: AUC = 0.9134, G-Mean = 0.8360, MCC = 0.6410, F1-score = 0.7176\n",
      "      OUBoost: AUC = 0.9779, G-Mean = 0.9399, MCC = 0.8951, F1-score = 0.9143\n",
      "      SVM: AUC = 0.9828, G-Mean = 0.9079, MCC = 0.8518, F1-score = 0.8768\n",
      "      SMOTE: AUC = 0.9814, G-Mean = 0.9052, MCC = 0.8407, F1-score = 0.8709\n",
      "      ADASYN: AUC = 0.9769, G-Mean = 0.8886, MCC = 0.8186, F1-score = 0.8518\n",
      "      bSMOTE: AUC = 0.9814, G-Mean = 0.9052, MCC = 0.8407, F1-score = 0.8709\n",
      "      ROS: AUC = 0.9814, G-Mean = 0.8886, MCC = 0.8186, F1-score = 0.8518\n",
      "      MWMOTE: AUC = 0.9786, G-Mean = 0.9052, MCC = 0.8407, F1-score = 0.8709\n",
      "      Trans(Direct): AUC = 0.9830, G-Mean = 0.9369, MCC = 0.8812, F1-score = 0.9063\n",
      "  Fold 8/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.25969, Reg Loss: 0.29300\n",
      "Epoch 200/2000, Avg Loss: 0.22698, Reg Loss: 0.28985\n",
      "Epoch 300/2000, Avg Loss: 0.20388, Reg Loss: 0.27857\n",
      "Epoch 400/2000, Avg Loss: 0.17194, Reg Loss: 0.27742\n",
      "Epoch 500/2000, Avg Loss: 0.13881, Reg Loss: 0.26225\n",
      "Epoch 600/2000, Avg Loss: 0.14424, Reg Loss: 0.26237\n",
      "Epoch 700/2000, Avg Loss: 0.12806, Reg Loss: 0.26688\n",
      "Epoch 800/2000, Avg Loss: 0.11748, Reg Loss: 0.26204\n",
      "Epoch 900/2000, Avg Loss: 0.11959, Reg Loss: 0.26991\n",
      "Epoch 1000/2000, Avg Loss: 0.10717, Reg Loss: 0.25581\n",
      "Epoch 1100/2000, Avg Loss: 0.10351, Reg Loss: 0.25560\n",
      "Epoch 1200/2000, Avg Loss: 0.10289, Reg Loss: 0.25442\n",
      "Epoch 1300/2000, Avg Loss: 0.10857, Reg Loss: 0.27092\n",
      "Epoch 1400/2000, Avg Loss: 0.11180, Reg Loss: 0.25228\n",
      "Epoch 1500/2000, Avg Loss: 0.09992, Reg Loss: 0.23705\n",
      "Epoch 1600/2000, Avg Loss: 0.11294, Reg Loss: 0.25853\n",
      "Epoch 1700/2000, Avg Loss: 0.12494, Reg Loss: 0.26110\n",
      "Epoch 1800/2000, Avg Loss: 0.10236, Reg Loss: 0.25158\n",
      "Epoch 1900/2000, Avg Loss: 0.10022, Reg Loss: 0.24974\n",
      "Epoch 2000/2000, Avg Loss: 0.09363, Reg Loss: 0.25101\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.9078, G-Mean = 0.9027, MCC = 0.8377, F1-score = 0.8672\n",
      "      SMOTEBoost: AUC = 0.9732, G-Mean = 0.9394, MCC = 0.8820, F1-score = 0.9042\n",
      "      RUSBoost: AUC = 0.9055, G-Mean = 0.8252, MCC = 0.6214, F1-score = 0.7014\n",
      "      OUBoost: AUC = 0.9635, G-Mean = 0.9108, MCC = 0.8285, F1-score = 0.8667\n",
      "      SVM: AUC = 0.9834, G-Mean = 0.9155, MCC = 0.8558, F1-score = 0.8809\n",
      "      SMOTE: AUC = 0.9821, G-Mean = 0.9003, MCC = 0.8278, F1-score = 0.8620\n",
      "      ADASYN: AUC = 0.9767, G-Mean = 0.8986, MCC = 0.8268, F1-score = 0.8590\n",
      "      bSMOTE: AUC = 0.9806, G-Mean = 0.9003, MCC = 0.8278, F1-score = 0.8620\n",
      "      ROS: AUC = 0.9821, G-Mean = 0.8858, MCC = 0.8085, F1-score = 0.8453\n",
      "      MWMOTE: AUC = 0.9750, G-Mean = 0.9131, MCC = 0.8461, F1-score = 0.8756\n",
      "      Trans(Direct): AUC = 0.9820, G-Mean = 0.9367, MCC = 0.8699, F1-score = 0.8972\n",
      "  Fold 9/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.27171, Reg Loss: 0.34081\n",
      "Epoch 200/2000, Avg Loss: 0.20357, Reg Loss: 0.34533\n",
      "Epoch 300/2000, Avg Loss: 0.18407, Reg Loss: 0.33962\n",
      "Epoch 400/2000, Avg Loss: 0.17086, Reg Loss: 0.33688\n",
      "Epoch 500/2000, Avg Loss: 0.14592, Reg Loss: 0.33837\n",
      "Epoch 600/2000, Avg Loss: 0.12805, Reg Loss: 0.33043\n",
      "Epoch 700/2000, Avg Loss: 0.12239, Reg Loss: 0.32753\n",
      "Epoch 800/2000, Avg Loss: 0.14612, Reg Loss: 0.32807\n",
      "Epoch 900/2000, Avg Loss: 0.14548, Reg Loss: 0.33531\n",
      "Epoch 1000/2000, Avg Loss: 0.12271, Reg Loss: 0.31547\n",
      "Epoch 1100/2000, Avg Loss: 0.10983, Reg Loss: 0.32043\n",
      "Epoch 1200/2000, Avg Loss: 0.12885, Reg Loss: 0.31849\n",
      "Epoch 1300/2000, Avg Loss: 0.10974, Reg Loss: 0.32282\n",
      "Epoch 1400/2000, Avg Loss: 0.12768, Reg Loss: 0.32793\n",
      "Epoch 1500/2000, Avg Loss: 0.09045, Reg Loss: 0.30341\n",
      "Epoch 1600/2000, Avg Loss: 0.11537, Reg Loss: 0.31674\n",
      "Epoch 1700/2000, Avg Loss: 0.09782, Reg Loss: 0.31292\n",
      "Epoch 1800/2000, Avg Loss: 0.10582, Reg Loss: 0.30726\n",
      "Epoch 1900/2000, Avg Loss: 0.12326, Reg Loss: 0.31091\n",
      "Epoch 2000/2000, Avg Loss: 0.10179, Reg Loss: 0.30105\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.9111, G-Mean = 0.9063, MCC = 0.8324, F1-score = 0.8635\n",
      "      SMOTEBoost: AUC = 0.9678, G-Mean = 0.9246, MCC = 0.8455, F1-score = 0.8778\n",
      "      RUSBoost: AUC = 0.8924, G-Mean = 0.7891, MCC = 0.5825, F1-score = 0.6740\n",
      "      OUBoost: AUC = 0.9592, G-Mean = 0.9136, MCC = 0.8243, F1-score = 0.8630\n",
      "      SVM: AUC = 0.9839, G-Mean = 0.9177, MCC = 0.8486, F1-score = 0.8756\n",
      "      SMOTE: AUC = 0.9799, G-Mean = 0.9042, MCC = 0.8236, F1-score = 0.8588\n",
      "      ADASYN: AUC = 0.9737, G-Mean = 0.9027, MCC = 0.8227, F1-score = 0.8561\n",
      "      bSMOTE: AUC = 0.9813, G-Mean = 0.9042, MCC = 0.8236, F1-score = 0.8588\n",
      "      ROS: AUC = 0.9841, G-Mean = 0.8913, MCC = 0.8065, F1-score = 0.8440\n",
      "      MWMOTE: AUC = 0.9722, G-Mean = 0.9156, MCC = 0.8399, F1-score = 0.8709\n",
      "      Trans(Direct): AUC = 0.9826, G-Mean = 0.9366, MCC = 0.8611, F1-score = 0.8901\n",
      "  Fold 10/10 - Experiment 6/10\n",
      "Epoch 100/2000, Avg Loss: 0.20854, Reg Loss: 0.28948\n",
      "Epoch 200/2000, Avg Loss: 0.17155, Reg Loss: 0.28734\n",
      "Epoch 300/2000, Avg Loss: 0.18743, Reg Loss: 0.31111\n",
      "Epoch 400/2000, Avg Loss: 0.17773, Reg Loss: 0.29304\n",
      "Epoch 500/2000, Avg Loss: 0.14718, Reg Loss: 0.27893\n",
      "Epoch 600/2000, Avg Loss: 0.12022, Reg Loss: 0.26803\n",
      "Epoch 700/2000, Avg Loss: 0.11004, Reg Loss: 0.27452\n",
      "Epoch 800/2000, Avg Loss: 0.11734, Reg Loss: 0.27965\n",
      "Epoch 900/2000, Avg Loss: 0.11209, Reg Loss: 0.27302\n",
      "Epoch 1000/2000, Avg Loss: 0.09364, Reg Loss: 0.27824\n",
      "Epoch 1100/2000, Avg Loss: 0.12453, Reg Loss: 0.30097\n",
      "Epoch 1200/2000, Avg Loss: 0.09542, Reg Loss: 0.27597\n",
      "Epoch 1300/2000, Avg Loss: 0.09359, Reg Loss: 0.27136\n",
      "Epoch 1400/2000, Avg Loss: 0.13069, Reg Loss: 0.26753\n",
      "Epoch 1500/2000, Avg Loss: 0.08784, Reg Loss: 0.26625\n",
      "Epoch 1600/2000, Avg Loss: 0.08291, Reg Loss: 0.26677\n",
      "Epoch 1700/2000, Avg Loss: 0.08638, Reg Loss: 0.26249\n",
      "Epoch 1800/2000, Avg Loss: 0.10462, Reg Loss: 0.27369\n",
      "Epoch 1900/2000, Avg Loss: 0.11086, Reg Loss: 0.25925\n",
      "Epoch 2000/2000, Avg Loss: 0.08392, Reg Loss: 0.26197\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.9062, G-Mean = 0.9023, MCC = 0.8229, F1-score = 0.8571\n",
      "      SMOTEBoost: AUC = 0.9710, G-Mean = 0.9216, MCC = 0.8477, F1-score = 0.8789\n",
      "      RUSBoost: AUC = 0.9007, G-Mean = 0.8037, MCC = 0.6033, F1-score = 0.6899\n",
      "      OUBoost: AUC = 0.9633, G-Mean = 0.9222, MCC = 0.8419, F1-score = 0.8767\n",
      "      SVM: AUC = 0.9855, G-Mean = 0.9259, MCC = 0.8637, F1-score = 0.8880\n",
      "      SMOTE: AUC = 0.9819, G-Mean = 0.9138, MCC = 0.8413, F1-score = 0.8729\n",
      "      ADASYN: AUC = 0.9763, G-Mean = 0.9092, MCC = 0.8288, F1-score = 0.8614\n",
      "      bSMOTE: AUC = 0.9832, G-Mean = 0.9138, MCC = 0.8413, F1-score = 0.8729\n",
      "      ROS: AUC = 0.9857, G-Mean = 0.9022, MCC = 0.8258, F1-score = 0.8596\n",
      "      MWMOTE: AUC = 0.9750, G-Mean = 0.9240, MCC = 0.8559, F1-score = 0.8838\n",
      "      Trans(Direct): AUC = 0.9844, G-Mean = 0.9398, MCC = 0.8633, F1-score = 0.8920\n",
      "\n",
      "Starting experiment 7/10\n",
      "  Fold 1/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.24644, Reg Loss: 0.30179\n",
      "Epoch 200/2000, Avg Loss: 0.21109, Reg Loss: 0.29879\n",
      "Epoch 300/2000, Avg Loss: 0.18013, Reg Loss: 0.29111\n",
      "Epoch 400/2000, Avg Loss: 0.15804, Reg Loss: 0.29778\n",
      "Epoch 500/2000, Avg Loss: 0.13718, Reg Loss: 0.28726\n",
      "Epoch 600/2000, Avg Loss: 0.13596, Reg Loss: 0.28369\n",
      "Epoch 700/2000, Avg Loss: 0.11799, Reg Loss: 0.28129\n",
      "Epoch 800/2000, Avg Loss: 0.14468, Reg Loss: 0.29180\n",
      "Epoch 900/2000, Avg Loss: 0.14057, Reg Loss: 0.30051\n",
      "Epoch 1000/2000, Avg Loss: 0.13182, Reg Loss: 0.30171\n",
      "Epoch 1100/2000, Avg Loss: 0.10209, Reg Loss: 0.29434\n",
      "Epoch 1200/2000, Avg Loss: 0.12497, Reg Loss: 0.30868\n",
      "Epoch 1300/2000, Avg Loss: 0.09774, Reg Loss: 0.29208\n",
      "Epoch 1400/2000, Avg Loss: 0.11922, Reg Loss: 0.31554\n",
      "Epoch 1500/2000, Avg Loss: 0.12558, Reg Loss: 0.31018\n",
      "Epoch 1600/2000, Avg Loss: 0.11246, Reg Loss: 0.30892\n",
      "Epoch 1700/2000, Avg Loss: 0.10192, Reg Loss: 0.30170\n",
      "Epoch 1800/2000, Avg Loss: 0.09890, Reg Loss: 0.30551\n",
      "Epoch 1900/2000, Avg Loss: 0.09966, Reg Loss: 0.30661\n",
      "Epoch 2000/2000, Avg Loss: 0.10434, Reg Loss: 0.29452\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      SMOTEBoost: AUC = 0.9882, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      RUSBoost: AUC = 0.9529, G-Mean = 0.8044, MCC = 0.5423, F1-score = 0.6250\n",
      "      OUBoost: AUC = 1.0000, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      SVM: AUC = 0.9882, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      SMOTE: AUC = 0.9882, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "      ADASYN: AUC = 0.9882, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      bSMOTE: AUC = 0.9882, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "      ROS: AUC = 0.9882, G-Mean = 0.8677, MCC = 0.7412, F1-score = 0.8000\n",
      "      MWMOTE: AUC = 0.9882, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      Trans(Direct): AUC = 0.9882, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "  Fold 2/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.25663, Reg Loss: 0.31211\n",
      "Epoch 200/2000, Avg Loss: 0.19067, Reg Loss: 0.30374\n",
      "Epoch 300/2000, Avg Loss: 0.20675, Reg Loss: 0.32139\n",
      "Epoch 400/2000, Avg Loss: 0.17971, Reg Loss: 0.30278\n",
      "Epoch 500/2000, Avg Loss: 0.16017, Reg Loss: 0.29577\n",
      "Epoch 600/2000, Avg Loss: 0.13596, Reg Loss: 0.29509\n",
      "Epoch 700/2000, Avg Loss: 0.11207, Reg Loss: 0.28943\n",
      "Epoch 800/2000, Avg Loss: 0.10819, Reg Loss: 0.29803\n",
      "Epoch 900/2000, Avg Loss: 0.09994, Reg Loss: 0.28956\n",
      "Epoch 1000/2000, Avg Loss: 0.11270, Reg Loss: 0.28773\n",
      "Epoch 1100/2000, Avg Loss: 0.11747, Reg Loss: 0.30169\n",
      "Epoch 1200/2000, Avg Loss: 0.11197, Reg Loss: 0.28917\n",
      "Epoch 1300/2000, Avg Loss: 0.08816, Reg Loss: 0.26923\n",
      "Epoch 1400/2000, Avg Loss: 0.09753, Reg Loss: 0.27434\n",
      "Epoch 1500/2000, Avg Loss: 0.09278, Reg Loss: 0.27509\n",
      "Epoch 1600/2000, Avg Loss: 0.09857, Reg Loss: 0.26711\n",
      "Epoch 1700/2000, Avg Loss: 0.09114, Reg Loss: 0.27331\n",
      "Epoch 1800/2000, Avg Loss: 0.08240, Reg Loss: 0.27154\n",
      "Epoch 1900/2000, Avg Loss: 0.08456, Reg Loss: 0.26300\n",
      "Epoch 2000/2000, Avg Loss: 0.08605, Reg Loss: 0.26142\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.9706, G-Mean = 0.9697, MCC = 0.8969, F1-score = 0.9167\n",
      "      SMOTEBoost: AUC = 0.9941, G-Mean = 0.9547, MCC = 0.8397, F1-score = 0.8712\n",
      "      RUSBoost: AUC = 0.9647, G-Mean = 0.8394, MCC = 0.5971, F1-score = 0.6696\n",
      "      OUBoost: AUC = 1.0000, G-Mean = 0.9323, MCC = 0.8774, F1-score = 0.8990\n",
      "      SVM: AUC = 0.9882, G-Mean = 0.9189, MCC = 0.8134, F1-score = 0.8545\n",
      "      SMOTE: AUC = 0.9824, G-Mean = 0.8539, MCC = 0.6916, F1-score = 0.7636\n",
      "      ADASYN: AUC = 0.9765, G-Mean = 0.9052, MCC = 0.7638, F1-score = 0.8182\n",
      "      bSMOTE: AUC = 0.9824, G-Mean = 0.8539, MCC = 0.6916, F1-score = 0.7636\n",
      "      ROS: AUC = 0.9824, G-Mean = 0.8539, MCC = 0.6916, F1-score = 0.7636\n",
      "      MWMOTE: AUC = 0.9765, G-Mean = 0.9052, MCC = 0.7638, F1-score = 0.8182\n",
      "      Trans(Direct): AUC = 0.9824, G-Mean = 0.9052, MCC = 0.7638, F1-score = 0.8182\n",
      "  Fold 3/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.24997, Reg Loss: 0.32245\n",
      "Epoch 200/2000, Avg Loss: 0.19414, Reg Loss: 0.32580\n",
      "Epoch 300/2000, Avg Loss: 0.17086, Reg Loss: 0.29016\n",
      "Epoch 400/2000, Avg Loss: 0.14998, Reg Loss: 0.31215\n",
      "Epoch 500/2000, Avg Loss: 0.12973, Reg Loss: 0.30941\n",
      "Epoch 600/2000, Avg Loss: 0.12383, Reg Loss: 0.31611\n",
      "Epoch 700/2000, Avg Loss: 0.11514, Reg Loss: 0.30809\n",
      "Epoch 800/2000, Avg Loss: 0.10817, Reg Loss: 0.30048\n",
      "Epoch 900/2000, Avg Loss: 0.11211, Reg Loss: 0.30179\n",
      "Epoch 1000/2000, Avg Loss: 0.12416, Reg Loss: 0.30452\n",
      "Epoch 1100/2000, Avg Loss: 0.10560, Reg Loss: 0.30091\n",
      "Epoch 1200/2000, Avg Loss: 0.10021, Reg Loss: 0.29234\n",
      "Epoch 1300/2000, Avg Loss: 0.09781, Reg Loss: 0.28607\n",
      "Epoch 1400/2000, Avg Loss: 0.12079, Reg Loss: 0.29539\n",
      "Epoch 1500/2000, Avg Loss: 0.09995, Reg Loss: 0.28808\n",
      "Epoch 1600/2000, Avg Loss: 0.11601, Reg Loss: 0.29502\n",
      "Epoch 1700/2000, Avg Loss: 0.08914, Reg Loss: 0.30458\n",
      "Epoch 1800/2000, Avg Loss: 0.09273, Reg Loss: 0.29097\n",
      "Epoch 1900/2000, Avg Loss: 0.12583, Reg Loss: 0.30925\n",
      "Epoch 2000/2000, Avg Loss: 0.10469, Reg Loss: 0.29448\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.9700, G-Mean = 0.9692, MCC = 0.8968, F1-score = 0.9188\n",
      "      SMOTEBoost: AUC = 0.9891, G-Mean = 0.9592, MCC = 0.8586, F1-score = 0.8885\n",
      "      RUSBoost: AUC = 0.9626, G-Mean = 0.8601, MCC = 0.6434, F1-score = 0.7131\n",
      "      OUBoost: AUC = 0.9931, G-Mean = 0.9443, MCC = 0.8838, F1-score = 0.9070\n",
      "      SVM: AUC = 0.9748, G-Mean = 0.9354, MCC = 0.8411, F1-score = 0.8774\n",
      "      SMOTE: AUC = 0.9709, G-Mean = 0.8920, MCC = 0.7599, F1-score = 0.8168\n",
      "      ADASYN: AUC = 0.9670, G-Mean = 0.9262, MCC = 0.8080, F1-score = 0.8531\n",
      "      bSMOTE: AUC = 0.9709, G-Mean = 0.8920, MCC = 0.7599, F1-score = 0.8168\n",
      "      ROS: AUC = 0.9709, G-Mean = 0.8920, MCC = 0.7599, F1-score = 0.8168\n",
      "      MWMOTE: AUC = 0.9670, G-Mean = 0.9262, MCC = 0.8080, F1-score = 0.8531\n",
      "      Trans(Direct): AUC = 0.9709, G-Mean = 0.9262, MCC = 0.8080, F1-score = 0.8531\n",
      "  Fold 4/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.24227, Reg Loss: 0.30688\n",
      "Epoch 200/2000, Avg Loss: 0.17870, Reg Loss: 0.29868\n",
      "Epoch 300/2000, Avg Loss: 0.14487, Reg Loss: 0.28333\n",
      "Epoch 400/2000, Avg Loss: 0.13625, Reg Loss: 0.27129\n",
      "Epoch 500/2000, Avg Loss: 0.11975, Reg Loss: 0.27633\n",
      "Epoch 600/2000, Avg Loss: 0.12565, Reg Loss: 0.28381\n",
      "Epoch 700/2000, Avg Loss: 0.11166, Reg Loss: 0.25644\n",
      "Epoch 800/2000, Avg Loss: 0.10539, Reg Loss: 0.27311\n",
      "Epoch 900/2000, Avg Loss: 0.11540, Reg Loss: 0.27051\n",
      "Epoch 1000/2000, Avg Loss: 0.10967, Reg Loss: 0.25530\n",
      "Epoch 1100/2000, Avg Loss: 0.08948, Reg Loss: 0.24297\n",
      "Epoch 1200/2000, Avg Loss: 0.08568, Reg Loss: 0.26456\n",
      "Epoch 1300/2000, Avg Loss: 0.09003, Reg Loss: 0.24998\n",
      "Epoch 1400/2000, Avg Loss: 0.07571, Reg Loss: 0.24982\n",
      "Epoch 1500/2000, Avg Loss: 0.09082, Reg Loss: 0.24559\n",
      "Epoch 1600/2000, Avg Loss: 0.08430, Reg Loss: 0.25379\n",
      "Epoch 1700/2000, Avg Loss: 0.09611, Reg Loss: 0.26264\n",
      "Epoch 1800/2000, Avg Loss: 0.06710, Reg Loss: 0.23291\n",
      "Epoch 1900/2000, Avg Loss: 0.07855, Reg Loss: 0.24349\n",
      "Epoch 2000/2000, Avg Loss: 0.07776, Reg Loss: 0.24298\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.9525, G-Mean = 0.9205, MCC = 0.8552, F1-score = 0.8766\n",
      "      SMOTEBoost: AUC = 0.9575, G-Mean = 0.9131, MCC = 0.8266, F1-score = 0.8539\n",
      "      RUSBoost: AUC = 0.9422, G-Mean = 0.8542, MCC = 0.6416, F1-score = 0.7166\n",
      "      OUBoost: AUC = 0.9729, G-Mean = 0.9019, MCC = 0.8454, F1-score = 0.8678\n",
      "      SVM: AUC = 0.9655, G-Mean = 0.9251, MCC = 0.8477, F1-score = 0.8803\n",
      "      SMOTE: AUC = 0.9657, G-Mean = 0.8926, MCC = 0.7868, F1-score = 0.8348\n",
      "      ADASYN: AUC = 0.9658, G-Mean = 0.9182, MCC = 0.8230, F1-score = 0.8621\n",
      "      bSMOTE: AUC = 0.9688, G-Mean = 0.8926, MCC = 0.7868, F1-score = 0.8348\n",
      "      ROS: AUC = 0.9657, G-Mean = 0.8926, MCC = 0.7868, F1-score = 0.8348\n",
      "      MWMOTE: AUC = 0.9627, G-Mean = 0.9182, MCC = 0.8230, F1-score = 0.8621\n",
      "      Trans(Direct): AUC = 0.9688, G-Mean = 0.9182, MCC = 0.8230, F1-score = 0.8621\n",
      "  Fold 5/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.23125, Reg Loss: 0.29294\n",
      "Epoch 200/2000, Avg Loss: 0.22893, Reg Loss: 0.29348\n",
      "Epoch 300/2000, Avg Loss: 0.15641, Reg Loss: 0.27234\n",
      "Epoch 400/2000, Avg Loss: 0.14408, Reg Loss: 0.26590\n",
      "Epoch 500/2000, Avg Loss: 0.15259, Reg Loss: 0.27990\n",
      "Epoch 600/2000, Avg Loss: 0.13977, Reg Loss: 0.26769\n",
      "Epoch 700/2000, Avg Loss: 0.11942, Reg Loss: 0.25542\n",
      "Epoch 800/2000, Avg Loss: 0.13401, Reg Loss: 0.26860\n",
      "Epoch 900/2000, Avg Loss: 0.14691, Reg Loss: 0.26425\n",
      "Epoch 1000/2000, Avg Loss: 0.10242, Reg Loss: 0.25359\n",
      "Epoch 1100/2000, Avg Loss: 0.09554, Reg Loss: 0.25554\n",
      "Epoch 1200/2000, Avg Loss: 0.11870, Reg Loss: 0.25990\n",
      "Epoch 1300/2000, Avg Loss: 0.10194, Reg Loss: 0.24994\n",
      "Epoch 1400/2000, Avg Loss: 0.10713, Reg Loss: 0.24599\n",
      "Epoch 1500/2000, Avg Loss: 0.09280, Reg Loss: 0.24884\n",
      "Epoch 1600/2000, Avg Loss: 0.10551, Reg Loss: 0.26160\n",
      "Epoch 1700/2000, Avg Loss: 0.11744, Reg Loss: 0.26610\n",
      "Epoch 1800/2000, Avg Loss: 0.07849, Reg Loss: 0.24529\n",
      "Epoch 1900/2000, Avg Loss: 0.08893, Reg Loss: 0.24000\n",
      "Epoch 2000/2000, Avg Loss: 0.08515, Reg Loss: 0.24973\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.9620, G-Mean = 0.9301, MCC = 0.8609, F1-score = 0.8831\n",
      "      SMOTEBoost: AUC = 0.9635, G-Mean = 0.9241, MCC = 0.8380, F1-score = 0.8649\n",
      "      RUSBoost: AUC = 0.9538, G-Mean = 0.8637, MCC = 0.6558, F1-score = 0.7272\n",
      "      OUBoost: AUC = 0.9758, G-Mean = 0.9151, MCC = 0.8531, F1-score = 0.8760\n",
      "      SVM: AUC = 0.9724, G-Mean = 0.9401, MCC = 0.8782, F1-score = 0.9042\n",
      "      SMOTE: AUC = 0.9725, G-Mean = 0.9141, MCC = 0.8295, F1-score = 0.8678\n",
      "      ADASYN: AUC = 0.9727, G-Mean = 0.9346, MCC = 0.8584, F1-score = 0.8897\n",
      "      bSMOTE: AUC = 0.9750, G-Mean = 0.9141, MCC = 0.8295, F1-score = 0.8678\n",
      "      ROS: AUC = 0.9725, G-Mean = 0.9141, MCC = 0.8295, F1-score = 0.8678\n",
      "      MWMOTE: AUC = 0.9702, G-Mean = 0.9346, MCC = 0.8584, F1-score = 0.8897\n",
      "      Trans(Direct): AUC = 0.9750, G-Mean = 0.9346, MCC = 0.8584, F1-score = 0.8897\n",
      "  Fold 6/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.25086, Reg Loss: 0.33107\n",
      "Epoch 200/2000, Avg Loss: 0.21631, Reg Loss: 0.31043\n",
      "Epoch 300/2000, Avg Loss: 0.19135, Reg Loss: 0.31093\n",
      "Epoch 400/2000, Avg Loss: 0.15919, Reg Loss: 0.31312\n",
      "Epoch 500/2000, Avg Loss: 0.16550, Reg Loss: 0.32041\n",
      "Epoch 600/2000, Avg Loss: 0.13629, Reg Loss: 0.30813\n",
      "Epoch 700/2000, Avg Loss: 0.14522, Reg Loss: 0.30212\n",
      "Epoch 800/2000, Avg Loss: 0.12180, Reg Loss: 0.29817\n",
      "Epoch 900/2000, Avg Loss: 0.10633, Reg Loss: 0.29477\n",
      "Epoch 1000/2000, Avg Loss: 0.09932, Reg Loss: 0.29748\n",
      "Epoch 1100/2000, Avg Loss: 0.11246, Reg Loss: 0.29944\n",
      "Epoch 1200/2000, Avg Loss: 0.14025, Reg Loss: 0.30533\n",
      "Epoch 1300/2000, Avg Loss: 0.10999, Reg Loss: 0.31382\n",
      "Epoch 1400/2000, Avg Loss: 0.12773, Reg Loss: 0.30225\n",
      "Epoch 1500/2000, Avg Loss: 0.09901, Reg Loss: 0.29250\n",
      "Epoch 1600/2000, Avg Loss: 0.09939, Reg Loss: 0.29258\n",
      "Epoch 1700/2000, Avg Loss: 0.08607, Reg Loss: 0.29681\n",
      "Epoch 1800/2000, Avg Loss: 0.08325, Reg Loss: 0.28385\n",
      "Epoch 1900/2000, Avg Loss: 0.10034, Reg Loss: 0.28112\n",
      "Epoch 2000/2000, Avg Loss: 0.10339, Reg Loss: 0.28804\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.9350, G-Mean = 0.9042, MCC = 0.8391, F1-score = 0.8609\n",
      "      SMOTEBoost: AUC = 0.9696, G-Mean = 0.9368, MCC = 0.8650, F1-score = 0.8874\n",
      "      RUSBoost: AUC = 0.9490, G-Mean = 0.8699, MCC = 0.6653, F1-score = 0.7342\n",
      "      OUBoost: AUC = 0.9799, G-Mean = 0.9293, MCC = 0.8776, F1-score = 0.8967\n",
      "      SVM: AUC = 0.9749, G-Mean = 0.9325, MCC = 0.8764, F1-score = 0.9017\n",
      "      SMOTE: AUC = 0.9771, G-Mean = 0.9108, MCC = 0.8359, F1-score = 0.8714\n",
      "      ADASYN: AUC = 0.9772, G-Mean = 0.9455, MCC = 0.8820, F1-score = 0.9081\n",
      "      bSMOTE: AUC = 0.9792, G-Mean = 0.9108, MCC = 0.8359, F1-score = 0.8714\n",
      "      ROS: AUC = 0.9771, G-Mean = 0.9284, MCC = 0.8579, F1-score = 0.8899\n",
      "      MWMOTE: AUC = 0.9751, G-Mean = 0.9279, MCC = 0.8599, F1-score = 0.8895\n",
      "      Trans(Direct): AUC = 0.9792, G-Mean = 0.9455, MCC = 0.8820, F1-score = 0.9081\n",
      "  Fold 7/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.24206, Reg Loss: 0.34383\n",
      "Epoch 200/2000, Avg Loss: 0.17898, Reg Loss: 0.31909\n",
      "Epoch 300/2000, Avg Loss: 0.17417, Reg Loss: 0.33593\n",
      "Epoch 400/2000, Avg Loss: 0.14950, Reg Loss: 0.33272\n",
      "Epoch 500/2000, Avg Loss: 0.12196, Reg Loss: 0.32789\n",
      "Epoch 600/2000, Avg Loss: 0.12349, Reg Loss: 0.32804\n",
      "Epoch 700/2000, Avg Loss: 0.11694, Reg Loss: 0.32353\n",
      "Epoch 800/2000, Avg Loss: 0.11535, Reg Loss: 0.32116\n",
      "Epoch 900/2000, Avg Loss: 0.11267, Reg Loss: 0.31965\n",
      "Epoch 1000/2000, Avg Loss: 0.11538, Reg Loss: 0.32890\n",
      "Epoch 1100/2000, Avg Loss: 0.10694, Reg Loss: 0.32205\n",
      "Epoch 1200/2000, Avg Loss: 0.11884, Reg Loss: 0.31740\n",
      "Epoch 1300/2000, Avg Loss: 0.09209, Reg Loss: 0.31145\n",
      "Epoch 1400/2000, Avg Loss: 0.11512, Reg Loss: 0.31103\n",
      "Epoch 1500/2000, Avg Loss: 0.09409, Reg Loss: 0.31476\n",
      "Epoch 1600/2000, Avg Loss: 0.09484, Reg Loss: 0.31630\n",
      "Epoch 1700/2000, Avg Loss: 0.10312, Reg Loss: 0.30499\n",
      "Epoch 1800/2000, Avg Loss: 0.09070, Reg Loss: 0.31623\n",
      "Epoch 1900/2000, Avg Loss: 0.08789, Reg Loss: 0.31774\n",
      "Epoch 2000/2000, Avg Loss: 0.08628, Reg Loss: 0.30901\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.9255, G-Mean = 0.8987, MCC = 0.8246, F1-score = 0.8522\n",
      "      SMOTEBoost: AUC = 0.9739, G-Mean = 0.9458, MCC = 0.8843, F1-score = 0.9035\n",
      "      RUSBoost: AUC = 0.9474, G-Mean = 0.8467, MCC = 0.6329, F1-score = 0.7087\n",
      "      OUBoost: AUC = 0.9827, G-Mean = 0.9394, MCC = 0.8951, F1-score = 0.9114\n",
      "      SVM: AUC = 0.9767, G-Mean = 0.9271, MCC = 0.8752, F1-score = 0.8998\n",
      "      SMOTE: AUC = 0.9804, G-Mean = 0.9236, MCC = 0.8593, F1-score = 0.8897\n",
      "      ADASYN: AUC = 0.9805, G-Mean = 0.9533, MCC = 0.8988, F1-score = 0.9212\n",
      "      bSMOTE: AUC = 0.9822, G-Mean = 0.9236, MCC = 0.8593, F1-score = 0.8897\n",
      "      ROS: AUC = 0.9804, G-Mean = 0.9387, MCC = 0.8782, F1-score = 0.9056\n",
      "      MWMOTE: AUC = 0.9787, G-Mean = 0.9382, MCC = 0.8799, F1-score = 0.9053\n",
      "      Trans(Direct): AUC = 0.9822, G-Mean = 0.9487, MCC = 0.8822, F1-score = 0.9082\n",
      "  Fold 8/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.23172, Reg Loss: 0.30073\n",
      "Epoch 200/2000, Avg Loss: 0.18315, Reg Loss: 0.29256\n",
      "Epoch 300/2000, Avg Loss: 0.17413, Reg Loss: 0.27932\n",
      "Epoch 400/2000, Avg Loss: 0.13860, Reg Loss: 0.27655\n",
      "Epoch 500/2000, Avg Loss: 0.12386, Reg Loss: 0.25803\n",
      "Epoch 600/2000, Avg Loss: 0.12575, Reg Loss: 0.26176\n",
      "Epoch 700/2000, Avg Loss: 0.12393, Reg Loss: 0.25764\n",
      "Epoch 800/2000, Avg Loss: 0.11190, Reg Loss: 0.25353\n",
      "Epoch 900/2000, Avg Loss: 0.09359, Reg Loss: 0.24918\n",
      "Epoch 1000/2000, Avg Loss: 0.10000, Reg Loss: 0.25464\n",
      "Epoch 1100/2000, Avg Loss: 0.11991, Reg Loss: 0.25589\n",
      "Epoch 1200/2000, Avg Loss: 0.09591, Reg Loss: 0.24517\n",
      "Epoch 1300/2000, Avg Loss: 0.08287, Reg Loss: 0.23575\n",
      "Epoch 1400/2000, Avg Loss: 0.08561, Reg Loss: 0.24015\n",
      "Epoch 1500/2000, Avg Loss: 0.08332, Reg Loss: 0.22693\n",
      "Epoch 1600/2000, Avg Loss: 0.10035, Reg Loss: 0.24468\n",
      "Epoch 1700/2000, Avg Loss: 0.08248, Reg Loss: 0.23157\n",
      "Epoch 1800/2000, Avg Loss: 0.07697, Reg Loss: 0.22515\n",
      "Epoch 1900/2000, Avg Loss: 0.06696, Reg Loss: 0.22556\n",
      "Epoch 2000/2000, Avg Loss: 0.09189, Reg Loss: 0.23658\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.9348, G-Mean = 0.9114, MCC = 0.8465, F1-score = 0.8707\n",
      "      SMOTEBoost: AUC = 0.9772, G-Mean = 0.9526, MCC = 0.8988, F1-score = 0.9156\n",
      "      RUSBoost: AUC = 0.9524, G-Mean = 0.8445, MCC = 0.6271, F1-score = 0.7034\n",
      "      OUBoost: AUC = 0.9849, G-Mean = 0.9346, MCC = 0.8723, F1-score = 0.8937\n",
      "      SVM: AUC = 0.9796, G-Mean = 0.9362, MCC = 0.8908, F1-score = 0.9124\n",
      "      SMOTE: AUC = 0.9828, G-Mean = 0.9331, MCC = 0.8769, F1-score = 0.9035\n",
      "      ADASYN: AUC = 0.9829, G-Mean = 0.9591, MCC = 0.9115, F1-score = 0.9310\n",
      "      bSMOTE: AUC = 0.9844, G-Mean = 0.9331, MCC = 0.8769, F1-score = 0.9035\n",
      "      ROS: AUC = 0.9828, G-Mean = 0.9463, MCC = 0.8934, F1-score = 0.9174\n",
      "      MWMOTE: AUC = 0.9814, G-Mean = 0.9459, MCC = 0.8949, F1-score = 0.9172\n",
      "      Trans(Direct): AUC = 0.9844, G-Mean = 0.9552, MCC = 0.8970, F1-score = 0.9197\n",
      "  Fold 9/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.25424, Reg Loss: 0.31124\n",
      "Epoch 200/2000, Avg Loss: 0.21253, Reg Loss: 0.29352\n",
      "Epoch 300/2000, Avg Loss: 0.16787, Reg Loss: 0.29778\n",
      "Epoch 400/2000, Avg Loss: 0.13585, Reg Loss: 0.27649\n",
      "Epoch 500/2000, Avg Loss: 0.14176, Reg Loss: 0.29760\n",
      "Epoch 600/2000, Avg Loss: 0.13079, Reg Loss: 0.28619\n",
      "Epoch 700/2000, Avg Loss: 0.13429, Reg Loss: 0.28349\n",
      "Epoch 800/2000, Avg Loss: 0.09917, Reg Loss: 0.26167\n",
      "Epoch 900/2000, Avg Loss: 0.08584, Reg Loss: 0.28280\n",
      "Epoch 1000/2000, Avg Loss: 0.12238, Reg Loss: 0.27200\n",
      "Epoch 1100/2000, Avg Loss: 0.10286, Reg Loss: 0.28110\n",
      "Epoch 1200/2000, Avg Loss: 0.09753, Reg Loss: 0.26169\n",
      "Epoch 1300/2000, Avg Loss: 0.10175, Reg Loss: 0.26556\n",
      "Epoch 1400/2000, Avg Loss: 0.09865, Reg Loss: 0.26905\n",
      "Epoch 1500/2000, Avg Loss: 0.10562, Reg Loss: 0.27093\n",
      "Epoch 1600/2000, Avg Loss: 0.08790, Reg Loss: 0.27157\n",
      "Epoch 1700/2000, Avg Loss: 0.09406, Reg Loss: 0.26448\n",
      "Epoch 1800/2000, Avg Loss: 0.07743, Reg Loss: 0.25730\n",
      "Epoch 1900/2000, Avg Loss: 0.09827, Reg Loss: 0.26865\n",
      "Epoch 2000/2000, Avg Loss: 0.07621, Reg Loss: 0.25276\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.9275, G-Mean = 0.9063, MCC = 0.8344, F1-score = 0.8628\n",
      "      SMOTEBoost: AUC = 0.9797, G-Mean = 0.9461, MCC = 0.8953, F1-score = 0.9126\n",
      "      RUSBoost: AUC = 0.9577, G-Mean = 0.7784, MCC = 0.5713, F1-score = 0.6697\n",
      "      OUBoost: AUC = 0.9866, G-Mean = 0.9419, MCC = 0.8865, F1-score = 0.9055\n",
      "      SVM: AUC = 0.9819, G-Mean = 0.9315, MCC = 0.8882, F1-score = 0.9097\n",
      "      SMOTE: AUC = 0.9847, G-Mean = 0.9406, MCC = 0.8906, F1-score = 0.9142\n",
      "      ADASYN: AUC = 0.9848, G-Mean = 0.9637, MCC = 0.9213, F1-score = 0.9387\n",
      "      bSMOTE: AUC = 0.9861, G-Mean = 0.9406, MCC = 0.8906, F1-score = 0.9142\n",
      "      ROS: AUC = 0.9847, G-Mean = 0.9523, MCC = 0.9053, F1-score = 0.9266\n",
      "      MWMOTE: AUC = 0.9834, G-Mean = 0.9519, MCC = 0.9066, F1-score = 0.9264\n",
      "      Trans(Direct): AUC = 0.9861, G-Mean = 0.9601, MCC = 0.9084, F1-score = 0.9286\n",
      "  Fold 10/10 - Experiment 7/10\n",
      "Epoch 100/2000, Avg Loss: 0.31827, Reg Loss: 0.32244\n",
      "Epoch 200/2000, Avg Loss: 0.20432, Reg Loss: 0.31871\n",
      "Epoch 300/2000, Avg Loss: 0.20814, Reg Loss: 0.31852\n",
      "Epoch 400/2000, Avg Loss: 0.17814, Reg Loss: 0.32071\n",
      "Epoch 500/2000, Avg Loss: 0.15738, Reg Loss: 0.32485\n",
      "Epoch 600/2000, Avg Loss: 0.15174, Reg Loss: 0.31866\n",
      "Epoch 700/2000, Avg Loss: 0.13542, Reg Loss: 0.30618\n",
      "Epoch 800/2000, Avg Loss: 0.12499, Reg Loss: 0.30801\n",
      "Epoch 900/2000, Avg Loss: 0.12732, Reg Loss: 0.32683\n",
      "Epoch 1000/2000, Avg Loss: 0.11153, Reg Loss: 0.32830\n",
      "Epoch 1100/2000, Avg Loss: 0.09741, Reg Loss: 0.30566\n",
      "Epoch 1200/2000, Avg Loss: 0.11744, Reg Loss: 0.30925\n",
      "Epoch 1300/2000, Avg Loss: 0.11242, Reg Loss: 0.30217\n",
      "Epoch 1400/2000, Avg Loss: 0.08825, Reg Loss: 0.31256\n",
      "Epoch 1500/2000, Avg Loss: 0.09637, Reg Loss: 0.28601\n",
      "Epoch 1600/2000, Avg Loss: 0.11820, Reg Loss: 0.29257\n",
      "Epoch 1700/2000, Avg Loss: 0.10921, Reg Loss: 0.31374\n",
      "Epoch 1800/2000, Avg Loss: 0.09955, Reg Loss: 0.29466\n",
      "Epoch 1900/2000, Avg Loss: 0.09977, Reg Loss: 0.29946\n",
      "Epoch 2000/2000, Avg Loss: 0.09153, Reg Loss: 0.30803\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.9254, G-Mean = 0.9058, MCC = 0.8222, F1-score = 0.8535\n",
      "      SMOTEBoost: AUC = 0.9767, G-Mean = 0.9416, MCC = 0.8770, F1-score = 0.8983\n",
      "      RUSBoost: AUC = 0.9463, G-Mean = 0.7756, MCC = 0.5626, F1-score = 0.6615\n",
      "      OUBoost: AUC = 0.9879, G-Mean = 0.9412, MCC = 0.8769, F1-score = 0.8983\n",
      "      SVM: AUC = 0.9749, G-Mean = 0.9250, MCC = 0.8640, F1-score = 0.8902\n",
      "      SMOTE: AUC = 0.9800, G-Mean = 0.9366, MCC = 0.8728, F1-score = 0.8997\n",
      "      ADASYN: AUC = 0.9788, G-Mean = 0.9539, MCC = 0.8937, F1-score = 0.9163\n",
      "      bSMOTE: AUC = 0.9800, G-Mean = 0.9366, MCC = 0.8728, F1-score = 0.8997\n",
      "      ROS: AUC = 0.9788, G-Mean = 0.9472, MCC = 0.8860, F1-score = 0.9108\n",
      "      MWMOTE: AUC = 0.9751, G-Mean = 0.9397, MCC = 0.8746, F1-score = 0.9004\n",
      "      Trans(Direct): AUC = 0.9800, G-Mean = 0.9507, MCC = 0.8821, F1-score = 0.9072\n",
      "\n",
      "Starting experiment 8/10\n",
      "  Fold 1/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.24770, Reg Loss: 0.31441\n",
      "Epoch 200/2000, Avg Loss: 0.17919, Reg Loss: 0.30872\n",
      "Epoch 300/2000, Avg Loss: 0.15875, Reg Loss: 0.29924\n",
      "Epoch 400/2000, Avg Loss: 0.15389, Reg Loss: 0.29363\n",
      "Epoch 500/2000, Avg Loss: 0.12456, Reg Loss: 0.30034\n",
      "Epoch 600/2000, Avg Loss: 0.13622, Reg Loss: 0.28948\n",
      "Epoch 700/2000, Avg Loss: 0.12390, Reg Loss: 0.30203\n",
      "Epoch 800/2000, Avg Loss: 0.12511, Reg Loss: 0.31367\n",
      "Epoch 900/2000, Avg Loss: 0.12216, Reg Loss: 0.29484\n",
      "Epoch 1000/2000, Avg Loss: 0.10517, Reg Loss: 0.29267\n",
      "Epoch 1100/2000, Avg Loss: 0.10119, Reg Loss: 0.28685\n",
      "Epoch 1200/2000, Avg Loss: 0.10839, Reg Loss: 0.29523\n",
      "Epoch 1300/2000, Avg Loss: 0.08390, Reg Loss: 0.28827\n",
      "Epoch 1400/2000, Avg Loss: 0.08143, Reg Loss: 0.28385\n",
      "Epoch 1500/2000, Avg Loss: 0.09335, Reg Loss: 0.27730\n",
      "Epoch 1600/2000, Avg Loss: 0.09244, Reg Loss: 0.27768\n",
      "Epoch 1700/2000, Avg Loss: 0.11134, Reg Loss: 0.27199\n",
      "Epoch 1800/2000, Avg Loss: 0.09032, Reg Loss: 0.27980\n",
      "Epoch 1900/2000, Avg Loss: 0.09059, Reg Loss: 0.26613\n",
      "Epoch 2000/2000, Avg Loss: 0.08546, Reg Loss: 0.27589\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 1.0000, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      SMOTEBoost: AUC = 1.0000, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      RUSBoost: AUC = 1.0000, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      OUBoost: AUC = 1.0000, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      SVM: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      SMOTE: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      ADASYN: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      bSMOTE: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      ROS: AUC = 1.0000, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      MWMOTE: AUC = 0.9882, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      Trans(Direct): AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "  Fold 2/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.26878, Reg Loss: 0.29063\n",
      "Epoch 200/2000, Avg Loss: 0.21114, Reg Loss: 0.29765\n",
      "Epoch 300/2000, Avg Loss: 0.18974, Reg Loss: 0.30554\n",
      "Epoch 400/2000, Avg Loss: 0.18894, Reg Loss: 0.29809\n",
      "Epoch 500/2000, Avg Loss: 0.14835, Reg Loss: 0.29132\n",
      "Epoch 600/2000, Avg Loss: 0.13733, Reg Loss: 0.29879\n",
      "Epoch 700/2000, Avg Loss: 0.12638, Reg Loss: 0.28558\n",
      "Epoch 800/2000, Avg Loss: 0.13514, Reg Loss: 0.29817\n",
      "Epoch 900/2000, Avg Loss: 0.10518, Reg Loss: 0.27368\n",
      "Epoch 1000/2000, Avg Loss: 0.11014, Reg Loss: 0.28849\n",
      "Epoch 1100/2000, Avg Loss: 0.10079, Reg Loss: 0.28084\n",
      "Epoch 1200/2000, Avg Loss: 0.13644, Reg Loss: 0.28931\n",
      "Epoch 1300/2000, Avg Loss: 0.12016, Reg Loss: 0.28278\n",
      "Epoch 1400/2000, Avg Loss: 0.11589, Reg Loss: 0.26814\n",
      "Epoch 1500/2000, Avg Loss: 0.09935, Reg Loss: 0.28173\n",
      "Epoch 1600/2000, Avg Loss: 0.08682, Reg Loss: 0.27668\n",
      "Epoch 1700/2000, Avg Loss: 0.12040, Reg Loss: 0.28351\n",
      "Epoch 1800/2000, Avg Loss: 0.10139, Reg Loss: 0.27211\n",
      "Epoch 1900/2000, Avg Loss: 0.08930, Reg Loss: 0.27146\n",
      "Epoch 2000/2000, Avg Loss: 0.09696, Reg Loss: 0.26163\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 1.0000, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      SMOTEBoost: AUC = 1.0000, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      RUSBoost: AUC = 1.0000, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      OUBoost: AUC = 1.0000, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      SVM: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      SMOTE: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      ADASYN: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      bSMOTE: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      ROS: AUC = 1.0000, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      MWMOTE: AUC = 0.9941, G-Mean = 0.9851, MCC = 0.9428, F1-score = 0.9545\n",
      "      Trans(Direct): AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "  Fold 3/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.25652, Reg Loss: 0.30799\n",
      "Epoch 200/2000, Avg Loss: 0.20979, Reg Loss: 0.30611\n",
      "Epoch 300/2000, Avg Loss: 0.17711, Reg Loss: 0.31138\n",
      "Epoch 400/2000, Avg Loss: 0.14279, Reg Loss: 0.30808\n",
      "Epoch 500/2000, Avg Loss: 0.12537, Reg Loss: 0.30479\n",
      "Epoch 600/2000, Avg Loss: 0.13363, Reg Loss: 0.30220\n",
      "Epoch 700/2000, Avg Loss: 0.11736, Reg Loss: 0.31880\n",
      "Epoch 800/2000, Avg Loss: 0.11437, Reg Loss: 0.30435\n",
      "Epoch 900/2000, Avg Loss: 0.12610, Reg Loss: 0.30782\n",
      "Epoch 1000/2000, Avg Loss: 0.10326, Reg Loss: 0.29364\n",
      "Epoch 1100/2000, Avg Loss: 0.10334, Reg Loss: 0.28315\n",
      "Epoch 1200/2000, Avg Loss: 0.10174, Reg Loss: 0.28771\n",
      "Epoch 1300/2000, Avg Loss: 0.09914, Reg Loss: 0.29127\n",
      "Epoch 1400/2000, Avg Loss: 0.11475, Reg Loss: 0.28053\n",
      "Epoch 1500/2000, Avg Loss: 0.11720, Reg Loss: 0.28983\n",
      "Epoch 1600/2000, Avg Loss: 0.09090, Reg Loss: 0.27949\n",
      "Epoch 1700/2000, Avg Loss: 0.07627, Reg Loss: 0.27027\n",
      "Epoch 1800/2000, Avg Loss: 0.08932, Reg Loss: 0.27573\n",
      "Epoch 1900/2000, Avg Loss: 0.08727, Reg Loss: 0.27369\n",
      "Epoch 2000/2000, Avg Loss: 0.07660, Reg Loss: 0.27958\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.9722, G-Mean = 0.9358, MCC = 0.9183, F1-score = 0.9327\n",
      "      SMOTEBoost: AUC = 1.0000, G-Mean = 0.9006, MCC = 0.8747, F1-score = 0.8956\n",
      "      RUSBoost: AUC = 1.0000, G-Mean = 0.9472, MCC = 0.8357, F1-score = 0.8727\n",
      "      OUBoost: AUC = 0.9965, G-Mean = 0.9358, MCC = 0.9183, F1-score = 0.9327\n",
      "      SVM: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      SMOTE: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      ADASYN: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      bSMOTE: AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "      ROS: AUC = 1.0000, G-Mean = 0.9648, MCC = 0.9564, F1-score = 0.9630\n",
      "      MWMOTE: AUC = 0.9961, G-Mean = 0.9900, MCC = 0.9619, F1-score = 0.9697\n",
      "      Trans(Direct): AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "  Fold 4/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.25881, Reg Loss: 0.36920\n",
      "Epoch 200/2000, Avg Loss: 0.22893, Reg Loss: 0.35298\n",
      "Epoch 300/2000, Avg Loss: 0.17080, Reg Loss: 0.33926\n",
      "Epoch 400/2000, Avg Loss: 0.16516, Reg Loss: 0.32942\n",
      "Epoch 500/2000, Avg Loss: 0.13633, Reg Loss: 0.31142\n",
      "Epoch 600/2000, Avg Loss: 0.12664, Reg Loss: 0.32184\n",
      "Epoch 700/2000, Avg Loss: 0.12191, Reg Loss: 0.29464\n",
      "Epoch 800/2000, Avg Loss: 0.11016, Reg Loss: 0.29958\n",
      "Epoch 900/2000, Avg Loss: 0.09822, Reg Loss: 0.29032\n",
      "Epoch 1000/2000, Avg Loss: 0.10564, Reg Loss: 0.28707\n",
      "Epoch 1100/2000, Avg Loss: 0.09248, Reg Loss: 0.28632\n",
      "Epoch 1200/2000, Avg Loss: 0.09194, Reg Loss: 0.28856\n",
      "Epoch 1300/2000, Avg Loss: 0.10004, Reg Loss: 0.27363\n",
      "Epoch 1400/2000, Avg Loss: 0.07799, Reg Loss: 0.27878\n",
      "Epoch 1500/2000, Avg Loss: 0.10057, Reg Loss: 0.26858\n",
      "Epoch 1600/2000, Avg Loss: 0.09545, Reg Loss: 0.26202\n",
      "Epoch 1700/2000, Avg Loss: 0.09836, Reg Loss: 0.27191\n",
      "Epoch 1800/2000, Avg Loss: 0.08330, Reg Loss: 0.27134\n",
      "Epoch 1900/2000, Avg Loss: 0.09188, Reg Loss: 0.25062\n",
      "Epoch 2000/2000, Avg Loss: 0.08678, Reg Loss: 0.26935\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.9385, G-Mean = 0.9110, MCC = 0.8478, F1-score = 0.8813\n",
      "      SMOTEBoost: AUC = 0.9938, G-Mean = 0.9175, MCC = 0.8770, F1-score = 0.8990\n",
      "      RUSBoost: AUC = 0.9906, G-Mean = 0.9269, MCC = 0.7882, F1-score = 0.8331\n",
      "      OUBoost: AUC = 0.9943, G-Mean = 0.9439, MCC = 0.9097, F1-score = 0.9268\n",
      "      SVM: AUC = 0.9938, G-Mean = 0.9665, MCC = 0.9344, F1-score = 0.9500\n",
      "      SMOTE: AUC = 0.9938, G-Mean = 0.9921, MCC = 0.9710, F1-score = 0.9773\n",
      "      ADASYN: AUC = 0.9938, G-Mean = 0.9921, MCC = 0.9710, F1-score = 0.9773\n",
      "      bSMOTE: AUC = 0.9938, G-Mean = 0.9921, MCC = 0.9710, F1-score = 0.9773\n",
      "      ROS: AUC = 0.9938, G-Mean = 0.9657, MCC = 0.9383, F1-score = 0.9495\n",
      "      MWMOTE: AUC = 0.9908, G-Mean = 0.9846, MCC = 0.9424, F1-score = 0.9545\n",
      "      Trans(Direct): AUC = 0.9938, G-Mean = 0.9839, MCC = 0.9476, F1-score = 0.9583\n",
      "  Fold 5/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.23635, Reg Loss: 0.31983\n",
      "Epoch 200/2000, Avg Loss: 0.18208, Reg Loss: 0.30706\n",
      "Epoch 300/2000, Avg Loss: 0.15837, Reg Loss: 0.32126\n",
      "Epoch 400/2000, Avg Loss: 0.14349, Reg Loss: 0.31991\n",
      "Epoch 500/2000, Avg Loss: 0.15367, Reg Loss: 0.31457\n",
      "Epoch 600/2000, Avg Loss: 0.12947, Reg Loss: 0.31753\n",
      "Epoch 700/2000, Avg Loss: 0.11262, Reg Loss: 0.30607\n",
      "Epoch 800/2000, Avg Loss: 0.12022, Reg Loss: 0.31679\n",
      "Epoch 900/2000, Avg Loss: 0.10645, Reg Loss: 0.31703\n",
      "Epoch 1000/2000, Avg Loss: 0.13242, Reg Loss: 0.30528\n",
      "Epoch 1100/2000, Avg Loss: 0.10486, Reg Loss: 0.30203\n",
      "Epoch 1200/2000, Avg Loss: 0.08390, Reg Loss: 0.30664\n",
      "Epoch 1300/2000, Avg Loss: 0.10071, Reg Loss: 0.30078\n",
      "Epoch 1400/2000, Avg Loss: 0.09050, Reg Loss: 0.30032\n",
      "Epoch 1500/2000, Avg Loss: 0.08519, Reg Loss: 0.29561\n",
      "Epoch 1600/2000, Avg Loss: 0.08419, Reg Loss: 0.29185\n",
      "Epoch 1700/2000, Avg Loss: 0.08541, Reg Loss: 0.29852\n",
      "Epoch 1800/2000, Avg Loss: 0.08781, Reg Loss: 0.28664\n",
      "Epoch 1900/2000, Avg Loss: 0.07173, Reg Loss: 0.29453\n",
      "Epoch 2000/2000, Avg Loss: 0.08710, Reg Loss: 0.29718\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.9508, G-Mean = 0.9288, MCC = 0.8782, F1-score = 0.9051\n",
      "      SMOTEBoost: AUC = 0.9950, G-Mean = 0.9340, MCC = 0.9016, F1-score = 0.9192\n",
      "      RUSBoost: AUC = 0.9550, G-Mean = 0.7915, MCC = 0.6555, F1-score = 0.7465\n",
      "      OUBoost: AUC = 0.9954, G-Mean = 0.9551, MCC = 0.9277, F1-score = 0.9414\n",
      "      SVM: AUC = 0.9950, G-Mean = 0.9732, MCC = 0.9475, F1-score = 0.9600\n",
      "      SMOTE: AUC = 0.9950, G-Mean = 0.9936, MCC = 0.9768, F1-score = 0.9818\n",
      "      ADASYN: AUC = 0.9950, G-Mean = 0.9936, MCC = 0.9768, F1-score = 0.9818\n",
      "      bSMOTE: AUC = 0.9950, G-Mean = 0.9936, MCC = 0.9768, F1-score = 0.9818\n",
      "      ROS: AUC = 0.9950, G-Mean = 0.9725, MCC = 0.9506, F1-score = 0.9596\n",
      "      MWMOTE: AUC = 0.9926, G-Mean = 0.9877, MCC = 0.9539, F1-score = 0.9636\n",
      "      Trans(Direct): AUC = 0.9950, G-Mean = 0.9871, MCC = 0.9581, F1-score = 0.9667\n",
      "  Fold 6/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.23003, Reg Loss: 0.31531\n",
      "Epoch 200/2000, Avg Loss: 0.16974, Reg Loss: 0.28870\n",
      "Epoch 300/2000, Avg Loss: 0.17191, Reg Loss: 0.29830\n",
      "Epoch 400/2000, Avg Loss: 0.15392, Reg Loss: 0.29969\n",
      "Epoch 500/2000, Avg Loss: 0.13491, Reg Loss: 0.29301\n",
      "Epoch 600/2000, Avg Loss: 0.09720, Reg Loss: 0.28748\n",
      "Epoch 700/2000, Avg Loss: 0.11894, Reg Loss: 0.28940\n",
      "Epoch 800/2000, Avg Loss: 0.11037, Reg Loss: 0.28816\n",
      "Epoch 900/2000, Avg Loss: 0.11167, Reg Loss: 0.30065\n",
      "Epoch 1000/2000, Avg Loss: 0.09580, Reg Loss: 0.29634\n",
      "Epoch 1100/2000, Avg Loss: 0.09726, Reg Loss: 0.28342\n",
      "Epoch 1200/2000, Avg Loss: 0.13082, Reg Loss: 0.27465\n",
      "Epoch 1300/2000, Avg Loss: 0.11176, Reg Loss: 0.27987\n",
      "Epoch 1400/2000, Avg Loss: 0.08677, Reg Loss: 0.26789\n",
      "Epoch 1500/2000, Avg Loss: 0.09421, Reg Loss: 0.27501\n",
      "Epoch 1600/2000, Avg Loss: 0.08293, Reg Loss: 0.26962\n",
      "Epoch 1700/2000, Avg Loss: 0.08030, Reg Loss: 0.26207\n",
      "Epoch 1800/2000, Avg Loss: 0.08541, Reg Loss: 0.27056\n",
      "Epoch 1900/2000, Avg Loss: 0.08372, Reg Loss: 0.26809\n",
      "Epoch 2000/2000, Avg Loss: 0.06951, Reg Loss: 0.25926\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.9205, G-Mean = 0.8990, MCC = 0.8290, F1-score = 0.8653\n",
      "      SMOTEBoost: AUC = 0.9958, G-Mean = 0.9397, MCC = 0.8986, F1-score = 0.9175\n",
      "      RUSBoost: AUC = 0.9417, G-Mean = 0.7617, MCC = 0.6052, F1-score = 0.7054\n",
      "      OUBoost: AUC = 0.9962, G-Mean = 0.9626, MCC = 0.9398, F1-score = 0.9512\n",
      "      SVM: AUC = 0.9896, G-Mean = 0.9724, MCC = 0.9369, F1-score = 0.9515\n",
      "      SMOTE: AUC = 0.9917, G-Mean = 0.9894, MCC = 0.9613, F1-score = 0.9697\n",
      "      ADASYN: AUC = 0.9917, G-Mean = 0.9894, MCC = 0.9613, F1-score = 0.9697\n",
      "      bSMOTE: AUC = 0.9896, G-Mean = 0.9894, MCC = 0.9613, F1-score = 0.9697\n",
      "      ROS: AUC = 0.9896, G-Mean = 0.9718, MCC = 0.9395, F1-score = 0.9512\n",
      "      MWMOTE: AUC = 0.9897, G-Mean = 0.9844, MCC = 0.9422, F1-score = 0.9545\n",
      "      Trans(Direct): AUC = 0.9896, G-Mean = 0.9785, MCC = 0.9302, F1-score = 0.9444\n",
      "  Fold 7/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.25924, Reg Loss: 0.40185\n",
      "Epoch 200/2000, Avg Loss: 0.19285, Reg Loss: 0.39899\n",
      "Epoch 300/2000, Avg Loss: 0.17005, Reg Loss: 0.38040\n",
      "Epoch 400/2000, Avg Loss: 0.15926, Reg Loss: 0.39187\n",
      "Epoch 500/2000, Avg Loss: 0.14463, Reg Loss: 0.37452\n",
      "Epoch 600/2000, Avg Loss: 0.13307, Reg Loss: 0.36724\n",
      "Epoch 700/2000, Avg Loss: 0.11875, Reg Loss: 0.37100\n",
      "Epoch 800/2000, Avg Loss: 0.13749, Reg Loss: 0.38209\n",
      "Epoch 900/2000, Avg Loss: 0.11249, Reg Loss: 0.36562\n",
      "Epoch 1000/2000, Avg Loss: 0.13398, Reg Loss: 0.35344\n",
      "Epoch 1100/2000, Avg Loss: 0.10617, Reg Loss: 0.34603\n",
      "Epoch 1200/2000, Avg Loss: 0.09934, Reg Loss: 0.35375\n",
      "Epoch 1300/2000, Avg Loss: 0.09799, Reg Loss: 0.36470\n",
      "Epoch 1400/2000, Avg Loss: 0.10479, Reg Loss: 0.36446\n",
      "Epoch 1500/2000, Avg Loss: 0.11508, Reg Loss: 0.36645\n",
      "Epoch 1600/2000, Avg Loss: 0.11774, Reg Loss: 0.35359\n",
      "Epoch 1700/2000, Avg Loss: 0.10157, Reg Loss: 0.34973\n",
      "Epoch 1800/2000, Avg Loss: 0.11133, Reg Loss: 0.35650\n",
      "Epoch 1900/2000, Avg Loss: 0.09557, Reg Loss: 0.35894\n",
      "Epoch 2000/2000, Avg Loss: 0.09855, Reg Loss: 0.33628\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.9292, G-Mean = 0.8943, MCC = 0.8160, F1-score = 0.8560\n",
      "      SMOTEBoost: AUC = 0.9964, G-Mean = 0.9483, MCC = 0.9131, F1-score = 0.9293\n",
      "      RUSBoost: AUC = 0.9339, G-Mean = 0.7539, MCC = 0.5814, F1-score = 0.6840\n",
      "      OUBoost: AUC = 0.9914, G-Mean = 0.9403, MCC = 0.8846, F1-score = 0.9105\n",
      "      SVM: AUC = 0.9911, G-Mean = 0.9763, MCC = 0.9459, F1-score = 0.9584\n",
      "      SMOTE: AUC = 0.9929, G-Mean = 0.9909, MCC = 0.9668, F1-score = 0.9740\n",
      "      ADASYN: AUC = 0.9929, G-Mean = 0.9909, MCC = 0.9668, F1-score = 0.9740\n",
      "      bSMOTE: AUC = 0.9911, G-Mean = 0.9909, MCC = 0.9668, F1-score = 0.9740\n",
      "      ROS: AUC = 0.9911, G-Mean = 0.9758, MCC = 0.9481, F1-score = 0.9582\n",
      "      MWMOTE: AUC = 0.9912, G-Mean = 0.9867, MCC = 0.9505, F1-score = 0.9610\n",
      "      Trans(Direct): AUC = 0.9911, G-Mean = 0.9815, MCC = 0.9402, F1-score = 0.9524\n",
      "  Fold 8/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.22994, Reg Loss: 0.32193\n",
      "Epoch 200/2000, Avg Loss: 0.19891, Reg Loss: 0.30727\n",
      "Epoch 300/2000, Avg Loss: 0.15162, Reg Loss: 0.28634\n",
      "Epoch 400/2000, Avg Loss: 0.16143, Reg Loss: 0.28866\n",
      "Epoch 500/2000, Avg Loss: 0.13243, Reg Loss: 0.28271\n",
      "Epoch 600/2000, Avg Loss: 0.11393, Reg Loss: 0.27553\n",
      "Epoch 700/2000, Avg Loss: 0.11678, Reg Loss: 0.27501\n",
      "Epoch 800/2000, Avg Loss: 0.12649, Reg Loss: 0.26651\n",
      "Epoch 900/2000, Avg Loss: 0.10372, Reg Loss: 0.28358\n",
      "Epoch 1000/2000, Avg Loss: 0.10364, Reg Loss: 0.26776\n",
      "Epoch 1100/2000, Avg Loss: 0.09503, Reg Loss: 0.26997\n",
      "Epoch 1200/2000, Avg Loss: 0.10033, Reg Loss: 0.26900\n",
      "Epoch 1300/2000, Avg Loss: 0.08815, Reg Loss: 0.27085\n",
      "Epoch 1400/2000, Avg Loss: 0.09036, Reg Loss: 0.28054\n",
      "Epoch 1500/2000, Avg Loss: 0.08818, Reg Loss: 0.26812\n",
      "Epoch 1600/2000, Avg Loss: 0.07782, Reg Loss: 0.25701\n",
      "Epoch 1700/2000, Avg Loss: 0.09851, Reg Loss: 0.26620\n",
      "Epoch 1800/2000, Avg Loss: 0.07897, Reg Loss: 0.25455\n",
      "Epoch 1900/2000, Avg Loss: 0.09075, Reg Loss: 0.25597\n",
      "Epoch 2000/2000, Avg Loss: 0.08472, Reg Loss: 0.25159\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.8927, G-Mean = 0.8564, MCC = 0.7513, F1-score = 0.8045\n",
      "      SMOTEBoost: AUC = 0.9938, G-Mean = 0.9467, MCC = 0.8978, F1-score = 0.9173\n",
      "      RUSBoost: AUC = 0.9297, G-Mean = 0.7679, MCC = 0.5894, F1-score = 0.6878\n",
      "      OUBoost: AUC = 0.9901, G-Mean = 0.9438, MCC = 0.8845, F1-score = 0.9104\n",
      "      SVM: AUC = 0.9766, G-Mean = 0.8543, MCC = 0.8050, F1-score = 0.8386\n",
      "      SMOTE: AUC = 0.9734, G-Mean = 0.9175, MCC = 0.8477, F1-score = 0.8801\n",
      "      ADASYN: AUC = 0.9719, G-Mean = 0.9383, MCC = 0.8725, F1-score = 0.9023\n",
      "      bSMOTE: AUC = 0.9734, G-Mean = 0.9175, MCC = 0.8477, F1-score = 0.8801\n",
      "      ROS: AUC = 0.9719, G-Mean = 0.9043, MCC = 0.8313, F1-score = 0.8662\n",
      "      MWMOTE: AUC = 0.9704, G-Mean = 0.9346, MCC = 0.8582, F1-score = 0.8909\n",
      "      Trans(Direct): AUC = 0.9750, G-Mean = 0.9301, MCC = 0.8492, F1-score = 0.8833\n",
      "  Fold 9/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.23761, Reg Loss: 0.30559\n",
      "Epoch 200/2000, Avg Loss: 0.21034, Reg Loss: 0.29727\n",
      "Epoch 300/2000, Avg Loss: 0.17648, Reg Loss: 0.28192\n",
      "Epoch 400/2000, Avg Loss: 0.16929, Reg Loss: 0.30230\n",
      "Epoch 500/2000, Avg Loss: 0.13755, Reg Loss: 0.29220\n",
      "Epoch 600/2000, Avg Loss: 0.14566, Reg Loss: 0.29121\n",
      "Epoch 700/2000, Avg Loss: 0.11651, Reg Loss: 0.28220\n",
      "Epoch 800/2000, Avg Loss: 0.10271, Reg Loss: 0.28526\n",
      "Epoch 900/2000, Avg Loss: 0.10560, Reg Loss: 0.27641\n",
      "Epoch 1000/2000, Avg Loss: 0.09790, Reg Loss: 0.27228\n",
      "Epoch 1100/2000, Avg Loss: 0.10487, Reg Loss: 0.28896\n",
      "Epoch 1200/2000, Avg Loss: 0.09737, Reg Loss: 0.27204\n",
      "Epoch 1300/2000, Avg Loss: 0.12552, Reg Loss: 0.27886\n",
      "Epoch 1400/2000, Avg Loss: 0.09877, Reg Loss: 0.27965\n",
      "Epoch 1500/2000, Avg Loss: 0.09137, Reg Loss: 0.26956\n",
      "Epoch 1600/2000, Avg Loss: 0.09685, Reg Loss: 0.26802\n",
      "Epoch 1700/2000, Avg Loss: 0.07995, Reg Loss: 0.27080\n",
      "Epoch 1800/2000, Avg Loss: 0.08319, Reg Loss: 0.26371\n",
      "Epoch 1900/2000, Avg Loss: 0.08468, Reg Loss: 0.26028\n",
      "Epoch 2000/2000, Avg Loss: 0.08951, Reg Loss: 0.28186\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.9012, G-Mean = 0.8689, MCC = 0.7660, F1-score = 0.8162\n",
      "      SMOTEBoost: AUC = 0.9917, G-Mean = 0.9491, MCC = 0.8963, F1-score = 0.9164\n",
      "      RUSBoost: AUC = 0.9347, G-Mean = 0.7827, MCC = 0.6031, F1-score = 0.6968\n",
      "      OUBoost: AUC = 0.9898, G-Mean = 0.9465, MCC = 0.8844, F1-score = 0.9102\n",
      "      SVM: AUC = 0.9750, G-Mean = 0.8556, MCC = 0.7975, F1-score = 0.8343\n",
      "      SMOTE: AUC = 0.9722, G-Mean = 0.9231, MCC = 0.8517, F1-score = 0.8833\n",
      "      ADASYN: AUC = 0.9681, G-Mean = 0.9416, MCC = 0.8738, F1-score = 0.9030\n",
      "      bSMOTE: AUC = 0.9708, G-Mean = 0.9231, MCC = 0.8517, F1-score = 0.8833\n",
      "      ROS: AUC = 0.9708, G-Mean = 0.9000, MCC = 0.8209, F1-score = 0.8588\n",
      "      MWMOTE: AUC = 0.9667, G-Mean = 0.9383, MCC = 0.8611, F1-score = 0.8929\n",
      "      Trans(Direct): AUC = 0.9736, G-Mean = 0.9344, MCC = 0.8531, F1-score = 0.8862\n",
      "  Fold 10/10 - Experiment 8/10\n",
      "Epoch 100/2000, Avg Loss: 0.27191, Reg Loss: 0.30882\n",
      "Epoch 200/2000, Avg Loss: 0.20042, Reg Loss: 0.30842\n",
      "Epoch 300/2000, Avg Loss: 0.20554, Reg Loss: 0.31394\n",
      "Epoch 400/2000, Avg Loss: 0.15940, Reg Loss: 0.30963\n",
      "Epoch 500/2000, Avg Loss: 0.16043, Reg Loss: 0.31255\n",
      "Epoch 600/2000, Avg Loss: 0.13957, Reg Loss: 0.29671\n",
      "Epoch 700/2000, Avg Loss: 0.11930, Reg Loss: 0.29275\n",
      "Epoch 800/2000, Avg Loss: 0.11712, Reg Loss: 0.29154\n",
      "Epoch 900/2000, Avg Loss: 0.10627, Reg Loss: 0.28215\n",
      "Epoch 1000/2000, Avg Loss: 0.11242, Reg Loss: 0.28641\n",
      "Epoch 1100/2000, Avg Loss: 0.09218, Reg Loss: 0.28190\n",
      "Epoch 1200/2000, Avg Loss: 0.10090, Reg Loss: 0.27747\n",
      "Epoch 1300/2000, Avg Loss: 0.09376, Reg Loss: 0.27348\n",
      "Epoch 1400/2000, Avg Loss: 0.10273, Reg Loss: 0.28292\n",
      "Epoch 1500/2000, Avg Loss: 0.10482, Reg Loss: 0.27330\n",
      "Epoch 1600/2000, Avg Loss: 0.11807, Reg Loss: 0.27910\n",
      "Epoch 1700/2000, Avg Loss: 0.10686, Reg Loss: 0.27251\n",
      "Epoch 1800/2000, Avg Loss: 0.10606, Reg Loss: 0.28481\n",
      "Epoch 1900/2000, Avg Loss: 0.09830, Reg Loss: 0.27228\n",
      "Epoch 2000/2000, Avg Loss: 0.11682, Reg Loss: 0.27472\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.8848, G-Mean = 0.8544, MCC = 0.7369, F1-score = 0.7945\n",
      "      SMOTEBoost: AUC = 0.9688, G-Mean = 0.9133, MCC = 0.8365, F1-score = 0.8692\n",
      "      RUSBoost: AUC = 0.9262, G-Mean = 0.7819, MCC = 0.5910, F1-score = 0.6887\n",
      "      OUBoost: AUC = 0.9677, G-Mean = 0.9243, MCC = 0.8435, F1-score = 0.8792\n",
      "      SVM: AUC = 0.9638, G-Mean = 0.8450, MCC = 0.7761, F1-score = 0.8176\n",
      "      SMOTE: AUC = 0.9625, G-Mean = 0.9058, MCC = 0.8248, F1-score = 0.8616\n",
      "      ADASYN: AUC = 0.9613, G-Mean = 0.9341, MCC = 0.8602, F1-score = 0.8927\n",
      "      bSMOTE: AUC = 0.9637, G-Mean = 0.9174, MCC = 0.8403, F1-score = 0.8749\n",
      "      ROS: AUC = 0.9587, G-Mean = 0.8850, MCC = 0.7971, F1-score = 0.8396\n",
      "      MWMOTE: AUC = 0.9601, G-Mean = 0.9311, MCC = 0.8487, F1-score = 0.8836\n",
      "      Trans(Direct): AUC = 0.9663, G-Mean = 0.9275, MCC = 0.8415, F1-score = 0.8776\n",
      "\n",
      "Starting experiment 9/10\n",
      "  Fold 1/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.28897, Reg Loss: 0.46887\n",
      "Epoch 200/2000, Avg Loss: 0.22832, Reg Loss: 0.47211\n",
      "Epoch 300/2000, Avg Loss: 0.18766, Reg Loss: 0.45293\n",
      "Epoch 400/2000, Avg Loss: 0.16570, Reg Loss: 0.45290\n",
      "Epoch 500/2000, Avg Loss: 0.17649, Reg Loss: 0.45910\n",
      "Epoch 600/2000, Avg Loss: 0.14553, Reg Loss: 0.45460\n",
      "Epoch 700/2000, Avg Loss: 0.15893, Reg Loss: 0.44755\n",
      "Epoch 800/2000, Avg Loss: 0.11442, Reg Loss: 0.44819\n",
      "Epoch 900/2000, Avg Loss: 0.13406, Reg Loss: 0.44086\n",
      "Epoch 1000/2000, Avg Loss: 0.13549, Reg Loss: 0.43079\n",
      "Epoch 1100/2000, Avg Loss: 0.13042, Reg Loss: 0.43363\n",
      "Epoch 1200/2000, Avg Loss: 0.12513, Reg Loss: 0.44886\n",
      "Epoch 1300/2000, Avg Loss: 0.10255, Reg Loss: 0.44103\n",
      "Epoch 1400/2000, Avg Loss: 0.11353, Reg Loss: 0.44464\n",
      "Epoch 1500/2000, Avg Loss: 0.14850, Reg Loss: 0.45337\n",
      "Epoch 1600/2000, Avg Loss: 0.11492, Reg Loss: 0.43926\n",
      "Epoch 1700/2000, Avg Loss: 0.11081, Reg Loss: 0.43050\n",
      "Epoch 1800/2000, Avg Loss: 0.10203, Reg Loss: 0.42754\n",
      "Epoch 1900/2000, Avg Loss: 0.09545, Reg Loss: 0.43469\n",
      "Epoch 2000/2000, Avg Loss: 0.11011, Reg Loss: 0.42796\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.9706, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      SMOTEBoost: AUC = 0.9588, G-Mean = 0.9393, MCC = 0.7939, F1-score = 0.8333\n",
      "      RUSBoost: AUC = 0.9765, G-Mean = 0.9393, MCC = 0.7939, F1-score = 0.8333\n",
      "      OUBoost: AUC = 0.9882, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      SVM: AUC = 0.9647, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      SMOTE: AUC = 0.9412, G-Mean = 0.9393, MCC = 0.7939, F1-score = 0.8333\n",
      "      ADASYN: AUC = 0.9412, G-Mean = 0.9393, MCC = 0.7939, F1-score = 0.8333\n",
      "      bSMOTE: AUC = 0.9529, G-Mean = 0.9393, MCC = 0.7939, F1-score = 0.8333\n",
      "      ROS: AUC = 0.9647, G-Mean = 0.9393, MCC = 0.7939, F1-score = 0.8333\n",
      "      MWMOTE: AUC = 0.9294, G-Mean = 0.9393, MCC = 0.7939, F1-score = 0.8333\n",
      "      Trans(Direct): AUC = 0.9647, G-Mean = 0.9393, MCC = 0.7939, F1-score = 0.8333\n",
      "  Fold 2/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.22584, Reg Loss: 0.30406\n",
      "Epoch 200/2000, Avg Loss: 0.20303, Reg Loss: 0.31166\n",
      "Epoch 300/2000, Avg Loss: 0.19074, Reg Loss: 0.30711\n",
      "Epoch 400/2000, Avg Loss: 0.14661, Reg Loss: 0.28861\n",
      "Epoch 500/2000, Avg Loss: 0.16070, Reg Loss: 0.30337\n",
      "Epoch 600/2000, Avg Loss: 0.16406, Reg Loss: 0.30500\n",
      "Epoch 700/2000, Avg Loss: 0.12608, Reg Loss: 0.28543\n",
      "Epoch 800/2000, Avg Loss: 0.12312, Reg Loss: 0.28440\n",
      "Epoch 900/2000, Avg Loss: 0.11860, Reg Loss: 0.28476\n",
      "Epoch 1000/2000, Avg Loss: 0.09702, Reg Loss: 0.27605\n",
      "Epoch 1100/2000, Avg Loss: 0.10932, Reg Loss: 0.28254\n",
      "Epoch 1200/2000, Avg Loss: 0.09369, Reg Loss: 0.26189\n",
      "Epoch 1300/2000, Avg Loss: 0.10722, Reg Loss: 0.28414\n",
      "Epoch 1400/2000, Avg Loss: 0.09919, Reg Loss: 0.27785\n",
      "Epoch 1500/2000, Avg Loss: 0.09717, Reg Loss: 0.27101\n",
      "Epoch 1600/2000, Avg Loss: 0.09645, Reg Loss: 0.26989\n",
      "Epoch 1700/2000, Avg Loss: 0.08349, Reg Loss: 0.25590\n",
      "Epoch 1800/2000, Avg Loss: 0.10212, Reg Loss: 0.26809\n",
      "Epoch 1900/2000, Avg Loss: 0.10225, Reg Loss: 0.26601\n",
      "Epoch 2000/2000, Avg Loss: 0.08708, Reg Loss: 0.26060\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.9353, G-Mean = 0.9323, MCC = 0.8774, F1-score = 0.8990\n",
      "      SMOTEBoost: AUC = 0.9794, G-Mean = 0.9169, MCC = 0.8316, F1-score = 0.8611\n",
      "      RUSBoost: AUC = 0.9471, G-Mean = 0.8532, MCC = 0.6445, F1-score = 0.7108\n",
      "      OUBoost: AUC = 0.9941, G-Mean = 0.9323, MCC = 0.8774, F1-score = 0.8990\n",
      "      SVM: AUC = 0.9765, G-Mean = 0.9323, MCC = 0.8774, F1-score = 0.8990\n",
      "      SMOTE: AUC = 0.9706, G-Mean = 0.9697, MCC = 0.8969, F1-score = 0.9167\n",
      "      ADASYN: AUC = 0.9706, G-Mean = 0.9697, MCC = 0.8969, F1-score = 0.9167\n",
      "      bSMOTE: AUC = 0.9765, G-Mean = 0.9697, MCC = 0.8969, F1-score = 0.9167\n",
      "      ROS: AUC = 0.9824, G-Mean = 0.9697, MCC = 0.8969, F1-score = 0.9167\n",
      "      MWMOTE: AUC = 0.9647, G-Mean = 0.9697, MCC = 0.8969, F1-score = 0.9167\n",
      "      Trans(Direct): AUC = 0.9824, G-Mean = 0.9697, MCC = 0.8969, F1-score = 0.9167\n",
      "  Fold 3/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.28673, Reg Loss: 0.31234\n",
      "Epoch 200/2000, Avg Loss: 0.22679, Reg Loss: 0.29780\n",
      "Epoch 300/2000, Avg Loss: 0.17083, Reg Loss: 0.30069\n",
      "Epoch 400/2000, Avg Loss: 0.15727, Reg Loss: 0.30395\n",
      "Epoch 500/2000, Avg Loss: 0.16066, Reg Loss: 0.29769\n",
      "Epoch 600/2000, Avg Loss: 0.15906, Reg Loss: 0.30855\n",
      "Epoch 700/2000, Avg Loss: 0.13273, Reg Loss: 0.29096\n",
      "Epoch 800/2000, Avg Loss: 0.13176, Reg Loss: 0.28812\n",
      "Epoch 900/2000, Avg Loss: 0.13638, Reg Loss: 0.29067\n",
      "Epoch 1000/2000, Avg Loss: 0.13400, Reg Loss: 0.29044\n",
      "Epoch 1100/2000, Avg Loss: 0.13026, Reg Loss: 0.29709\n",
      "Epoch 1200/2000, Avg Loss: 0.11634, Reg Loss: 0.29225\n",
      "Epoch 1300/2000, Avg Loss: 0.13038, Reg Loss: 0.30277\n",
      "Epoch 1400/2000, Avg Loss: 0.11642, Reg Loss: 0.28572\n",
      "Epoch 1500/2000, Avg Loss: 0.09418, Reg Loss: 0.27318\n",
      "Epoch 1600/2000, Avg Loss: 0.11435, Reg Loss: 0.28634\n",
      "Epoch 1700/2000, Avg Loss: 0.10368, Reg Loss: 0.28136\n",
      "Epoch 1800/2000, Avg Loss: 0.10274, Reg Loss: 0.27962\n",
      "Epoch 1900/2000, Avg Loss: 0.09145, Reg Loss: 0.27701\n",
      "Epoch 2000/2000, Avg Loss: 0.10172, Reg Loss: 0.27110\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.9569, G-Mean = 0.9549, MCC = 0.9183, F1-score = 0.9327\n",
      "      SMOTEBoost: AUC = 0.9863, G-Mean = 0.9340, MCC = 0.8532, F1-score = 0.8818\n",
      "      RUSBoost: AUC = 0.9647, G-Mean = 0.8323, MCC = 0.6160, F1-score = 0.6961\n",
      "      OUBoost: AUC = 0.9961, G-Mean = 0.9443, MCC = 0.8838, F1-score = 0.9070\n",
      "      SVM: AUC = 0.9808, G-Mean = 0.9443, MCC = 0.8838, F1-score = 0.9070\n",
      "      SMOTE: AUC = 0.9769, G-Mean = 0.9692, MCC = 0.8968, F1-score = 0.9188\n",
      "      ADASYN: AUC = 0.9804, G-Mean = 0.9692, MCC = 0.8968, F1-score = 0.9188\n",
      "      bSMOTE: AUC = 0.9808, G-Mean = 0.9692, MCC = 0.8968, F1-score = 0.9188\n",
      "      ROS: AUC = 0.9848, G-Mean = 0.9692, MCC = 0.8968, F1-score = 0.9188\n",
      "      MWMOTE: AUC = 0.9730, G-Mean = 0.9692, MCC = 0.8968, F1-score = 0.9188\n",
      "      Trans(Direct): AUC = 0.9848, G-Mean = 0.9692, MCC = 0.8968, F1-score = 0.9188\n",
      "  Fold 4/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.24719, Reg Loss: 0.30802\n",
      "Epoch 200/2000, Avg Loss: 0.20762, Reg Loss: 0.31178\n",
      "Epoch 300/2000, Avg Loss: 0.18074, Reg Loss: 0.31479\n",
      "Epoch 400/2000, Avg Loss: 0.17616, Reg Loss: 0.31109\n",
      "Epoch 500/2000, Avg Loss: 0.13615, Reg Loss: 0.29134\n",
      "Epoch 600/2000, Avg Loss: 0.14343, Reg Loss: 0.30844\n",
      "Epoch 700/2000, Avg Loss: 0.14451, Reg Loss: 0.30171\n",
      "Epoch 800/2000, Avg Loss: 0.13685, Reg Loss: 0.30471\n",
      "Epoch 900/2000, Avg Loss: 0.11411, Reg Loss: 0.30082\n",
      "Epoch 1000/2000, Avg Loss: 0.09680, Reg Loss: 0.30019\n",
      "Epoch 1100/2000, Avg Loss: 0.09599, Reg Loss: 0.30116\n",
      "Epoch 1200/2000, Avg Loss: 0.12193, Reg Loss: 0.28490\n",
      "Epoch 1300/2000, Avg Loss: 0.11668, Reg Loss: 0.28658\n",
      "Epoch 1400/2000, Avg Loss: 0.10242, Reg Loss: 0.27861\n",
      "Epoch 1500/2000, Avg Loss: 0.13427, Reg Loss: 0.28576\n",
      "Epoch 1600/2000, Avg Loss: 0.09921, Reg Loss: 0.27424\n",
      "Epoch 1700/2000, Avg Loss: 0.09655, Reg Loss: 0.28265\n",
      "Epoch 1800/2000, Avg Loss: 0.08654, Reg Loss: 0.27865\n",
      "Epoch 1900/2000, Avg Loss: 0.09135, Reg Loss: 0.27629\n",
      "Epoch 2000/2000, Avg Loss: 0.09976, Reg Loss: 0.27071\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.9348, G-Mean = 0.9326, MCC = 0.8731, F1-score = 0.8995\n",
      "      SMOTEBoost: AUC = 0.9803, G-Mean = 0.9426, MCC = 0.8609, F1-score = 0.8886\n",
      "      RUSBoost: AUC = 0.9735, G-Mean = 0.8496, MCC = 0.6401, F1-score = 0.7144\n",
      "      OUBoost: AUC = 0.9814, G-Mean = 0.9098, MCC = 0.8012, F1-score = 0.8469\n",
      "      SVM: AUC = 0.9763, G-Mean = 0.9247, MCC = 0.8472, F1-score = 0.8803\n",
      "      SMOTE: AUC = 0.9764, G-Mean = 0.9690, MCC = 0.8935, F1-score = 0.9164\n",
      "      ADASYN: AUC = 0.9790, G-Mean = 0.9690, MCC = 0.8935, F1-score = 0.9164\n",
      "      bSMOTE: AUC = 0.9763, G-Mean = 0.9690, MCC = 0.8935, F1-score = 0.9164\n",
      "      ROS: AUC = 0.9792, G-Mean = 0.9690, MCC = 0.8935, F1-score = 0.9164\n",
      "      MWMOTE: AUC = 0.9735, G-Mean = 0.9690, MCC = 0.8935, F1-score = 0.9164\n",
      "      Trans(Direct): AUC = 0.9792, G-Mean = 0.9690, MCC = 0.8935, F1-score = 0.9164\n",
      "  Fold 5/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.26143, Reg Loss: 0.32916\n",
      "Epoch 200/2000, Avg Loss: 0.19357, Reg Loss: 0.31438\n",
      "Epoch 300/2000, Avg Loss: 0.16751, Reg Loss: 0.30828\n",
      "Epoch 400/2000, Avg Loss: 0.16870, Reg Loss: 0.30045\n",
      "Epoch 500/2000, Avg Loss: 0.13568, Reg Loss: 0.31455\n",
      "Epoch 600/2000, Avg Loss: 0.12464, Reg Loss: 0.30557\n",
      "Epoch 700/2000, Avg Loss: 0.12495, Reg Loss: 0.31104\n",
      "Epoch 800/2000, Avg Loss: 0.13182, Reg Loss: 0.30426\n",
      "Epoch 900/2000, Avg Loss: 0.13638, Reg Loss: 0.30068\n",
      "Epoch 1000/2000, Avg Loss: 0.11738, Reg Loss: 0.28850\n",
      "Epoch 1100/2000, Avg Loss: 0.09102, Reg Loss: 0.30055\n",
      "Epoch 1200/2000, Avg Loss: 0.14088, Reg Loss: 0.29227\n",
      "Epoch 1300/2000, Avg Loss: 0.11856, Reg Loss: 0.30801\n",
      "Epoch 1400/2000, Avg Loss: 0.10481, Reg Loss: 0.29268\n",
      "Epoch 1500/2000, Avg Loss: 0.08527, Reg Loss: 0.29514\n",
      "Epoch 1600/2000, Avg Loss: 0.08703, Reg Loss: 0.29672\n",
      "Epoch 1700/2000, Avg Loss: 0.08687, Reg Loss: 0.29194\n",
      "Epoch 1800/2000, Avg Loss: 0.09991, Reg Loss: 0.29508\n",
      "Epoch 1900/2000, Avg Loss: 0.10064, Reg Loss: 0.29295\n",
      "Epoch 2000/2000, Avg Loss: 0.10420, Reg Loss: 0.29180\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.9279, G-Mean = 0.9250, MCC = 0.8720, F1-score = 0.8974\n",
      "      SMOTEBoost: AUC = 0.9843, G-Mean = 0.9541, MCC = 0.8887, F1-score = 0.9109\n",
      "      RUSBoost: AUC = 0.9788, G-Mean = 0.8667, MCC = 0.6702, F1-score = 0.7382\n",
      "      OUBoost: AUC = 0.9851, G-Mean = 0.9278, MCC = 0.8409, F1-score = 0.8775\n",
      "      SVM: AUC = 0.9810, G-Mean = 0.9398, MCC = 0.8778, F1-score = 0.9042\n",
      "      SMOTE: AUC = 0.9812, G-Mean = 0.9752, MCC = 0.9148, F1-score = 0.9331\n",
      "      ADASYN: AUC = 0.9832, G-Mean = 0.9752, MCC = 0.9148, F1-score = 0.9331\n",
      "      bSMOTE: AUC = 0.9810, G-Mean = 0.9752, MCC = 0.9148, F1-score = 0.9331\n",
      "      ROS: AUC = 0.9834, G-Mean = 0.9752, MCC = 0.9148, F1-score = 0.9331\n",
      "      MWMOTE: AUC = 0.9788, G-Mean = 0.9752, MCC = 0.9148, F1-score = 0.9331\n",
      "      Trans(Direct): AUC = 0.9834, G-Mean = 0.9752, MCC = 0.9148, F1-score = 0.9331\n",
      "  Fold 6/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.22479, Reg Loss: 0.30065\n",
      "Epoch 200/2000, Avg Loss: 0.24767, Reg Loss: 0.30981\n",
      "Epoch 300/2000, Avg Loss: 0.18374, Reg Loss: 0.28931\n",
      "Epoch 400/2000, Avg Loss: 0.15846, Reg Loss: 0.28684\n",
      "Epoch 500/2000, Avg Loss: 0.16000, Reg Loss: 0.28919\n",
      "Epoch 600/2000, Avg Loss: 0.13462, Reg Loss: 0.30083\n",
      "Epoch 700/2000, Avg Loss: 0.10931, Reg Loss: 0.28180\n",
      "Epoch 800/2000, Avg Loss: 0.12559, Reg Loss: 0.29515\n",
      "Epoch 900/2000, Avg Loss: 0.10952, Reg Loss: 0.27129\n",
      "Epoch 1000/2000, Avg Loss: 0.08430, Reg Loss: 0.28426\n",
      "Epoch 1100/2000, Avg Loss: 0.10670, Reg Loss: 0.27403\n",
      "Epoch 1200/2000, Avg Loss: 0.11648, Reg Loss: 0.29128\n",
      "Epoch 1300/2000, Avg Loss: 0.09290, Reg Loss: 0.27268\n",
      "Epoch 1400/2000, Avg Loss: 0.08705, Reg Loss: 0.25516\n",
      "Epoch 1500/2000, Avg Loss: 0.06676, Reg Loss: 0.25940\n",
      "Epoch 1600/2000, Avg Loss: 0.08778, Reg Loss: 0.26877\n",
      "Epoch 1700/2000, Avg Loss: 0.08039, Reg Loss: 0.26242\n",
      "Epoch 1800/2000, Avg Loss: 0.07662, Reg Loss: 0.25759\n",
      "Epoch 1900/2000, Avg Loss: 0.09764, Reg Loss: 0.25876\n",
      "Epoch 2000/2000, Avg Loss: 0.09217, Reg Loss: 0.26607\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.9399, G-Mean = 0.9375, MCC = 0.8933, F1-score = 0.9145\n",
      "      SMOTEBoost: AUC = 0.9869, G-Mean = 0.9617, MCC = 0.9072, F1-score = 0.9257\n",
      "      RUSBoost: AUC = 0.9824, G-Mean = 0.8605, MCC = 0.6562, F1-score = 0.7262\n",
      "      OUBoost: AUC = 0.9876, G-Mean = 0.9345, MCC = 0.8481, F1-score = 0.8828\n",
      "      SVM: AUC = 0.9842, G-Mean = 0.9498, MCC = 0.8981, F1-score = 0.9202\n",
      "      SMOTE: AUC = 0.9843, G-Mean = 0.9793, MCC = 0.9290, F1-score = 0.9443\n",
      "      ADASYN: AUC = 0.9860, G-Mean = 0.9793, MCC = 0.9290, F1-score = 0.9443\n",
      "      bSMOTE: AUC = 0.9842, G-Mean = 0.9793, MCC = 0.9290, F1-score = 0.9443\n",
      "      ROS: AUC = 0.9861, G-Mean = 0.9793, MCC = 0.9290, F1-score = 0.9443\n",
      "      MWMOTE: AUC = 0.9823, G-Mean = 0.9793, MCC = 0.9290, F1-score = 0.9443\n",
      "      Trans(Direct): AUC = 0.9861, G-Mean = 0.9793, MCC = 0.9290, F1-score = 0.9443\n",
      "  Fold 7/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.23419, Reg Loss: 0.38903\n",
      "Epoch 200/2000, Avg Loss: 0.22439, Reg Loss: 0.36471\n",
      "Epoch 300/2000, Avg Loss: 0.16356, Reg Loss: 0.35466\n",
      "Epoch 400/2000, Avg Loss: 0.13867, Reg Loss: 0.34817\n",
      "Epoch 500/2000, Avg Loss: 0.14136, Reg Loss: 0.34704\n",
      "Epoch 600/2000, Avg Loss: 0.12754, Reg Loss: 0.34551\n",
      "Epoch 700/2000, Avg Loss: 0.12049, Reg Loss: 0.33973\n",
      "Epoch 800/2000, Avg Loss: 0.11924, Reg Loss: 0.32714\n",
      "Epoch 900/2000, Avg Loss: 0.09977, Reg Loss: 0.32877\n",
      "Epoch 1000/2000, Avg Loss: 0.10597, Reg Loss: 0.32603\n",
      "Epoch 1100/2000, Avg Loss: 0.12096, Reg Loss: 0.31429\n",
      "Epoch 1200/2000, Avg Loss: 0.09086, Reg Loss: 0.30365\n",
      "Epoch 1300/2000, Avg Loss: 0.13034, Reg Loss: 0.31163\n",
      "Epoch 1400/2000, Avg Loss: 0.10379, Reg Loss: 0.30929\n",
      "Epoch 1500/2000, Avg Loss: 0.11548, Reg Loss: 0.32512\n",
      "Epoch 1600/2000, Avg Loss: 0.08819, Reg Loss: 0.31060\n",
      "Epoch 1700/2000, Avg Loss: 0.08302, Reg Loss: 0.29305\n",
      "Epoch 1800/2000, Avg Loss: 0.08995, Reg Loss: 0.31303\n",
      "Epoch 1900/2000, Avg Loss: 0.09566, Reg Loss: 0.30494\n",
      "Epoch 2000/2000, Avg Loss: 0.10526, Reg Loss: 0.30769\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.9297, G-Mean = 0.9273, MCC = 0.8711, F1-score = 0.8981\n",
      "      SMOTEBoost: AUC = 0.9852, G-Mean = 0.9626, MCC = 0.9039, F1-score = 0.9234\n",
      "      RUSBoost: AUC = 0.9759, G-Mean = 0.8505, MCC = 0.6386, F1-score = 0.7118\n",
      "      OUBoost: AUC = 0.9867, G-Mean = 0.9394, MCC = 0.8532, F1-score = 0.8866\n",
      "      SVM: AUC = 0.9846, G-Mean = 0.9524, MCC = 0.8961, F1-score = 0.9186\n",
      "      SMOTE: AUC = 0.9830, G-Mean = 0.9777, MCC = 0.9226, F1-score = 0.9392\n",
      "      ADASYN: AUC = 0.9845, G-Mean = 0.9777, MCC = 0.9226, F1-score = 0.9392\n",
      "      bSMOTE: AUC = 0.9829, G-Mean = 0.9777, MCC = 0.9226, F1-score = 0.9392\n",
      "      ROS: AUC = 0.9845, G-Mean = 0.9777, MCC = 0.9226, F1-score = 0.9392\n",
      "      MWMOTE: AUC = 0.9795, G-Mean = 0.9777, MCC = 0.9226, F1-score = 0.9392\n",
      "      Trans(Direct): AUC = 0.9863, G-Mean = 0.9777, MCC = 0.9226, F1-score = 0.9392\n",
      "  Fold 8/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.21085, Reg Loss: 0.28467\n",
      "Epoch 200/2000, Avg Loss: 0.18226, Reg Loss: 0.29577\n",
      "Epoch 300/2000, Avg Loss: 0.16245, Reg Loss: 0.30444\n",
      "Epoch 400/2000, Avg Loss: 0.15700, Reg Loss: 0.29999\n",
      "Epoch 500/2000, Avg Loss: 0.12600, Reg Loss: 0.28983\n",
      "Epoch 600/2000, Avg Loss: 0.12405, Reg Loss: 0.28414\n",
      "Epoch 700/2000, Avg Loss: 0.11031, Reg Loss: 0.26754\n",
      "Epoch 800/2000, Avg Loss: 0.10228, Reg Loss: 0.28562\n",
      "Epoch 900/2000, Avg Loss: 0.09289, Reg Loss: 0.27540\n",
      "Epoch 1000/2000, Avg Loss: 0.08706, Reg Loss: 0.28001\n",
      "Epoch 1100/2000, Avg Loss: 0.11051, Reg Loss: 0.27394\n",
      "Epoch 1200/2000, Avg Loss: 0.09729, Reg Loss: 0.27284\n",
      "Epoch 1300/2000, Avg Loss: 0.09797, Reg Loss: 0.26775\n",
      "Epoch 1400/2000, Avg Loss: 0.07743, Reg Loss: 0.27089\n",
      "Epoch 1500/2000, Avg Loss: 0.08756, Reg Loss: 0.27244\n",
      "Epoch 1600/2000, Avg Loss: 0.09494, Reg Loss: 0.27494\n",
      "Epoch 1700/2000, Avg Loss: 0.08924, Reg Loss: 0.26999\n",
      "Epoch 1800/2000, Avg Loss: 0.09226, Reg Loss: 0.26581\n",
      "Epoch 1900/2000, Avg Loss: 0.10572, Reg Loss: 0.27258\n",
      "Epoch 2000/2000, Avg Loss: 0.08129, Reg Loss: 0.26568\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.9330, G-Mean = 0.9324, MCC = 0.8727, F1-score = 0.8995\n",
      "      SMOTEBoost: AUC = 0.9824, G-Mean = 0.9506, MCC = 0.8831, F1-score = 0.9079\n",
      "      RUSBoost: AUC = 0.9750, G-Mean = 0.8611, MCC = 0.6576, F1-score = 0.7270\n",
      "      OUBoost: AUC = 0.9852, G-Mean = 0.9302, MCC = 0.8387, F1-score = 0.8757\n",
      "      SVM: AUC = 0.9834, G-Mean = 0.9416, MCC = 0.8763, F1-score = 0.9038\n",
      "      SMOTE: AUC = 0.9820, G-Mean = 0.9493, MCC = 0.8801, F1-score = 0.9052\n",
      "      ADASYN: AUC = 0.9833, G-Mean = 0.9493, MCC = 0.8801, F1-score = 0.9052\n",
      "      bSMOTE: AUC = 0.9819, G-Mean = 0.9638, MCC = 0.8994, F1-score = 0.9218\n",
      "      ROS: AUC = 0.9833, G-Mean = 0.9493, MCC = 0.8801, F1-score = 0.9052\n",
      "      MWMOTE: AUC = 0.9789, G-Mean = 0.9638, MCC = 0.8994, F1-score = 0.9218\n",
      "      Trans(Direct): AUC = 0.9849, G-Mean = 0.9638, MCC = 0.8994, F1-score = 0.9218\n",
      "  Fold 9/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.23774, Reg Loss: 0.30713\n",
      "Epoch 200/2000, Avg Loss: 0.18208, Reg Loss: 0.30605\n",
      "Epoch 300/2000, Avg Loss: 0.16186, Reg Loss: 0.30661\n",
      "Epoch 400/2000, Avg Loss: 0.16963, Reg Loss: 0.31197\n",
      "Epoch 500/2000, Avg Loss: 0.14070, Reg Loss: 0.31303\n",
      "Epoch 600/2000, Avg Loss: 0.12587, Reg Loss: 0.30836\n",
      "Epoch 700/2000, Avg Loss: 0.12916, Reg Loss: 0.30785\n",
      "Epoch 800/2000, Avg Loss: 0.12434, Reg Loss: 0.30743\n",
      "Epoch 900/2000, Avg Loss: 0.12541, Reg Loss: 0.29917\n",
      "Epoch 1000/2000, Avg Loss: 0.10708, Reg Loss: 0.28141\n",
      "Epoch 1100/2000, Avg Loss: 0.11112, Reg Loss: 0.29263\n",
      "Epoch 1200/2000, Avg Loss: 0.11418, Reg Loss: 0.28923\n",
      "Epoch 1300/2000, Avg Loss: 0.08719, Reg Loss: 0.28141\n",
      "Epoch 1400/2000, Avg Loss: 0.10756, Reg Loss: 0.29322\n",
      "Epoch 1500/2000, Avg Loss: 0.14720, Reg Loss: 0.30491\n",
      "Epoch 1600/2000, Avg Loss: 0.09588, Reg Loss: 0.29281\n",
      "Epoch 1700/2000, Avg Loss: 0.10053, Reg Loss: 0.28177\n",
      "Epoch 1800/2000, Avg Loss: 0.09405, Reg Loss: 0.26875\n",
      "Epoch 1900/2000, Avg Loss: 0.08511, Reg Loss: 0.28132\n",
      "Epoch 2000/2000, Avg Loss: 0.09117, Reg Loss: 0.28143\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.9148, G-Mean = 0.9121, MCC = 0.8405, F1-score = 0.8736\n",
      "      SMOTEBoost: AUC = 0.9697, G-Mean = 0.9412, MCC = 0.8669, F1-score = 0.8959\n",
      "      RUSBoost: AUC = 0.9674, G-Mean = 0.8550, MCC = 0.6460, F1-score = 0.7203\n",
      "      OUBoost: AUC = 0.9730, G-Mean = 0.9102, MCC = 0.8103, F1-score = 0.8525\n",
      "      SVM: AUC = 0.9825, G-Mean = 0.9364, MCC = 0.8753, F1-score = 0.9021\n",
      "      SMOTE: AUC = 0.9812, G-Mean = 0.9432, MCC = 0.8788, F1-score = 0.9033\n",
      "      ADASYN: AUC = 0.9824, G-Mean = 0.9432, MCC = 0.8788, F1-score = 0.9033\n",
      "      bSMOTE: AUC = 0.9797, G-Mean = 0.9561, MCC = 0.8959, F1-score = 0.9182\n",
      "      ROS: AUC = 0.9824, G-Mean = 0.9432, MCC = 0.8788, F1-score = 0.9033\n",
      "      MWMOTE: AUC = 0.9785, G-Mean = 0.9561, MCC = 0.8959, F1-score = 0.9182\n",
      "      Trans(Direct): AUC = 0.9838, G-Mean = 0.9561, MCC = 0.8959, F1-score = 0.9182\n",
      "  Fold 10/10 - Experiment 9/10\n",
      "Epoch 100/2000, Avg Loss: 0.22329, Reg Loss: 0.30447\n",
      "Epoch 200/2000, Avg Loss: 0.17717, Reg Loss: 0.31114\n",
      "Epoch 300/2000, Avg Loss: 0.15761, Reg Loss: 0.29497\n",
      "Epoch 400/2000, Avg Loss: 0.12694, Reg Loss: 0.30029\n",
      "Epoch 500/2000, Avg Loss: 0.18049, Reg Loss: 0.31226\n",
      "Epoch 600/2000, Avg Loss: 0.14115, Reg Loss: 0.29912\n",
      "Epoch 700/2000, Avg Loss: 0.13810, Reg Loss: 0.28848\n",
      "Epoch 800/2000, Avg Loss: 0.11040, Reg Loss: 0.28040\n",
      "Epoch 900/2000, Avg Loss: 0.09490, Reg Loss: 0.25968\n",
      "Epoch 1000/2000, Avg Loss: 0.10664, Reg Loss: 0.28448\n",
      "Epoch 1100/2000, Avg Loss: 0.08489, Reg Loss: 0.26228\n",
      "Epoch 1200/2000, Avg Loss: 0.08393, Reg Loss: 0.26986\n",
      "Epoch 1300/2000, Avg Loss: 0.11571, Reg Loss: 0.26174\n",
      "Epoch 1400/2000, Avg Loss: 0.08481, Reg Loss: 0.26903\n",
      "Epoch 1500/2000, Avg Loss: 0.09133, Reg Loss: 0.26510\n",
      "Epoch 1600/2000, Avg Loss: 0.09443, Reg Loss: 0.26076\n",
      "Epoch 1700/2000, Avg Loss: 0.07237, Reg Loss: 0.26132\n",
      "Epoch 1800/2000, Avg Loss: 0.08924, Reg Loss: 0.26250\n",
      "Epoch 1900/2000, Avg Loss: 0.07805, Reg Loss: 0.24931\n",
      "Epoch 2000/2000, Avg Loss: 0.07975, Reg Loss: 0.24791\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.9071, G-Mean = 0.9046, MCC = 0.8201, F1-score = 0.8590\n",
      "      SMOTEBoost: AUC = 0.9703, G-Mean = 0.9406, MCC = 0.8593, F1-score = 0.8897\n",
      "      RUSBoost: AUC = 0.9644, G-Mean = 0.8630, MCC = 0.6605, F1-score = 0.7316\n",
      "      OUBoost: AUC = 0.9694, G-Mean = 0.9127, MCC = 0.8083, F1-score = 0.8506\n",
      "      SVM: AUC = 0.9805, G-Mean = 0.9294, MCC = 0.8615, F1-score = 0.8919\n",
      "      SMOTE: AUC = 0.9818, G-Mean = 0.9355, MCC = 0.8646, F1-score = 0.8930\n",
      "      ADASYN: AUC = 0.9816, G-Mean = 0.9325, MCC = 0.8545, F1-score = 0.8857\n",
      "      bSMOTE: AUC = 0.9805, G-Mean = 0.9471, MCC = 0.8801, F1-score = 0.9063\n",
      "      ROS: AUC = 0.9817, G-Mean = 0.9355, MCC = 0.8646, F1-score = 0.8930\n",
      "      MWMOTE: AUC = 0.9769, G-Mean = 0.9441, MCC = 0.8700, F1-score = 0.8991\n",
      "      Trans(Direct): AUC = 0.9842, G-Mean = 0.9573, MCC = 0.8947, F1-score = 0.9173\n",
      "\n",
      "Starting experiment 10/10\n",
      "  Fold 1/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.23097, Reg Loss: 0.31491\n",
      "Epoch 200/2000, Avg Loss: 0.18484, Reg Loss: 0.30850\n",
      "Epoch 300/2000, Avg Loss: 0.16805, Reg Loss: 0.30741\n",
      "Epoch 400/2000, Avg Loss: 0.15462, Reg Loss: 0.30636\n",
      "Epoch 500/2000, Avg Loss: 0.14666, Reg Loss: 0.30162\n",
      "Epoch 600/2000, Avg Loss: 0.12427, Reg Loss: 0.30748\n",
      "Epoch 700/2000, Avg Loss: 0.11079, Reg Loss: 0.30797\n",
      "Epoch 800/2000, Avg Loss: 0.11592, Reg Loss: 0.30996\n",
      "Epoch 900/2000, Avg Loss: 0.10213, Reg Loss: 0.29879\n",
      "Epoch 1000/2000, Avg Loss: 0.10879, Reg Loss: 0.29616\n",
      "Epoch 1100/2000, Avg Loss: 0.12538, Reg Loss: 0.29823\n",
      "Epoch 1200/2000, Avg Loss: 0.09927, Reg Loss: 0.27585\n",
      "Epoch 1300/2000, Avg Loss: 0.10448, Reg Loss: 0.29090\n",
      "Epoch 1400/2000, Avg Loss: 0.08520, Reg Loss: 0.27516\n",
      "Epoch 1500/2000, Avg Loss: 0.09938, Reg Loss: 0.28620\n",
      "Epoch 1600/2000, Avg Loss: 0.11198, Reg Loss: 0.27840\n",
      "Epoch 1700/2000, Avg Loss: 0.10384, Reg Loss: 0.28097\n",
      "Epoch 1800/2000, Avg Loss: 0.08677, Reg Loss: 0.27186\n",
      "Epoch 1900/2000, Avg Loss: 0.09031, Reg Loss: 0.27964\n",
      "Epoch 2000/2000, Avg Loss: 0.08101, Reg Loss: 0.27038\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.8000, G-Mean = 0.7746, MCC = 0.7327, F1-score = 0.7500\n",
      "      SMOTEBoost: AUC = 0.8824, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      RUSBoost: AUC = 1.0000, G-Mean = 0.9701, MCC = 0.8856, F1-score = 0.9091\n",
      "      OUBoost: AUC = 0.9176, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      SVM: AUC = 0.9765, G-Mean = 0.7746, MCC = 0.7327, F1-score = 0.7500\n",
      "      SMOTE: AUC = 0.9765, G-Mean = 0.7746, MCC = 0.7327, F1-score = 0.7500\n",
      "      ADASYN: AUC = 0.9882, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      bSMOTE: AUC = 0.9882, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      ROS: AUC = 1.0000, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      MWMOTE: AUC = 1.0000, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "      Trans(Direct): AUC = 0.9765, G-Mean = 0.8944, MCC = 0.8692, F1-score = 0.8889\n",
      "  Fold 2/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.26356, Reg Loss: 0.30054\n",
      "Epoch 200/2000, Avg Loss: 0.19567, Reg Loss: 0.30588\n",
      "Epoch 300/2000, Avg Loss: 0.16456, Reg Loss: 0.29954\n",
      "Epoch 400/2000, Avg Loss: 0.16037, Reg Loss: 0.29781\n",
      "Epoch 500/2000, Avg Loss: 0.15270, Reg Loss: 0.29806\n",
      "Epoch 600/2000, Avg Loss: 0.12657, Reg Loss: 0.29428\n",
      "Epoch 700/2000, Avg Loss: 0.13694, Reg Loss: 0.29121\n",
      "Epoch 800/2000, Avg Loss: 0.11036, Reg Loss: 0.27827\n",
      "Epoch 900/2000, Avg Loss: 0.13122, Reg Loss: 0.28423\n",
      "Epoch 1000/2000, Avg Loss: 0.12433, Reg Loss: 0.28632\n",
      "Epoch 1100/2000, Avg Loss: 0.10875, Reg Loss: 0.27666\n",
      "Epoch 1200/2000, Avg Loss: 0.08770, Reg Loss: 0.26679\n",
      "Epoch 1300/2000, Avg Loss: 0.10049, Reg Loss: 0.27205\n",
      "Epoch 1400/2000, Avg Loss: 0.08976, Reg Loss: 0.27193\n",
      "Epoch 1500/2000, Avg Loss: 0.08498, Reg Loss: 0.26244\n",
      "Epoch 1600/2000, Avg Loss: 0.09074, Reg Loss: 0.25747\n",
      "Epoch 1700/2000, Avg Loss: 0.12864, Reg Loss: 0.28733\n",
      "Epoch 1800/2000, Avg Loss: 0.10386, Reg Loss: 0.26694\n",
      "Epoch 1900/2000, Avg Loss: 0.11903, Reg Loss: 0.27334\n",
      "Epoch 2000/2000, Avg Loss: 0.08992, Reg Loss: 0.26157\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.8353, G-Mean = 0.8212, MCC = 0.7369, F1-score = 0.7750\n",
      "      SMOTEBoost: AUC = 0.9412, G-Mean = 0.9323, MCC = 0.8774, F1-score = 0.8990\n",
      "      RUSBoost: AUC = 0.9824, G-Mean = 0.9223, MCC = 0.7687, F1-score = 0.8117\n",
      "      OUBoost: AUC = 0.9588, G-Mean = 0.9323, MCC = 0.8774, F1-score = 0.8990\n",
      "      SVM: AUC = 0.9882, G-Mean = 0.8873, MCC = 0.8663, F1-score = 0.8750\n",
      "      SMOTE: AUC = 0.9882, G-Mean = 0.8724, MCC = 0.8092, F1-score = 0.8295\n",
      "      ADASYN: AUC = 0.9941, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      bSMOTE: AUC = 0.9941, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      ROS: AUC = 1.0000, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      MWMOTE: AUC = 1.0000, G-Mean = 0.9472, MCC = 0.9346, F1-score = 0.9444\n",
      "      Trans(Direct): AUC = 0.9882, G-Mean = 0.9323, MCC = 0.8774, F1-score = 0.8990\n",
      "  Fold 3/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.25792, Reg Loss: 0.30358\n",
      "Epoch 200/2000, Avg Loss: 0.25262, Reg Loss: 0.29991\n",
      "Epoch 300/2000, Avg Loss: 0.19321, Reg Loss: 0.29125\n",
      "Epoch 400/2000, Avg Loss: 0.17915, Reg Loss: 0.28948\n",
      "Epoch 500/2000, Avg Loss: 0.16353, Reg Loss: 0.29348\n",
      "Epoch 600/2000, Avg Loss: 0.15011, Reg Loss: 0.28536\n",
      "Epoch 700/2000, Avg Loss: 0.13878, Reg Loss: 0.29826\n",
      "Epoch 800/2000, Avg Loss: 0.14063, Reg Loss: 0.29111\n",
      "Epoch 900/2000, Avg Loss: 0.12918, Reg Loss: 0.28173\n",
      "Epoch 1000/2000, Avg Loss: 0.10694, Reg Loss: 0.28544\n",
      "Epoch 1100/2000, Avg Loss: 0.10117, Reg Loss: 0.28348\n",
      "Epoch 1200/2000, Avg Loss: 0.15253, Reg Loss: 0.29048\n",
      "Epoch 1300/2000, Avg Loss: 0.10411, Reg Loss: 0.29053\n",
      "Epoch 1400/2000, Avg Loss: 0.11119, Reg Loss: 0.27184\n",
      "Epoch 1500/2000, Avg Loss: 0.12924, Reg Loss: 0.27769\n",
      "Epoch 1600/2000, Avg Loss: 0.10964, Reg Loss: 0.27760\n",
      "Epoch 1700/2000, Avg Loss: 0.12027, Reg Loss: 0.27379\n",
      "Epoch 1800/2000, Avg Loss: 0.11908, Reg Loss: 0.27462\n",
      "Epoch 1900/2000, Avg Loss: 0.09784, Reg Loss: 0.26307\n",
      "Epoch 2000/2000, Avg Loss: 0.08512, Reg Loss: 0.26518\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.8902, G-Mean = 0.8808, MCC = 0.8246, F1-score = 0.8500\n",
      "      SMOTEBoost: AUC = 0.9469, G-Mean = 0.9443, MCC = 0.8838, F1-score = 0.9070\n",
      "      RUSBoost: AUC = 0.9570, G-Mean = 0.9267, MCC = 0.7825, F1-score = 0.8268\n",
      "      OUBoost: AUC = 0.9725, G-Mean = 0.9443, MCC = 0.8838, F1-score = 0.9070\n",
      "      SVM: AUC = 0.9922, G-Mean = 0.9143, MCC = 0.8764, F1-score = 0.8910\n",
      "      SMOTE: AUC = 0.9922, G-Mean = 0.8934, MCC = 0.8095, F1-score = 0.8387\n",
      "      ADASYN: AUC = 0.9961, G-Mean = 0.9433, MCC = 0.8931, F1-score = 0.9153\n",
      "      bSMOTE: AUC = 0.9961, G-Mean = 0.9433, MCC = 0.8931, F1-score = 0.9153\n",
      "      ROS: AUC = 1.0000, G-Mean = 0.9433, MCC = 0.8931, F1-score = 0.9153\n",
      "      MWMOTE: AUC = 1.0000, G-Mean = 0.9433, MCC = 0.8931, F1-score = 0.9153\n",
      "      Trans(Direct): AUC = 0.9922, G-Mean = 0.9333, MCC = 0.8550, F1-score = 0.8850\n",
      "  Fold 4/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.22090, Reg Loss: 0.29798\n",
      "Epoch 200/2000, Avg Loss: 0.17449, Reg Loss: 0.29623\n",
      "Epoch 300/2000, Avg Loss: 0.14383, Reg Loss: 0.28039\n",
      "Epoch 400/2000, Avg Loss: 0.14200, Reg Loss: 0.27878\n",
      "Epoch 500/2000, Avg Loss: 0.11837, Reg Loss: 0.25980\n",
      "Epoch 600/2000, Avg Loss: 0.11255, Reg Loss: 0.26287\n",
      "Epoch 700/2000, Avg Loss: 0.10502, Reg Loss: 0.26709\n",
      "Epoch 800/2000, Avg Loss: 0.10958, Reg Loss: 0.25298\n",
      "Epoch 900/2000, Avg Loss: 0.10693, Reg Loss: 0.26125\n",
      "Epoch 1000/2000, Avg Loss: 0.10514, Reg Loss: 0.24975\n",
      "Epoch 1100/2000, Avg Loss: 0.09813, Reg Loss: 0.24781\n",
      "Epoch 1200/2000, Avg Loss: 0.09413, Reg Loss: 0.25963\n",
      "Epoch 1300/2000, Avg Loss: 0.10507, Reg Loss: 0.25545\n",
      "Epoch 1400/2000, Avg Loss: 0.08984, Reg Loss: 0.25496\n",
      "Epoch 1500/2000, Avg Loss: 0.11703, Reg Loss: 0.25563\n",
      "Epoch 1600/2000, Avg Loss: 0.12252, Reg Loss: 0.26770\n",
      "Epoch 1700/2000, Avg Loss: 0.10676, Reg Loss: 0.25416\n",
      "Epoch 1800/2000, Avg Loss: 0.10541, Reg Loss: 0.25944\n",
      "Epoch 1900/2000, Avg Loss: 0.10732, Reg Loss: 0.25428\n",
      "Epoch 2000/2000, Avg Loss: 0.08587, Reg Loss: 0.23982\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.9145, G-Mean = 0.8771, MCC = 0.8028, F1-score = 0.8375\n",
      "      SMOTEBoost: AUC = 0.9602, G-Mean = 0.9582, MCC = 0.9128, F1-score = 0.9303\n",
      "      RUSBoost: AUC = 0.9584, G-Mean = 0.8348, MCC = 0.6650, F1-score = 0.7392\n",
      "      OUBoost: AUC = 0.9794, G-Mean = 0.9318, MCC = 0.8797, F1-score = 0.9025\n",
      "      SVM: AUC = 0.9941, G-Mean = 0.9093, MCC = 0.8742, F1-score = 0.8905\n",
      "      SMOTE: AUC = 0.9941, G-Mean = 0.8936, MCC = 0.8240, F1-score = 0.8513\n",
      "      ADASYN: AUC = 0.9971, G-Mean = 0.9311, MCC = 0.8868, F1-score = 0.9087\n",
      "      bSMOTE: AUC = 0.9971, G-Mean = 0.9311, MCC = 0.8868, F1-score = 0.9087\n",
      "      ROS: AUC = 1.0000, G-Mean = 0.9311, MCC = 0.8868, F1-score = 0.9087\n",
      "      MWMOTE: AUC = 1.0000, G-Mean = 0.9575, MCC = 0.9198, F1-score = 0.9365\n",
      "      Trans(Direct): AUC = 0.9941, G-Mean = 0.9500, MCC = 0.8912, F1-score = 0.9138\n",
      "  Fold 5/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.23571, Reg Loss: 0.32878\n",
      "Epoch 200/2000, Avg Loss: 0.19453, Reg Loss: 0.32744\n",
      "Epoch 300/2000, Avg Loss: 0.16470, Reg Loss: 0.32528\n",
      "Epoch 400/2000, Avg Loss: 0.13890, Reg Loss: 0.32534\n",
      "Epoch 500/2000, Avg Loss: 0.13905, Reg Loss: 0.32208\n",
      "Epoch 600/2000, Avg Loss: 0.12796, Reg Loss: 0.31824\n",
      "Epoch 700/2000, Avg Loss: 0.13212, Reg Loss: 0.31796\n",
      "Epoch 800/2000, Avg Loss: 0.10232, Reg Loss: 0.31382\n",
      "Epoch 900/2000, Avg Loss: 0.12127, Reg Loss: 0.30758\n",
      "Epoch 1000/2000, Avg Loss: 0.10127, Reg Loss: 0.30431\n",
      "Epoch 1100/2000, Avg Loss: 0.12607, Reg Loss: 0.31542\n",
      "Epoch 1200/2000, Avg Loss: 0.10308, Reg Loss: 0.31105\n",
      "Epoch 1300/2000, Avg Loss: 0.14831, Reg Loss: 0.31838\n",
      "Epoch 1400/2000, Avg Loss: 0.11138, Reg Loss: 0.29549\n",
      "Epoch 1500/2000, Avg Loss: 0.12233, Reg Loss: 0.30124\n",
      "Epoch 1600/2000, Avg Loss: 0.13193, Reg Loss: 0.31542\n",
      "Epoch 1700/2000, Avg Loss: 0.11109, Reg Loss: 0.28951\n",
      "Epoch 1800/2000, Avg Loss: 0.09643, Reg Loss: 0.29423\n",
      "Epoch 1900/2000, Avg Loss: 0.09621, Reg Loss: 0.28500\n",
      "Epoch 2000/2000, Avg Loss: 0.08915, Reg Loss: 0.27503\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.9116, G-Mean = 0.8806, MCC = 0.8158, F1-score = 0.8478\n",
      "      SMOTEBoost: AUC = 0.9681, G-Mean = 0.9454, MCC = 0.9038, F1-score = 0.9220\n",
      "      RUSBoost: AUC = 0.9667, G-Mean = 0.8410, MCC = 0.6611, F1-score = 0.7342\n",
      "      OUBoost: AUC = 0.9835, G-Mean = 0.9454, MCC = 0.9038, F1-score = 0.9220\n",
      "      SVM: AUC = 0.9903, G-Mean = 0.9063, MCC = 0.8729, F1-score = 0.8902\n",
      "      SMOTE: AUC = 0.9928, G-Mean = 0.8938, MCC = 0.8328, F1-score = 0.8588\n",
      "      ADASYN: AUC = 0.9976, G-Mean = 0.9237, MCC = 0.8830, F1-score = 0.9048\n",
      "      bSMOTE: AUC = 0.9976, G-Mean = 0.9237, MCC = 0.8830, F1-score = 0.9048\n",
      "      ROS: AUC = 1.0000, G-Mean = 0.9237, MCC = 0.8830, F1-score = 0.9048\n",
      "      MWMOTE: AUC = 1.0000, G-Mean = 0.9449, MCC = 0.9094, F1-score = 0.9270\n",
      "      Trans(Direct): AUC = 0.9953, G-Mean = 0.9389, MCC = 0.8865, F1-score = 0.9088\n",
      "  Fold 6/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.31697, Reg Loss: 0.37968\n",
      "Epoch 200/2000, Avg Loss: 0.22779, Reg Loss: 0.35880\n",
      "Epoch 300/2000, Avg Loss: 0.19236, Reg Loss: 0.35930\n",
      "Epoch 400/2000, Avg Loss: 0.17971, Reg Loss: 0.36037\n",
      "Epoch 500/2000, Avg Loss: 0.16424, Reg Loss: 0.34876\n",
      "Epoch 600/2000, Avg Loss: 0.13431, Reg Loss: 0.33918\n",
      "Epoch 700/2000, Avg Loss: 0.12230, Reg Loss: 0.34126\n",
      "Epoch 800/2000, Avg Loss: 0.11448, Reg Loss: 0.33177\n",
      "Epoch 900/2000, Avg Loss: 0.11193, Reg Loss: 0.31119\n",
      "Epoch 1000/2000, Avg Loss: 0.10284, Reg Loss: 0.32960\n",
      "Epoch 1100/2000, Avg Loss: 0.10962, Reg Loss: 0.31093\n",
      "Epoch 1200/2000, Avg Loss: 0.11445, Reg Loss: 0.32052\n",
      "Epoch 1300/2000, Avg Loss: 0.11131, Reg Loss: 0.31318\n",
      "Epoch 1400/2000, Avg Loss: 0.09700, Reg Loss: 0.31577\n",
      "Epoch 1500/2000, Avg Loss: 0.09369, Reg Loss: 0.31371\n",
      "Epoch 1600/2000, Avg Loss: 0.10773, Reg Loss: 0.31320\n",
      "Epoch 1700/2000, Avg Loss: 0.09772, Reg Loss: 0.29371\n",
      "Epoch 1800/2000, Avg Loss: 0.10179, Reg Loss: 0.32096\n",
      "Epoch 1900/2000, Avg Loss: 0.10371, Reg Loss: 0.28653\n",
      "Epoch 2000/2000, Avg Loss: 0.11285, Reg Loss: 0.30340\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.9180, G-Mean = 0.8897, MCC = 0.8116, F1-score = 0.8454\n",
      "      SMOTEBoost: AUC = 0.9693, G-Mean = 0.9322, MCC = 0.8761, F1-score = 0.9017\n",
      "      RUSBoost: AUC = 0.9722, G-Mean = 0.8390, MCC = 0.6486, F1-score = 0.7229\n",
      "      OUBoost: AUC = 0.9842, G-Mean = 0.9322, MCC = 0.8761, F1-score = 0.9017\n",
      "      SVM: AUC = 0.9898, G-Mean = 0.9112, MCC = 0.8592, F1-score = 0.8807\n",
      "      SMOTE: AUC = 0.9898, G-Mean = 0.9007, MCC = 0.8257, F1-score = 0.8546\n",
      "      ADASYN: AUC = 0.9918, G-Mean = 0.9257, MCC = 0.8676, F1-score = 0.8929\n",
      "      bSMOTE: AUC = 0.9939, G-Mean = 0.9257, MCC = 0.8676, F1-score = 0.8929\n",
      "      ROS: AUC = 0.9958, G-Mean = 0.9257, MCC = 0.8676, F1-score = 0.8929\n",
      "      MWMOTE: AUC = 0.9958, G-Mean = 0.9433, MCC = 0.8896, F1-score = 0.9114\n",
      "      Trans(Direct): AUC = 0.9898, G-Mean = 0.9383, MCC = 0.8705, F1-score = 0.8962\n",
      "  Fold 7/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.26661, Reg Loss: 0.34235\n",
      "Epoch 200/2000, Avg Loss: 0.23342, Reg Loss: 0.34272\n",
      "Epoch 300/2000, Avg Loss: 0.14943, Reg Loss: 0.32420\n",
      "Epoch 400/2000, Avg Loss: 0.16298, Reg Loss: 0.34033\n",
      "Epoch 500/2000, Avg Loss: 0.13198, Reg Loss: 0.32334\n",
      "Epoch 600/2000, Avg Loss: 0.11308, Reg Loss: 0.32543\n",
      "Epoch 700/2000, Avg Loss: 0.15218, Reg Loss: 0.32116\n",
      "Epoch 800/2000, Avg Loss: 0.12678, Reg Loss: 0.30833\n",
      "Epoch 900/2000, Avg Loss: 0.11183, Reg Loss: 0.30909\n",
      "Epoch 1000/2000, Avg Loss: 0.10076, Reg Loss: 0.31350\n",
      "Epoch 1100/2000, Avg Loss: 0.09979, Reg Loss: 0.30487\n",
      "Epoch 1200/2000, Avg Loss: 0.10644, Reg Loss: 0.30784\n",
      "Epoch 1300/2000, Avg Loss: 0.11729, Reg Loss: 0.31760\n",
      "Epoch 1400/2000, Avg Loss: 0.10743, Reg Loss: 0.31522\n",
      "Epoch 1500/2000, Avg Loss: 0.10136, Reg Loss: 0.30912\n",
      "Epoch 1600/2000, Avg Loss: 0.13611, Reg Loss: 0.30804\n",
      "Epoch 1700/2000, Avg Loss: 0.09079, Reg Loss: 0.30146\n",
      "Epoch 1800/2000, Avg Loss: 0.10798, Reg Loss: 0.29751\n",
      "Epoch 1900/2000, Avg Loss: 0.09404, Reg Loss: 0.29454\n",
      "Epoch 2000/2000, Avg Loss: 0.07498, Reg Loss: 0.28984\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.9253, G-Mean = 0.9009, MCC = 0.8219, F1-score = 0.8545\n",
      "      SMOTEBoost: AUC = 0.9701, G-Mean = 0.9374, MCC = 0.8772, F1-score = 0.9027\n",
      "      RUSBoost: AUC = 0.9673, G-Mean = 0.7697, MCC = 0.5819, F1-score = 0.6792\n",
      "      OUBoost: AUC = 0.9829, G-Mean = 0.9278, MCC = 0.8527, F1-score = 0.8827\n",
      "      SVM: AUC = 0.9895, G-Mean = 0.9047, MCC = 0.8418, F1-score = 0.8692\n",
      "      SMOTE: AUC = 0.9895, G-Mean = 0.9104, MCC = 0.8340, F1-score = 0.8623\n",
      "      ADASYN: AUC = 0.9912, G-Mean = 0.9318, MCC = 0.8699, F1-score = 0.8952\n",
      "      bSMOTE: AUC = 0.9930, G-Mean = 0.9318, MCC = 0.8699, F1-score = 0.8952\n",
      "      ROS: AUC = 0.9946, G-Mean = 0.9318, MCC = 0.8699, F1-score = 0.8952\n",
      "      MWMOTE: AUC = 0.9929, G-Mean = 0.9468, MCC = 0.8888, F1-score = 0.9110\n",
      "      Trans(Direct): AUC = 0.9895, G-Mean = 0.9426, MCC = 0.8724, F1-score = 0.8981\n",
      "  Fold 8/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.27532, Reg Loss: 0.29824\n",
      "Epoch 200/2000, Avg Loss: 0.18732, Reg Loss: 0.29146\n",
      "Epoch 300/2000, Avg Loss: 0.15374, Reg Loss: 0.28457\n",
      "Epoch 400/2000, Avg Loss: 0.14928, Reg Loss: 0.28290\n",
      "Epoch 500/2000, Avg Loss: 0.12174, Reg Loss: 0.28417\n",
      "Epoch 600/2000, Avg Loss: 0.12326, Reg Loss: 0.27858\n",
      "Epoch 700/2000, Avg Loss: 0.11518, Reg Loss: 0.26179\n",
      "Epoch 800/2000, Avg Loss: 0.12237, Reg Loss: 0.25978\n",
      "Epoch 900/2000, Avg Loss: 0.10259, Reg Loss: 0.25500\n",
      "Epoch 1000/2000, Avg Loss: 0.11364, Reg Loss: 0.26877\n",
      "Epoch 1100/2000, Avg Loss: 0.10103, Reg Loss: 0.27072\n",
      "Epoch 1200/2000, Avg Loss: 0.09194, Reg Loss: 0.26918\n",
      "Epoch 1300/2000, Avg Loss: 0.08852, Reg Loss: 0.26652\n",
      "Epoch 1400/2000, Avg Loss: 0.09752, Reg Loss: 0.28169\n",
      "Epoch 1500/2000, Avg Loss: 0.09271, Reg Loss: 0.28428\n",
      "Epoch 1600/2000, Avg Loss: 0.09190, Reg Loss: 0.26203\n",
      "Epoch 1700/2000, Avg Loss: 0.09672, Reg Loss: 0.25256\n",
      "Epoch 1800/2000, Avg Loss: 0.12556, Reg Loss: 0.27206\n",
      "Epoch 1900/2000, Avg Loss: 0.09012, Reg Loss: 0.25915\n",
      "Epoch 2000/2000, Avg Loss: 0.09491, Reg Loss: 0.26156\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.9143, G-Mean = 0.8929, MCC = 0.7987, F1-score = 0.8386\n",
      "      SMOTEBoost: AUC = 0.9645, G-Mean = 0.9371, MCC = 0.8664, F1-score = 0.8940\n",
      "      RUSBoost: AUC = 0.9636, G-Mean = 0.7619, MCC = 0.5640, F1-score = 0.6637\n",
      "      OUBoost: AUC = 0.9788, G-Mean = 0.9107, MCC = 0.8128, F1-score = 0.8505\n",
      "      SVM: AUC = 0.9799, G-Mean = 0.9086, MCC = 0.8354, F1-score = 0.8647\n",
      "      SMOTE: AUC = 0.9799, G-Mean = 0.9135, MCC = 0.8286, F1-score = 0.8587\n",
      "      ADASYN: AUC = 0.9829, G-Mean = 0.9322, MCC = 0.8600, F1-score = 0.8874\n",
      "      bSMOTE: AUC = 0.9860, G-Mean = 0.9322, MCC = 0.8600, F1-score = 0.8874\n",
      "      ROS: AUC = 0.9859, G-Mean = 0.9322, MCC = 0.8600, F1-score = 0.8874\n",
      "      MWMOTE: AUC = 0.9844, G-Mean = 0.9454, MCC = 0.8765, F1-score = 0.9013\n",
      "      Trans(Direct): AUC = 0.9799, G-Mean = 0.9417, MCC = 0.8622, F1-score = 0.8900\n",
      "  Fold 9/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.27389, Reg Loss: 0.32271\n",
      "Epoch 200/2000, Avg Loss: 0.16437, Reg Loss: 0.30102\n",
      "Epoch 300/2000, Avg Loss: 0.15986, Reg Loss: 0.29065\n",
      "Epoch 400/2000, Avg Loss: 0.14152, Reg Loss: 0.27750\n",
      "Epoch 500/2000, Avg Loss: 0.13457, Reg Loss: 0.27979\n",
      "Epoch 600/2000, Avg Loss: 0.12135, Reg Loss: 0.27896\n",
      "Epoch 700/2000, Avg Loss: 0.11831, Reg Loss: 0.29290\n",
      "Epoch 800/2000, Avg Loss: 0.12516, Reg Loss: 0.27764\n",
      "Epoch 900/2000, Avg Loss: 0.11347, Reg Loss: 0.27401\n",
      "Epoch 1000/2000, Avg Loss: 0.10032, Reg Loss: 0.28720\n",
      "Epoch 1100/2000, Avg Loss: 0.10388, Reg Loss: 0.26508\n",
      "Epoch 1200/2000, Avg Loss: 0.09593, Reg Loss: 0.28031\n",
      "Epoch 1300/2000, Avg Loss: 0.10168, Reg Loss: 0.26822\n",
      "Epoch 1400/2000, Avg Loss: 0.10287, Reg Loss: 0.26361\n",
      "Epoch 1500/2000, Avg Loss: 0.08938, Reg Loss: 0.26285\n",
      "Epoch 1600/2000, Avg Loss: 0.08657, Reg Loss: 0.26712\n",
      "Epoch 1700/2000, Avg Loss: 0.09473, Reg Loss: 0.26988\n",
      "Epoch 1800/2000, Avg Loss: 0.08676, Reg Loss: 0.26751\n",
      "Epoch 1900/2000, Avg Loss: 0.11194, Reg Loss: 0.26218\n",
      "Epoch 2000/2000, Avg Loss: 0.08454, Reg Loss: 0.26369\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.9016, G-Mean = 0.8797, MCC = 0.7911, F1-score = 0.8287\n",
      "      SMOTEBoost: AUC = 0.9684, G-Mean = 0.9406, MCC = 0.8683, F1-score = 0.8957\n",
      "      RUSBoost: AUC = 0.9648, G-Mean = 0.7774, MCC = 0.5805, F1-score = 0.6755\n",
      "      OUBoost: AUC = 0.9811, G-Mean = 0.9171, MCC = 0.8207, F1-score = 0.8570\n",
      "      SVM: AUC = 0.9821, G-Mean = 0.9187, MCC = 0.8537, F1-score = 0.8797\n",
      "      SMOTE: AUC = 0.9821, G-Mean = 0.9231, MCC = 0.8477, F1-score = 0.8744\n",
      "      ADASYN: AUC = 0.9848, G-Mean = 0.9398, MCC = 0.8755, F1-score = 0.9000\n",
      "      bSMOTE: AUC = 0.9876, G-Mean = 0.9398, MCC = 0.8755, F1-score = 0.9000\n",
      "      ROS: AUC = 0.9875, G-Mean = 0.9398, MCC = 0.8755, F1-score = 0.9000\n",
      "      MWMOTE: AUC = 0.9861, G-Mean = 0.9515, MCC = 0.8902, F1-score = 0.9123\n",
      "      Trans(Direct): AUC = 0.9821, G-Mean = 0.9482, MCC = 0.8775, F1-score = 0.9022\n",
      "  Fold 10/10 - Experiment 10/10\n",
      "Epoch 100/2000, Avg Loss: 0.24172, Reg Loss: 0.29983\n",
      "Epoch 200/2000, Avg Loss: 0.19595, Reg Loss: 0.29424\n",
      "Epoch 300/2000, Avg Loss: 0.16655, Reg Loss: 0.27858\n",
      "Epoch 400/2000, Avg Loss: 0.15184, Reg Loss: 0.27467\n",
      "Epoch 500/2000, Avg Loss: 0.13280, Reg Loss: 0.27356\n",
      "Epoch 600/2000, Avg Loss: 0.11630, Reg Loss: 0.26862\n",
      "Epoch 700/2000, Avg Loss: 0.11084, Reg Loss: 0.25883\n",
      "Epoch 800/2000, Avg Loss: 0.11511, Reg Loss: 0.26651\n",
      "Epoch 900/2000, Avg Loss: 0.09548, Reg Loss: 0.27890\n",
      "Epoch 1000/2000, Avg Loss: 0.10275, Reg Loss: 0.26305\n",
      "Epoch 1100/2000, Avg Loss: 0.10293, Reg Loss: 0.26267\n",
      "Epoch 1200/2000, Avg Loss: 0.09706, Reg Loss: 0.25630\n",
      "Epoch 1300/2000, Avg Loss: 0.10114, Reg Loss: 0.25897\n",
      "Epoch 1400/2000, Avg Loss: 0.08913, Reg Loss: 0.25248\n",
      "Epoch 1500/2000, Avg Loss: 0.08501, Reg Loss: 0.25906\n",
      "Epoch 1600/2000, Avg Loss: 0.08972, Reg Loss: 0.24579\n",
      "Epoch 1700/2000, Avg Loss: 0.08667, Reg Loss: 0.25675\n",
      "Epoch 1800/2000, Avg Loss: 0.10177, Reg Loss: 0.25447\n",
      "Epoch 1900/2000, Avg Loss: 0.10458, Reg Loss: 0.25810\n",
      "Epoch 2000/2000, Avg Loss: 0.12879, Reg Loss: 0.26651\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.8914, G-Mean = 0.8692, MCC = 0.7851, F1-score = 0.8209\n",
      "      SMOTEBoost: AUC = 0.9716, G-Mean = 0.9465, MCC = 0.8815, F1-score = 0.9061\n",
      "      RUSBoost: AUC = 0.9683, G-Mean = 0.7555, MCC = 0.5537, F1-score = 0.6555\n",
      "      OUBoost: AUC = 0.9830, G-Mean = 0.9253, MCC = 0.8386, F1-score = 0.8713\n",
      "      SVM: AUC = 0.9839, G-Mean = 0.9043, MCC = 0.8413, F1-score = 0.8668\n",
      "      SMOTE: AUC = 0.9839, G-Mean = 0.9083, MCC = 0.8359, F1-score = 0.8620\n",
      "      ADASYN: AUC = 0.9863, G-Mean = 0.9352, MCC = 0.8748, F1-score = 0.8988\n",
      "      bSMOTE: AUC = 0.9876, G-Mean = 0.9352, MCC = 0.8748, F1-score = 0.8988\n",
      "      ROS: AUC = 0.9887, G-Mean = 0.9352, MCC = 0.8748, F1-score = 0.8988\n",
      "      MWMOTE: AUC = 0.9875, G-Mean = 0.9458, MCC = 0.8880, F1-score = 0.9100\n",
      "      Trans(Direct): AUC = 0.9839, G-Mean = 0.9428, MCC = 0.8765, F1-score = 0.9009\n",
      "\n",
      "Final Averaged Results Across Experiments:\n",
      "  AdaBoost:\n",
      "    AUC: 0.9066\n",
      "    G-Mean: 0.8846\n",
      "    MCC: 0.8012\n",
      "    F1-score: 0.8369\n",
      "  SMOTEBoost:\n",
      "    AUC: 0.9717\n",
      "    G-Mean: 0.9376\n",
      "    MCC: 0.8642\n",
      "    F1-score: 0.8915\n",
      "  RUSBoost:\n",
      "    AUC: 0.9484\n",
      "    G-Mean: 0.8197\n",
      "    MCC: 0.6186\n",
      "    F1-score: 0.7016\n",
      "  OUBoost:\n",
      "    AUC: 0.9769\n",
      "    G-Mean: 0.9353\n",
      "    MCC: 0.8539\n",
      "    F1-score: 0.8841\n",
      "  SVM:\n",
      "    AUC: 0.9792\n",
      "    G-Mean: 0.9099\n",
      "    MCC: 0.8431\n",
      "    F1-score: 0.8734\n",
      "  SMOTE:\n",
      "    AUC: 0.9806\n",
      "    G-Mean: 0.9293\n",
      "    MCC: 0.8594\n",
      "    F1-score: 0.8877\n",
      "  ADASYN:\n",
      "    AUC: 0.9786\n",
      "    G-Mean: 0.9353\n",
      "    MCC: 0.8647\n",
      "    F1-score: 0.8931\n",
      "  bSMOTE:\n",
      "    AUC: 0.9813\n",
      "    G-Mean: 0.9350\n",
      "    MCC: 0.8672\n",
      "    F1-score: 0.8945\n",
      "  ROS:\n",
      "    AUC: 0.9822\n",
      "    G-Mean: 0.9287\n",
      "    MCC: 0.8589\n",
      "    F1-score: 0.8873\n",
      "  MWMOTE:\n",
      "    AUC: 0.9761\n",
      "    G-Mean: 0.9387\n",
      "    MCC: 0.8680\n",
      "    F1-score: 0.8958\n",
      "  Trans(Direct):\n",
      "    AUC: 0.9823\n",
      "    G-Mean: 0.9457\n",
      "    MCC: 0.8729\n",
      "    F1-score: 0.9004\n",
      "\n",
      "Final results saved to /data4/oldrain123/oldrain123/results/real_results/glass-0-1-2-3_vs_4-5-6_final_results.csv\n",
      "\n",
      "Method: AdaBoost\n",
      "  AUC: 0.9066  0.0133\n",
      "  G-Mean: 0.8846  0.0177\n",
      "  MCC: 0.8012  0.0244\n",
      "  F1-score: 0.8369  0.0197\n",
      "\n",
      "Method: SMOTEBoost\n",
      "  AUC: 0.9717  0.0038\n",
      "  G-Mean: 0.9376  0.0127\n",
      "  MCC: 0.8642  0.0206\n",
      "  F1-score: 0.8915  0.0160\n",
      "\n",
      "Method: RUSBoost\n",
      "  AUC: 0.9484  0.0209\n",
      "  G-Mean: 0.8197  0.0440\n",
      "  MCC: 0.6186  0.0541\n",
      "  F1-score: 0.7016  0.0394\n",
      "\n",
      "Method: OUBoost\n",
      "  AUC: 0.9769  0.0079\n",
      "  G-Mean: 0.9353  0.0193\n",
      "  MCC: 0.8539  0.0311\n",
      "  F1-score: 0.8841  0.0249\n",
      "\n",
      "Method: SVM\n",
      "  AUC: 0.9792  0.0063\n",
      "  G-Mean: 0.9099  0.0233\n",
      "  MCC: 0.8431  0.0243\n",
      "  F1-score: 0.8734  0.0206\n",
      "\n",
      "Method: SMOTE\n",
      "  AUC: 0.9806  0.0063\n",
      "  G-Mean: 0.9293  0.0145\n",
      "  MCC: 0.8594  0.0181\n",
      "  F1-score: 0.8877  0.0159\n",
      "\n",
      "Method: ADASYN\n",
      "  AUC: 0.9786  0.0066\n",
      "  G-Mean: 0.9353  0.0112\n",
      "  MCC: 0.8647  0.0168\n",
      "  F1-score: 0.8931  0.0141\n",
      "\n",
      "Method: bSMOTE\n",
      "  AUC: 0.9813  0.0064\n",
      "  G-Mean: 0.9350  0.0125\n",
      "  MCC: 0.8672  0.0151\n",
      "  F1-score: 0.8945  0.0127\n",
      "\n",
      "Method: ROS\n",
      "  AUC: 0.9822  0.0084\n",
      "  G-Mean: 0.9287  0.0214\n",
      "  MCC: 0.8589  0.0290\n",
      "  F1-score: 0.8873  0.0242\n",
      "\n",
      "Method: MWMOTE\n",
      "  AUC: 0.9761  0.0065\n",
      "  G-Mean: 0.9387  0.0085\n",
      "  MCC: 0.8680  0.0126\n",
      "  F1-score: 0.8958  0.0105\n",
      "\n",
      "Method: Trans(Direct)\n",
      "  AUC: 0.9823  0.0058\n",
      "  G-Mean: 0.9457  0.0082\n",
      "  MCC: 0.8729  0.0148\n",
      "  F1-score: 0.9004  0.0112\n"
     ]
    }
   ],
   "source": [
    "# glass-0-1-2-3_vs_4-5-6\n",
    "data_name = 'glass-0-1-2-3_vs_4-5-6'\n",
    "dataframe = pd.read_csv(f\"{data_path}{data_name}.dat\")\n",
    "results = run_experiment(dataframe, device, h_dim=512, num_layers=10, beta=0.1, lr = 0.001, save_path=save_path, data_name = data_name)\n",
    "\n",
    "for method, metrics in results.items():\n",
    "    print(f\"\\nMethod: {method}\")\n",
    "    for metric, values in metrics.items():\n",
    "        mean_value = np.mean(values)\n",
    "        std_value = np.std(values)\n",
    "        print(f\"  {metric}: {mean_value:.4f}  {std_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1483, 8)\n",
      "Class distribution: Counter({np.int64(0): 1432, np.int64(1): 51})\n",
      "\n",
      "Starting experiment 1/10\n",
      "  Fold 1/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.10894, Reg Loss: 0.18164\n",
      "Epoch 200/2000, Avg Loss: 0.09434, Reg Loss: 0.15794\n",
      "Epoch 300/2000, Avg Loss: 0.10512, Reg Loss: 0.16805\n",
      "Epoch 400/2000, Avg Loss: 0.09314, Reg Loss: 0.15694\n",
      "Epoch 500/2000, Avg Loss: 0.08485, Reg Loss: 0.15505\n",
      "Epoch 600/2000, Avg Loss: 0.08077, Reg Loss: 0.15192\n",
      "Epoch 700/2000, Avg Loss: 0.08315, Reg Loss: 0.15055\n",
      "Epoch 800/2000, Avg Loss: 0.07507, Reg Loss: 0.15087\n",
      "Epoch 900/2000, Avg Loss: 0.07536, Reg Loss: 0.15165\n",
      "Epoch 1000/2000, Avg Loss: 0.07668, Reg Loss: 0.15399\n",
      "Epoch 1100/2000, Avg Loss: 0.07400, Reg Loss: 0.14826\n",
      "Epoch 1200/2000, Avg Loss: 0.07270, Reg Loss: 0.15083\n",
      "Epoch 1300/2000, Avg Loss: 0.07291, Reg Loss: 0.15224\n",
      "Epoch 1400/2000, Avg Loss: 0.07073, Reg Loss: 0.15006\n",
      "Epoch 1500/2000, Avg Loss: 0.06803, Reg Loss: 0.14794\n",
      "Epoch 1600/2000, Avg Loss: 0.06549, Reg Loss: 0.14768\n",
      "Epoch 1700/2000, Avg Loss: 0.06714, Reg Loss: 0.14905\n",
      "Epoch 1800/2000, Avg Loss: 0.06602, Reg Loss: 0.14609\n",
      "Epoch 1900/2000, Avg Loss: 0.07553, Reg Loss: 0.15364\n",
      "Epoch 2000/2000, Avg Loss: 0.06393, Reg Loss: 0.14774\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.9569, G-Mean = 0.4425, MCC = 0.1996, F1-score = 0.2222\n",
      "      SMOTEBoost: AUC = 0.7778, G-Mean = 0.4441, MCC = 0.2386, F1-score = 0.2500\n",
      "      RUSBoost: AUC = 0.9132, G-Mean = 0.8233, MCC = 0.3071, F1-score = 0.2581\n",
      "      OUBoost: AUC = 0.7674, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0649\n",
      "      SVM: AUC = 0.7472, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SMOTE: AUC = 0.9028, G-Mean = 0.7274, MCC = 0.2546, F1-score = 0.2400\n",
      "      ADASYN: AUC = 0.8917, G-Mean = 0.7303, MCC = 0.2640, F1-score = 0.2500\n",
      "      bSMOTE: AUC = 0.9306, G-Mean = 0.7472, MCC = 0.3386, F1-score = 0.3333\n",
      "      ROS: AUC = 0.9181, G-Mean = 0.8333, MCC = 0.3330, F1-score = 0.2857\n",
      "      MWMOTE: AUC = 0.8986, G-Mean = 0.7360, MCC = 0.2848, F1-score = 0.2727\n",
      "      Trans(Direct): AUC = 0.9417, G-Mean = 0.7360, MCC = 0.2848, F1-score = 0.2727\n",
      "  Fold 2/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.12298, Reg Loss: 0.20775\n",
      "Epoch 200/2000, Avg Loss: 0.11272, Reg Loss: 0.18624\n",
      "Epoch 300/2000, Avg Loss: 0.10562, Reg Loss: 0.17754\n",
      "Epoch 400/2000, Avg Loss: 0.10097, Reg Loss: 0.17452\n",
      "Epoch 500/2000, Avg Loss: 0.09016, Reg Loss: 0.17008\n",
      "Epoch 600/2000, Avg Loss: 0.08332, Reg Loss: 0.16856\n",
      "Epoch 700/2000, Avg Loss: 0.07389, Reg Loss: 0.16272\n",
      "Epoch 800/2000, Avg Loss: 0.08054, Reg Loss: 0.16553\n",
      "Epoch 900/2000, Avg Loss: 0.07717, Reg Loss: 0.16208\n",
      "Epoch 1000/2000, Avg Loss: 0.07647, Reg Loss: 0.16283\n",
      "Epoch 1100/2000, Avg Loss: 0.07683, Reg Loss: 0.16456\n",
      "Epoch 1200/2000, Avg Loss: 0.07637, Reg Loss: 0.16620\n",
      "Epoch 1300/2000, Avg Loss: 0.07546, Reg Loss: 0.16379\n",
      "Epoch 1400/2000, Avg Loss: 0.07464, Reg Loss: 0.16430\n",
      "Epoch 1500/2000, Avg Loss: 0.06821, Reg Loss: 0.15915\n",
      "Epoch 1600/2000, Avg Loss: 0.06768, Reg Loss: 0.15991\n",
      "Epoch 1700/2000, Avg Loss: 0.06507, Reg Loss: 0.16038\n",
      "Epoch 1800/2000, Avg Loss: 0.06545, Reg Loss: 0.16065\n",
      "Epoch 1900/2000, Avg Loss: 0.06465, Reg Loss: 0.15784\n",
      "Epoch 2000/2000, Avg Loss: 0.06604, Reg Loss: 0.16139\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.9639, G-Mean = 0.6059, MCC = 0.3929, F1-score = 0.4111\n",
      "      SMOTEBoost: AUC = 0.7889, G-Mean = 0.5361, MCC = 0.3344, F1-score = 0.3472\n",
      "      RUSBoost: AUC = 0.8795, G-Mean = 0.7908, MCC = 0.3646, F1-score = 0.3433\n",
      "      OUBoost: AUC = 0.8351, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0649\n",
      "      SVM: AUC = 0.8681, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SMOTE: AUC = 0.9201, G-Mean = 0.7886, MCC = 0.3215, F1-score = 0.2939\n",
      "      ADASYN: AUC = 0.9198, G-Mean = 0.8384, MCC = 0.3686, F1-score = 0.3250\n",
      "      bSMOTE: AUC = 0.9479, G-Mean = 0.8050, MCC = 0.3947, F1-score = 0.3772\n",
      "      ROS: AUC = 0.9389, G-Mean = 0.8399, MCC = 0.3543, F1-score = 0.3095\n",
      "      MWMOTE: AUC = 0.9153, G-Mean = 0.7962, MCC = 0.3508, F1-score = 0.3268\n",
      "      Trans(Direct): AUC = 0.9403, G-Mean = 0.7962, MCC = 0.3508, F1-score = 0.3268\n",
      "  Fold 3/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.09821, Reg Loss: 0.16886\n",
      "Epoch 200/2000, Avg Loss: 0.08131, Reg Loss: 0.14337\n",
      "Epoch 300/2000, Avg Loss: 0.07834, Reg Loss: 0.14464\n",
      "Epoch 400/2000, Avg Loss: 0.07479, Reg Loss: 0.14141\n",
      "Epoch 500/2000, Avg Loss: 0.06616, Reg Loss: 0.13408\n",
      "Epoch 600/2000, Avg Loss: 0.06402, Reg Loss: 0.13728\n",
      "Epoch 700/2000, Avg Loss: 0.06415, Reg Loss: 0.13595\n",
      "Epoch 800/2000, Avg Loss: 0.06373, Reg Loss: 0.13588\n",
      "Epoch 900/2000, Avg Loss: 0.06355, Reg Loss: 0.13332\n",
      "Epoch 1000/2000, Avg Loss: 0.06258, Reg Loss: 0.13527\n",
      "Epoch 1100/2000, Avg Loss: 0.05844, Reg Loss: 0.13239\n",
      "Epoch 1200/2000, Avg Loss: 0.06037, Reg Loss: 0.12981\n",
      "Epoch 1300/2000, Avg Loss: 0.05598, Reg Loss: 0.13219\n",
      "Epoch 1400/2000, Avg Loss: 0.05840, Reg Loss: 0.13397\n",
      "Epoch 1500/2000, Avg Loss: 0.05670, Reg Loss: 0.13267\n",
      "Epoch 1600/2000, Avg Loss: 0.05410, Reg Loss: 0.13207\n",
      "Epoch 1700/2000, Avg Loss: 0.05557, Reg Loss: 0.13317\n",
      "Epoch 1800/2000, Avg Loss: 0.05467, Reg Loss: 0.13052\n",
      "Epoch 1900/2000, Avg Loss: 0.05273, Reg Loss: 0.13187\n",
      "Epoch 2000/2000, Avg Loss: 0.05219, Reg Loss: 0.13104\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.9448, G-Mean = 0.5957, MCC = 0.4142, F1-score = 0.4222\n",
      "      SMOTEBoost: AUC = 0.8212, G-Mean = 0.5478, MCC = 0.3366, F1-score = 0.3527\n",
      "      RUSBoost: AUC = 0.8940, G-Mean = 0.8206, MCC = 0.4093, F1-score = 0.3876\n",
      "      OUBoost: AUC = 0.8147, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0691\n",
      "      SVM: AUC = 0.8627, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SMOTE: AUC = 0.8854, G-Mean = 0.7782, MCC = 0.3082, F1-score = 0.2848\n",
      "      ADASYN: AUC = 0.8879, G-Mean = 0.8093, MCC = 0.3343, F1-score = 0.3000\n",
      "      bSMOTE: AUC = 0.9117, G-Mean = 0.7962, MCC = 0.3818, F1-score = 0.3674\n",
      "      ROS: AUC = 0.8932, G-Mean = 0.8175, MCC = 0.3466, F1-score = 0.3130\n",
      "      MWMOTE: AUC = 0.8817, G-Mean = 0.7852, MCC = 0.3338, F1-score = 0.3131\n",
      "      Trans(Direct): AUC = 0.9241, G-Mean = 0.7863, MCC = 0.3370, F1-score = 0.3167\n",
      "  Fold 4/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.11478, Reg Loss: 0.18840\n",
      "Epoch 200/2000, Avg Loss: 0.10817, Reg Loss: 0.16967\n",
      "Epoch 300/2000, Avg Loss: 0.11002, Reg Loss: 0.17212\n",
      "Epoch 400/2000, Avg Loss: 0.09555, Reg Loss: 0.16261\n",
      "Epoch 500/2000, Avg Loss: 0.08257, Reg Loss: 0.15389\n",
      "Epoch 600/2000, Avg Loss: 0.08000, Reg Loss: 0.15477\n",
      "Epoch 700/2000, Avg Loss: 0.08011, Reg Loss: 0.15487\n",
      "Epoch 800/2000, Avg Loss: 0.07254, Reg Loss: 0.15095\n",
      "Epoch 900/2000, Avg Loss: 0.07530, Reg Loss: 0.15011\n",
      "Epoch 1000/2000, Avg Loss: 0.07478, Reg Loss: 0.15262\n",
      "Epoch 1100/2000, Avg Loss: 0.07333, Reg Loss: 0.15154\n",
      "Epoch 1200/2000, Avg Loss: 0.07017, Reg Loss: 0.15160\n",
      "Epoch 1300/2000, Avg Loss: 0.07103, Reg Loss: 0.15172\n",
      "Epoch 1400/2000, Avg Loss: 0.06788, Reg Loss: 0.14668\n",
      "Epoch 1500/2000, Avg Loss: 0.06420, Reg Loss: 0.14681\n",
      "Epoch 1600/2000, Avg Loss: 0.06868, Reg Loss: 0.14968\n",
      "Epoch 1700/2000, Avg Loss: 0.06641, Reg Loss: 0.15029\n",
      "Epoch 1800/2000, Avg Loss: 0.06688, Reg Loss: 0.14917\n",
      "Epoch 1900/2000, Avg Loss: 0.06242, Reg Loss: 0.14581\n",
      "Epoch 2000/2000, Avg Loss: 0.06506, Reg Loss: 0.14791\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.9391, G-Mean = 0.6043, MCC = 0.4366, F1-score = 0.4417\n",
      "      SMOTEBoost: AUC = 0.8551, G-Mean = 0.5684, MCC = 0.3784, F1-score = 0.3895\n",
      "      RUSBoost: AUC = 0.8985, G-Mean = 0.8050, MCC = 0.4125, F1-score = 0.3978\n",
      "      OUBoost: AUC = 0.8255, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0682\n",
      "      SVM: AUC = 0.8215, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SMOTE: AUC = 0.8941, G-Mean = 0.7676, MCC = 0.3023, F1-score = 0.2818\n",
      "      ADASYN: AUC = 0.8935, G-Mean = 0.7895, MCC = 0.3166, F1-score = 0.2875\n",
      "      bSMOTE: AUC = 0.9103, G-Mean = 0.7839, MCC = 0.3710, F1-score = 0.3589\n",
      "      ROS: AUC = 0.9028, G-Mean = 0.7970, MCC = 0.3311, F1-score = 0.3029\n",
      "      MWMOTE: AUC = 0.8903, G-Mean = 0.7729, MCC = 0.3215, F1-score = 0.3030\n",
      "      Trans(Direct): AUC = 0.9210, G-Mean = 0.7764, MCC = 0.3374, F1-score = 0.3208\n",
      "  Fold 5/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.11450, Reg Loss: 0.19703\n",
      "Epoch 200/2000, Avg Loss: 0.10386, Reg Loss: 0.17497\n",
      "Epoch 300/2000, Avg Loss: 0.09982, Reg Loss: 0.17004\n",
      "Epoch 400/2000, Avg Loss: 0.08819, Reg Loss: 0.16469\n",
      "Epoch 500/2000, Avg Loss: 0.08613, Reg Loss: 0.16346\n",
      "Epoch 600/2000, Avg Loss: 0.08507, Reg Loss: 0.16397\n",
      "Epoch 700/2000, Avg Loss: 0.07997, Reg Loss: 0.16226\n",
      "Epoch 800/2000, Avg Loss: 0.08125, Reg Loss: 0.16420\n",
      "Epoch 900/2000, Avg Loss: 0.07795, Reg Loss: 0.16271\n",
      "Epoch 1000/2000, Avg Loss: 0.07372, Reg Loss: 0.15754\n",
      "Epoch 1100/2000, Avg Loss: 0.07342, Reg Loss: 0.16156\n",
      "Epoch 1200/2000, Avg Loss: 0.07246, Reg Loss: 0.15680\n",
      "Epoch 1300/2000, Avg Loss: 0.07515, Reg Loss: 0.15864\n",
      "Epoch 1400/2000, Avg Loss: 0.07145, Reg Loss: 0.15938\n",
      "Epoch 1500/2000, Avg Loss: 0.07492, Reg Loss: 0.16232\n",
      "Epoch 1600/2000, Avg Loss: 0.07291, Reg Loss: 0.16107\n",
      "Epoch 1700/2000, Avg Loss: 0.06800, Reg Loss: 0.16035\n",
      "Epoch 1800/2000, Avg Loss: 0.06719, Reg Loss: 0.15963\n",
      "Epoch 1900/2000, Avg Loss: 0.06606, Reg Loss: 0.15741\n",
      "Epoch 2000/2000, Avg Loss: 0.06932, Reg Loss: 0.15986\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 5:\n",
      "      AdaBoost: AUC = 0.9384, G-Mean = 0.5723, MCC = 0.3970, F1-score = 0.4033\n",
      "      SMOTEBoost: AUC = 0.8762, G-Mean = 0.5803, MCC = 0.3887, F1-score = 0.4005\n",
      "      RUSBoost: AUC = 0.9059, G-Mean = 0.8099, MCC = 0.3947, F1-score = 0.3735\n",
      "      OUBoost: AUC = 0.8484, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0676\n",
      "      SVM: AUC = 0.8441, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SMOTE: AUC = 0.9007, G-Mean = 0.7612, MCC = 0.2987, F1-score = 0.2800\n",
      "      ADASYN: AUC = 0.8994, G-Mean = 0.7995, MCC = 0.3238, F1-score = 0.2915\n",
      "      bSMOTE: AUC = 0.9179, G-Mean = 0.7787, MCC = 0.3811, F1-score = 0.3728\n",
      "      ROS: AUC = 0.9088, G-Mean = 0.7853, MCC = 0.3241, F1-score = 0.2995\n",
      "      MWMOTE: AUC = 0.8997, G-Mean = 0.7671, MCC = 0.3218, F1-score = 0.3056\n",
      "      Trans(Direct): AUC = 0.9301, G-Mean = 0.7937, MCC = 0.3600, F1-score = 0.3409\n",
      "  Fold 6/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.11036, Reg Loss: 0.18122\n",
      "Epoch 200/2000, Avg Loss: 0.10647, Reg Loss: 0.17264\n",
      "Epoch 300/2000, Avg Loss: 0.10311, Reg Loss: 0.16676\n",
      "Epoch 400/2000, Avg Loss: 0.08465, Reg Loss: 0.15714\n",
      "Epoch 500/2000, Avg Loss: 0.08044, Reg Loss: 0.15675\n",
      "Epoch 600/2000, Avg Loss: 0.07725, Reg Loss: 0.15227\n",
      "Epoch 700/2000, Avg Loss: 0.07603, Reg Loss: 0.15285\n",
      "Epoch 800/2000, Avg Loss: 0.08087, Reg Loss: 0.15730\n",
      "Epoch 900/2000, Avg Loss: 0.07533, Reg Loss: 0.15636\n",
      "Epoch 1000/2000, Avg Loss: 0.07636, Reg Loss: 0.15589\n",
      "Epoch 1100/2000, Avg Loss: 0.07579, Reg Loss: 0.15631\n",
      "Epoch 1200/2000, Avg Loss: 0.07089, Reg Loss: 0.15258\n",
      "Epoch 1300/2000, Avg Loss: 0.06781, Reg Loss: 0.15294\n",
      "Epoch 1400/2000, Avg Loss: 0.06589, Reg Loss: 0.15212\n",
      "Epoch 1500/2000, Avg Loss: 0.06730, Reg Loss: 0.15307\n",
      "Epoch 1600/2000, Avg Loss: 0.06599, Reg Loss: 0.15172\n",
      "Epoch 1700/2000, Avg Loss: 0.06614, Reg Loss: 0.14967\n",
      "Epoch 1800/2000, Avg Loss: 0.06995, Reg Loss: 0.15201\n",
      "Epoch 1900/2000, Avg Loss: 0.06463, Reg Loss: 0.14963\n",
      "Epoch 2000/2000, Avg Loss: 0.06135, Reg Loss: 0.15092\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 6:\n",
      "      AdaBoost: AUC = 0.9438, G-Mean = 0.5823, MCC = 0.4351, F1-score = 0.4313\n",
      "      SMOTEBoost: AUC = 0.8785, G-Mean = 0.5879, MCC = 0.3871, F1-score = 0.4004\n",
      "      RUSBoost: AUC = 0.8953, G-Mean = 0.7971, MCC = 0.3745, F1-score = 0.3547\n",
      "      OUBoost: AUC = 0.8179, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0672\n",
      "      SVM: AUC = 0.8416, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SMOTE: AUC = 0.9033, G-Mean = 0.7584, MCC = 0.3028, F1-score = 0.2860\n",
      "      ADASYN: AUC = 0.9013, G-Mean = 0.7898, MCC = 0.3213, F1-score = 0.2929\n",
      "      bSMOTE: AUC = 0.9164, G-Mean = 0.7510, MCC = 0.3563, F1-score = 0.3524\n",
      "      ROS: AUC = 0.9074, G-Mean = 0.7780, MCC = 0.3216, F1-score = 0.2996\n",
      "      MWMOTE: AUC = 0.9008, G-Mean = 0.7638, MCC = 0.3245, F1-score = 0.3102\n",
      "      Trans(Direct): AUC = 0.9268, G-Mean = 0.7850, MCC = 0.3515, F1-score = 0.3341\n",
      "  Fold 7/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.12273, Reg Loss: 0.19311\n",
      "Epoch 200/2000, Avg Loss: 0.11718, Reg Loss: 0.18528\n",
      "Epoch 300/2000, Avg Loss: 0.10011, Reg Loss: 0.16823\n",
      "Epoch 400/2000, Avg Loss: 0.09357, Reg Loss: 0.16625\n",
      "Epoch 500/2000, Avg Loss: 0.08739, Reg Loss: 0.16289\n",
      "Epoch 600/2000, Avg Loss: 0.09011, Reg Loss: 0.16336\n",
      "Epoch 700/2000, Avg Loss: 0.07937, Reg Loss: 0.16161\n",
      "Epoch 800/2000, Avg Loss: 0.08012, Reg Loss: 0.15961\n",
      "Epoch 900/2000, Avg Loss: 0.08110, Reg Loss: 0.16224\n",
      "Epoch 1000/2000, Avg Loss: 0.08071, Reg Loss: 0.16322\n",
      "Epoch 1100/2000, Avg Loss: 0.07274, Reg Loss: 0.15908\n",
      "Epoch 1200/2000, Avg Loss: 0.07456, Reg Loss: 0.16019\n",
      "Epoch 1300/2000, Avg Loss: 0.07504, Reg Loss: 0.15868\n",
      "Epoch 1400/2000, Avg Loss: 0.07431, Reg Loss: 0.15864\n",
      "Epoch 1500/2000, Avg Loss: 0.07189, Reg Loss: 0.16073\n",
      "Epoch 1600/2000, Avg Loss: 0.06945, Reg Loss: 0.16066\n",
      "Epoch 1700/2000, Avg Loss: 0.06864, Reg Loss: 0.15552\n",
      "Epoch 1800/2000, Avg Loss: 0.07070, Reg Loss: 0.15754\n",
      "Epoch 1900/2000, Avg Loss: 0.07073, Reg Loss: 0.15785\n",
      "Epoch 2000/2000, Avg Loss: 0.06647, Reg Loss: 0.15547\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 7:\n",
      "      AdaBoost: AUC = 0.9464, G-Mean = 0.5626, MCC = 0.4070, F1-score = 0.4054\n",
      "      SMOTEBoost: AUC = 0.8875, G-Mean = 0.6126, MCC = 0.3963, F1-score = 0.4092\n",
      "      RUSBoost: AUC = 0.9017, G-Mean = 0.8036, MCC = 0.3730, F1-score = 0.3497\n",
      "      OUBoost: AUC = 0.8331, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0670\n",
      "      SVM: AUC = 0.8604, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SMOTE: AUC = 0.9153, G-Mean = 0.7846, MCC = 0.3252, F1-score = 0.3001\n",
      "      ADASYN: AUC = 0.9136, G-Mean = 0.8105, MCC = 0.3377, F1-score = 0.3021\n",
      "      bSMOTE: AUC = 0.9256, G-Mean = 0.7815, MCC = 0.3850, F1-score = 0.3734\n",
      "      ROS: AUC = 0.9171, G-Mean = 0.8015, MCC = 0.3413, F1-score = 0.3117\n",
      "      MWMOTE: AUC = 0.9128, G-Mean = 0.7914, MCC = 0.3523, F1-score = 0.3308\n",
      "      Trans(Direct): AUC = 0.9349, G-Mean = 0.8080, MCC = 0.3689, F1-score = 0.3435\n",
      "  Fold 8/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.11504, Reg Loss: 0.18916\n",
      "Epoch 200/2000, Avg Loss: 0.11207, Reg Loss: 0.18019\n",
      "Epoch 300/2000, Avg Loss: 0.09956, Reg Loss: 0.17005\n",
      "Epoch 400/2000, Avg Loss: 0.09234, Reg Loss: 0.16802\n",
      "Epoch 500/2000, Avg Loss: 0.09703, Reg Loss: 0.17606\n",
      "Epoch 600/2000, Avg Loss: 0.08531, Reg Loss: 0.16510\n",
      "Epoch 700/2000, Avg Loss: 0.08107, Reg Loss: 0.16131\n",
      "Epoch 800/2000, Avg Loss: 0.08018, Reg Loss: 0.16154\n",
      "Epoch 900/2000, Avg Loss: 0.08092, Reg Loss: 0.16047\n",
      "Epoch 1000/2000, Avg Loss: 0.07594, Reg Loss: 0.15950\n",
      "Epoch 1100/2000, Avg Loss: 0.07250, Reg Loss: 0.15744\n",
      "Epoch 1200/2000, Avg Loss: 0.06871, Reg Loss: 0.16102\n",
      "Epoch 1300/2000, Avg Loss: 0.07340, Reg Loss: 0.15830\n",
      "Epoch 1400/2000, Avg Loss: 0.06703, Reg Loss: 0.15704\n",
      "Epoch 1500/2000, Avg Loss: 0.06566, Reg Loss: 0.15595\n",
      "Epoch 1600/2000, Avg Loss: 0.06525, Reg Loss: 0.15474\n",
      "Epoch 1700/2000, Avg Loss: 0.06491, Reg Loss: 0.15656\n",
      "Epoch 1800/2000, Avg Loss: 0.06792, Reg Loss: 0.15956\n",
      "Epoch 1900/2000, Avg Loss: 0.06362, Reg Loss: 0.15826\n",
      "Epoch 2000/2000, Avg Loss: 0.06804, Reg Loss: 0.15552\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 8:\n",
      "      AdaBoost: AUC = 0.9454, G-Mean = 0.5710, MCC = 0.4191, F1-score = 0.4173\n",
      "      SMOTEBoost: AUC = 0.8981, G-Mean = 0.5918, MCC = 0.3845, F1-score = 0.3937\n",
      "      RUSBoost: AUC = 0.9127, G-Mean = 0.8138, MCC = 0.4092, F1-score = 0.3893\n",
      "      OUBoost: AUC = 0.8512, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0668\n",
      "      SVM: AUC = 0.8746, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SMOTE: AUC = 0.9203, G-Mean = 0.7792, MCC = 0.3232, F1-score = 0.3000\n",
      "      ADASYN: AUC = 0.9191, G-Mean = 0.8146, MCC = 0.3410, F1-score = 0.3044\n",
      "      bSMOTE: AUC = 0.9237, G-Mean = 0.7606, MCC = 0.3678, F1-score = 0.3601\n",
      "      ROS: AUC = 0.9220, G-Mean = 0.8075, MCC = 0.3472, F1-score = 0.3162\n",
      "      MWMOTE: AUC = 0.9081, G-Mean = 0.7678, MCC = 0.3314, F1-score = 0.3145\n",
      "      Trans(Direct): AUC = 0.9390, G-Mean = 0.8168, MCC = 0.3951, F1-score = 0.3720\n",
      "  Fold 9/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.09759, Reg Loss: 0.19190\n",
      "Epoch 200/2000, Avg Loss: 0.09608, Reg Loss: 0.16987\n",
      "Epoch 300/2000, Avg Loss: 0.09421, Reg Loss: 0.16797\n",
      "Epoch 400/2000, Avg Loss: 0.09843, Reg Loss: 0.16977\n",
      "Epoch 500/2000, Avg Loss: 0.08017, Reg Loss: 0.15676\n",
      "Epoch 600/2000, Avg Loss: 0.08140, Reg Loss: 0.15922\n",
      "Epoch 700/2000, Avg Loss: 0.07860, Reg Loss: 0.15924\n",
      "Epoch 800/2000, Avg Loss: 0.07770, Reg Loss: 0.15669\n",
      "Epoch 900/2000, Avg Loss: 0.07739, Reg Loss: 0.15746\n",
      "Epoch 1000/2000, Avg Loss: 0.07452, Reg Loss: 0.15593\n",
      "Epoch 1100/2000, Avg Loss: 0.08085, Reg Loss: 0.16237\n",
      "Epoch 1200/2000, Avg Loss: 0.07208, Reg Loss: 0.15718\n",
      "Epoch 1300/2000, Avg Loss: 0.06914, Reg Loss: 0.15534\n",
      "Epoch 1400/2000, Avg Loss: 0.06828, Reg Loss: 0.15518\n",
      "Epoch 1500/2000, Avg Loss: 0.06692, Reg Loss: 0.15445\n",
      "Epoch 1600/2000, Avg Loss: 0.06914, Reg Loss: 0.15499\n",
      "Epoch 1700/2000, Avg Loss: 0.06677, Reg Loss: 0.15388\n",
      "Epoch 1800/2000, Avg Loss: 0.06842, Reg Loss: 0.15253\n",
      "Epoch 1900/2000, Avg Loss: 0.06868, Reg Loss: 0.15571\n",
      "Epoch 2000/2000, Avg Loss: 0.06839, Reg Loss: 0.15424\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 9:\n",
      "      AdaBoost: AUC = 0.8888, G-Mean = 0.5076, MCC = 0.3701, F1-score = 0.3709\n",
      "      SMOTEBoost: AUC = 0.8650, G-Mean = 0.5260, MCC = 0.3383, F1-score = 0.3500\n",
      "      RUSBoost: AUC = 0.9000, G-Mean = 0.7234, MCC = 0.3588, F1-score = 0.3461\n",
      "      OUBoost: AUC = 0.8437, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0666\n",
      "      SVM: AUC = 0.8619, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SMOTE: AUC = 0.8998, G-Mean = 0.7609, MCC = 0.3148, F1-score = 0.2963\n",
      "      ADASYN: AUC = 0.8975, G-Mean = 0.7918, MCC = 0.3273, F1-score = 0.2967\n",
      "      bSMOTE: AUC = 0.8818, G-Mean = 0.6761, MCC = 0.3235, F1-score = 0.3201\n",
      "      ROS: AUC = 0.9024, G-Mean = 0.7853, MCC = 0.3315, F1-score = 0.3058\n",
      "      MWMOTE: AUC = 0.8861, G-Mean = 0.7308, MCC = 0.3067, F1-score = 0.2954\n",
      "      Trans(Direct): AUC = 0.9096, G-Mean = 0.7740, MCC = 0.3611, F1-score = 0.3445\n",
      "  Fold 10/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.10536, Reg Loss: 0.18647\n",
      "Epoch 200/2000, Avg Loss: 0.11254, Reg Loss: 0.17710\n",
      "Epoch 300/2000, Avg Loss: 0.10152, Reg Loss: 0.16667\n",
      "Epoch 400/2000, Avg Loss: 0.10106, Reg Loss: 0.16558\n",
      "Epoch 500/2000, Avg Loss: 0.09969, Reg Loss: 0.16363\n",
      "Epoch 600/2000, Avg Loss: 0.08758, Reg Loss: 0.15613\n",
      "Epoch 700/2000, Avg Loss: 0.08170, Reg Loss: 0.15203\n",
      "Epoch 800/2000, Avg Loss: 0.07908, Reg Loss: 0.14834\n",
      "Epoch 900/2000, Avg Loss: 0.07294, Reg Loss: 0.14619\n",
      "Epoch 1000/2000, Avg Loss: 0.07669, Reg Loss: 0.15034\n",
      "Epoch 1100/2000, Avg Loss: 0.06944, Reg Loss: 0.14611\n",
      "Epoch 1200/2000, Avg Loss: 0.06723, Reg Loss: 0.14461\n",
      "Epoch 1300/2000, Avg Loss: 0.06886, Reg Loss: 0.14628\n",
      "Epoch 1400/2000, Avg Loss: 0.06603, Reg Loss: 0.14465\n",
      "Epoch 1500/2000, Avg Loss: 0.07219, Reg Loss: 0.15012\n",
      "Epoch 1600/2000, Avg Loss: 0.06510, Reg Loss: 0.14502\n",
      "Epoch 1700/2000, Avg Loss: 0.06679, Reg Loss: 0.14415\n",
      "Epoch 1800/2000, Avg Loss: 0.07002, Reg Loss: 0.14760\n",
      "Epoch 1900/2000, Avg Loss: 0.06784, Reg Loss: 0.14523\n",
      "Epoch 2000/2000, Avg Loss: 0.06637, Reg Loss: 0.14710\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oldrain123/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 10:\n",
      "      AdaBoost: AUC = 0.8608, G-Mean = 0.4568, MCC = 0.3309, F1-score = 0.3338\n",
      "      SMOTEBoost: AUC = 0.8535, G-Mean = 0.5175, MCC = 0.3217, F1-score = 0.3350\n",
      "      RUSBoost: AUC = 0.8748, G-Mean = 0.7073, MCC = 0.3313, F1-score = 0.3223\n",
      "      OUBoost: AUC = 0.8110, G-Mean = 0.0324, MCC = 0.0063, F1-score = 0.0672\n",
      "      SVM: AUC = 0.8513, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SMOTE: AUC = 0.8879, G-Mean = 0.7435, MCC = 0.2965, F1-score = 0.2815\n",
      "      ADASYN: AUC = 0.8837, G-Mean = 0.7704, MCC = 0.3056, F1-score = 0.2799\n",
      "      bSMOTE: AUC = 0.8745, G-Mean = 0.6823, MCC = 0.3207, F1-score = 0.3166\n",
      "      ROS: AUC = 0.8888, G-Mean = 0.7777, MCC = 0.3192, F1-score = 0.2946\n",
      "      MWMOTE: AUC = 0.8759, G-Mean = 0.7169, MCC = 0.2905, F1-score = 0.2819\n",
      "      Trans(Direct): AUC = 0.9085, G-Mean = 0.7684, MCC = 0.3480, F1-score = 0.3315\n",
      "\n",
      "Starting experiment 2/10\n",
      "  Fold 1/10 - Experiment 2/10\n",
      "Epoch 100/2000, Avg Loss: 0.11673, Reg Loss: 0.18652\n",
      "Epoch 200/2000, Avg Loss: 0.10756, Reg Loss: 0.17118\n",
      "Epoch 300/2000, Avg Loss: 0.08967, Reg Loss: 0.16033\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m data_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myeast4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdata_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myeast4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method, metrics \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMethod: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 56\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(data, device, h_dim, num_layers, beta, lr, n_runs, n_splits, save_path, data_name)\u001b[0m\n\u001b[1;32m     53\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Apply transformations\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m X_maj_direct, X_min_direct, X_trans_direct \u001b[38;5;241m=\u001b[39m \u001b[43mapply_transformation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_maj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMMD_est_torch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdirect\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# selection=\"overlap\",\u001b[39;49;00m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mundersample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m datasets \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m\"\u001b[39m: (X_train, Y_train),\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoost\u001b[39m\u001b[38;5;124m\"\u001b[39m: (X_train, Y_train),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     ),\n\u001b[1;32m     88\u001b[0m }\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method, (X_resampled, Y_resampled) \u001b[38;5;129;01min\u001b[39;00m datasets\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/IMBALANCED_CLASSIFICATION/MOMs/moms_generate.py:614\u001b[0m, in \u001b[0;36mapply_transformation\u001b[0;34m(X_maj, X_min, in_dim, h_dim, num_layers, loss_fn, device, method, n_epochs, lr, h, beta, batch_size, seed, undersample, k)\u001b[0m\n\u001b[1;32m    611\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m select_majority_samples(X_maj, X_min, n_trans)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# Train the transformation function\u001b[39;00m\n\u001b[0;32m--> 614\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;66;03m#   \u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_samples\u001b[39m(f, X_maj_selected, X_min, n_samples, seed):\n",
      "File \u001b[0;32m~/IMBALANCED_CLASSIFICATION/MOMs/moms_train.py:244\u001b[0m, in \u001b[0;36mtrain_map\u001b[0;34m(X_maj, X_min, in_dim, h_dim, num_layers, loss_fn, device, n_epochs, lr, h, batch_size, beta, seed, loss_params)\u001b[0m\n\u001b[1;32m    239\u001b[0m feature_mmd_loss \u001b[38;5;241m=\u001b[39m loss_fn(X_trans, X_min)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# smooth_reg_loss = torch.norm(X_trans - X_maj, p=2)  # L2 Regularization\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# Feature space Boundary Feature Regularization \u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# (X_trans:  Majority sample, X_min: Minority sample, X_maj:  Majority sample)\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m bod_reg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mboundary_feature_regularization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_maj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m cov_reg_loss \u001b[38;5;241m=\u001b[39m coverage_regularization(X_trans, X_min)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m#  loss: latent MMD loss + beta * regularization\u001b[39;00m\n",
      "File \u001b[0;32m~/IMBALANCED_CLASSIFICATION/MOMs/moms_losses.py:248\u001b[0m, in \u001b[0;36mboundary_feature_regularization\u001b[0;34m(X_trans, X_min, X_maj, beta, k, batch_size)\u001b[0m\n\u001b[1;32m    246\u001b[0m nn \u001b[38;5;241m=\u001b[39m NearestNeighbors(n_neighbors\u001b[38;5;241m=\u001b[39mk\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    247\u001b[0m nn\u001b[38;5;241m.\u001b[39mfit(X_all_np)\n\u001b[0;32m--> 248\u001b[0m _, nn_idx \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_min_np\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m nn_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(nn_idx, device\u001b[38;5;241m=\u001b[39mX_min\u001b[38;5;241m.\u001b[39mdevice)[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# Identify DANGER and refined DANGER sets\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/neighbors/_base.py:923\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    920\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not work with sparse matrices. Densify the data, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    921\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor set algorithm=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method\n\u001b[1;32m    922\u001b[0m         )\n\u001b[0;32m--> 923\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternal: _fit_method not recognized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# yeast4\n",
    "data_name = 'yeast4'\n",
    "dataframe = pd.read_csv(f\"{data_path}{data_name}.dat\")\n",
    "results = run_experiment(dataframe, device, h_dim=256, num_layers=10, beta=0.1, lr = 0.001, save_path=save_path, data_name = 'yeast4')\n",
    "\n",
    "for method, metrics in results.items():\n",
    "    print(f\"\\nMethod: {method}\")\n",
    "    for metric, values in metrics.items():\n",
    "        mean_value = np.mean(values)\n",
    "        std_value = np.std(values)\n",
    "        print(f\"  {metric}: {mean_value:.4f}  {std_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (213, 9)\n",
      "Class distribution: Counter({np.int64(0): 200, np.int64(1): 13})\n",
      "\n",
      "Starting experiment 1/10\n",
      "  Fold 1/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.23014, Reg Loss: 0.30246\n",
      "Epoch 200/2000, Avg Loss: 0.24868, Reg Loss: 0.30516\n",
      "Epoch 300/2000, Avg Loss: 0.21862, Reg Loss: 0.28338\n",
      "Epoch 400/2000, Avg Loss: 0.23902, Reg Loss: 0.31693\n",
      "Epoch 500/2000, Avg Loss: 0.20166, Reg Loss: 0.27800\n",
      "Epoch 600/2000, Avg Loss: 0.20400, Reg Loss: 0.26491\n",
      "Epoch 700/2000, Avg Loss: 0.18652, Reg Loss: 0.26249\n",
      "Epoch 800/2000, Avg Loss: 0.20080, Reg Loss: 0.28091\n",
      "Epoch 900/2000, Avg Loss: 0.20401, Reg Loss: 0.27937\n",
      "Epoch 1000/2000, Avg Loss: 0.18883, Reg Loss: 0.28744\n",
      "Epoch 1100/2000, Avg Loss: 0.19172, Reg Loss: 0.27041\n",
      "Epoch 1200/2000, Avg Loss: 0.20076, Reg Loss: 0.27804\n",
      "Epoch 1300/2000, Avg Loss: 0.19759, Reg Loss: 0.27031\n",
      "Epoch 1400/2000, Avg Loss: 0.19554, Reg Loss: 0.27585\n",
      "Epoch 1500/2000, Avg Loss: 0.19513, Reg Loss: 0.27948\n",
      "Epoch 1600/2000, Avg Loss: 0.20281, Reg Loss: 0.28169\n",
      "Epoch 1700/2000, Avg Loss: 0.18925, Reg Loss: 0.26967\n",
      "Epoch 1800/2000, Avg Loss: 0.19189, Reg Loss: 0.26588\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m data_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglass4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdata_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mglass4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method, metrics \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMethod: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 56\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(data, device, h_dim, num_layers, beta, lr, n_runs, n_splits, save_path, data_name)\u001b[0m\n\u001b[1;32m     53\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Apply transformations\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m X_maj_direct, X_min_direct, X_trans_direct \u001b[38;5;241m=\u001b[39m \u001b[43mapply_transformation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_maj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMMD_est_torch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdirect\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# selection=\"overlap\",\u001b[39;49;00m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mundersample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m datasets \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m\"\u001b[39m: (X_train, Y_train),\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoost\u001b[39m\u001b[38;5;124m\"\u001b[39m: (X_train, Y_train),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     ),\n\u001b[1;32m     88\u001b[0m }\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method, (X_resampled, Y_resampled) \u001b[38;5;129;01min\u001b[39;00m datasets\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/IMBALANCED_CLASSIFICATION/MOMs/moms_generate.py:614\u001b[0m, in \u001b[0;36mapply_transformation\u001b[0;34m(X_maj, X_min, in_dim, h_dim, num_layers, loss_fn, device, method, n_epochs, lr, h, beta, batch_size, seed, undersample, k)\u001b[0m\n\u001b[1;32m    611\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m select_majority_samples(X_maj, X_min, n_trans)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# Train the transformation function\u001b[39;00m\n\u001b[0;32m--> 614\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;66;03m#   \u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_samples\u001b[39m(f, X_maj_selected, X_min, n_samples, seed):\n",
      "File \u001b[0;32m~/IMBALANCED_CLASSIFICATION/MOMs/moms_train.py:244\u001b[0m, in \u001b[0;36mtrain_map\u001b[0;34m(X_maj, X_min, in_dim, h_dim, num_layers, loss_fn, device, n_epochs, lr, h, batch_size, beta, seed, loss_params)\u001b[0m\n\u001b[1;32m    239\u001b[0m feature_mmd_loss \u001b[38;5;241m=\u001b[39m loss_fn(X_trans, X_min)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# smooth_reg_loss = torch.norm(X_trans - X_maj, p=2)  # L2 Regularization\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# Feature space Boundary Feature Regularization \u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# (X_trans:  Majority sample, X_min: Minority sample, X_maj:  Majority sample)\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m bod_reg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mboundary_feature_regularization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_maj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m cov_reg_loss \u001b[38;5;241m=\u001b[39m coverage_regularization(X_trans, X_min)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m#  loss: latent MMD loss + beta * regularization\u001b[39;00m\n",
      "File \u001b[0;32m~/IMBALANCED_CLASSIFICATION/MOMs/moms_losses.py:248\u001b[0m, in \u001b[0;36mboundary_feature_regularization\u001b[0;34m(X_trans, X_min, X_maj, beta, k, batch_size)\u001b[0m\n\u001b[1;32m    246\u001b[0m nn \u001b[38;5;241m=\u001b[39m NearestNeighbors(n_neighbors\u001b[38;5;241m=\u001b[39mk\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    247\u001b[0m nn\u001b[38;5;241m.\u001b[39mfit(X_all_np)\n\u001b[0;32m--> 248\u001b[0m _, nn_idx \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_min_np\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m nn_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(nn_idx, device\u001b[38;5;241m=\u001b[39mX_min\u001b[38;5;241m.\u001b[39mdevice)[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# Identify DANGER and refined DANGER sets\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/neighbors/_base.py:923\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    920\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not work with sparse matrices. Densify the data, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    921\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor set algorithm=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method\n\u001b[1;32m    922\u001b[0m         )\n\u001b[0;32m--> 923\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternal: _fit_method not recognized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/site-packages/joblib/parallel.py:2005\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1999\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_ref \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(output)\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m-> 2005\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/site-packages/joblib/parallel.py:1643\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1641\u001b[0m detach_generator_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1643\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1644\u001b[0m     \u001b[38;5;66;03m# first yield returns None, for internal use only. This ensures\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m     \u001b[38;5;66;03m# that we enter the try/except block and start dispatching the\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m     \u001b[38;5;66;03m# tasks.\u001b[39;00m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/site-packages/joblib/parallel.py:1626\u001b[0m, in \u001b[0;36mParallel._start\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator, pre_dispatch):\n\u001b[1;32m   1618\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1623\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1624\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1626\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/site-packages/joblib/parallel.py:1517\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m   1515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1517\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/site-packages/joblib/parallel.py:1418\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39mappend(batch_tracker)\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;66;03m# If return_ordered is False, the batch_tracker is not stored in the\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;66;03m# jobs queue at the time of submission. Instead, it will be appended to\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;66;03m# the queue by itself as soon as the callback is triggered to be able\u001b[39;00m\n\u001b[1;32m   1416\u001b[0m \u001b[38;5;66;03m# to return the results in the order of completion.\u001b[39;00m\n\u001b[0;32m-> 1418\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1419\u001b[0m batch_tracker\u001b[38;5;241m.\u001b[39mregister_job(job)\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/site-packages/joblib/_parallel_backends.py:275\u001b[0m, in \u001b[0;36mPoolManagerMixin.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Here, we need a wrapper to avoid crashes on KeyboardInterruptErrors.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# We also call the callback on error, to make sure the pool does not\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# wait on crashed jobs.\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mapply_async(\n\u001b[1;32m    276\u001b[0m     _TracebackCapturingWrapper(func), (),\n\u001b[1;32m    277\u001b[0m     callback\u001b[38;5;241m=\u001b[39mcallback, error_callback\u001b[38;5;241m=\u001b[39mcallback\n\u001b[1;32m    278\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/site-packages/joblib/_parallel_backends.py:438\u001b[0m, in \u001b[0;36mThreadingBackend._get_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Lazily initialize the thread pool\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03mThe actual pool of worker threads is only initialized at the first\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03mcall to apply_async.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[43mThreadPool\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/multiprocessing/pool.py:930\u001b[0m, in \u001b[0;36mThreadPool.__init__\u001b[0;34m(self, processes, initializer, initargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, initargs\u001b[38;5;241m=\u001b[39m()):\n\u001b[0;32m--> 930\u001b[0m     \u001b[43mPool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/multiprocessing/pool.py:215\u001b[0m, in \u001b[0;36mPool.__init__\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_processes \u001b[38;5;241m=\u001b[39m processes\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_repopulate_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool:\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/multiprocessing/pool.py:306\u001b[0m, in \u001b[0;36mPool._repopulate_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_repopulate_pool\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_repopulate_pool_static\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_processes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inqueue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_outqueue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maxtasksperchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_exception\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/multiprocessing/pool.py:329\u001b[0m, in \u001b[0;36mPool._repopulate_pool_static\u001b[0;34m(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception)\u001b[0m\n\u001b[1;32m    327\u001b[0m w\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcess\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPoolWorker\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    328\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m pool\u001b[38;5;241m.\u001b[39mappend(w)\n\u001b[1;32m    331\u001b[0m util\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madded worker\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/multiprocessing/dummy/__init__.py:51\u001b[0m, in \u001b[0;36mDummyProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_children\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent\u001b[38;5;241m.\u001b[39m_children[\u001b[38;5;28mself\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mthreading\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mThread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/threading.py:999\u001b[0m, in \u001b[0;36mThread.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m _limbo[\u001b[38;5;28mself\u001b[39m]\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m--> 999\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_started\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/imb_clf/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# glass4\n",
    "data_name = 'glass4'\n",
    "dataframe = pd.read_csv(f\"{data_path}{data_name}.dat\")\n",
    "results = run_experiment(dataframe, device, h_dim=256, num_layers=10, beta=0.1, lr = 0.1, save_path=save_path, data_name = 'glass4')\n",
    "\n",
    "for method, metrics in results.items():\n",
    "    print(f\"\\nMethod: {method}\")\n",
    "    for metric, values in metrics.items():\n",
    "        mean_value = np.mean(values)\n",
    "        std_value = np.std(values)\n",
    "        print(f\"  {metric}: {mean_value:.4f}  {std_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1598, 11)\n",
      "Class distribution: Counter({np.int64(0): 1545, np.int64(1): 53})\n",
      "\n",
      "Starting experiment 1/10\n",
      "  Fold 1/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.21844, Reg Loss: 0.29565\n",
      "Epoch 200/2000, Avg Loss: 0.22965, Reg Loss: 0.30846\n",
      "Epoch 300/2000, Avg Loss: 0.20432, Reg Loss: 0.29588\n",
      "Epoch 400/2000, Avg Loss: 0.18249, Reg Loss: 0.29066\n",
      "Epoch 500/2000, Avg Loss: 0.16899, Reg Loss: 0.28834\n",
      "Epoch 600/2000, Avg Loss: 0.18095, Reg Loss: 0.29909\n",
      "Epoch 700/2000, Avg Loss: 0.16101, Reg Loss: 0.29043\n",
      "Epoch 800/2000, Avg Loss: 0.15472, Reg Loss: 0.28654\n",
      "Epoch 900/2000, Avg Loss: 0.16060, Reg Loss: 0.29076\n",
      "Epoch 1000/2000, Avg Loss: 0.15013, Reg Loss: 0.28531\n",
      "Epoch 1100/2000, Avg Loss: 0.15133, Reg Loss: 0.28913\n",
      "Epoch 1200/2000, Avg Loss: 0.14699, Reg Loss: 0.28186\n",
      "Epoch 1300/2000, Avg Loss: 0.14976, Reg Loss: 0.28157\n",
      "Epoch 1400/2000, Avg Loss: 0.14581, Reg Loss: 0.28416\n",
      "Epoch 1500/2000, Avg Loss: 0.14302, Reg Loss: 0.28100\n",
      "Epoch 1600/2000, Avg Loss: 0.13764, Reg Loss: 0.27899\n",
      "Epoch 1700/2000, Avg Loss: 0.14418, Reg Loss: 0.28171\n",
      "Epoch 1800/2000, Avg Loss: 0.14869, Reg Loss: 0.28435\n",
      "Epoch 1900/2000, Avg Loss: 0.13747, Reg Loss: 0.28098\n",
      "Epoch 2000/2000, Avg Loss: 0.14287, Reg Loss: 0.27851\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.9032, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SMOTEBoost: AUC = 0.7194, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      RUSBoost: AUC = 0.7355, G-Mean = 0.6816, MCC = 0.1530, F1-score = 0.1395\n",
      "      OUBoost: AUC = 0.6206, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SVM: AUC = 0.6452, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SMOTE: AUC = 0.9213, G-Mean = 0.8500, MCC = 0.3782, F1-score = 0.3333\n",
      "      ADASYN: AUC = 0.9226, G-Mean = 0.8531, MCC = 0.3908, F1-score = 0.3478\n",
      "      bSMOTE: AUC = 0.9161, G-Mean = 0.6180, MCC = 0.2680, F1-score = 0.2857\n",
      "      ROS: AUC = 0.9252, G-Mean = 0.8591, MCC = 0.4191, F1-score = 0.3810\n",
      "      MWMOTE: AUC = 0.9316, G-Mean = 0.7492, MCC = 0.3410, F1-score = 0.3333\n",
      "      Trans(Direct): AUC = 0.9135, G-Mean = 0.8223, MCC = 0.2954, F1-score = 0.2424\n",
      "  Fold 2/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.17720, Reg Loss: 0.24178\n",
      "Epoch 200/2000, Avg Loss: 0.16705, Reg Loss: 0.23789\n",
      "Epoch 300/2000, Avg Loss: 0.16149, Reg Loss: 0.23024\n",
      "Epoch 400/2000, Avg Loss: 0.14256, Reg Loss: 0.22814\n",
      "Epoch 500/2000, Avg Loss: 0.13799, Reg Loss: 0.22864\n",
      "Epoch 600/2000, Avg Loss: 0.13531, Reg Loss: 0.22551\n",
      "Epoch 700/2000, Avg Loss: 0.13291, Reg Loss: 0.22432\n",
      "Epoch 800/2000, Avg Loss: 0.13016, Reg Loss: 0.22168\n",
      "Epoch 900/2000, Avg Loss: 0.12675, Reg Loss: 0.22129\n",
      "Epoch 1000/2000, Avg Loss: 0.12557, Reg Loss: 0.22285\n",
      "Epoch 1100/2000, Avg Loss: 0.12509, Reg Loss: 0.22278\n",
      "Epoch 1200/2000, Avg Loss: 0.11894, Reg Loss: 0.21520\n",
      "Epoch 1300/2000, Avg Loss: 0.12159, Reg Loss: 0.21733\n",
      "Epoch 1400/2000, Avg Loss: 0.12307, Reg Loss: 0.21793\n",
      "Epoch 1500/2000, Avg Loss: 0.12042, Reg Loss: 0.21822\n",
      "Epoch 1600/2000, Avg Loss: 0.12195, Reg Loss: 0.21674\n",
      "Epoch 1700/2000, Avg Loss: 0.11691, Reg Loss: 0.22141\n",
      "Epoch 1800/2000, Avg Loss: 0.11157, Reg Loss: 0.21695\n",
      "Epoch 1900/2000, Avg Loss: 0.11984, Reg Loss: 0.21793\n",
      "Epoch 2000/2000, Avg Loss: 0.11176, Reg Loss: 0.21758\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 2:\n",
      "      AdaBoost: AUC = 0.7397, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SMOTEBoost: AUC = 0.5523, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      RUSBoost: AUC = 0.7258, G-Mean = 0.6120, MCC = 0.1031, F1-score = 0.1114\n",
      "      OUBoost: AUC = 0.5003, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SVM: AUC = 0.7123, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SMOTE: AUC = 0.7290, G-Mean = 0.6314, MCC = 0.2017, F1-score = 0.2011\n",
      "      ADASYN: AUC = 0.7316, G-Mean = 0.6337, MCC = 0.2098, F1-score = 0.2096\n",
      "      bSMOTE: AUC = 0.7316, G-Mean = 0.5238, MCC = 0.1730, F1-score = 0.1984\n",
      "      ROS: AUC = 0.7581, G-Mean = 0.6367, MCC = 0.2239, F1-score = 0.2262\n",
      "      MWMOTE: AUC = 0.7232, G-Mean = 0.5833, MCC = 0.1888, F1-score = 0.2051\n",
      "      Trans(Direct): AUC = 0.7948, G-Mean = 0.6151, MCC = 0.1552, F1-score = 0.1525\n",
      "  Fold 3/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.22251, Reg Loss: 0.27709\n",
      "Epoch 200/2000, Avg Loss: 0.21528, Reg Loss: 0.27645\n",
      "Epoch 300/2000, Avg Loss: 0.21553, Reg Loss: 0.27013\n",
      "Epoch 400/2000, Avg Loss: 0.21727, Reg Loss: 0.28313\n",
      "Epoch 500/2000, Avg Loss: 0.19524, Reg Loss: 0.27067\n",
      "Epoch 600/2000, Avg Loss: 0.18018, Reg Loss: 0.26863\n",
      "Epoch 700/2000, Avg Loss: 0.16446, Reg Loss: 0.26824\n",
      "Epoch 800/2000, Avg Loss: 0.16585, Reg Loss: 0.27062\n",
      "Epoch 900/2000, Avg Loss: 0.18815, Reg Loss: 0.27503\n",
      "Epoch 1000/2000, Avg Loss: 0.15807, Reg Loss: 0.26787\n",
      "Epoch 1100/2000, Avg Loss: 0.16115, Reg Loss: 0.26661\n",
      "Epoch 1200/2000, Avg Loss: 0.15990, Reg Loss: 0.26358\n",
      "Epoch 1300/2000, Avg Loss: 0.15417, Reg Loss: 0.26451\n",
      "Epoch 1400/2000, Avg Loss: 0.15226, Reg Loss: 0.26526\n",
      "Epoch 1500/2000, Avg Loss: 0.15868, Reg Loss: 0.26269\n",
      "Epoch 1600/2000, Avg Loss: 0.15102, Reg Loss: 0.25933\n",
      "Epoch 1700/2000, Avg Loss: 0.15058, Reg Loss: 0.25653\n",
      "Epoch 1800/2000, Avg Loss: 0.14221, Reg Loss: 0.25878\n",
      "Epoch 1900/2000, Avg Loss: 0.14771, Reg Loss: 0.26259\n",
      "Epoch 2000/2000, Avg Loss: 0.14331, Reg Loss: 0.26155\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 3:\n",
      "      AdaBoost: AUC = 0.7482, G-Mean = 0.1491, MCC = 0.1472, F1-score = 0.1111\n",
      "      SMOTEBoost: AUC = 0.6260, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      RUSBoost: AUC = 0.7084, G-Mean = 0.5546, MCC = 0.1199, F1-score = 0.1349\n",
      "      OUBoost: AUC = 0.5918, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SVM: AUC = 0.7497, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SMOTE: AUC = 0.7277, G-Mean = 0.5641, MCC = 0.1605, F1-score = 0.1711\n",
      "      ADASYN: AUC = 0.7308, G-Mean = 0.6221, MCC = 0.1943, F1-score = 0.1977\n",
      "      bSMOTE: AUC = 0.7578, G-Mean = 0.4949, MCC = 0.1565, F1-score = 0.1836\n",
      "      ROS: AUC = 0.7578, G-Mean = 0.6234, MCC = 0.2013, F1-score = 0.2063\n",
      "      MWMOTE: AUC = 0.7329, G-Mean = 0.5921, MCC = 0.1957, F1-score = 0.2108\n",
      "      Trans(Direct): AUC = 0.7966, G-Mean = 0.5482, MCC = 0.1131, F1-score = 0.1255\n",
      "  Fold 4/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.20081, Reg Loss: 0.29448\n",
      "Epoch 200/2000, Avg Loss: 0.19687, Reg Loss: 0.29935\n",
      "Epoch 300/2000, Avg Loss: 0.18480, Reg Loss: 0.28602\n",
      "Epoch 400/2000, Avg Loss: 0.17401, Reg Loss: 0.27767\n",
      "Epoch 500/2000, Avg Loss: 0.17059, Reg Loss: 0.27693\n",
      "Epoch 600/2000, Avg Loss: 0.15214, Reg Loss: 0.27179\n",
      "Epoch 700/2000, Avg Loss: 0.16507, Reg Loss: 0.27320\n",
      "Epoch 800/2000, Avg Loss: 0.15389, Reg Loss: 0.27271\n",
      "Epoch 900/2000, Avg Loss: 0.15297, Reg Loss: 0.26993\n",
      "Epoch 1000/2000, Avg Loss: 0.14573, Reg Loss: 0.26938\n",
      "Epoch 1100/2000, Avg Loss: 0.15377, Reg Loss: 0.27193\n",
      "Epoch 1200/2000, Avg Loss: 0.14191, Reg Loss: 0.26992\n",
      "Epoch 1300/2000, Avg Loss: 0.13848, Reg Loss: 0.26869\n",
      "Epoch 1400/2000, Avg Loss: 0.13993, Reg Loss: 0.26618\n",
      "Epoch 1500/2000, Avg Loss: 0.13868, Reg Loss: 0.26597\n",
      "Epoch 1600/2000, Avg Loss: 0.13481, Reg Loss: 0.26541\n",
      "Epoch 1700/2000, Avg Loss: 0.14277, Reg Loss: 0.26680\n",
      "Epoch 1800/2000, Avg Loss: 0.13736, Reg Loss: 0.26387\n",
      "Epoch 1900/2000, Avg Loss: 0.14523, Reg Loss: 0.26824\n",
      "Epoch 2000/2000, Avg Loss: 0.14604, Reg Loss: 0.26419\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 4:\n",
      "      AdaBoost: AUC = 0.7368, G-Mean = 0.1118, MCC = 0.1104, F1-score = 0.0833\n",
      "      SMOTEBoost: AUC = 0.5998, G-Mean = 0.1114, MCC = 0.0758, F1-score = 0.0714\n",
      "      RUSBoost: AUC = 0.6413, G-Mean = 0.5184, MCC = 0.0945, F1-score = 0.1173\n",
      "      OUBoost: AUC = 0.5669, G-Mean = 0.1111, MCC = 0.0600, F1-score = 0.0625\n",
      "      SVM: AUC = 0.7310, G-Mean = 0.0000, MCC = 0.0000, F1-score = 0.0000\n",
      "      SMOTE: AUC = 0.7313, G-Mean = 0.5690, MCC = 0.1505, F1-score = 0.1617\n",
      "      ADASYN: AUC = 0.7306, G-Mean = 0.6125, MCC = 0.1759, F1-score = 0.1816\n",
      "      bSMOTE: AUC = 0.7313, G-Mean = 0.4793, MCC = 0.1407, F1-score = 0.1689\n",
      "      ROS: AUC = 0.7487, G-Mean = 0.6123, MCC = 0.1787, F1-score = 0.1860\n",
      "      MWMOTE: AUC = 0.7490, G-Mean = 0.5943, MCC = 0.1896, F1-score = 0.2036\n",
      "      Trans(Direct): AUC = 0.7758, G-Mean = 0.5537, MCC = 0.1082, F1-score = 0.1219\n",
      "  Fold 5/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.21103, Reg Loss: 0.27400\n",
      "Epoch 200/2000, Avg Loss: 0.22064, Reg Loss: 0.28260\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# wine\u001b[39;00m\n\u001b[1;32m      2\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/sumancha/WORKSPACE/IMBALANCED_CLASSIFICATION/dataset/winequality-red-4.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method, metrics \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMethod: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 56\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(data, device, h_dim, num_layers, beta, lr, n_runs, n_splits, save_path, data_name)\u001b[0m\n\u001b[1;32m     53\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Apply transformations\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m X_maj_direct, X_min_direct, X_trans_direct \u001b[38;5;241m=\u001b[39m \u001b[43mapply_transformation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_maj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMMD_est_torch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdirect\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# selection=\"overlap\",\u001b[39;49;00m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mundersample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m datasets \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m\"\u001b[39m: (X_train, Y_train),\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoost\u001b[39m\u001b[38;5;124m\"\u001b[39m: (X_train, Y_train),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     ),\n\u001b[1;32m     88\u001b[0m }\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method, (X_resampled, Y_resampled) \u001b[38;5;129;01min\u001b[39;00m datasets\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/WORKSPACE/IMBALANCED_CLASSIFICATION/MOMs/moms_generate.py:614\u001b[0m, in \u001b[0;36mapply_transformation\u001b[0;34m(X_maj, X_min, in_dim, h_dim, num_layers, loss_fn, device, method, n_epochs, lr, h, beta, batch_size, seed, undersample, k)\u001b[0m\n\u001b[1;32m    611\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m select_majority_samples(X_maj, X_min, n_trans)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# Train the transformation function\u001b[39;00m\n\u001b[0;32m--> 614\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;66;03m#   \u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_samples\u001b[39m(f, X_maj_selected, X_min, n_samples, seed):\n",
      "File \u001b[0;32m~/WORKSPACE/IMBALANCED_CLASSIFICATION/MOMs/moms_train.py:249\u001b[0m, in \u001b[0;36mtrain_map\u001b[0;34m(X_maj, X_min, in_dim, h_dim, num_layers, loss_fn, device, n_epochs, lr, h, batch_size, beta, seed, loss_params)\u001b[0m\n\u001b[1;32m    246\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;241m*\u001b[39m latent_mmd_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m*\u001b[39mfeature_mmd_loss  \u001b[38;5;241m+\u001b[39m beta \u001b[38;5;241m*\u001b[39m cov_reg_loss \u001b[38;5;241m+\u001b[39m beta \u001b[38;5;241m*\u001b[39m bod_reg_loss\n\u001b[1;32m    248\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 249\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    252\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m total_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/imb_clf/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/imb_clf/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/imb_clf/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# wine\n",
    "data_name = 'wine'\n",
    "dataframe = pd.read_csv(f\"{data_path}{data_name}.dat\")\n",
    "results = run_experiment(dataframe, device, h_dim=512, num_layers=10, beta=0.1, lr = 0.001, save_path=save_path, data_name = 'wine')\n",
    "\n",
    "for method, metrics in results.items():\n",
    "    print(f\"\\nMethod: {method}\")\n",
    "    for metric, values in metrics.items():\n",
    "        mean_value = np.mean(values)\n",
    "        std_value = np.std(values)\n",
    "        print(f\"  {metric}: {mean_value:.4f}  {std_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (335, 7)\n",
      "Class distribution: Counter({np.int64(0): 313, np.int64(1): 22})\n",
      "\n",
      "Starting experiment 1/10\n",
      "  Fold 1/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.11124, Reg Loss: 0.18714\n",
      "Epoch 200/2000, Avg Loss: 0.12892, Reg Loss: 0.19627\n",
      "Epoch 300/2000, Avg Loss: 0.10946, Reg Loss: 0.18046\n",
      "Epoch 400/2000, Avg Loss: 0.10211, Reg Loss: 0.18288\n",
      "Epoch 500/2000, Avg Loss: 0.10903, Reg Loss: 0.18684\n",
      "Epoch 600/2000, Avg Loss: 0.10382, Reg Loss: 0.18059\n",
      "Epoch 700/2000, Avg Loss: 0.10442, Reg Loss: 0.18376\n",
      "Epoch 800/2000, Avg Loss: 0.10542, Reg Loss: 0.18425\n",
      "Epoch 900/2000, Avg Loss: 0.10481, Reg Loss: 0.18120\n",
      "Epoch 1000/2000, Avg Loss: 0.10502, Reg Loss: 0.18415\n",
      "Epoch 1100/2000, Avg Loss: 0.11223, Reg Loss: 0.18651\n",
      "Epoch 1200/2000, Avg Loss: 0.10848, Reg Loss: 0.18338\n",
      "Epoch 1300/2000, Avg Loss: 0.10274, Reg Loss: 0.17875\n",
      "Epoch 1400/2000, Avg Loss: 0.10054, Reg Loss: 0.18149\n",
      "Epoch 1500/2000, Avg Loss: 0.10885, Reg Loss: 0.18280\n",
      "Epoch 1600/2000, Avg Loss: 0.11028, Reg Loss: 0.18229\n",
      "Epoch 1700/2000, Avg Loss: 0.09794, Reg Loss: 0.18084\n",
      "Epoch 1800/2000, Avg Loss: 0.10348, Reg Loss: 0.18185\n",
      "Epoch 1900/2000, Avg Loss: 0.11843, Reg Loss: 0.18808\n",
      "Epoch 2000/2000, Avg Loss: 0.10085, Reg Loss: 0.18175\n",
      "fit BaseWeightBoosting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_proba\n",
      "_compute_proba_from_decision\n",
      "    Intermediate Fold Results for Fold 1:\n",
      "      AdaBoost: AUC = 0.9297, G-Mean = 0.6731, MCC = 0.2967, F1-score = 0.3333\n",
      "      SMOTEBoost: AUC = 0.9531, G-Mean = 0.6731, MCC = 0.2967, F1-score = 0.3333\n",
      "      RUSBoost: AUC = 0.9609, G-Mean = 0.8660, MCC = 0.3873, F1-score = 0.3333\n",
      "      OUBoost: AUC = 0.9531, G-Mean = 0.6731, MCC = 0.2967, F1-score = 0.3333\n",
      "      SVM: AUC = 1.0000, G-Mean = 0.7071, MCC = 0.6963, F1-score = 0.6667\n",
      "      SMOTE: AUC = 0.9844, G-Mean = 0.7071, MCC = 0.6963, F1-score = 0.6667\n",
      "      ADASYN: AUC = 0.9531, G-Mean = 0.7071, MCC = 0.6963, F1-score = 0.6667\n",
      "      bSMOTE: AUC = 0.9531, G-Mean = 0.7071, MCC = 0.6963, F1-score = 0.6667\n",
      "      ROS: AUC = 0.9844, G-Mean = 0.7071, MCC = 0.6963, F1-score = 0.6667\n",
      "      MWMOTE: AUC = 0.9844, G-Mean = 0.7071, MCC = 0.6963, F1-score = 0.6667\n",
      "      Trans(Direct): AUC = 1.0000, G-Mean = 1.0000, MCC = 1.0000, F1-score = 1.0000\n",
      "  Fold 2/10 - Experiment 1/10\n",
      "Epoch 100/2000, Avg Loss: 0.12427, Reg Loss: 0.19279\n",
      "Epoch 200/2000, Avg Loss: 0.13536, Reg Loss: 0.18848\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ecoli4\u001b[39;00m\n\u001b[1;32m      2\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/sumancha/WORKSPACE/IMBALANCED_CLASSIFICATION/dataset/ecoli4.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mecoli4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method, metrics \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMethod: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 56\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(data, device, h_dim, num_layers, beta, lr, n_runs, n_splits, save_path, data_name)\u001b[0m\n\u001b[1;32m     53\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Apply transformations\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m X_maj_direct, X_min_direct, X_trans_direct \u001b[38;5;241m=\u001b[39m \u001b[43mapply_transformation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_maj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMMD_est_torch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdirect\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# selection=\"overlap\",\u001b[39;49;00m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mundersample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m datasets \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m\"\u001b[39m: (X_train, Y_train),\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoost\u001b[39m\u001b[38;5;124m\"\u001b[39m: (X_train, Y_train),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     ),\n\u001b[1;32m     88\u001b[0m }\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method, (X_resampled, Y_resampled) \u001b[38;5;129;01min\u001b[39;00m datasets\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/WORKSPACE/IMBALANCED_CLASSIFICATION/MOMs/moms_generate.py:614\u001b[0m, in \u001b[0;36mapply_transformation\u001b[0;34m(X_maj, X_min, in_dim, h_dim, num_layers, loss_fn, device, method, n_epochs, lr, h, beta, batch_size, seed, undersample, k)\u001b[0m\n\u001b[1;32m    611\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m select_majority_samples(X_maj, X_min, n_trans)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;66;03m# Train the transformation function\u001b[39;00m\n\u001b[0;32m--> 614\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;66;03m#   \u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_samples\u001b[39m(f, X_maj_selected, X_min, n_samples, seed):\n",
      "File \u001b[0;32m~/WORKSPACE/IMBALANCED_CLASSIFICATION/MOMs/moms_train.py:244\u001b[0m, in \u001b[0;36mtrain_map\u001b[0;34m(X_maj, X_min, in_dim, h_dim, num_layers, loss_fn, device, n_epochs, lr, h, batch_size, beta, seed, loss_params)\u001b[0m\n\u001b[1;32m    239\u001b[0m feature_mmd_loss \u001b[38;5;241m=\u001b[39m loss_fn(X_trans, X_min)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# smooth_reg_loss = torch.norm(X_trans - X_maj, p=2)  # L2 Regularization\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# Feature space Boundary Feature Regularization \u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# (X_trans:  Majority sample, X_min: Minority sample, X_maj:  Majority sample)\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m bod_reg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mboundary_feature_regularization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_maj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m cov_reg_loss \u001b[38;5;241m=\u001b[39m coverage_regularization(X_trans, X_min)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m#  loss: latent MMD loss + beta * regularization\u001b[39;00m\n",
      "File \u001b[0;32m~/WORKSPACE/IMBALANCED_CLASSIFICATION/MOMs/moms_losses.py:248\u001b[0m, in \u001b[0;36mboundary_feature_regularization\u001b[0;34m(X_trans, X_min, X_maj, beta, k, batch_size)\u001b[0m\n\u001b[1;32m    246\u001b[0m nn \u001b[38;5;241m=\u001b[39m NearestNeighbors(n_neighbors\u001b[38;5;241m=\u001b[39mk\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    247\u001b[0m nn\u001b[38;5;241m.\u001b[39mfit(X_all_np)\n\u001b[0;32m--> 248\u001b[0m _, nn_idx \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_min_np\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m nn_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(nn_idx, device\u001b[38;5;241m=\u001b[39mX_min\u001b[38;5;241m.\u001b[39mdevice)[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# Identify DANGER and refined DANGER sets\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/neighbors/_base.py:923\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    920\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not work with sparse matrices. Densify the data, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    921\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor set algorithm=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method\n\u001b[1;32m    922\u001b[0m         )\n\u001b[0;32m--> 923\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternal: _fit_method not recognized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/imb_clf/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/imb_clf/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/imb_clf/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/imb_clf/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ecoli4\n",
    "data_name = 'ecoli4'\n",
    "dataframe = pd.read_csv(f\"{data_path}{data_name}.dat\")\n",
    "results = run_experiment(dataframe, device='cpu', h_dim=256, num_layers=10, beta=0.1, lr = 0.01, save_path=save_path, data_name = 'ecoli4')\n",
    "\n",
    "for method, metrics in results.items():\n",
    "    print(f\"\\nMethod: {method}\")\n",
    "    for metric, values in metrics.items():\n",
    "        mean_value = np.mean(values)\n",
    "        std_value = np.std(values)\n",
    "        print(f\"  {metric}: {mean_value:.4f}  {std_value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imb_clf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
